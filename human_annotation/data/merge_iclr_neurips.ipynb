{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1e624ab0-011d-476b-9403-bcc039f6274b",
       "rows": [
        [
         "0",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_eS3u",
         "1698243150596",
         "1699636093263",
         "6",
         "2",
         "3",
         "2",
         "3",
         "This work proposes LSTNet, a self-supervised method to establish reliable 3D dense correspondences irrespective of the input point clouds’ rotational orientation.\n\nSpecifically, LSTNet learns to formulate SO(3)-invariant local shape transform for each point in a dynamic, input-dependent manner. Each point-wise local shape transform can map the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor, which is passed to the decoder to reconstruct the shape and pose of the input point cloud. \n\nThe proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish dense point-wise correspondences via nearest point pairs between cross-reconstructed point clouds. The self- and cross-reconstruction training strategy is simple yet effective. \n\nLSTNet demonstrates state-of-the-art performance on 3D semantic matching when evaluated on the KeypointNet dataset and part segmentation label transfer when evaluated on the ShapeNet dataset. The performance of aligned shape pairs under the setting of I/I shows that other methods, such as CPAE, are much better than LSTNet. The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.\n\nLack of limitations.",
         "191",
         "0",
         "0",
         "0.7074",
         "0.09",
         "0.9708871841000001",
         "52",
         "16",
         "28.0536",
         "14.6186",
         "17.913",
         "16.0443",
         "17.8357",
         "0.1213",
         "78",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_jP4i",
         "1698652503617",
         "1699636093190",
         "5",
         "4",
         "3",
         "3",
         "2",
         "1) This paper proposes a self-supervised method to find semantically corresponding points for a point cloud pair;\n\n2）The main idea is to decouple a point cloud feature learning process into a SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms;\n\n3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method. 1) This paper is generally well-written;\n\n2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant\npoint-wise local shape transforms seems to be novel;\n\n3) Experimental results are good. 1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset. \n\n2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation. \n\n3) The running time and GPU memory cost is blurry for me;\n\n4) Please compare the proposed method with more recent papers, e.g., \\[SC3K: Self-supervised and Coherent 3D Keypoints Estimation\nfrom Rotated, Noisy, and Decimated Point Cloud Data\\]. Please refer to the weaknesses.",
         "215",
         "0",
         "0",
         "0.7009",
         "0.1601851852",
         "0.8842770457",
         "52",
         "11",
         "32.339",
         "14.0899",
         "17.5302",
         "15.9032",
         "16.5285",
         "0.1719",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_wiS9",
         "1698706547448",
         "1699636093122",
         "3",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces LSTNet, which leverages an SO(3)-equivariant encoder-decoder architecture(Vector Neuron Networks, VNNs) and proposes a novel function called local shape transform to further transform the learned features. The proposed method is validated on both the 3D keypoint transfer and part segmentation label transformer tasks. 1. The idea of cross-reconstruction for generating inter-object correspondences in a self-supervised way is interesting;\n\n2. The overall writing is good and the methodology part is well-organized and easy to follow. 1. The novelty of this work seems insufficient for ICLR. The whole pipeline heavily relies on VNNs and the main contribution I personally consider is the local shape transform and the self-supervised mechanism for correspondences.\n\n2. Regarding the local shape transform:\n   2.1. From 3.1.1, the SO(3)-invariant output is $\\mathbf{V}\\mathbf{U}^T \\in \\mathbb{R}^{C \\times C}$, while in 3.1.2, the obtained SO(3)-invariant features $\\mathbf{V} \\in \\mathbb{R}^{C^\\prime \\times 3 \\times N}$ have a different shape;\n\n   2.2 The authors claimed that the local shape transform transforms the global features to local ones. Regarding this, I have two questions. \n\n      2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer. \n\n      2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the \"global\" features by such a mechanism, the features turn to \"local\"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so)\n\n3. Regarding the experiments:\n    3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments;\n\n     3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.\n\n    3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., \\[1\\], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.\n\n   3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?\n\n4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration \\[2, 3, 4, 5\\] should also be discussed.\n---------------------------------------------\n\\[1\\]. Zohaib et al. SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data, ICCV 2023;\n\n\\[2\\]. Dent et al. PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors, ECCV 2018\n\n\\[3\\]. Ao et al. SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration, CVPR 2021\n\n\\[4\\]. Wang et al. You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors, ACM MM 2022\n\n\\[5\\]. Yu et al. Rotation-Invariant Transformer for Point Cloud Matching, CVPR 2023 See weaknesses.",
         "570",
         "7",
         "10",
         "0.7698",
         "0.0953869048",
         "0.8982679844",
         "52",
         "10",
         "49.1847",
         "9.5403",
         "12.0174",
         "11.8969",
         "11.5244",
         "0.050300000000000004",
         "77",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_a6Ps",
         "1698768293694",
         "1699636092942",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper attempts to register point cloud properties to their templates without precise correspondences and exact shape matching. To achieve this, the authors trained a local shape transform (LST) network that produces SO(3) invariant correspondences. The training is self-supervised. The experimental results on ShapeNet look nice. - Valid motivation. Unlike the abused topic, vanilla point cloud registration, the motivation stands and could potentially benefit practical usages.\n- The SO(3)-invariant network design intrinsically ensures robustness against rotations.\n- The joint usage of a global descriptor and a local descriptor makes sense and may help with classification and recognition directly.\n- The self-supervision scheme looks plausible by self and cross-reconstruction. My major concern is with the experimental setup. While the experiments on ShapeNet is common in the community and shows good result, I am in general doubtful whether such an approach could be really applied to the real world. \nIn motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. \\[Scan2CAD, CVPR 2019\\]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases. \n\nThe authors also take groundtruth keypoints and semantic segmentations from datasets for the experiments. In the real-world, however, obtaining such accurate high-level semantic information already requires a deep understanding of the point cloud, and its segmentation backbone may already be SO(3) invariant. This impairs the strength that the authors proposed. Following my points in the \"weaknesses\" section, I am curious about several relevant problems in the practical setup (i.e., scan to model). \n1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity? \n2. Will the network still be functional if the density distributions are different across input and output? \n3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?\n4. Would non-gt and/or biased key points and semantic parts be transferred properly?\n\nIt would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.",
         "412",
         "0",
         "5",
         "0.7920",
         "0.1400193798",
         "0.9250699282",
         "52",
         "10",
         "43.5803",
         "10.8007",
         "13.4756",
         "13.141",
         "11.9551",
         "0.129",
         "85",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "4",
         "zzv4Bf50RW",
         "1647",
         "1695102158671",
         "['~Chunghyun_Park1', '~Seungwook_Kim2', '~Jaesik_Park3', '~Minsu_Cho1']",
         "Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform",
         "Establishing accurate dense 3D correspondences between diverse shapes stands as a pivotal challenge with profound implications for computer vision and robotics. However, existing self-supervised methods for this problem assume perfect input shape alignment, restricting their real-world applicability. In this work, we introduce a novel self-supervised SO(3)-invariant 3D correspondence learner, dubbed LSTNet, that learns to establish dense correspondences between shapes even under challenging intra-class variations. Specifically, LSTNet learns to dynamically formulate an SO(3)-invariant local shape transform for each point, which maps the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor. These local shape descriptors are provided as inputs to our decoder to facilitate point cloud self- and cross-reconstruction. Our proposed self-supervised training pipeline encourages semantically corresponding points from different shape instances to be mapped to similar local shape descriptors, enabling LSTNet to establish the dense point-wise correspondences. LSTNet demonstrates state-of-the-art performances on 3D semantic keypoint transfer and part segmentation label transfer given arbitrarily rotated point cloud pairs, outperforming existing methods by significant margins.",
         "Reviewer_Frem",
         "1699350072271",
         "1699636092872",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a method of learning dense 3D correspondence between shapes in a self-supervised manner. Specifically, it is built on an existing SO(3)-equivariant representation. The input point clouds are independently encoded to SO(3)-equivariant global shape descriptor Z and dynamic SO(3)-invariant point-wise local shape transforms. Then the network is trained via penalizing errors in self- and cross- reconstructions via the decoder. The experiment validates the effectiveness of the proposed method. 1. The paper is in general well organized and easy to follow. \n2. The proposed method is straightforward and shown to be effective on the test data. 1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method. \n2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.\n3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?\n4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design. Please refer to the Weaknees part.",
         "290",
         "0",
         "7",
         "0.6900",
         "0.1242424242",
         "0.9471604824000001",
         "52",
         "3",
         "43.0465",
         "10.8574",
         "13.8",
         "13.106",
         "11.3839",
         "0.1864",
         "81",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "5",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_xDut",
         "1698437142685",
         "1699636121514",
         "8",
         "5",
         "4",
         "4",
         "3",
         "This paper is about multilingual federated prompt tuning for low-resource languages, bringing together federated learning and prompt-tuning techniques. This approach leverages parameter-efficient fine-tuning which preserves user privacy, and additionally, the authors introduce language distance in order to highlight the strengths of the proposed paradigm. The results show that the technique is parameter efficient and computationally beneficial, reducing by 99% the number of trainable parameters while increasing the performance on downstream tasks (XNLI, NC) of ~7% accuracy. This paper makes a contribution to the federated learning field showing how federated learning can be used to enhance the performance of language models while preserving user privacy. The experiments are well-designed and the results are convincing - added to extensive analyses in order to leverage the capabilities of the proposed paradigm, but also its limitations. Although the paper is generally well-structured, the title mentions `low-resource` languages. However, the two tasks leveraged are primarily on high-resource languages, rather than low-resourced language. I would suggest to the authors to include more tasks - there are many low-resource language datasets (for instance on African languages MasakhaNEWS, Masakhaner (1.0 and 2.0 - which have been cited by the way but not used), MasakhaPOS; Indic languages: https://github.com/AI4Bharat/indicnlp_catalog; etc) and tasks.\n\nThis is rather a highly recommended suggestion, that does not take away the contribution of the paper. Including them would strengthen the paper and be more in accordance with the title. The Aggregation formula is a bit confusing. Did you mean h_{global, t+1} = \\sum_{k=1}^{m} h_{k, t}? Because the `t+1` on the last term does not make sense to me.",
         "262",
         "1",
         "0",
         "0.7963",
         "0.1664583333",
         "0.9397115707",
         "52",
         "13",
         "34.7123",
         "12.4236",
         "15.2872",
         "14.0992",
         "14.6228",
         "0.25730000000000003",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_E7Lk",
         "1698484432194",
         "1700794322411",
         "1",
         "5",
         "1",
         "2",
         "2",
         "The paper introduces a finetuning paradigm that combines federated learning (FL) with prompt tuning for multilingual finetuning on certain, with the goal to preserve the privacy of the local data used for the finetuning job. The results show better performance in certain classification tasks, such as New Classification and XNLI. - Federated learning have recently gained good traction, the paper is a good application of it in the tasks of finetuning LLM. The paper chooses to use prompt tuning instead of full tuning to save costs, as well as to avoid overfitting on small data.\n- The method produces better performance on the 2 classification tasks compared to baselines - The proposed is a very trivial combination of federated learning and prompt tuning, which both are established methodology in their own realm. There is no novelty, such as modification or adjustment to the method that may have give a better results. In other words, people with an objective to do federated learning for privacy purpose can easily come up with prompt tuning as a solution to reduce costs.\n- Though it may have implicitly inferred by the concept of FL, the paper did not mention why and how federated learning helps with privacy and in which case one should use FL for their application.\n- The purpose of the task of multilingual finetuning in this case, is not warranted use case of privacy preservation.\n- There is no reported evidence that privacy is actually preserved. Such as whether the final model memorize the local data.\n- There are better parameter-efficient finetuning methods, such as LORA/QLora, that the authors should conduct experiments on and do comparision with prompt tuning.\n- The results show prompt tuning are much worse than full-federated tuning, thus casting doubt if the cost-saving is worth it.\n- Other generative and knowledge-based tasks, such as QA, translations and summarizations should be performed.\n\n**I have read the author responses and I advocate for a strong reject, below are reasons:**\n\n* I mentioned the paper has fundamental problems with originality, novelty, where the paper uses an unrelated existing and non-novel method designed for a different problem (fed-learning) to solve a low-resource \"privacy\" problem that does not make sense or exist yet, in which the method itself much worse than standard training. \n* Instead of addressing the scientific issue, the authors distracted away by pressing that they are helping the low-resource communities, or improving inequality as a societal issue. These multiple responses are lengthy, wordy, unnecessary, and filled with many \"politically correct\" (I don't know better word) things to avoid the scientific issue. Agree that we should help those under-represented communities, but after reading these, I shouldn't feel like rejecting the paper is an action against those communities.\n* The problem of \"a low-resource community who wants to shut down their internet and border\" is unfounded. We train LLM on public data we can find. If they wants to protect their secret data, they can download a public pre-trained model and fine-tune on their own. \n* The real problem is how to improve low-resource with the limited data we have, which the paper fails to suggest a better solution than trivial.\n* Less communication doens't mean more privacy, because we transfer model weights, not the data. And less parameters doesn't mean less private information be leaked. This misconception leads to wrong approach.\n* The author claims to be the first to target the low-resource problem and many other things, but there have been many works in previous years about this. Please be careful with this kind of \"we are first\" statements.\n* Overall, none of the responses has helped resolve the issues stated in the review. - Citation formet incorrect, \\citep{} be used to produce something like (Abc, et al., 2023) and not Abc, et al., 2023 everywhere.\n- Many grammatical errors, such as \"Throughout the fine-tuning...\"\"",
         "646",
         "0",
         "0",
         "0.8297",
         "0.1105421563",
         "0.9287629724",
         "65",
         "26",
         "45.2282",
         "11.9836",
         "14.6",
         "13.5927",
         "13.0802",
         "0.0978",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "7",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_AG4r",
         "1698731849876",
         "1700723834276",
         "3",
         "4",
         "4",
         "1",
         "3",
         "The paper proposes a Multilingual Federated Prompt Tuning paradigm, where lightweight multilingual prompts are encoded and on regional devices in different languages and aggregated by averaging the prompt embeddings. The goal is fine-tuning multilingual large language models on resource-constraint devices in a privacy-preserving way. The paper evaluates this approach via the XNLI task, ablated into data efficiency, \"language distance\", and communication cost, against \"monolingual\" training (baseline). The innovation lies in that the paper somehow mashes federated learning, multi-lingual (low resource) language models, and Parameter-Efficient Fine-Tuning in one paper. The fact that they managed to come up with a storyline for a system that bolsters the benefit of each approach is commendable. - poor presentation: the citations are not separable enough from the main text, e.g., without any parenthesis, rendering the submission unreadable. Against the tradition and ease of reading, abbreviations are not defined in advance, e.g., NLI, PFL, PLM.\n- claims unverifiable: no code release.\n- conflating existing metrics with innovation: language distance is not a new concept.\n- conceptual weakness: the contrived baseline was bound to give the proposed approach an edge due to lack of federated learning. Also, what the paper refers to as prompts are just classifier model input, which are different from decoders-style LLM prompts as commonly acknowledged. Finally, the approach has absolutely nothing to do with privacy which the abstract and the main body consistently bolsters. \n- evaluation weakness: only two tasks (new classification and XNLI) was used in evaluation. In section 5.4.1 \n\n>  In both the NC and XNLI tasks, despite the total number of\nparameters exceeding 278 million, the trainable parameters are only around 1.2 million, accounting\nfor less than 0.5% of the total.\n\nCould the authors clarify which part of the model is being fine-tuned?",
         "293",
         "0",
         "0",
         "0.8387",
         "-0.0202793239",
         "0.8988320827",
         "64",
         "23",
         "35.1555",
         "11.9208",
         "14.2417",
         "13.3484",
         "12.5904",
         "0.0999",
         "77",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "8",
         "zzqn5G9fjn",
         "1909",
         "1695134452464",
         "['~Wanru_Zhao1', '~Yihong_Chen3', '~Royson_Lee1', '~Xinchi_Qiu1', '~Yan_Gao4', '~Hongxiang_Fan1', '~Nicholas_Donald_Lane1']",
         "Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages",
         "Pretrained large language models (LLMs) have emerged as a cornerstone in modern natural language processing, with their utility expanding to various applications and languages. However, the fine-tuning of multilingual LLMs, particularly for low-resource languages, is fraught with challenges steming from data-sharing restrictions (the physical border) and from the inherent linguistic differences (the linguistic border). These barriers hinder users of various languages, especially those in low-resource regions, from fully benefiting from the advantages of LLMs.\n\nTo overcome these challenges, we propose the Federated Prompt Tuning Paradigm for Multilingual Scenarios, which leverages parameter-efficient fine-tuning in a manner that preserves user privacy. We have designed a comprehensive set of experiments and introduced the concept of \"language distance\" to highlight the several strengths of this paradigm. Even under computational constraints, our method not only bolsters data efficiency but also facilitates mutual enhancements across languages, particularly benefiting low-resource ones. Compared to traditional local crosslingual transfer tuning methods, our approach achieves a 6.9\\% higher accuracy, reduces the training parameters by over 99\\%, and demonstrates stronger cross-lingual generalization. Such findings underscore the potential of our approach to promote social equality, ensure user privacy, and champion linguistic diversity.",
         "Reviewer_LsRx",
         "1698767055794",
         "1700887244625",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The paper applies federated learning on multilingual scenarios to efficiently parameter-efficient prompt fine-tuning in a manner that preserves user privacy. The idea is to utilize a single global encoder that accumulates the information via federated prompt averaging. Thus, it learns the language patterns without knowing about the user information. They evaluated the experiment on NC and XNLI datasets and found performance improvement over the baseline. - The method is very practical since it is simple and efficient, and it is an appropriate method for training multilingual model.\n- Good analysis on the data efficiency and distance measurement, showing the effectiveness of the proposed method. - In terms of novelty, the proposed idea is not new, and it is only a further investigation of the multilingual setting.\n- Lack of clarity. The paper does not provide enough information about how the prompts are constructed or look like and hyperparameters for all settings. I suggest adding the information to the paper or appendix. Questions:\n- Do you have any findings on why multilingual centralized learning is far worse than federated learning in Table 2?\n- How did you tune the training and parameter averaging?\n\nSuggestions:\n- Figure number is missing on Page 2\n\n\"As depicted in Figure , \"\n\n- Missing Figure/Table \n\n\"This translates to over 99% reduction in the communication overhead shown in 3\"\n\n- Typo\n\n\"Finetuning accuracy across different lanugages on the NC task.\"",
         "234",
         "0",
         "0",
         "0.7573",
         "0.0373593074",
         "0.9010972977",
         "66",
         "24",
         "31.2256",
         "13.1655",
         "15.1127",
         "14.332699999999999",
         "12.1462",
         "0.25730000000000003",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "9",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_agCZ",
         "1698322956814",
         "1699636820093",
         "5",
         "3",
         "2",
         "2",
         "2",
         "To tackle Multi-Domain Text Classification (MDTC) task, one mainstream of proposed techniques is to extract the features via the shared and private extractors to capture the domain-invariant and domain-specific knowledge, respectively. However, as the number of domains increases, the count of their private extractors will also rapidly surge.  \nThe author proposed a novel approach Stochastic Adversarial Network (SAN) to avoid the unaffordable explosion of parameters when encountering the newly emerged domains. Specifically, the author modeled the domain-specific feature extractors as a multivariate Gaussian distribution. Furthermore, some tricks, such as domain label smoothing and robust pseudo-label regularization techniques, are utilized to improve the overall performance.\nExtensive experiments on two benchmarks demonstrate the superiority of the proposed method compared with the state-of-the-art baselines. 1.\tThis paper proposes a novel approach, called Stochastic Adversarial Network, to reduce the computational cost while meeting a large amount of domains.\n2.\tThis paper originally employs Gaussian distribution to generate private extractors in order to circumvent the extensive parameters found in previous works. \n3.\tThis paper conducts numerous experiments to show the effectiveness of the proposed scheme. Moreover, the parameter sensitivity and ablation study demonstrate the rationale of parameter selection and the necessity of each modules, respectively. 1.\tThe motivation is trivial. It is hard to say that the model size is the bottleneck of the training process according to Table.1 and 9. 342.91M is absolutely fine in current period. Further, inference process may gain nothing in the aspect of computational acceleration as we only choose one private extractor from the Domain Discriminator D. \n2.\tThe baselines are outdated and improvements on two benchmarks are limited. According to Table 2,3 and 4, it can hardly convince me that the proposed model exactly outperforms the SOTA models. It is worth noting that the author points out this limitation in Appendix E. \n3.\tThe writing and organization need to be improved. \na)\tThe emphasis in writing has been misplaced. As the author highlights the role of multivariate Gaussian distribution in Abstract, you are supposed to tell more story of it instead of the regularization term, which is the idea of others.\nb)\tThe effectiveness is not the focus of this article, efficiency is. Therefore, moving D. 5 to the main body of the article perhaps make your contribution more prominent. \nc)\tSome tools can be utilized effectively to optimize sentence structure and composition. 1.\tThe aim of equation (3) is to ensure that the shared Feature Extractor F_s exactly extract the domain-invariant features. Thus the author maximum this loss to let the discriminator D be confused about the features coming from F_s. Here is the question: discriminator D may lack of capabilities to recognize the difference among domains as this loss function does not involve any domain knowledge.\nThere may exists another adversarial network in equation (3), i.e. domain-specific extractor enhances the capabilities of discriminator D and domain-invariant extractor still confuse the discriminator D. \n2.\tAs a classic NLP task, this method inevitably needs to be compared with chatgpt. Currently, chatgpt has shown remarkable zero-shot capabilities. Therefore, you need to convince the reviewers why your method should be used instead of chatgpt or highlight the scenarios in which your method has significant advantages.",
         "534",
         "0",
         "5",
         "0.7784",
         "0.09682159950000001",
         "0.9668992162000001",
         "48",
         "15",
         "31.5082",
         "12.8846",
         "15.6113",
         "14.3361",
         "13.4832",
         "0.20270000000000002",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "10",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_NpVu",
         "1698685251472",
         "1699636819980",
         "1",
         "4",
         "1",
         "3",
         "1",
         "The paper presents a new model for MDTC, built on the previous shared-private feature extraction architecture. The innovation includes 1) modelling the parameter of domain-specific feature extractors as a Gaussian random variable, and for each domain, the parameter is drawn from the distribution. This is why the model is called stochastic adversarial network, or SAN, 2)  domain label smoothing 3) pseudo labelling regularization.  The authors show some empirical successes on some datasets. The paper demonstrates that the authors are well aware of the challenges in MDTC and are familiar with various tools in deep learning (such as reparametrization trick, label smoothing, pseudo labelling etc). I have some concerns about this work.\n\n1. Assuming the design of proposed model is sensible (in fact I have doubts on this; see 2), the work heuristically puts together a bunch of well-known techniques to improve performance. Works of primarily such a nature, although potentially valuable in practice, do not possess enough novelty that justifies a publication in ICLR. \n\n2. I have doubts on the proposed approach in the \"stochastic\" part. Let us track the parameter $W_1$ of the domain-specific feature extractor for domain 1. In the beginning it is drawn from the prescribed Gaussian, say, its value is $W_1^{(0)}$, and after the first iteration, the Gaussian parameter gets updated (using the reparametrization trick)  -- well, whether Gaussian parameter is updated or not is not critical here. Then in the next iteration, $W_1$  is drawn again, let us call it $W_1^{(1)}$. If this understanding is correct, then $W_1^{(0)}$ and $W_1^{(1)}$ can be very different. That is, along the training process, $W_1$ will randomly hop everywhere as long as the Gaussian variance is not vanishing. How would such a scheme work at all? Bringing the parameter $W_2$ of the second domain-specific extractor into the picture would show an even more absurd picture: at each iteration $t$, $W_1^{(t)}$ and  $W_2^{(t)}$ are random variables following the same Gaussian distribution. How would $W_1$ and $W_2$ track their respective domain specific features?  If this structure were to work, it would have to be the case where the Gaussian variance is very small (which might be the case as shown in Figure 3 of the appendix). In that case, all domain-specific extractors are more or less the same, i.e, all equal to the Gaussian mean, only subject to some tiny *domain-nonspecific* random perturbation. That would defeat the entire purpose of having domain specific feature extractors. -- I could misunderstood the paper and I am willing to hear the authors' defence on this. In your defence, please also show the initial and final values of the Gaussian mean vector $\\mu$ (say, in terms of its L1-norm divided by its dimension), I would like compare it with $\\sigma$. See weakness 2.\n\nAdditional question: The authors say that the conventional shared-private adversarial scheme will have \"exponential increase\" in model parameters as new domains emerge? Why is it exponential?",
         "484",
         "0",
         "3",
         "0.7855",
         "-0.0365584416",
         "0.847129941",
         "48",
         "11",
         "47.077",
         "11.2985",
         "14.3863",
         "13.7578",
         "12.8684",
         "0.1563",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "11",
         "zz61V8bIab",
         "7001",
         "1695450633393",
         "['~Xu_Wang22', '~Yuan_Wu2']",
         "Stochastic Adversarial Networks for Multi-Domain Text Classification",
         "Adversarial training has played a pivotal role in the significant advancements of multi-domain text classification (MDTC). Recent MDTC methods often adopt the shared-private paradigm, wherein a shared feature extractor captures domain-invariant knowledge, while private feature extractors per domain extract domain-dependent knowledge. These approaches have demonstrated state-of-the-art performance. However, a major challenge remains: the exponential increase in model parameters as new domains emerge. To address this challenge, we propose the Stochastic Adversarial Network (SAN), which models multiple domain-specific feature extractors as a multivariate Gaussian distribution rather than weight vectors. With SAN, we can sample as many domain-specific feature extractors as necessary without drastically increasing the number of model parameters. Consequently, the model size of SAN remains comparable to having a single domain-specific feature extractor when data from multiple domains. Additionally, we incorporate domain label smoothing and robust pseudo-label regularization techniques to enhance the stability of the adversarial training and improve feature discriminability, respectively. The evaluations conducted on two prominent MDTC benchmarks validate the competitiveness of our proposed SAN method against state-of-the-art approaches.",
         "Reviewer_bAwA",
         "1698806204960",
         "1699636819830",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper tackles the multi-domain text classification (MDTC) problem, and tries to minimize the amount the learning parameters by introducing a stochastic feature extractor (domain feature). The model is effective in handling the benchmark datasets and outperform the other baseline models. Additional multi-source UDA experiment is also conducted as a simple model extension. The proposed model performs strong in the benchmark dataset, with minimized learning parameters. The design of using both shared/private feature extractor is interesting and effective in merging the domain in the latent space. The proposed method is straightforward and easy to understand. 1. Though the proposal seems to be effective and achieving strong performance, the model itself still uses a relative old adversarial backbone, with the discriminator approach for removing the domain invariant feature. The two-feature-extractor approach is interesting, but that is mainly to deal with parameter increase in the MDTC problem. It would be great to see other design improvement in the model.\n2. The performance gain in using the proposed model is marginal on the Amazon review/FDU-MTL datasets. Also, it would be great to have some analysis on adjusting the setting between the two feature extractors. 1. This might be somewhat irrelevant, but would the model perform well in multi domain classification in other domain type(s), e.g., images?",
         "213",
         "0",
         "3",
         "0.7456",
         "0.26833333330000003",
         "0.9479958415",
         "48",
         "9",
         "35.1089",
         "12.7719",
         "15.5507",
         "14.5546",
         "14.2456",
         "0.1041",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "12",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_skmj",
         "1698632081062",
         "1701140370231",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper studies multi-modal generalization in neural networks such as transformer-based models and recurrent networks. To do so, the authors propose Genertic COG, a modular benchmark with multi-modal splits to test for 3 types of generalization: 1) distractor (generalization to different noise distribution), 2) systemic compositional (generalization to new permutation of task structures) and 3) productive compositional (generalization to tasks of greater complexity) generalization. Experiments conducted by the authors showed that while cross-attention based transformers (e.g. CrossAttn and Perceiver) outperform other models and perform well on distractor and systemic compositional generalization, they fail at productive generalization when the depth of the task tree goes to out-of-distribution (>3). Representational analysis is done to show that cross-attention based transformers (e.g. CrossAttn and Perceiver) superior performance on distractor generalization might be due to their ability to better retain task-relevant (e.g. stimulus and response) information at the penultimate layer. +The paper studies a timely and critical question about the generalization capability of multimodal transformer-based models\n\n+The proposed benchmark dataset uncovers a limitation of current multimodal transformer-based models: productive generalization which can facilitate the development of more generalizable transformers/LLMs. \n\n+The paper is generally well-written and easy to follow -While the paper’s studies show that certain designs (e.g. cross-attention) seem to confer multi-modal generalization, there are still some key questions that can be more thoroughly studied to uncover the reasons why this is the case.\n\n-Similarly, important discussions such as why the (cross-attention) transformers might fail at productive generalization is lacking. What is the key architectural difference between dual stream transformer and transformers with cross attn that can explain their generalization performance? Is it only the lack of a cross attention between the different modalities?\n\nPossible typo:\n“Finally, we included a Perceiver-like model (Jaegle et al., 2021), an architecture designed to generically process multimodal inputs (Fig. 2f).”:  (Fig. 2f) > (Fig. 2e).\n\n\n==Post-Rebuttal==\nI appreciate the authors' response and decided to keep my score.",
         "318",
         "1",
         "3",
         "0.8097",
         "0.0690708101",
         "0.8793090582",
         "69",
         "29",
         "14.3228",
         "16.1836",
         "19.2815",
         "17.1951",
         "18.7062",
         "0.6926",
         "76",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "13",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_a4Su",
         "1699400405601",
         "1699636123172",
         "3",
         "3",
         "1",
         "2",
         "2",
         "This paper proposes a new benchmark for assessing various forms of generalization in a multimodal setting named gCOG. The dataset includes several different splits intended to measure different aspects of generalization. The paper also compares several different model architectures on the dataset. * The paper introduces a new dataset, gCOG. While the dataset is conceptually similar to those from prior work, such as gSCAN, it supports different types of contexts and instruction types, including more compositional instructions. I'm aware of some prior work (e.g. \\[1\\], \\[2\\]) that studied compositional generalization in natural language tasks and found that gains on one synthetic task did not always transfer to other tasks, so increasing the diversity of such benchmarks for assessing compositional generalization and related challenges in the multimodal setting could be a potentially valuable contribution.\n\n\\[1\\] https://arxiv.org/abs/2007.08970\n\\[2\\] https://aclanthology.org/2021.acl-long.75/ * I'm concerned about the strength of the baselines used in the paper (see my related questions below). While the primary contribution of the paper is the dataset, it is also important to establish strong baselines for this new dataset and to ensure that the conclusions from the empirical results are valid. The appendix states that only a *single Transformer layer* with a *single attention head* was used. This is almost certainly not an optimal depth and number of attention heads. Relatedly, it looks like some models are potentially underfit, according to the figures. With >5M training examples and a relatively simple input space, I would have expected a reasonably sized Transformer model to achieve low training loss and reasonable IID generalization. If these models could have been applied to similar tasks such as gSCAN (even using symbolic tokens to represent the scene context), where they could be compared with comparable baselines from prior work, this would have helped establish that these are indeed reasonably strong baselines that have been well tuned.\n* The qualitative difference between gCOG and datasets from prior work such as gSCAN was not very clearly described. For example, one of the key claims seemed to be gCOG \"employs generic feature sets that are not tied to any specific modality\". However, it seems like it is a useful property for a multimodal dataset to have a clear relation to real-world multimodal tasks. Indeed, the authors provide interpretations of their tasks in the form of natural language instructions and visual scenes (e.g. in Figure 1), and these are very useful for understanding the task. Representing this dataset using familiar modalities (e.g. vision, natural language) could enable future work to study different research questions, e.g. the impact of pre-training. The ability to alternatively represent the task input as a sequence of tokens is also reasonable for studying certain research questions, but this also seems possible for datasets from prior work. For example, I understand that gSCAN includes both symbolic descriptions as well as visual renderings. Anyways, I think clarifying the motivation for this dataset (e.g. increasing diversity of available benchmarks, focusing on different generalization challenges, etc.) separately from how inputs are represented for the experiments in this paper (e.g. token sequence vs. images and natural language) would be useful.\n* Some of the main empirical conclusions (e.g. that generalization to greater \"depth\" is challenging for models such as Transformers) are generally known from prior work.\n\nnits:\n* Introduction paragraph 1 - \"on a carefully controlled generic multimodal reasoning tasks\" -> \"on carefully...\" or \"...task\"\n* Appendix A.2.1 - Maybe reference Tables 8 and 9 where you discuss different positional embeddings.\n* Consider discussing \\[3\\] in related work. \\[3\\] demonstrated the importance of cross-modal attention for gSCAN, and similarly studied the relative difficulty of various aspects of generalization, including distractors.\n\n\\[3\\] https://aclanthology.org/2021.emnlp-main.166/ * Why not try more layers and attention heads, e.g. following a standard hyperparameter setting for model size such as those of BERT-Base? Or even BERT-Small?\n* In Figure 2 (F) why does the single-stream Transformer have almost double the parameters of the double stream Transformer? For the other Transformers, do the encoder blocks used for the task vector and stimulus vector share parameters? \n* What optimizer and hyperparameters (e.g. learning rate) were used for training? How were these chosen? I didn't see these details in Appendix A.2. \n* Position embeddings - Since you are representing 10x10 grids as 1D sequences, 1D relative positions may not capture this structure well. On the other hand, absolute position embeddings seem potentially problematic in the case of the SSTrfmr model, since they will not be consistently assigned to the same grid position if the text sequence is first and has varying length. Mitigating this may be important to provide for a fairer comparison with the SSTrfmr model.\n* To what do you attribute the periodic loss spikes during training that are shown in Figure 4 (E)?\n* I found the usage of \"cross-attention\" a bit confusing. For example, the single stream Transformer features cross-modal attention as an implicit consequence of self-attention over the concatenated sequence. I thought this would commonly be referred to as an instance of \"cross-attention\" between modalities. \n* Does the dataset also contain visual renderings and natural language instructions to enable future work to study these tasks using familiar modalities?",
         "860",
         "10",
         "1",
         "0.8184",
         "0.076096273",
         "0.8955636024",
         "52",
         "2",
         "37.0807",
         "11.9609",
         "15.3107",
         "14.4483",
         "12.808",
         "0.1278",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "14",
         "zyBJodMrn5",
         "1924",
         "1695135324143",
         "['~Takuya_Ito1', '~Soham_Dan1', '~Mattia_Rigotti1', '~James_Kozloski1', '~Murray_Campbell1']",
         "On the generalization capacity of neural networks during generic multimodal reasoning",
         "The advent of the Transformer has led to the development of large language models (LLM), which appear to demonstrate human-like capabilities. To assess the generality of this class of models and a variety of other base neural network architectures to multimodal domains, we evaluated and compared their capacity for multimodal generalization. We introduce a multimodal question-answer benchmark to evaluate three specific types of out-of-distribution (OOD) generalization performance: distractor generalization (generalization in the presence of distractors), systematic compositional generalization (generalization to new task permutations), and productive compositional generalization (generalization to more complex tasks with deeper dependencies). While we found that most architectures faired poorly on most forms of generalization (e.g., RNNs and standard Transformers), models that leveraged cross-attention mechanisms between input domains, such as the Perceiver, fared better. Our positive results demonstrate that for multimodal distractor and systematic generalization, cross-attention is an important mechanism to integrate multiple sources of information. On the other hand, all architectures failed in productive generalization, suggesting fundamental limitations of existing architectures for specific types of multimodal OOD generalization. These results demonstrate the strengths and limitations of specific architectural components underlying modern neural models for multimodal reasoning. Finally, we provide *Generic COG* (gCOG), a configurable benchmark with several multimodal generalization splits, for future studies to explore.",
         "Reviewer_DJb6",
         "1699470958350",
         "1699636122858",
         "8",
         "4",
         "3",
         "3",
         "3",
         "The paper introduces a new multimodal question answering benchmark for out-of-distribution generalization, specifically covering task compositionality, robustness to distractors and combinatorial generalization. It uses this benchmark to evaluate various models and analyze their performance. - **Topic**: The paper studies an important topic which in my opinion is underexplored in current deep learning research. Especially given the tendency these days to scale training up to vast amounts of data, I believe it is particularly important to design carefully controlled benchmarks that can: evaluate the model’s performance from a critical and cautious standpoint, point to their fundamental limitations (e.g. systematic generalization), and support further research about ways to overcome these.  \n- **Evaluation**: The paper offers both extensive extrinsic evaluation, with performance comparison of various models on the different generalization skills, as well as intrinsic analysis of their internal representations’ degree of alignment to the stimuli.\n- **Clarity**: The writing quality is good and the paper is clear and easy to follow. The paper is well-organized, claims and findings are clearly stated, and useful figures and diagrams are provided.\n- **Related Works**: It does a good job in providing the relevant context, motivation and related works. \n- **Contribution**: The empirical findings of the paper on the benefits and limitations of different inductive biases such as recurrent and attention-based are important and may be of broad interest to the community. - **Pre-trained models** The paper focuses on models trained from scratch rather than pre-trained. This could be a strength and a weakness. On the one hand, it allows for isolating the contribution of the architectural choices from other factors of optimization, and training data. On the other hand, it has been observed that by training models at large enough scales enables the emergence of generalization capabilities, which we don’t see in smaller scales. I think it will be critical to also analyze the performance of pretrained models on the benchmark, in order to strengthen the paper.\n- **Visual Simplicity**: The visual side of the benchmark is quite rudimentary, featuring colorful letters. Extending it to a larger range of visual tokens/objects, that could have more than one property (color), and a broader set of elements and variations (than 26 letters), could be a straightforward extension that could help make it a bit more challenging visually. - **COG task**: It will be useful to discuss the COG task (rather than just mentioning it) before describing the new gCOG one, so that it will be clearer to the reader what are new contributions of the new benchmark compared to COG and the degree of their importance. In the overview diagram I would also recommend showing a sample also from COG to make the differences clearer. \n- **Grid size / generalization**: It could be interesting to vary the size of the grid in training/evaluation and study its impact on model’s performance. \n- **Terminology**: I recommend changing the phrase “Distractor generalization” to one that better conveys it’s about changing the answer distribution. Maybe e.g. answer distribution shift. I also recommend changing the name “Systematic compositional generalization” to “combinatorial generalization”, to emphasize that the main point is the generalization to permutation, and also to better contrast it with the following “Productive generalization” (which could also be systematic).\n- **Figures**: Would be good to increase the size of the plots in Figure 3b. It will also be good the increase the distance and visual separation between the sub-figures in each figure throughout the paper. \n- In the introduction: “multimodal question-answer” -> “answering”.\n- “This design allowed us” -> “This design allow us”.",
         "591",
         "0",
         "2",
         "0.7407",
         "0.1749524183",
         "0.9485415220000001",
         "52",
         "1",
         "28.5253",
         "14.5712",
         "17.3533",
         "15.8558",
         "15.5336",
         "0.25520000000000004",
         "90",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "15",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2",
         "0.8079",
         "0.1061594203",
         "0.8954392672",
         "49",
         "12",
         "30.6084",
         "13.0004",
         "15.6607",
         "14.5546",
         "14.526299999999999",
         "0.0364",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "16",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head \\[1\\], \\[2\\], \\[3\\]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works \\[1\\]\\[2\\] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n\\[1\\], Frozen clip models are efficient video learners, ECCV-2022\n\n\\[2\\], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n\\[3\\]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0",
         "0.7694",
         "0.0820393375",
         "0.8567712307",
         "49",
         "11",
         "39.7853",
         "10.703",
         "12.5661",
         "12.2047",
         "12.4388",
         "0.07200000000000001",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "17",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7",
         "0.8374",
         "0.0525974026",
         "0.9221839309000001",
         "49",
         "8",
         "20.0915",
         "14.8293",
         "18.2521",
         "15.9032",
         "16.8967",
         "0.19390000000000002",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "18",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0",
         "0.7506",
         "0.3529761905",
         "0.8587207794",
         "49",
         "2",
         "56.3637",
         "9.621",
         "12.2299",
         "12.231",
         "10.3101",
         "0.4364",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "19",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_5Cgw",
         "1697885084973",
         "1699636148336",
         "3",
         "5",
         "3",
         "2",
         "2",
         "The study puts forward a VAE-based approach to acquire disentangled representations without the need for supervision. In this framework, it assumes that diverse data samples exhibit variations across multiple factors, making it particularly well-suited for real-world datasets. The newly proposed technique, referred to as CFASL, introduces a range of unsupervised loss components that serve to instill \"inductive biases.\" These include parallel and perpendicular loss terms, in addition to a sparsity loss designed to encourage alignment along factor axes. The outcomes of this study illustrate the method's superior performance when compared to various other unsupervised disentanglement VAEs, both under single-factor and multi-factor alteration scenarios, across multiple widely used benchmark datasets. 1. The paper represents a significant stride in enhancing the practicality of disentanglement techniques within the realm of real image domains. It grapples with a formidable challenge where we cannot presume access to images that solely vary in a singular factor, thereby intensifying the complexity of extracting disentangled representations.\n\n2. The quantitative findings not only exhibit enhancements in the primary focus of this study, which is the alteration of multiple factors, but also in the scenario involving changes in a single factor. 1. The proposed approach incorporates a diverse array of loss terms within its training objectives, with each term potentially making a distinct contribution. However, this diversity comes at the expense of imposing significant assumptions on the underlying image distribution. While I acknowledge that these assumptions may be justified within the context of the datasets considered in this paper, it's worth noting that some metrics, such as DCI, do not unequivocally demonstrate superiority in the ablation study presented in Table 2.\n\nNevertheless, I believe that the paper could benefit from a more comprehensive exploration of the limitations stemming from these strong assumptions. It would be valuable for the authors to provide concrete examples where these assumptions result in unintended or adverse outcomes. Even for an unsupervised setting, it remains crucial to take into account the nature of transformations within the image domain. A more explicit discussion of these assumption-related limitations would substantially bolster the significance of the claims advanced in this paper, in my view.\n\n2. The qualitative results exhibit low image quality. While this is common across unsupervised disentanglement methods, it is really challenging to get convinced that better disentanglement is achieved. It would be valuable for the author to consider domain-specific metrics for the evaluation phase e.g. face identity loss, facial expression classification, head pose regression, etc. to assess whether only a specific attribute is altered during the single factor change experiments. 1. Following the weaknesses mentioned above, could the authors provide concrete examples (other datasets) where the assumptions induced by the loss terms result in unintended or adverse outcomes compared to the baseline beta-VAE?\n\n2. Could the authors please provide the ablation study results of the different loss terms for all datasets considered in the paper (and not only 3D-Cars)?",
         "483",
         "0",
         "7",
         "0.8442",
         "0.138866012",
         "0.8097960949",
         "51",
         "20",
         "20.0803",
         "15.9126",
         "18.6369",
         "16.6917",
         "17.3977",
         "0.15430000000000002",
         "88",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "20",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_oACj",
         "1698758328711",
         "1699636148260",
         "5",
         "3",
         "3",
         "1",
         "2",
         "The authors introduce a new VAE architecture which operates on pairs of inputs and utilizes a set of regularization terms to induce structured disentanglement of the latent space with respect to observed symmetry transformations between examples in these pairs. The authors show that their model indeed achieves higher disentanglement scores than relevant baselines on a variety of datasets with a variety of different metrics. Specifically, the authors target the 'multi-factor change' regime, and demonstrate improved performance in this setting with their newly introduced metric. - The related work is well covered, and the authors position their method well in the literature.\n- The proposed combination of losses appears novel to the best of my knowledge, and the use of parallelism and orthogonality losses specifically on latent transformations is an interesting and exciting idea. \n- The study of disentanglement with respect to multiple simultaneously changing factors is important and interesting, and the authors make a notable contribution to this direction.\n- The results appear promising, and indicate that the model is performing well with respect to the baselines. \n- The methodology and extended results in the appendix appear sound. The calculation of P-values in the appendix is very important and appreciated. Furthermore, the use of an ablation study to validate their proposed model is a welcome addition. Weaknesses summarized:\n- The paper is challenging to read as the english is quite poor and the logical flow of the work is unorganized.\n- The method itself is composed of a wide variety of loss terms and the intuition or reasoning for why these terms are necessary is not provided. (Specifically for the parallel and perpendicular losses).\n\nIn more detail:\n\nWeakness 1:\nThere are many typos and poor grammar throughout the paper, with many sentences simply not making much sense. I include a few examples below, but there are many many more and the authors should have someone proof read this work more carefully:\n- In the abstract: \"We propose ... (CFASL) on VAEs for the extension to \\[a\\] general multi-factor change condition without constraint.\" \n- \"To implement  group equivariant VAE, Winter et al. (2022); Nasiri & Bepler (2022) achieve the translation and  rotation equivariant VAE\"\n- \"For the equivariant encoder and decoder, we differently propose the single forward process by the  encoder and decoder objective functions compared to previous work (Yang et al., 2022).\"\n- \"Differently, we induce disentanglement learning  with group equivariant VAE for inductive bias.\"\n- 'The unsupervised learning work (Winter et al., 2022) achieves class invariant and group equivariant  function in less constraint condition.'\n\nWeakness 2: \nNaming is extremely unclear. For example, what are 'sections' referred to in Section 3.2? How do these differ from factors? \n\nWeakness 3: \nDespite appealing to a precise probabilistic generative model as its primary value and distinction from prior work, the model itself could be made significantly more elegant in the context of generative models. For example, the 'factor prediction' mechanism could be integrated as a component of the generative model and inferred with another approximate posterior, as done in prior work (Song et al 2023).\n\nWeakness 4:\nThe discussion of learning the Lie algebra is quite rushed and the intuition for why the large set of different loss terms should be incorporated is largely missing.\n\n\\[1\\] (Song et al. 2023) https://arxiv.org/pdf/2309.13167.pdf Question 1:\nThe point that prior work with autoencoders does not extend to VAE's does not make much sense to me. Specifically the quote: \"Furthermore, the methods on autoencoder are not directly applicable to VAEs, because  of the large difference to VAE in probabilistic interpretation\". Can the authors provide further details to reinforce this claim?\n\nQuestion 2:\nGiven there are so many loss terms for this model, it is likely that it will be computationally expensive to estimate the correct weightings for each of these terms in a hyperparamter search. Can the authors speak to how this was done in their case and how expensive it was? \n\nQuestion 3:\nOne of the main selling points for this paper was the ability to extend disentanglement methods to 'multi-factor' change. However, for the experiments, the authors consider datasets which guarantee commutativity of transformations. Theoretically then, is there a reason why we should expect the other baseline models to not be able to handle this multi factor change? For example, it seems the axis aligned disentangled representations of the beta-vae should be able to compose multiple transformations simply by jointly changing multiple latent dimensions. Is this not the case?",
         "744",
         "6",
         "1",
         "0.7790",
         "0.16209867760000002",
         "0.887704134",
         "51",
         "10",
         "39.4602",
         "12.5279",
         "15.1911",
         "14.4792",
         "13.6498",
         "0.09770000000000001",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "21",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_A4b1",
         "1698803382759",
         "1699636148172",
         "5",
         "3",
         "2",
         "2",
         "2",
         "Following the Variational Auto Encoder (VAE) framework, this paper proposes an extension of the single factor (change condition) disentanglement learning method, which they call as Composite Factor-Aligned Symmetry Learning (CFASL). The main idea and/or the assumption is certain scenarios such as the composite/complex symmetries (where certain mathematical transformational relationships exist) can be better captured by utilizing explicit symmetrical relationship information, if provided as additional input to the VAE learning framework. \n\nAs a part of the learning scheme, to facilitate this required piece of information, the proposed method explicitly inputs pairwise symmetrical relationship (and corresponding transformation) information. The expectation is the model, if learned in this fashion, should generate better representative samples from within those transformational subspace/domains. \n\nTo better explain and evaluate the scenario, some new metrics such as m-FVMk (extension of a common metric for a single factor change condition evaluation) have been proposed. They have compared their method with some state-of-the-art methods and on nine benchmark datasets; reported results are found to be promising. The following items seem to have some originality: (i) learning from explicit pairwise transformations, (ii) a network architecture to learn the codebook of symmetries for (i),  (iii) some associated metrics supporting (i) and (ii), and (iv) imposing group equivariant encoder-decoder into the learning framework. \n\nOverall, the paper is well written.  Mathematical derivations of different components seem to be sufficient. The proposed method has been tested on a number of benchmarks (both quantitative and qualitative analysis), and reported results are found to be promising. In addition, the ablation study of different loss functions may have added some extra points. \n\nIn terms of quality, I would rate the work as \"moderate\". In this work, one of the important missing part is the proper probabilistic derivation of the methodology, the core of the VAE framework. Or it may be due to the way the paper/work has been presented. To me, it's not sufficient to connect to the VAE world. It is suggested the authors clarify this important aspect with necessary derivations.  \n\nFor certain items/results, the authors claim statistical significance performance (section 5.2, and appendix D); however, without sufficient details of their significance tests. It is suggested authors include details of these statistical tests. \n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, we may require additional details for a fair companion of their results. \n\nThe paper/research may have some significance, and it would be beneficial if the source code could be released. It is suggested the authors clarify the probabilistic derivation of the approach and make a proper connection to the VAE basics. \n\nIt is suggested authors include details of these statistical tests.\n\nAs the authors have implemented the benchmark approaches (section 5) by themselves, I suggest authors provide further details and release code if possible.",
         "461",
         "0",
         "0",
         "0.7849",
         "0.0855008418",
         "0.9382466078",
         "51",
         "9",
         "30.801",
         "13.7351",
         "16.5337",
         "15.4148",
         "15.7803",
         "0.08660000000000001",
         "84",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "22",
         "zxOFe1mx26",
         "2152",
         "1695174125203",
         "['~Hee-Jun_Jung1', '~Jaehyoung_Jeong1', '~Kangil_Kim1']",
         "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder",
         "Implemented symmetries of input and latent vectors is important for disentanglement learning in VAEs, but most works focus on disentangling each factor without consideration of multi-factor change close to real world transformation between two samples, and even a few studies to handle it in autoencoder literature are constrained to pre-defined factors. We propose a novel disentanglement framework\nfor Composite Factor-Aligned Symmetry Learning (CFASL) on VAEs for the extension to general multi-factor change condition without constraint. CFASL disentangles representations by 1) aligning their changes, explicit symmetries, and unknown factors via proposed inductive bias, 2) building a composite symmetry for multi-factor change between two samples, and 3) inducing group equivariant\nencoder and decoder in the condition. To set up the multi-factor change condition, we propose sample pairing for inputs, and an extended evaluation metric. In quantitative and in-depth qualitative analysis, CFASL shows significant improvement of disentanglement in multi-factor change condition compared to state-of-the-art methods and also gradually improves in single factor change condition on common benchmarks.",
         "Reviewer_DbMo",
         "1698968978898",
         "1699636148102",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The manuscript aims to improve existing methods of unsupervised disentangled representations learning.  Inspired by the symmetry group action approach from (Higgins et al 2018,2022), authors suggest several additions for the conventional beta-VAE  method, resulting  in the form of seven supplementary loss terms. The article is devoted to important subject of disentanglement learning. Authors report improvements over some of existing methods on four simple datasets 1) Only simple datasets are considered, the method is not tested on standard complex datasets like MPI 3D. \n\n2) Reported improvements of CFASL in all measured metrics are essentially always situated within standard deviations of some other methods. \n\n3) Reconstruction loss is not reported in 3 out of 4 datasets. Upon visual inspection of reported samples, the reconstruction quality is not satisfactory. \n\n4) As reported on Figure 4, on 3DShapes dataset, there is no consistent improvement in FVM metric even at the expense of deteriorating reconstruction quality . \n\n5) There is no theoretic justifications for introduction of so many, seven in total,  additional loss terms. \n\n6) Description of Lie group action is not clear, how the action by psi_i is defined? how the dimensions of Lie groups are chosen?\n\n7) The described group action by matrix multiplications do not preserve the normal distribution, so the group equivariant term is not compatible with the  standard KL term from beta-VAE loss. \n\n8) There is no comparison with most recent disentanglement methods like DAVA, TCWAE.\n\n9) Related work section does not mention many works from vast literature on disentanglement learning, eg Disentangling Adversarial Variational Autoencoder (ICLR 2023). Why is the reconstruction quality not reported in three out of four datasets?\n\nWhy the method was not tested on standard more complex datasets like MPI3D?",
         "284",
         "0",
         "0",
         "0.7452",
         "0.070014881",
         "0.8747272491",
         "51",
         "7",
         "34.0313",
         "12.9067",
         "16.1209",
         "14.7317",
         "13.6173",
         "0.0751",
         "89",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "23",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_mr2r",
         "1698569976113",
         "1699636242675",
         "3",
         "4",
         "2",
         "2",
         "1",
         "The article offers a Gaussian Mixture-based differential entropy/mutual entropy estimation approach. Furthermore, it provides numerical experiments to test the expected behavior of the estimator and its application to self-supervised learning. The article addresses an important problem of mutual information estimation. It provides relevant numerical experiments to test the validity of the proposed approach. - The main approach proposed by the authors seem to be already appeared in the literature in some references not cited by the authors (please see the questions part).\n\n- There seems to be a major issue about the expressions provided for the proposed approach (please see the questions part).\n\n- The presentation requires improvement. ### I. INTRODUCTION \n\n**3rd paragraph:** \n\n- \"identify matrix\":  identity matrix?\n\n- \"The mutual information can be consequently estimated by the entropy decomposition.\": This sentence follows identity matrix addition sentence. I guess it might be better to clarify causality here. At this point, it is not clear what is meant by \"entropy decomposition\", whether it is a trivial procedure and what enables it (mixture of Gaussians modelling?).\n\n### 2.1 BACKGROUND\n\n**Paragraph before (4)**\n\n- After equation (1): instead of \"for a multi-variable Gaussian variable\" use Gaussian (random) vector ?\n\n- In the notation $$X=\\[x_1,x_2, \\ldots x_n\\]$$ $x_i$'s appear as column vectors, however, they are actuallly row vectors as $X\\in\\mathbb{R}^{n\\times d}$\n\n- (5) should be\n\n$$\\mathbf{H}_D(X)=\\sum_{i=1}^k \\frac{1}{2} \\log \\left(\\lambda_i+\\beta\\right)+(d-k)\\log(\\beta)+C_d$$\n\n- After (5): \"Therefore, LogDet can estimate the entropy of multivariate Gaussian variables by approximating the differential entropy.\". This is not a surprise/or contribution as the authors  simply defined (5) using (2) by replacing the true covariance with $\\beta I$ perturbed sample correlation (covariance?) matrix. This is sort of obvious. \n\n### 2.1.1 LOGDET ENTROPY ESTIMATOR FOR NON-GAUSSIAN VARIABLE\n\n- Title : ... NON-GAUSSIAN VECTOR\n\n- Replace variable->vector\n\n- There already exists GMM based entropy/mutual information approximation based works such as \n\n\\[a\\]. Lan T, Erdogmus D, Ozertem U, Huang Y. Estimating mutual information using gaussian mixture model for feature ranking and selection. InThe 2006 IEEE international joint conference on neural network proceedings 2006 Jul 16 (pp. 5034-5039). IEEE.\n\n\\[b\\]. Huber MF, Bailey T, Durrant-Whyte H, Hanebeck UD. On entropy approximation for Gaussian mixture random vectors. In2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems 2008 Aug 20 (pp. 181-188). IEEE.\n\nYou need to refer to existing literature and clearly state what is novel in your approach relative to them.\n\n\n- Theorem 2 and Theorem 3 of \\[b\\] above already covers the lower and upper bounds of mixture of Gaussians. It looks like they are same as what is provided in this section. \n\n- There seems to be a major issue about the upper bound expression. The first expression for the upper bound (at the bottom of page 3), contains covariances ($\\Sigma_i$'s ) obtained from the GMM fitting algorithm, whereas the second line contains the overall sample covariance of actual data, instead of conditional covariance estimates. How do you equate these lines? The second line in fact equals to\n\n$$\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)+\\sum_{i=1}^K \\pi_i \\cdot\\left(-\\log \\pi_i+C_d\\right)$$\n\nas $\\frac{1}{2} \\log \\operatorname{det}\\left(\\frac{X^T X}{n}\\right)$ is independent of the summation index $i$. This does not make sense as you disregard covariance parameters of the GMM. \n\n- How do you make the upper bound objective co\n\n### 2.2 THE ISSUE OF MODEL SELECTION\n\n- Title: Model Selection is to generic for the discussion in this section. \"The Issue of Model Order Selection\" could be a better title.\n\n\n\n\n### 3. APPLICATION IN SELF-SUPERVISED LEARNING\n\nThe logdet-mutual information based SSL appears to be proposed in the following reference:\n\n\\[c\\]. Ozsoy S, Hamdan S, Arik S, Yuret D, Erdogan A. Self-supervised learning with an information maximization criterion. Advances in Neural Information Processing Systems. 2022 Dec 6;35:35240-53.\n\nThe authors should also clarify the relative novelty relative to \\[c\\]. Especially, the impact of GMM order selection as the approach in \\[c\\] appears to be for $K=1$. There is also claim in \\[c\\] that the use of $K=1$  defines correlative information maximizing which targets a linear (identity in their modified setting) between the representations of augmented versions of inputs. For $K>1$ does  maximizing mutual information between augmentation representation lead to nonlinear mappings between them? Is such organization of representation space desirable for classification tasks, for example?\n\nOr are you just using (18) with order $1$, which seems to be just the approach in \\[c\\]. \n\n### 4. RELATED WORKS & 5 SIMULATION STUDIES\n\nAll the references we mentioned above and the relevant references that cite them should be included in this discussion, and simulation results \n\n- 5.2 : ofBelghazi...-> of Belghazi\n- Figure 2: Two small figures and caption could be more informative.\n- 5.4 SSL: What is K for EMP-MILE? Is upper bound employed in EMP-MILE?  what if you directly use MILE?\nHow is backprop used in coordination with the GMM algorithm? As GMM parameters are algorithmically obtained from network output, how does backprop do backward mapping from probabilities $\\pi_i$'s (and there should be covariance estimates $\\hat{\\Sigma}_i$'s, as discussed above)",
         "825",
         "0",
         "11",
         "0.7898",
         "0.0758333333",
         "0.9194312096",
         "50",
         "12",
         "32.871",
         "12.3962",
         "15.7154",
         "14.1987",
         "13.0703",
         "0.1107",
         "100",
         "0",
         "2",
         "1",
         "0"
        ],
        [
         "24",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_fvqj",
         "1698878886574",
         "1699636242588",
         "3",
         "5",
         "2",
         "1",
         "2",
         "This paper proposes a new approach to estimating the mutual information between a pair of random vectors, by extending the closed-form expression that is available to Gaussian variables to non-Gaussian variables. This is done by estimating Gaussian mixture approximations of the involved densities and then using bounds on the differential entropy of Gaussian mixtures. Estimating mutual information between high-dimensional non-Gaussian variables is an important problem with many applications. The proposed method extends Gaussian (which the authors refer to log-det) estimators to be applicable beyond Gaussian variables via the use of Gaussian mixture approximations, coupled with bounds on the differential entropy of mixtures. Unfortunately. the paper contains several critical flaws, namely a quite sloppy notation, that lead me to recommend its rejection. \n\nThe authors mixture, in a very confusing way, random variables and data matrices, typically using the same notation for both, $X$. For example, in Equations (1), (2), and (10), $X$ is a $d$-dimensional random variable, whereas in Equation (4), $X \\in \\mathbb{R}^{n\\times d}$ is a data matrix. Even worse, in the final equation of page 3, the two different definitions are used together and it is not even clear where the second equality means; it is simply wrong because $X^T X/n$ does not coincide with $\\Sigma_i$.\n\nUnlike what the authors claim, Equation (5) is not equivalent to Equation (5); the two differ by $\\frac{d-k}{2}\\log \\beta$.  \n\nAdding a matrix proportional to identity ($\\beta I$ in the paper) to the sample covariance was not proposed in a 2021 paper. It is a very classical method that can be found in any classical text on covariance matrix estimation, many decades ago.\n\nThe inequality in Equation (8) was not shown by Zhouyin and Liu in 2021. It is a classical result of information theory, that can be found, for example, in the famous Cover and Thomas book. By the way, the citation to this book is wrong in the paper; one of the authors (J. Thomas) is missing. \n\nThe two bounds for the differential entropy of mixtures that the authors claim to have introduced are in fact not new. The upper bound is in fact a well-known corollary of the log sum inequality (see the Cover and Thomas book). The lower bound was proved in 2008 by Huber et al. at https://doi.org/10.1109/MFI.2008.4648062 I have no questions.",
         "383",
         "1",
         "1",
         "0.7288",
         "-0.053505050500000005",
         "0.8470067382",
         "50",
         "8",
         "39.4844",
         "12.7598",
         "16.0005",
         "14.7779",
         "13.3057",
         "0.21480000000000002",
         "85",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "25",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_F4Ta",
         "1698980874812",
         "1699636242491",
         "6",
         "4",
         "3",
         "3",
         "2",
         "This work presents a mutual information (MI) estimator called MILE (LE=logdet estimator) which uses \nthe log det closed form formula of the entropy of Gaussians.\n\nTo accomodate MI to arbitrary densities, a Gaussian mixture model (GMM) is first fit to data and lower/upper bounds on the entropy of GMM is used to define MILE formula Eq 15. \n\nThen MILE is benchmarked with other MI  estimators and MILE can be used in loss functions in semi-supervised learning in experiments. - Simple MI estimator method based on  \n\nZhanghao Zhouyin and Ding Liu. Understanding neural networks with logarithm determinant entropy estimator. arXiv preprint arXiv:2105.03705, 2021\n\n(cited in the paper)\n\n- Very good experiments and comparisons with other MI estimators\n\n- Source codes provided in supplemental information  for reproducible research -The paper is sloppy in its writing, and one problem is to determine the number of components k of the GMM which\n loosen the lower upper bounds on the entropy. \n\n- Another problem is to deal with near singularity (det close to zero) by introducing a regularization term \\beta.\n\n- Give definition of MI and link with copulas, e.g.,\nMa, Jian, and Zengqi Sun. \"Mutual information is copula entropy.\" Tsinghua Science & Technology 16.1 (2011): 51-54.\nThis will relate to Eq. 8 as well.\n\n- Because MI estimation is an important and well-studied topic, I suggest to put Section 4 on related works after the introduction to that the contributions are better explained.\n\n- The lower/upper bounded of entropy of GMMs are not tight. There is a rich litterature which also compares the tightness of the various bounds.\n\nHuber, Marco F., et al. \"On entropy approximation for Gaussian mixture random vectors.\" 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems. IEEE, 2008.\n\nEven in 1D:\nNielsen, Frank, and Ke Sun. \"Guaranteed bounds on the Kullback–Leibler divergence of univariate mixtures.\" IEEE Signal Processing Letters 23.11 (2016): 1543-1546.\n\n- Notice that some distributions do not admit densities (some elliptical distributions for example)\n\n\n\n- Mention MI properties (i.e., tensorization) which defines the self-consistency test of estimators\n\n\n- small remarks:\n* data covariance = scatter matrix\n* after (3), define $\\Sigma_x$ as scatter matrix?\n*  page 3, first sentence need to be rephrased\n* some typos: \npage 7  hyperparamter -> hyperparameter\npage 9 self-supervied -> self-supervised    competitve -> competitive - Would using PCA beforehand be more appropriate in the case of near singularity?\n\n- Can we tackle robustness/variance with f-MI?\n\nMoon, Kevin, and Alfred Hero. \"Multivariate f-divergence estimation with confidence.\" Advances in neural information processing systems 27 (2014).\nEsposito, Amedeo Roberto, Michael Gastpar, and Ibrahim Issa. \"Robust Generalization via f− Mutual Information.\" 2020 IEEE International Symposium on Information Theory (ISIT). IEEE, 2020.",
         "447",
         "3",
         "7",
         "0.8255",
         "0.1368315018",
         "0.9330754280000001",
         "50",
         "7",
         "35.4092",
         "11.3442",
         "14.446",
         "12.9766",
         "10.7556",
         "0.08660000000000001",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "26",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_MHkc",
         "1699156174555",
         "1699636242410",
         "3",
         "4",
         "2",
         "3",
         "2",
         "this paper proposes to use the logdet function for the estimation of mutual information. \ntwo bounds are proposed for this purpose. the results show improvement in comparison \nto the editing methods. the proposed function itself is \"the Coding Length Function\". simple method with good results. In my opinion this paper reinvents \"Coding Length Function\".  \"...the difference is we put a scaling hyperparameter β on the identity matrix I..\" - that is not a difference. both affects SNR. The latter can be affected either way: by multiplying the noise covariance or by division of the data covariance. I do agree that the results are interesting, but the novelty is quite limited due the the above. \n\nplease elaborate on the limitations. \"So, we recommend β = 1e−3 in the following simulation studies\" why not beta=zero? \nFigure 1.b shows that beta=zero correctly estimates the true MI. \nThat raises a question why do you need beta > 0?\n\nHow do you define $\\pi_c$ in e.g., Eq17?\n\nBoth bounds are loose. How can you explain that such loose bounds lead to very small variance in MI?\n\nDo you calculate MILE in batches?",
         "187",
         "0",
         "1",
         "0.7572",
         "0.0981946625",
         "0.8652637601000001",
         "50",
         "5",
         "61.8294",
         "7.0412",
         "9.7432",
         "10.4262",
         "6.5339",
         "0.4252",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "27",
         "zwcRnM8lD6",
         "2981",
         "1695258507554",
         "['~Chunlin_Ji1', '~Feng_Chen17', '~Fu_Yuhao1', '~Jun_Liu3']",
         "MILE: Mutual Information LogDet Estimator",
         "Mutual information (MI) estimation plays an important role in representational learning. However, accurately estimating mutual information is challenging, especially for high-dimensional variables with limited batch data. In this work, we approach the mutual information estimation problem via the logdet function of data covariance. To extend the logdet function for entropy estimation of non-Gaussian variables, we assume that the data can be approximated well by a Gaussian mixture distribution and introduce a lower and upper bound for the entropy of such distributions. To deal with high dimensionality, we introduce ``ridge'' term in the logdet function to stabilize the estimation. Consequently, the mutual information can be estimated by the entropy decomposition. Our method MILE significant outperforms conventional neural network-based MI estimators in obtaining low bias and low variance MI estimation. Besides, it well pass the challenging self-consistency tests. Simulation studies also show that, beyond a better MI estimator, MILE can simultaneously gain competitive performance with SOTA MI based loss in self-supervised learning.",
         "Reviewer_oYZA",
         "1699327631740",
         "1699636242348",
         "3",
         "4",
         "2",
         "2",
         "2",
         "The paper proposes uses bounds on the entropy and mutual information for a mixture of Gaussian random variables based on the log determinant calculations used in calculating the entropy for a single Gaussian. In the context of self-supervised learning, the Gaussian mixture is assumed to known based on the augmentation. In other cases the number of mixture components has to be selected. Empirical results are reported on a synthetic benchmark of correlated Gaussians with and without non-linear transformations. Results of self-consistency measures are reported on CIFAR10. The paper is a logical motivation. Differential entropy is easy to calculate for Gaussian distributions, and mixture of Gaussians are universal approximations given enough data, so why not use GMM for mutual information estimation. The insight of using the augmentations as defining the GMM is a useful, simplifying assumption. One main weakness is the lack of extensive comparisons of using this method for self-supervised learning versus other. The one example in the main body (Table 1) shows that at 300 epochs the method is better than some other methods but is inferior to EMP-SSL. At 1000 epochs the other methods outperform the listed, but no results for 1000 epochs are reported. \n\nThe second main weakness is the paper does not give a complete description of the method. The paper is lacking in clarity with some key point unaddressed. The notation is confusing since the random variables (Z,Z') are denoted the same as Z_c, which may be a data point in the empirical sample. There should more clarity on random variables as compared to  sample sets, starting back before equation 4. The confusion carries to last paragraph of Section 4 where $\\mathbf{X}$ is defined but then $X$ is used in the definition. \n\nThe use of one instance for one cluster is not clear to me upon reading it\n\"This is because we treat the augmented data from one instance as a cluster, and this data\naugmentation strategy automatically clusters the data.\" This should be re written.\n\n In equation 17 it is not clear how $\\zeta_c$ captures all instances in the batch. It has only a single $i$ index. Perhaps the $\\zeta_c$ should concatenate them all. In section 3.2, $\\zeta_c$ is a set which indexes the whole match, which makes more sense, but it should be a matrix not a set. In any case, how is the $H(Z)$ term estimated in section 3.1? By keeping $Z_c$ fixed and only augmenting the second the one covariance matrix will be rank-1 (before ridge). \n\nIt doesn't sound like the experiments for the 5.2 are run fairly \" our MILE estimator does not require extra training,\" In this problem the point is that the MI could be changing at each data instance. Thus, other methods do not use access to the change points. MILE should have to be run (which involves performing the GMM since there are no self-clusters as in SSL) at each point. Running an expectation maximization is as much or more training than the updates of network.  \t\n\nIn the SSL, the trade-off parameter having to be searched in the grid  \\[0.01,0.1,1.0,2.0\\] doesn't seem to be efficient compared to EMP-SSL. \n \nIn terms of unsubstantiated claims, the method is clearly biased (not only by the choice of number of components) but also on the non-linear transform cases. It is not clear how well the mutual information estimation would actually work on more complicated data. Thus, even if it is useful for self-supervised learning is not necessarily a more accurate estimate of differential entropy. \n\n**Minor:**\nThere are a number of typographical mistakes that are distracting.\n\nI don't understand what this means\n\"often dwarfing traditional parametric and non-parametric approaches in statistics\"\n\n\" base on the \" -> \"based on the \" \n\nI'm not familiar with this phrasing \"When X subjects to a Gaussian\" \n\n\"a ‘noise’ $\\hat{X}$ \" -> \"a noisy $\\hat{X}$\" \n\nThe paragraph before equation (4) are not clear. \" an expanding factor\" is not defined nor is it clear what is meant by \"enlarging the original covariance matrix\".\n\nExtra $=$ on equation 14.\n\n\"trading each\" -> \"treating each\" ? \n\n\" ground true data\" \n\n\"SMILE: moothed\" -> \"SMILE: smoothed\" \n\nIt should be a parenthetical reference for You et al. (2017) fo LARS optimizer. How is the $H(Z)$ term estimated in section 3.1? Is it also based on augmented data?\n\nIn the SSL, the trade-off parameter having to be searched in the grid  \\[0.01,0.1,1.0,2.0\\] doesn't seem to be efficient compared to EMP-SSL. Are there hyper-parameters for EMP-SSL?  \n\nWhy in Table 1 is 1000 epochs not tested?\n\nIs the GMM method run at each time point in Figure 2?",
         "766",
         "1",
         "2",
         "0.7605",
         "0.0532218443",
         "0.8940244317",
         "50",
         "3",
         "54.1694",
         "9.5215",
         "12.4683",
         "12.0691",
         "9.6868",
         "0.1494",
         "91",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "28",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_e4bh",
         "1698824679826",
         "1700667146725",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs) which build on the graph theoretical concept of graphexes to include sparse network structures between agents. This improves over prior work on Graphon Mean Field Games which only allows for modelling with dense graphs. The authors derive convergence properties for the finite game. In addition, a learning algorithm based on online mirror descent is provided for a particular class of GXMFGs that follow a core-periphery network structure. Finally, the theoretical claims are empirically validated over both synthetic and real-world networks. - This paper has a clear motivation to extend Graphon Mean Field Games to deal with sparse graphs which are frequently seen in practice. The hybrid graphex approach proposed in this work looks like a natural and intuitive solution.\n- The technical development is principled and the analysis is nontrivial.\n- The overall presentation and clarity is good. - Even though the authors explained in the paper, I didn't like the fact that the proposed GXMFGs have no baseline competitors to compare against. While I agree that one could argue on the contrary that the ability to work with sparse graphs is precisely the unique advantage of GXMGFs, I think that the authors should at least spend some efforts to discuss (if empirical comparison with LPGMFG is indeed unsuitable) how GXMFGs would compare with LPGMFG and GMFG in practice. In Figure 3a, it looks like the curves are diverging rather than converging as k increases? Are the curves coloured correctly?",
         "248",
         "0",
         "0",
         "0.8187",
         "0.0240079365",
         "0.9548254013",
         "61",
         "21",
         "47.3621",
         "11.3161",
         "14.0651",
         "13.2744",
         "12.8151",
         "0.1262",
         "95",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "29",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_hgJx",
         "1698838739665",
         "1699636550718",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper introduces Graphex Mean Field Games (GXMFGs), a framework for addressing the challenge of learning agent behavior in large populations. GXMFGs leverage graphon theory and graphexes, which represent limiting objects in sparse graph sequences. This approach suits real-world networks with both dense cores and sparse peripheries. The paper presents a specialized learning algorithm for GXMFGs. \n\nKey contributions include:\n\n1. Introduction of GXMFGs, extending the scope of Mean Field Games.\n2. Provides theoretical guarantees to show that GXMFGs accurately approximates finite systems.\n3. Development of a learning algorithm tailored to GXMFGs.\n4. Empirical validation on synthetic and real-world networks, demonstrating GXMFGs' ability to model agent interactions and determine equilibria effectively. - Well-Written and Organized: The paper demonstrates strong writing and organization, enhancing its overall readability and accessibility.\n\n- Clear Motivation: The paper effectively conveys a clear and compelling motivation for addressing the problem it tackles.\n\n- Thorough Discussion of Prior Works: The paper provides a comprehensive and well-structured overview of prior works related to the research area.\n\n- The paper provides solid theoretical contributions complimented with supporting empirical studies strengthens the paper's arguments and findings. As the current paper falls outside the scope of my research interests, I am unable to identify any significant weaknesses in the paper. Consequently, my confidence in assessing the paper is limited. - Providing an intuitive explanation for assumptions 1(b) and 1(c) would greatly enhance the paper's overall readability and accessibility.\n\n- While the paper assumes finite state and action spaces, it may be beneficial to explore whether the proposed approach can be extended to scenarios with infinite action spaces. \n- Including the code for the simulations, would enhance reproducibility.",
         "275",
         "0",
         "4",
         "0.8110",
         "0.1125396825",
         "0.9475759268",
         "49",
         "9",
         "19.6817",
         "14.2129",
         "17.5973",
         "15.0211",
         "14.8225",
         "0.1213",
         "79",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "30",
         "zwU9scoU4A",
         "5423",
         "1695386194798",
         "['~Christian_Fabian1', '~Kai_Cui3', '~Heinz_Koeppl1']",
         "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach",
         "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods.",
         "Reviewer_P6cQ",
         "1698854680058",
         "1699636550633",
         "6",
         "4",
         "3",
         "3",
         "3",
         "In this paper, the authors study a class of games with many players who are interacting through a sparse graph structure. More specifically, they are interested in the regime where the number of players tend to infinity. The main solution concept is an extension of the notion of Nash equilibrium. The authors propose a learning algorithm based on online mirror descent. They conclude the paper with examples and numerical simulations. Overall, the paper studies an interesting problem and is relatively clearly written. As far as I know, this is a new extension of MFG to sparse graphs. The algorithm is very inspired from existing ones but there is an adaptation to the problem under consideration (core vs periphery). The model is quite abstract at some places. For the theoretical results, they are mostly about the analysis of the game and I am not sure how relevant they are for this conference (although they are certainly interesting for a certain community). It might have been more interesting to focus more on the learning algorithm. \n\nThere are some typos which make it hard to check the correctness of some parts (see questions). 1. I am wondering if some assumptions are missing. For example below Lemma 1, should $f$ be at least measurable (and perhaps more?) with respect to $\\alpha$ for the integral to make sense?\n\n2. Assumption 2 as used for instance in Lemma 1 does not seem to make much sense (unless I missed something): What is $\\boldsymbol{\\pi}$? We do not know in advance the equilibrium policy and even if we did, we would still need to define the set of admissible deviations for the Nash equilibrium. Could you please clarify?\n\n3. Algorithm 1, line 14: Could you please explain or recall what is $Q^{k, \\mu^{\\tau_{\\mathrm{max}}}}$?\n\nSome typos: Should the state space be either $\\mathcal{X}$ or $X$ (see section 3 for instance)? Does $\\mathbb{G}^\\infty_{\\alpha,t}$ depend on $\\boldsymbol{\\mu}$ or not (see bottom of page 4)? Etc.",
         "324",
         "0",
         "4",
         "0.8025",
         "0.19302597400000002",
         "0.9195409417",
         "49",
         "9",
         "56.4417",
         "9.2197",
         "11.6035",
         "11.8555",
         "9.9651",
         "0.6631",
         "111",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "31",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_qFZD",
         "1698724264822",
         "1699636511957",
         "5",
         "2",
         "3",
         "3",
         "2",
         "The paper introduces out-of-variable (OOV) generalization, which is an the ability to generalize in environments with variables that have never been jointly observed before. OOV is an issue in settings where different variables (e.g. diagnostic tests) are available for different environments (e.g. different patients). The paper investigates challenges for common approaches when faced with the OOV problem, and proposes an OOV predictor that leverage moments of the error distribution. The work contributes to theoretical understandings of OOV and offers a proof-of-concept for a predictor capable of non-trivial OOV transfer. - The paper formally studies a new perspective on generalization.\n- The methods employed in the paper are sound. - The paper does not demonstrate the practical applicability of the concept of OOV generalization, and the setting feels a bit contrived. Also it seems like OOV generalization can be thought of just a case of OOD generalization--if we think about all the variables together as the input, the OOV generalization is just a case of OOD generalization (e.g. covariate shift) where some inputs have clear signal from some features and other inputs have clear signal from other features. \n- It would be helpful to include more intuitive discussion throughout the paper providing more analysis on the sections. For example, more discussion on the assumptions of the settings/theorems would be helpful, and it's not clear exactly under what assumptions the proposed predictor is appropriate. Please see weaknesses above.",
         "236",
         "0",
         "2",
         "0.7220",
         "0.11756198350000001",
         "0.8290046453000001",
         "49",
         "10",
         "31.9194",
         "13.2407",
         "15.9316",
         "14.8796",
         "13.7972",
         "0.1839",
         "85",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "32",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_s9Ga",
         "1698762596885",
         "1700684618252",
         "8",
         "4",
         "3",
         "4",
         "2",
         "This work investigates out-of-variable (OOV) generalization, which is a sub-problem to OOD generalization, and refers to scenarios where an agent needs to generalize to environments containing variables that were never jointly observed before. The paper shows that if the source and target environments contain some overlapping variables (and under certain conditions), information from the predictor in the source environment can improve predictions in the target environment. More specifically,  the moments of the residual distribution from the optimal classifier in the source environment can be used to calculate the generating function with respect to the unobserved variable in the target domain.\n\nBased on this observation, the paper proposes a practical algorithm for OOV prediction, evaluates its performance, and compares it against the marginal predictor and imputed predictor, as well as an Oracle predictor. The paper proposes a new and important problem-setting - OOV generalization, which can occur in real-world situations, on its own or alongside OOD aspects. The work also provides an extensive study of the identification problems of various variants of OOV scenarios, including theoretical proofs and examples. \n\nIn addition, the paper proposes a practical algorithm to solve several OOV scenarios that achieves non-trivial OOV transfer on synthetic data.\n\nThe ideas presented in the paper are novel and the conclusion that information from source domains can be used for prediction in the target domain in this setting is important, and can potentially have a broad impact on future research in the field. The main limitation of the paper is that the proposed approach was tested on only synthetic data, and was not validated using more challenging datasets. \n\nIn addition, the extension of OOV in multi-environments is mentioned mainly in the appendix and the algorithm was not tested empirically for that extension. I would like to ask the following questions:\n\n1. For future work, is there a more complicated/realistic dataset to validate the algorithm?\n2. Is it possible to compare the algorithm to state-of-the-art marginal or causal methods such as Mejia et al. (2021) or Janzing (2018)? To validate if Vapnik’s principle holds and whether the proposed approach indeed improves results due to solving a less general problem.\n3. Theorem 3 connects all moments of the residual distribution to the partial derivatives with respect to the unique variable of the target environment. If additional moments were to be calculated as part of the proposed algorithm, would it improve results (for the general function case)? \n4. In general, since the paper's main claim is that in the real world, it is likely to encounter both aspects of OOD and OOV - How simple is it to combine state-of-the-art  OOD methods with the proposed approach? I cannot imagine at the moment a straightforward way to do that.",
         "454",
         "2",
         "3",
         "0.7695",
         "0.1422634079",
         "0.9121482372",
         "61",
         "22",
         "27.7135",
         "15.3038",
         "18.6308",
         "16.8747",
         "15.9651",
         "0.1633",
         "97",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "33",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_woi7",
         "1698788842803",
         "1699636511769",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper describes the out-of-variable OOV problem, which in its simplest form, aims to learn a predictor Y = f_t(X2, X3) given an OOV predictor Y = f_s(X1, X2) and a dataset (X2, X3), but without any instance of (X2, X3, Y). The authors describe the setting in which this is possible and develops an algorithm. The key observation is that the third moment of the residue Y - f_s(X1,X2) contains information about X3 that is least polluted by the noise. - The key observation/discovery is clever, and the algorithm is straight-forward to use.\n- The writing is clear, clean, and well-referenced. The examples also made things concrete and easy to follow.\n- The rigor and simplicity of the work can act as a foundation to build OOV research. - The main weakness is the applicability of the method. The authors only showed results for proof-of-concept, not for real-world usage. \n- It is unclear how one could identify whether the assumptions are satisfied given a dataset.\n- It is unclear how bad the predictor would be if the assumptions are not satisfied.\n- It is not yet clear what realistic problem can be well modeled by OOV generalization. Intro:\n- It seems OOV fits very well the frame of missing-not-at-random and covariate-dependent missingness. Could the authors comment on that?\n\nSection 2:\n- Theorem 2 is slightly confusing for me at first glance because I thought PA_Y by definition includes all parents of Y (so x1,x2, x3 in the example) and not just those in the target environment (x2, x3). It may be helpful to clarify.\n\nSection 3:\nAs I am trying to get a sense of the restriction and applicability of the approach, I was wondering the following questions: \n- How does the method fair with the oracle as the magnitude of the noise increases? \n- What if the noise is not gaussian but more heavy tailed? \n- Does the performance degrade or improve with increasing number of variables? \n- I assume Theorem 3 does not apply to discrete variables because of the violation of differentiability; is that right?\n\nSection 4:\n- Can include missing-not-at-random imputation and covariate-missing imputation as two more baseline models (a search in Google scholar using the two key phrases yields some methods).\n- It would be really interesting if the authors could find some real-world datasets, create source and target environments by sub-setting the columns, and see how the method performs.\n- Figure 3: I don’t quite understand the figure. It would be helpful to define OOV loss, be explicit about the number of samples on the y-axis being (x2,x3,y) or (x1,x2,y) or something else. I also don’t understand why relative loss is zero means the method is on par with the oracle predictor. Why not just show how the fine-tuning error compares with oracle training, which seems easier to interpret? Anyway, I am overall a bit confused about the figure, so my questions may not make sense.",
         "493",
         "0",
         "0",
         "0.7642",
         "0.0947004608",
         "0.8592604399",
         "49",
         "9",
         "53.3705",
         "10.1765",
         "12.6762",
         "12.5225",
         "10.2004",
         "0.0743",
         "74",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "34",
         "zwMfg9PfPs",
         "5166",
         "1695374748753",
         "['~Siyuan_Guo1', '~Jonas_Bernhard_Wildberger1', '~Bernhard_Schölkopf1']",
         "Out-of-Variable Generalisation for Discriminative Models",
         "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization",
         "Reviewer_xwQY",
         "1699441328198",
         "1699636511667",
         "8",
         "3",
         "3",
         "3",
         "3",
         "The paper investigates out-of-variable generalization, namely the ability for a predictive model to generalize to target domains in which the agent has never seen the joint variables in the target domain in a single source domain before. Under certain assumptions as well as when these assumptions don't fully hold, the paper shows that the error residual distribution in an environment provides information on the unobserved causal parent variable in this environment, and they use this information to derive an algorithm that performs OOV generalization with source and target domains that have overlapping sets of causal factors. **Originality**\n- As far as I know, though the problem the paper addresses is well-known as a significant problem, the paper provides several theoretical results, mathematical derivations, and supports these with simple empirical results that are novel.\n\n**Quality**\n- The quality of the paper is high. It addresses a high-value problem in a principled fashion, shows how certain assumptions help obtain certain results and how and in which cases these assumptions can be bypasses while maintain approximately accurate results, and evaluates these cases in terms of loss accuracy as well as sample complexity of its approach versus baseline approaches.\n- The paper openly highlights limitations in its work, such as assumptions made for theorems to hold, and proposes prospective future work in multiple avenues. This refreshingly is (1) included at all and (2) doesn't seem like a mere afterthought.\n\n**Clarity**\n- The paper is mostly clear in its explanation of motivation, preliminaries, approach, baseline usage, results, and limitations.\n- The paper does a great job providing simple, clear real-world examples to elucidate the problem and applications of the various theorems included in multiple cases.\n\n**Significance**\n- The significance of the problem the paper addresses is high and the problem is ubiquitous. The approach is promising and can be applied in many real-world settings through Monte-Carlo sampling or similar methods. The paper shows that their approach can perform relatively well in \"few\"-shot settings though this depends on the number of variables involved and the complexity of the problem.\n\nFrom what I can tell, this is excellent work that I hope motivates further addressing this *out-of-variable* generalization problem by the research and applied AI community. My only reservation is my limited knowledge on the understanding of and state-of-the-art theoretical and applied approaches addressing this problem. - Referring to Figure 1, in the first paragraph in page 3, the claim \"it would seem all but impossible...(orange box)\" could be better explained.\n- In Figure 1, it is unclear whether \"With $Y$ not observed in the target domain\" is an assumption made or is somehow indicated in the diagram or earlier in the paper. Eventually I realized that it's an assumption made, but the illustration Figure 1a alone isn't enough to show this assumption. This ambiguity may clear for some or compound for some later in Section 3. - The abstract states \"merely considering differences in data distributions is inadequate for fully capturing differences between learning environments.\" Doesn't out-of-variable technically fall under out-of-distribution, so shouldn't this be adequate? Perhaps more specificity is needed here.\n- The abstract states \"Mathematically, out-of-variable generalization requires the efficient re-use of past marginal information...\" Why does it require efficient re-use? Could it work with \"non-efficient\" or inefficient re-use?\n- On page 2, should \"modal\" be \"model?\"\n- On page 6, do you mean \"parentheses\" instead of \"brackets\" between Eq (9) and Eq (10)?\n- Why is the joint predictor considered an oracle predictor if MomentLearn outperforms it?\n- Could you explain why MomentLearn is reliably more sample efficient than the oracle predictor for \"few\"-shot prediction?",
         "602",
         "0",
         "0",
         "0.7701",
         "0.10227124180000001",
         "0.9314678907",
         "49",
         "2",
         "29.5723",
         "14.1717",
         "17.226",
         "15.4091",
         "14.9494",
         "0.45280000000000004",
         "97",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "35",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_HgHQ",
         "1697165838375",
         "1699635934990",
         "3",
         "5",
         "2",
         "3",
         "2",
         "The paper proposes a simple yet efficient feature direction distillation loss. Experiments show that this significantly improves KD\nperformance. 1. Improving KD by feature norm and direction is reasonable and effectiveness.\n2. Experiments on standard benchmarks demonstrate that adopting $\\mathcal{L}_{dino}$ remarkably improves existing KD methods. 1. The contributions seem a little limited. \n2. There is lack of theoretical analysis of DINO loss. The paper is not good enough to be published on ICLR. 1. How to align the features between heterogeneous architectures?\n2. Could you please provide more theoretical analysis?\n3. What about extending it to a multi-layer version of feature distillation?\n4. How to apply the proposed method to existing KD methods, e.g. ReviewKD, DKD, DIST? Just add the DINO loss function to the total loss ? If so, I think adding other loss like contrastive distillation loss or RKD may also make a improvement.",
         "146",
         "0",
         "8",
         "0.8205",
         "0.07793367350000001",
         "0.8326533437",
         "56",
         "28",
         "43.4591",
         "9.7707",
         "12.1429",
         "11.6299",
         "9.46",
         "0.5162",
         "80",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "36",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_yLjx",
         "1697172920902",
         "1699635934905",
         "6",
         "5",
         "3",
         "3",
         "2",
         "Here is a summary of the key points from the paper:\n\n- The paper proposes a method to improve knowledge distillation (KD) by regularizing student features to align direction with teacher class-means and have sufficiently large norms. \n\n- Current KD methods like logit or feature distillation align student and teacher but don't directly optimize for student's task performance.\n\n- The paper shows regularizing direction using cosine similarity to teacher class means helps improve student accuracy. \n\n- It also finds student models tend to produce smaller-norm features, so encouraging larger norms improves performance. \n\n- A simple combined loss called dino-loss is proposed to simultaneously regularize student feature direction and norm using teacher class means.\n\n- Experiments on CIFAR and ImageNet classification, and COCO detection show dino-loss consistently improves various KD methods like KD, ReviewKD, DKD.\n\n- Dino-loss achieves new state-of-the-art results among KD techniques on classification and detection benchmarks.\n\n- The method is model-agnostic, simple to implement, adds minimal overhead, and benefits from larger teacher models.\n\nIn summary, the key contributions are a way to improve KD by regularizing student features for better alignment and norms, along with a simple and effective dino-loss to achieve this jointly. The results demonstrate consistent gains across tasks and benchmarks. The paper presents an original and significant approach to improve KD via thoughtful feature regularization. The method is intuitive and supported by quality experiments. The gains are demonstrated to be significant across tasks. The presentation and discussion are clear:\n- The method and dino-loss are clearly explained with illustrations and equations. Results are well-presented in tables and figures. Limitations are properly discussed.\n- Improving KD is an important practical problem. The consistent gains are significant. Sets new state-of-the-art results on ImageNet classification and COCO detection.\n- Model-agnostic nature allows wide applicability to various KD methods and models. Simple extension can benefit the community compared to more complex techniques. - The paper should address the lack of novelty by acknowledging that feature normalization techniques have already been widely employed in knowledge distillation. For example, PKD (NeurIPS-2023) specifically incorporates channel alignment for detectors, and SKD (Guo Jia) explores normalization techniques on predictions. and Feature Normalized Knowledge Distillation for\n/mage Classification ECCV2022 also presents feature norm. Furthermore, it is worth investigating whether the proposed method has already been considered in the distiller's search work, as exemplified by KD-Zero: Evolving Knowledge Distiller for Any Teacher-Student Pairs (NeurIPS-2023).\n\n- In addition, the paper should incorporate a thorough discussion of relevant KD-related studies, including Self-Regulated Feature Learning via Teacher-free Feature Distillation (ECCV2022), NORM: Knowledge Distillation via N-to-One Representation Matching (ICLR2023), Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer (NIPS2022), DisWOT: Student Architecture Search for Distillation Without Training (CVPR2023), and Automated Knowledge Distillation via Monte Carlo Tree Search (ICCV2023). These discussions will provide valuable insights into the existing literature, establish connections with previous research, and potentially highlight points of comparison and contrast. The only concern to me is the novelty of the work and I hope the authors could discuss some of the related work I mentioned in the revised version.",
         "510",
         "0",
         "1",
         "0.8228",
         "0.134258658",
         "0.9310495853",
         "56",
         "28",
         "21.6614",
         "14.6476",
         "16.1946",
         "15.0048",
         "16.804",
         "0.063",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "37",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_VRvE",
         "1698736302686",
         "1699635934723",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper studies Knowledge Distillation (KD). A simple loss term namely ND loss is proposed to enhance the distillation performance. It encourages the student to produce large-norm features and aligns the direction of student features and teacher class-means. The ND loss helps not only logit-based distillation methods but also feature-based distillation methods. 1. The proposed method is simple but effective. Encouraging the feature norm for the student is novel in the field of KD.\n2. Experimental results are strong. The authors also conduct experiments on object detection. The proposed loss can improve the existing methods on both image classification and object detection.\n3. The whole paper is organized and written well. It is not a novel thing that decoupling the feature into the magnitude and the direction. Previous works \\[1\\]\\[2\\] already studied this point. \\[1\\] uses the teacher classifier to project both teacher features and student features into the same space and then align them. \\[2\\] proposes a loss term to align two features’ direction. Compared to the existing works, this paper proposes enlarging feature norm and utilizing the class-mean feature. Authors should check more existing papers and discuss their differences.\n\\[1\\] Yang, Jing, et al. \"Knowledge distillation via softmax regression representation learning.\" International Conference on Learning Representations (ICLR), 2021.\n\n\\[2\\] Wang, Guo-Hua, Yifan Ge, and Jianxin Wu. \"Distilling knowledge by mimicking features.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 44.11 (2021): 8183-8195. None",
         "235",
         "7",
         "6",
         "0.7478",
         "0.1515151515",
         "0.9257477522",
         "56",
         "10",
         "45.6243",
         "9.4339",
         "10.8955",
         "11.0306",
         "10.9165",
         "0.0999",
         "85",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "38",
         "zvTnwY5uS7",
         "96",
         "1694767211144",
         "['~Yuzhu_Wang1', '~Lechao_Cheng2', '~Manni_Duan2', '~Yongheng_Wang1', '~Zunlei_Feng1', '~Shu_Kong1']",
         "Improving Knowledge Distillation via Regularizing Feature Direction and Norm",
         "Knowledge distillation (KD) exploits a large well-trained {\\tt teacher} neural network to train a small {\\tt student} network on the same dataset for the same task.\nTreating {\\tt teacher}'s feature as knowledge, prevailing methods train {\\tt student} by aligning its features with the {\\tt teacher}'s, e.g., by minimizing the KL-divergence between their logits or L2 distance between their features at intermediate layers. \nWhile it is natural to assume that better feature alignment helps distill {\\tt teacher}'s knowledge, simply forcing this alignment does not directly contribute to the {\\tt student}'s performance, e.g., classification accuracy.\nFor example, minimizing the L2 distance between the penultimate-layer features (used to compute logits for classification) does not necessarily help learn a better {\\tt student}-classifier.\nTherefore, we are motivated to regularize {\\tt student} features at the penultimate layer using {\\tt teacher} towards training a better {\\tt student} classifier.\nSpecifically, we present a rather simple method that uses {\\tt teacher}'s class-mean features to align {\\tt student} features w.r.t their {\\em direction}.\nExperiments show that this significantly improves KD performance. Moreover, we empirically find that {\\tt student} produces features that have notably smaller norms than {\\tt teacher}'s, motivating us to regularize {\\tt student} to produce large-norm features.\nExperiments show that doing so also yields better performance. Finally, we present a simple loss as our main technical contribution that regularizes {\\tt student} by simultaneously (1) aligning the \\emph{direction} of its features with the {\\tt teacher} class-mean feature, and (2) encouraging it to produce large-\\emph{norm} features.\nExperiments on standard benchmarks demonstrate that adopting our technique remarkably improves existing KD methods, achieving the state-of-the-art KD performance through the lens of image classification (on ImageNet and CIFAR100 datasets) and object detection (on the COCO dataset).",
         "Reviewer_AuzT",
         "1698788774762",
         "1699635934515",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper proposes to use teacher's class-mean to align student's direction and encourage the student to produce large-norms features, improving the performance of KD. The paper is generally well-written, and the methodology is well-motivated. 1. would expect comparisons and discussion to similarity-preserving KD e.g., \\[1\\], which is a large family in feature distillation methods and shows some relations to the proposed method.\n2. Meanwhile, comparisons/discussion to explainablity-based KD, e.g., \\[2\\] are needed to see whether those methods can be benefited from the proposed method.\n\n\\[1\\] Tung, Fred, and Greg Mori. “Similarity-Preserving Knowledge Distillation.” ICCV 2019.\n\n\\[2\\] Guo, Ziyao, et al. \"Class Attention Transfer Based Knowledge Distillation.\" CVPR 2023. Please see weakness.",
         "111",
         "4",
         "6",
         "0.7517",
         "0.1321428571",
         "0.8699356318",
         "56",
         "9",
         "39.5873",
         "10.2446",
         "10.8832",
         "11.2081",
         "12.4695",
         "0.1376",
         "72",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "39",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_AcYB",
         "1697637540901",
         "1700740134087",
         "5",
         "4",
         "3",
         "2",
         "2",
         "The authors introduce Neural Sinkhorn gradient flow, which is a Wasserstein Gradient Flow wrt to the Sinkhorn divergence. The authors show that the velocity field can be calculated using the Sinkhorn potentials. This allows training a neural network approximating the velocity field. Furthermore, a mean field limit is established. The algorithm is evaluated on a toy example, MNIST image generation and CIFAR10 image generation. The authors do a good job at explaining the underlying concepts of their algorithms. The maths is nicely done. The core idea is very neat and the cifar10 results seem to be good quantitatively wrt other gradient flow works. 1) The article is full with typos. Just to name a few: \"piror\", \"Sinkhron\", \"Experimrnts\", \"speedest descent\", question mark in the appendix and so on. Please fix those. \n\n2) the authors write \"We do not compare with extant neural WGF methods on MNIST because most of the neural WGF\nmethods only show generative power and trajectories on this dataset and lack the criteria to make\ncomparisons.\" There are several papers (also gradient flow based ones), which evaluate a FID on MNIST. Please provide it as well. \n\n3) Also many of the MNIST digits appear flipped. Did the authors use data augmentation there? Also there seems to some slight noise present the generated MNIST digits. \n\n4) Although the CIFAR10 value seems good, there are unfortunately no generated images provided. It is standard practice to sample many images in the appendix. \n\n5) It is unclear what the trajectories show. Does it show the particle flow or the trained Neural Sinkhorn Gradient Flow? \n\n6) The statement of theorem 2 is incorrect. I guess the authors do not want to sample the Euler scheme (eq 14) but the continuous gradient flow, otherwise the statement would need to depend on the step size $\\eta$. \n\n7) In the proof of Theorem 2: Please provide a proof (or reference) why the mean field limit exists. Or do you mean the gradient flow starting at $\\mu_0$ with target $\\mu$ (first two sentences).\n\n8) Later in that proof: why does there exists a weakly convergent subsequence of $\\mu_t^M$? Further, I cant find the definition of $U_{\\mu}$. \n\n9) The code is not runnable, as the model (or any checkpoints) are not provided.\n\n10) From how I understood it, the learning of the velocity field is batched, i.e., one trains for different sets of $(z_i,x_i)$. Since the Sinkhorn dynamic describes an interacting particle system I dont see how this should be possible. To be more precise, one particle $\\tilde{x}$ could be sent to $x_0$ in the first batch, but to a totally different particle $x_1$ in another one, depending on the drawn prior and target samples. Are the positions of the other particles also input to the neural network (i.e by putting them in the channels)? Please elaborate. See weaknesses section. Overall I really like the idea, but the weaknesses prevent me from giving a higher score. It seems like the paper was rushed and is currently not ready for publication. I am willing to raise my score, if the authors address these issues.",
         "516",
         "0",
         "3",
         "0.7790",
         "0.1480691057",
         "0.8920141459",
         "62",
         "35",
         "60.9059",
         "8.1376",
         "10.8579",
         "11.2611",
         "8.6721",
         "0.2179",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "40",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KKim",
         "1698338217824",
         "1700755549491",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper introduces a novel way to train generative models. The authors want to approximate the gradient flow in the Wasserstein space.  They want to approximate the vector field which transports the source distribution to the real-data empirical distribution while minimizing the Sinkhorn divergence. The authors showed the analytical form of the vector field when one considers the Sinkhorn divergence and then they explain how to learn this vector field with a neural network through the simulation of a probability path. They showed that their procedures recover the true probability path when the number of iid samples goes to infinity. Finally, they validate their proposed method on several image-generative tasks. i) The motivation and the introduction are clear\n\nii) Regressing vector fields has been a recent and popular approach with many different applications in machine learning. The proposed approach is interesting and appears to be novel. The theoretical results also show that the proposed method has appealing properties. \n\niii) The authors also provided several experiments showing interesting results from their methods. The first thing I would like to highlight is that I have checked the provided code. I see several inconsistencies and weaknesses between the provided code and the paper:\n\n1. There are several differences in the empirical implementation between the paper and the code. In Appendix A, the authors state that they are computing the entropic potential through stochastic optimization algorithms \\[Genevay et al, 2016\\]. However, this is not what is done in practice according to the provided code. In practice, the authors compute the potential between mini-batches of samples, they sample a minibatch of cifar10 experiments, then sample a minibatch of the source Gaussian, and simulate the gradient flows between the two minibatches. This style of minibatch approximation induces a bias that should at least be mentioned in the main paper but also discussed. Indeed, the authors do not compute the true Sinkhorn divergence but a minibatch approximation of it; this approximation is slightly different than the one from \\[1,2\\] and that should be discussed. I understand the reason why the authors use this approach (decreasing the cost of this preprocessing step), but this is not what they say they do in Appendix A. In that regard, the paper is much closer to the minibatch optimal transport Flow Matching \\[Pooladian et al., Tong et al\\] and Appendix A deserves a major revision.\n\n2. With the provided code, there are several insights that should be discussed in the paper. In the provided cifar experiments, the number of Gaussian samples used is 50000 samples. This number is extremely low to approximate the semi-discrete OT. Therefore, a discussion regarding the statistical performance of the method is needed in my opinion.\n\n3. As your method requires the simulation of the probability path, I wonder about the training time between your method and the recent Flow Matching approaches which are simulation free.\n\n4. There are many typos in the paper (including in titles: ie ExperimRnts, Notaions) that lead to poor clarity...\n\n5. The experiments include two toy datasets (synthetic 2D and MNIST). I would like to know how the method performs on other big datasets (Flowers, CelebA) or on other tasks such as single-cell dynamics \\[4\\].\n\n6. The related work on optimal transport is incomplete. Several works used the sliced Wasserstein distance to perform gradient flows \\[3\\].\n\n\\[1\\] Learning Generative Models with Sinkhorn Divergences, Genevay et al, AISTATS 2018\n\\[2\\] Learning with minibatch Wasserstein, Fatras et al, AISTATS 2020\n\\[3\\] Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions\n\\[4\\] TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics 1. \\[Pooladian et al., Tong et al.\\] proved that when the minibatch increases, they get closer to the true optimal transport cost (W_2^2). The interest of their method is that they can rely on minibatches and learn the vector field from an unlimited number of minibatches. Could you follow a similar approach and simulate the gradient flow during training? While it would be an expensive step in training, it might improve the metrics on the different generative model experiments.\n\n2. What is the performance of your method concerning the number of simulation steps (ie Euler integration and its learning rate)?\n\n3. What is the time of the preprocessing step concerning the training time?\n\n4. Could you compare your method with OT-CFM \\[Pooladian et al., Tong et al.\\] on the synthetic data? I am curious to compare the differences.\n\nIn my opinion, the mentioned weaknesses have to be revised and this paper should go under a major revision. I deeply think that the experimental section should better highlight what is done in practice and the theoretical section should mention the different biases (statistical and minibatch). Therefore, I recommend rejecting the current manuscript as it does not meet the ICLR acceptance bar.\n\n\n----- EDIT POST REBUTTAL -----\n\nI thank the authors for their answers. I have read the updated manuscript. While it is now better than before, I suggest they add a limitation section where they describe the different biases in their algorithm. I understand the motivations of the paper. Overall, I think that the manuscript deserves another round of reviews but I have decided to move my score to 5 as they have given good answers.",
         "873",
         "7",
         "8",
         "0.7648",
         "0.0723611111",
         "0.8572189808",
         "62",
         "27",
         "47.6358",
         "10.776299999999999",
         "13.8642",
         "13.3974",
         "11.9247",
         "0.9374",
         "105",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "41",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_Kh9H",
         "1698606606187",
         "1699636333063",
         "6",
         "4",
         "3",
         "2",
         "2",
         "Through a series of approximations (and at times, really, relaxations) the authors show that the Sinkhorn gradient flow from one measure to another can be learned.  They do this by first reducing their relaxed problem to a vector field matching problem, and then proposing a neural network-based Algorithm for matching the Sinkhorn-Wasserstein flow's vector field by a neural network (though no convergence/approximation guarantees are proven).\nThe problem is interesting, and its solution is sufficiently novel to merit publication. The problem is natural to study, the results are mathematically correct, and the experiments are convincing. While the paper is mathematically correct, it does not provide theoretical justification for one of its main components, namely showing that approximate vector field matching yields approximate solutions for all time $t$.  I feel that without this guarantee, there is a gap in the theoretical viability of this model.  Nevertheless, this is a minor point since the length of a conference paper does not allow one to treat every such point.\n\nThere are minor typos throughout. \n* E.g. euclidean instead of Euclidean\n* $lim$ instead of $\\lim$ atop page 15 in the appendix\n* The positive scalar $\\delta$ is not defined in the proof of Theorem $1$\n* In the statement of Lemma 3: \"teh\" should read \"the\"\n\nSome references are obscure\n* For The fact that $\\mu + t\\delta \\mu$ converges weakly to $\\mu$, perhaps it is worth simply noting that due to linearity of integration (wrt to the measure term). Can it be shown that approximate vector field matching yields approximate solutions for all time $t$?",
         "262",
         "0",
         "1",
         "0.7647",
         "0.0019972452",
         "0.8472071886",
         "49",
         "11",
         "40.0713",
         "14.0299",
         "16.0213",
         "14.5546",
         "15.9806",
         "0.0613",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "42",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_KkYD",
         "1698745650108",
         "1700818697559",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper under consideration deals with the standard generative modelling setup (image generation from noise). To solve this problem, the authors propose to model the gradient flow w.r.t. the Sinkhorn divergence. The paper utilizes an explicit (forward) Euler discretization scheme, i.e., given a distribution $\\mu_t$ at the current time step $t$, the proposed method aims at finding the subsequent distribution $\\mu_{t + 1}$ following the gradient of the Sinkhorn divergence at point $\\mu_t$. The authors validate their methodology on toy 2D setups as well as standard image benchmarks (MNIST and CIFAR10).\n\n**Post-rebuttal update:** I thank the authors for the detailed answer. The majority of my concerns are properly addressed. I rise my score. However, I still tend to reject the paper. Also I agree with reviewer KKim that minibatch OT approximation should be discussed more thorougly. Thank you. To the best of my knowledge, the framework of the gradient flow w.r.t. Sinkhorn divergence for pure generative modelling has not yet been considered. This indicates that the paper is indeed bringing something novel to the ML community. At the same time, the idea of the Sinkhorn gradient flow has already arisen in previous research. In particular, \\[A\\] solves Sinkhorn barycenter problems by adjusting a generative distribution towards the barycenter distribution with the help of a procedure called “functional gradient descent” which is actually the discretization of the gradient flow w.r.t. the sum of Sinkhorn divergences to the target distributions. At the same time, it is worth mentioning, that \\[A\\] just simulates particles and does not build a generative model.\nRegarding the other strengths of the paper, I would like to note the well-organized Experiments section.\n\n\\[A\\] Sinkhorn Barycenter via Functional Gradient Descent, NeurIPS’2020 - Some theoretical results from the paper are known. For example, the statement of Theorem 1 could be found in \\[B\\] (eq. 26) or \\[C\\] (eq. 8). \n- The quality of the code provided is not good. There is no README/or other instruction to run the code. There are imports of non-existing classes. So, there is no possibility of checking (at least, qualitatively) the provided experimental results.\n\nFrom my point, the main weakness of the proposed paper is the limited methodological contribution. The authors simulate the particles of data following Sinkhorn divergence - as I already mentioned, this is not a super fresh idea. To make a generative model from these simulated trajectories, the authors simply solve the regression task to learn the local pushforward maps. And that is it. Combined with the fact, that the practical performance of the proposed approach is far from being SOTA in the generative modelling, the overall contribution of the paper seems for me to be limited. - My main question (and, probably, one of the main of my concerns) is regarding the proposed methodology. The authors propose to compute certain $\\mathcal{W}_{\\varepsilon}$ potentials (on discrete support of available samples) and then somehow take the gradients of these potentials w.r.t. the corresponding samples (eq. (13)). From the paper it is not clear how to compute the gradients, because the obtained potentials look like vectors of sample size shape, which are obtained through the iterations of the Sinkhorn algorithm. As I understand, in practice, the authors utilize SampleLoss from the geomloss package (\\[B\\]).  The outcome of this observation is that \\[B\\] should be properly cited when deriving the algorithm (section 4.2). I recommend authors explicitly use SampleLoss in the algorithm's listing. It will contribute to the clearness of what's going on. \n- The vector field of the Sinkhorn gradient flow is estimated by empirical samples. It is not clear how well this sample estimate approximates the true vector field. This point should be clarified. Note, that Theorem 2 works only for mean-field limit. \n- In the Introduction section, the authors consider a taxonomy of divergences used for gradient flow modelling, namely, \"divergences \\[...\\] with the same support\" and \"divergences \\[...\\]  with possible different support\". As I understand, the first class is about $f-$ divergences and the second class is about the other types (like Sinkhorn, MMD etc.). I have a question regarding the provided examples of works which deal with the former or the latter type of divergences. The fact is that the works \\[D\\], \\[E\\], \\[F\\], \\[G\\] deal with KL-divergence (or f-divergence) minimization. That is why I wonder why did the authors classify them as the second class.\n- A good work regarding poor expressiveness of ICNNs is \\[H\\].\n- What is the “ground” set ($\\S$ 3.1, first line).\n- Table 1. What are the differences between 1-RF, 2-RF and 3-RF methods?\n\n\\[B\\] Interpolating between Optimal Transport and MMD using Sinkhorn Divergences, AISTATS’2019\n\n\\[C\\] Sinkhorn Barycenters with Free Support via Frank-Wolfe Algorithm, NeurIPS’2019\n\n\\[D\\] Large-scale wasserstein gradient flows. NeurIPS'2021\n\n\\[E\\] Optimizing functionals on the space of probabilities with input convex neural networks. TMLR\n\n\\[F\\]  Proximal optimal tranport modeling of population dynamics. AISTATS\n\n\\[G\\] Variational wasserstein gradient flow. ICML\n\n\\[H\\] Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. NeurIPS’2021.",
         "827",
         "0",
         "8",
         "0.7673",
         "0.0867376775",
         "0.8458420038000001",
         "63",
         "23",
         "48.4494",
         "9.8761",
         "12.9425",
         "12.5739",
         "10.9848",
         "0.5343",
         "74",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "43",
         "ztuCObOc2i",
         "3768",
         "1695317147625",
         "['~Huminhao_Zhu1', '~Fangyikang_Wang1', '~Chao_Zhang19', '~Hanbin_Zhao1', '~Hui_Qian1']",
         "Neural Sinkhorn Gradient Flow",
         "Wasserstein Gradient Flows (WGF) with respect to specific functionals have been widely used in the machine learning literature. \nRecently, neural networks have been adopted to approximate certain intractable parts of the underlying Wasserstein gradient flow and result in efficient inference procedures. In this paper, we introduce the Neural Sinkhorn Gradient Flow (NSGF) model,  which parametrizes the time-varying velocity field of the Wasserstein gradient flow w.r.t. the Sinkhorn divergence to the target distribution starting a given source distribution.  We utilize the velocity field matching training scheme in NSGF, which only requires samples from the source and target distribution to compute an empirical velocity field approximation. Our theoretical analyses show that as the sample size increases to infinity, the mean-field limit of the empirical approximation converges to the true underlying velocity field. With specific source and target data samples, our NSGF models can be used in many machine learning tasks such as unconditional/conditional image generating, style transfer, and audio-text translations.  Numerical experiments with synthetic and real-world benchmark datasets support our theoretical results and demonstrate the effectiveness of the proposed method.",
         "Reviewer_MEFG",
         "1699146383667",
         "1699636332903",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces the idea of learning a time-dependent velocity field of the Sinkhorn Wasserstein gradient flow from samples from the target distribution to calculate the empirical velocity field approximations. The paper supports its claim by showing that the mean-field limit of this process recovers the true Sinkhorn Wasserstein gradient flow. They also validated the process with some empirical studies. The paper is well written and easy to follow. The proofs and arguments in the appendix are well-typed out and clear.  There are some nice diagrams in the empirical section to supports the claim the authors are making. I think the experiments could be more extensive. One thing about this method is to investigate the number of samples needed. effectively learn the velocity field. This is one important experiment missing as is remains unclear how sample-efficient the proposed method is. It would also make the paper more completing if the method is applied to generative models that output discrete random variable like binary mnist or even language modelling. One possible question is what happens if we change the source distribution to be closer to the target distribution like it was from a generator how would the method perform there. Another question is to better understand the sample complexity of the method as the current method may not be sample efficient due to the empirical distribution being approximated using the samples.",
         "230",
         "0",
         "0",
         "0.7569",
         "0.1872807018",
         "0.8377009034",
         "49",
         "5",
         "39.9077",
         "12.0883",
         "13.8595",
         "13.639",
         "12.502",
         "0.216",
         "99",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "44",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_JSi7",
         "1698680587788",
         "1699636955419",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This article discusses a method to improve the application of SLM in the medical field, utilizing LLM's medical proficiency to boost SLM performance in medical tasks under privacy-restricted scenarios which has important social significance. The method was tested on MedQA, HEADQA, MedMCQA, and MMLU-professional medicine datasets, showing some improvements over existing methods. Additionally, the authors compared results across different sizes of training sets. see summary 1). Imprecise example of Privacy Protection.\nThe example in Figure 1 indicates that personal privacy issues are only present in the first sentence, and the key words \"man\" and \"admitted\" in that sentence have almost no impact on the subsequent content. Could it then be possible to simply delete the first sentence to achieve privacy protection, as extracting key words here does not seem to play a significant role.\n\n2). Privacy Protection as an Innovation Point\nRegarding the extraction of key words for privacy protection, the paper uses a medical NER model proposed by Neumann et al in 2019. We suggest further improvement of this model, for example, considering age as a crucial keyword for certain diseases and extracting it as necessary to better enrich the innovative aspects of the paper.\n\n3). Ambiguity of Symbols in Annotations\nAnnotation 13 on page 8 only appears in the content of the article but is not explained.\n\n4) The overall innovation of the methodology needs improvement, as the majority of the content relies on existing methods, such as the medical NER (Named Entity Recognition) model. please see the weaknesses.",
         "251",
         "0",
         "3",
         "0.8122",
         "0.0869868637",
         "0.8446011543",
         "48",
         "11",
         "30.5608",
         "14.193",
         "18.2471",
         "16.5267",
         "14.5487",
         "0.1839",
         "83",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "45",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_gXvF",
         "1698819472631",
         "1699636955275",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This paper tried to improve the performance of small medical language models by introducing knowledge from large language models, which keeps the privacy of clinical text when using large language models.  The proposed method uses keywords instead of full raw text to generate initial evidence from LLM and feed the evidence to small language model. Privacy-preserving is an essential and common need when using LLM in clinical text. This paper tried to solve this problem by using keywords instead of raw text, the idea is novel and experiments demonstrated the effectiveness of this approach. 1. As this research utilized a named entity recognition model to extract keywords, it is possible that the NER model can extract privacy information such as patient names. Is there any filtering or postprocessing step to avoid that? In addition, it is not guaranteed that NER system will never extract sensitive patient information; for example, if the NER system incorrectly extracts a patient's address as a symptom, then the address may be leaked to LLM. Although it is very rare, it is still necessary to comment on this. \n2. As the LLM already provides a preliminary decision, I am curious about the performance if we only feed the preliminary decision from LLM to SLM. It is worth knowing which part of the LLM-generated information improves the SLM most. \n3. The related work section need to discuss more LLM application in the clinical area, especially the knowledge-enhanced LLM in clinical settings. For example, paper \"Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.\" also utilized external knowledge for clinical questions. \n4. By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem? By adding the LLM-generated content, will the new concatenated input be too long and out of the word window in SLM? How do you deal with the long content problem?",
         "326",
         "0",
         "4",
         "0.7696",
         "0.0399925075",
         "0.9072911739",
         "48",
         "9",
         "42.8243",
         "12.0502",
         "14.7872",
         "13.9505",
         "12.5318",
         "0.181",
         "108",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "46",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_TtE2",
         "1698819599156",
         "1700663756238",
         "6",
         "4",
         "2",
         "2",
         "3",
         "The paper studied medical QA problems by incorporating large language models (LLMs) to assist small-language models (SLMs). To protect the private information in the data, the authors propose to first extract keywords and then use the keywords to query LLMs for intermediate content which can be used for SLMs to enhance prediction accuracy. 1. (originality) The proposed method is novel by extracting keywords and privately incorporating LLM for SLM-based predictions.\n2. (clarity) Overall, the paper is fair in presentation. The demonstrations of synthetic medical data with private information and extracted keywords are helpful for understanding the concepts.\n3. (significance) Versus the compared baselines, the proposed methods significantly improve the prediction accuracy on three medical QA tasks.\n4. (quality) The authors thoroughly evaluate the performance of the proposed method. 1. (Clarity) There is no specific definition of the private information. From Figure 1, it seems that privacy definition is restricted to private identifiable information (PII). The authors should clarify the scope of privacy risks. Importantly, the proposed method cannot address general private information leakage that is considered by strict formulations like differential privacy.\n2. (Quality) The evaluation of privacy is not strict. \n  - Risks: It is possible that the keyword extraction includes private identifiable information (PII), for instance, names and dates as shown in Figure 1. There is no theoretical guarantee for privacy protection or empirical evaluation of the leakage rates of such PII.\n  - Metric: The authors used the privacy budget for quantifying privacy risks:  the ratio of the number of words provided to the LLM to the total words in the original question. However, I doubt if the metric can imply some privacy risks. There essentially lacks an intuitive explanation of the relationship between the privacy budget and privacy risks.\n3. (Motivation) As the authors said, SLM presents a large gap compared to LLMs and thus there is no clear motivation to use SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. In the paper, there is no referred evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks. Thus, I strongly doubt if the motivation of the paper can hold. * There is no clear motivation to see SLM for prediction. Although the authors mention that ChatGPT requires access to data, it is essentially ignored that open-source LLMs, for example, Llama, can be used. Is there any evidence for the large gap between open-source LLMs and ChatGPT on the concerned medical tasks?",
         "426",
         "0",
         "7",
         "0.7723",
         "0.0983912484",
         "0.9060524702",
         "59",
         "21",
         "36.5456",
         "12.5405",
         "15.7498",
         "14.4949",
         "13.1327",
         "0.1262",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "47",
         "ztpy1gsUpT",
         "7807",
         "1695486586687",
         "['~Xinlu_Zhang1', '~Shiyang_Li1', '~Xianjun_Yang1', '~Chenxin_Tian1', '~Yao_Qin1', '~Linda_Ruth_Petzold1']",
         "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting",
         "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability.",
         "Reviewer_EBQC",
         "1699202302455",
         "1701315616812",
         "6",
         "3",
         "3",
         "3",
         "3",
         "In situations where text data is subject to privacy protection constraints, this paper designs a small-scale language model to perform diagnoses of diseases. Utilizing the rich prior medical knowledge in LLM, the approach involves generating a medical knowledge-intensive context using privacy-protected text. This generated context, along with key terms extracted from the text and questions, is then input into the SLM, which is fine-tuned during training. Experiments across multiple datasets demonstrate that this fine-tuning process effectively enhances the accuracy of the diagnostic model. 1. This paper focuses on a very important research topic in the field of medicine: how to effectively extract more useful information from incomplete text under the conditions of privacy protection. The author has made full use of the domain knowledge in LLM to effectively fine-tune the SLM, which ensures that the lightweight models can achieve high accuracy.\n\n2. This paper presents rich and comprehensive experiments. Beyond basic decision-making tasks, it also explores solutions for few-shot experiments and out-of-distribution (OOD) model generalization using the methods discussed in this paper.\n\n3. This paper fully utilizes the rich domain knowledge in LLMs to expand the knowledge base of medical reports, achieving excellent diagnostic accuracy even while ensuring privacy protection. 1. The contribution of this paper to the algorithm and the significance of the clinical problems it addresses seem not to be very high.\n\n2. The main work of this paper appears more as an engineering problem, transferring domain knowledge from LLMs to SLMs. From the perspective of algorithmic contribution, there seems to be some room for improvement. 1. The experimental datasets in this paper are all question-and-answer test datasets, and whether the methods of this paper are applicable to medical report datasets requires additional experimentation. This is because in medical reports, how to generate high-quality questions using other LLM interfaces is a question worth studying.\n\n2. Large language models provide additional domain knowledge, but in the context of specific medical tasks, will the direct transfer of knowledge from LLMs to SLMs lead to incorrect information leakage into SLMs? How can we ensure that LLMs only enhance information relevant to the current medical issue without introducing additional errors or irrelevant information? This is a very important issue in the medical field, as it directly relates to patient diagnosis.",
         "378",
         "0",
         "7",
         "0.8087",
         "0.1651777003",
         "0.9162929654",
         "67",
         "24",
         "24.0186",
         "15.4331",
         "18.2063",
         "16.3464",
         "16.6892",
         "0.09870000000000001",
         "96",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "48",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E\\[x_t^\\top \\eta\\]>0$, where $E\\[\\cdot\\]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9",
         "0.7199",
         "0.1048061787",
         "0.9118013978",
         "49",
         "12",
         "45.2022",
         "10.9542",
         "14.0176",
         "13.1874",
         "11.7498",
         "0.1041",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "49",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9",
         "0.8034",
         "0.040322580600000005",
         "0.9313320518",
         "49",
         "9",
         "50.8505",
         "9.2389",
         "11.4157",
         "11.538",
         "10.4235",
         "0.1822",
         "96",
         "0",
         "0",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 28028
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_eS3u</td>\n",
       "      <td>1698243150596</td>\n",
       "      <td>1699636093263</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6186</td>\n",
       "      <td>17.9130</td>\n",
       "      <td>16.0443</td>\n",
       "      <td>17.8357</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_jP4i</td>\n",
       "      <td>1698652503617</td>\n",
       "      <td>1699636093190</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0899</td>\n",
       "      <td>17.5302</td>\n",
       "      <td>15.9032</td>\n",
       "      <td>16.5285</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_wiS9</td>\n",
       "      <td>1698706547448</td>\n",
       "      <td>1699636093122</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5403</td>\n",
       "      <td>12.0174</td>\n",
       "      <td>11.8969</td>\n",
       "      <td>11.5244</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_a6Ps</td>\n",
       "      <td>1698768293694</td>\n",
       "      <td>1699636092942</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8007</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>13.1410</td>\n",
       "      <td>11.9551</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>1647</td>\n",
       "      <td>1695102158671</td>\n",
       "      <td>[~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Reviewer_Frem</td>\n",
       "      <td>1699350072271</td>\n",
       "      <td>1699636092872</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8574</td>\n",
       "      <td>13.8000</td>\n",
       "      <td>13.1060</td>\n",
       "      <td>11.3839</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28023</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_vt7i</td>\n",
       "      <td>1698673110283</td>\n",
       "      <td>1699636153803</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0579</td>\n",
       "      <td>12.7786</td>\n",
       "      <td>12.5508</td>\n",
       "      <td>10.3710</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28024</th>\n",
       "      <td>014CgNPAGy</td>\n",
       "      <td>2200</td>\n",
       "      <td>1695179071455</td>\n",
       "      <td>[~Bochen_Lyu1, ~Zhanxing_Zhu1]</td>\n",
       "      <td>On the Role of Momentum in the Implicit Bias o...</td>\n",
       "      <td>Momentum is a widely adopted and crucial modif...</td>\n",
       "      <td>Reviewer_oaZ7</td>\n",
       "      <td>1698928691830</td>\n",
       "      <td>1699636153728</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8753</td>\n",
       "      <td>13.4660</td>\n",
       "      <td>12.9318</td>\n",
       "      <td>11.0496</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28025</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_fMm6</td>\n",
       "      <td>1698618130371</td>\n",
       "      <td>1699636636496</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2763</td>\n",
       "      <td>15.9379</td>\n",
       "      <td>14.6494</td>\n",
       "      <td>14.6519</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28026</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_tZQw</td>\n",
       "      <td>1698807944071</td>\n",
       "      <td>1699636636378</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11.3380</td>\n",
       "      <td>13.3077</td>\n",
       "      <td>12.5694</td>\n",
       "      <td>11.8039</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28027</th>\n",
       "      <td>0074qaufB6</td>\n",
       "      <td>5962</td>\n",
       "      <td>1695403263602</td>\n",
       "      <td>[~Subrata_Kumar_Biswas1, ~Bashima_Islam1]</td>\n",
       "      <td>InfoNet: Missing Information Retrieval in Mult...</td>\n",
       "      <td>Faulty sensors in a multiple input stream setu...</td>\n",
       "      <td>Reviewer_9qjF</td>\n",
       "      <td>1698910414535</td>\n",
       "      <td>1699636636278</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>16.9199</td>\n",
       "      <td>19.5537</td>\n",
       "      <td>17.1577</td>\n",
       "      <td>17.8347</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28028 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zzv4Bf50RW               1647             1695102158671   \n",
       "1        zzv4Bf50RW               1647             1695102158671   \n",
       "2        zzv4Bf50RW               1647             1695102158671   \n",
       "3        zzv4Bf50RW               1647             1695102158671   \n",
       "4        zzv4Bf50RW               1647             1695102158671   \n",
       "...             ...                ...                       ...   \n",
       "28023    014CgNPAGy               2200             1695179071455   \n",
       "28024    014CgNPAGy               2200             1695179071455   \n",
       "28025    0074qaufB6               5962             1695403263602   \n",
       "28026    0074qaufB6               5962             1695403263602   \n",
       "28027    0074qaufB6               5962             1695403263602   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "1      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "2      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "3      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "4      [~Chunghyun_Park1, ~Seungwook_Kim2, ~Jaesik_Pa...   \n",
       "...                                                  ...   \n",
       "28023                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28024                     [~Bochen_Lyu1, ~Zhanxing_Zhu1]   \n",
       "28025          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28026          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "28027          [~Subrata_Kumar_Biswas1, ~Bashima_Islam1]   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "1      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "2      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "3      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "4      Learning SO(3)-Invariant Correspondence via Po...   \n",
       "...                                                  ...   \n",
       "28023  On the Role of Momentum in the Implicit Bias o...   \n",
       "28024  On the Role of Momentum in the Implicit Bias o...   \n",
       "28025  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28026  InfoNet: Missing Information Retrieval in Mult...   \n",
       "28027  InfoNet: Missing Information Retrieval in Mult...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Establishing accurate dense 3D correspondences...  Reviewer_eS3u   \n",
       "1      Establishing accurate dense 3D correspondences...  Reviewer_jP4i   \n",
       "2      Establishing accurate dense 3D correspondences...  Reviewer_wiS9   \n",
       "3      Establishing accurate dense 3D correspondences...  Reviewer_a6Ps   \n",
       "4      Establishing accurate dense 3D correspondences...  Reviewer_Frem   \n",
       "...                                                  ...            ...   \n",
       "28023  Momentum is a widely adopted and crucial modif...  Reviewer_vt7i   \n",
       "28024  Momentum is a widely adopted and crucial modif...  Reviewer_oaZ7   \n",
       "28025  Faulty sensors in a multiple input stream setu...  Reviewer_fMm6   \n",
       "28026  Faulty sensors in a multiple input stream setu...  Reviewer_tZQw   \n",
       "28027  Faulty sensors in a multiple input stream setu...  Reviewer_9qjF   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1698243150596           1699636093263              6  ...   \n",
       "1      1698652503617           1699636093190              5  ...   \n",
       "2      1698706547448           1699636093122              3  ...   \n",
       "3      1698768293694           1699636092942              5  ...   \n",
       "4      1699350072271           1699636092872              5  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "28023  1698673110283           1699636153803              5  ...   \n",
       "28024  1698928691830           1699636153728              3  ...   \n",
       "28025  1698618130371           1699636636496              1  ...   \n",
       "28026  1698807944071           1699636636378              3  ...   \n",
       "28027  1698910414535           1699636636278              5  ...   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "0                   14.6186      17.9130     16.0443   \n",
       "1                   14.0899      17.5302     15.9032   \n",
       "2                    9.5403      12.0174     11.8969   \n",
       "3                   10.8007      13.4756     13.1410   \n",
       "4                   10.8574      13.8000     13.1060   \n",
       "...                     ...          ...         ...   \n",
       "28023               10.0579      12.7786     12.5508   \n",
       "28024               10.8753      13.4660     12.9318   \n",
       "28025               13.2763      15.9379     14.6494   \n",
       "28026               11.3380      13.3077     12.5694   \n",
       "28027               16.9199      19.5537     17.1577   \n",
       "\n",
       "       automated_readability_index politeness_score  hedge_C  hedge_D  \\\n",
       "0                          17.8357           0.1213       78        0   \n",
       "1                          16.5285           0.1719       73        0   \n",
       "2                          11.5244           0.0503       77        0   \n",
       "3                          11.9551           0.1290       85        0   \n",
       "4                          11.3839           0.1864       81        0   \n",
       "...                            ...              ...      ...      ...   \n",
       "28023                      10.3710           0.2111       90        0   \n",
       "28024                      11.0496           0.1100      100        1   \n",
       "28025                      14.6519           0.1507       98        0   \n",
       "28026                      11.8039           0.0720       99        0   \n",
       "28027                      17.8347           0.0917       74        0   \n",
       "\n",
       "       hedge_E hedge_I  hedge_N  \n",
       "0            0       0        0  \n",
       "1            0       0        0  \n",
       "2            0       0        0  \n",
       "3            2       0        0  \n",
       "4            0       0        0  \n",
       "...        ...     ...      ...  \n",
       "28023        0       0        0  \n",
       "28024        0       0        0  \n",
       "28025        1       0        0  \n",
       "28026        0       0        0  \n",
       "28027        0       0        0  \n",
       "\n",
       "[28028 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6f45bdc7-77e8-493a-9894-3d14920451c3",
       "rows": [
        [
         "0",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_AvJq",
         "1688368213177",
         "1702411303415",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes. 1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\n 1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\n 1. Checking some details in the paper, such as illustration, etc, corresponding to the paper.\n2. Adding the basis of classifying uncertain samples into three categories, or relevant explanations.\n3. Adding the explanation of DAUC approach model-agnostic.\n Is DAUC a model-agnostic approach that can be extended to other tasks or domains?",
         "225",
         "0",
         "8",
         "0.7494000000000001",
         "0.0416666667",
         "0.9411299229000001",
         "215",
         "162",
         "33.6037",
         "12.872",
         "15.9897",
         "14.4442",
         "13.2649",
         "0.09480000000000001",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_7E4k",
         "1688505633161",
         "1702411303319",
         "6",
         "4",
         "3",
         "3",
         "4",
         "In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure.  In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow. See questions. * In my opinion, at a high level, this method basically computes the kernel similarity scores between the test data and the samples in the train/val distribution in the latent space to find out whether the test sample is OOD, bnd etc. How does the choice of the layer chosen impact the categorization ? Does this change ? This is because, the earlier layers can capture only the basic semantics and the discrepancies between inliers and the suspicious samples may not be captured.\n\n* How exactly is uncertainty from the model computed ? Is epistemic uncertainty alone computed for first filtering the suspicious vs safe samples, or the total uncertainty ? Writing a brief section about the same either in the main/supplement will be beneficial for the reader.\n\n* Can the authors comment on how effective the proposed approach will be to handle open-set data or OOD/anamolous data samples for e.g,  classes unseen during training ? Consider that there is an unc. estimator that is sensitive to open-set data and flags the sample as suspicious. Will the kernel density estimate score that categorizes OOD data in your formulation be able to capture such subtle shifts ? These open-set data need not share the same labels as that of your training data, but share a large amount of semantic information ?\n\n* For computing the confusion density matrix elements for the bnd and IDM samples, how does the properties of the validation data impact the estimation ? For e.g., A certain class c1 can offer no misclassification while another class c2 offers a greater amount of misclassification. \n\n* Can the authors comment on the scalability of the algorithm ? For instance, if the number of classes exceeds K (K>=100),  it is required to obtain a K x K matrix.\n Yes, the limitations have been listed by the authors in the supplementary.  However, in my opinion,  I am skeptical about the scalability of the approach as well as its ability to handle data from open-set recognition conditions.  ",
         "513",
         "0",
         "1",
         "0.7788",
         "0.1071362434",
         "0.947173357",
         "215",
         "160",
         "32.9398",
         "13.0922",
         "15.3049",
         "14.1918",
         "12.6374",
         "0.069",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_hHZH",
         "1688552936677",
         "1702411303221",
         "6",
         "4",
         "3",
         "3",
         "2",
         "I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\n***\n***\n***\n***\n\n\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models. The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \n\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\n\nThe example in Section 4.1 is quite neat, it provides good intuition.\n\nThe use case in Section 4.4 seems potentially useful. I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\n\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\n\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n\nSmall thing:\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\". 1. Can the proposed method be applied to datasets with a lot more classes (e.g. 1000 classes)? Does the confusion density matrix become expensive to compute? What happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\n\n2. Does the validation set have be large, to ensure that the corpus C_{c1 --> c2} contains at least a few examples for each pair of classes? Does it have to be much bigger for e.g. 1000 classes than 10 classes?\n\n3. For the use case in Section 4.3, could you clarify how the Bnd/IDM categorization is useful? What type of conclusions does it enable? Could it be used as evidence that uncertainty estimation method X is better than method Y?\n\n4. Would it be possible to repeat the experiment in Section 4.4 on a larger dataset with more classes?\n\n\nMinor things:\n- Figure 1 caption: \"into four classes\" --> \"into three classes\"?\n- Line 104: \"for what a\" --> \"for why a\"?\n- Line 197: \"an different\" --> \"a different\".\n- In Section 3.1 the term \"inference-time\"/\"inference time\" is used, but in the rest of the paper \"test-time\"/\"test time\" is used?\n- In Definition 3 - 5 the full term \"confusion density matrix\" is used, but in the text in Section 3.3.1 and 3.3.2 just \"confusion matrix\" is used. Would it be more clear to always use the full term? Yes.",
         "650",
         "0",
         "6",
         "0.7975",
         "0.0933876124",
         "0.8911411762",
         "215",
         "160",
         "60.5595",
         "7.72",
         "10.1878",
         "10.7063",
         "7.5081",
         "0.16010000000000002",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "zyhxRc9bew",
         "10819",
         "1683789038840",
         "['~Hao_Sun1', '~Boris_van_Breugel2', '~Jonathan_Crabbé1', '~Nabeel_Seedat1', '~Mihaela_van_der_Schaar2']",
         "What is Flagged in Uncertainty Quantification?  Latent Density Models for Uncertainty Categorization",
         "Uncertainty quantification (UQ) is essential for creating trustworthy machine learning models. Recent years have seen a steep rise in UQ methods that can flag suspicious examples, however, it is often unclear what exactly these methods identify. In this work, we propose a framework for categorizing uncertain examples flagged by UQ methods. We introduce the confusion density matrix---a kernel-based approximation of the misclassification density---and use this to categorize suspicious examples identified by a given uncertainty method into three classes: out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM). Through extensive experiments, we show that our framework provides a new and distinct perspective for assessing differences between uncertainty quantification methods, thereby forming a valuable assessment benchmark.",
         "Reviewer_sVgx",
         "1688657604892",
         "1702411303144",
         "6",
         "4",
         "2",
         "3",
         "3",
         "Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models. To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\n\nSummary of strengths\n- Novel view on uncertainty quantification\n- Work in practice, at least in given classification tasks\n- Well-made empirical evaluation (see also weaknesses) There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\n\nSummary of weaknesses\n- Limited analysis of model assumptions and density estimation\n- Somewhat limited type of datasets and model architectures evaluated\n- Some polishing of text here and there (see questions)\n - Table 1: Could you ellaborate why other related approaches could not be used to improve the prediction? (if threshold is determined for the uncertainty estimates these methods are utilising). I see prediction improvement more related to use case than general property of particular method directly. It might be not give better predictive accuracy than proposed method, but is doable.\n- Figure 4: What is clustering/projecting method used? Maybe mention in the text.\n- Figure 5 & 6: How error bars are calculated? Maybe mention in the text.\n\nMinor\n- DAUC is developed for classification tasks in specific. Maybe that could be mentioned in the abstract.\n Some of the assumptions and limitations of proposed framework are listed in the supplementary material in relation to model structure and latent space density estimation. Furthermore, the usefulness of UQ are broader sense are mention as an important part of safety critical AI applications. No negative impact identified.",
         "453",
         "0",
         "1",
         "0.8136",
         "0.1130384199",
         "0.8543175459000001",
         "215",
         "159",
         "24.6842",
         "14.3916",
         "17.9549",
         "16.1666",
         "14.582699999999999",
         "0.5533",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_9QKU",
         "1688617232745",
         "1702411520565",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions. This paper analyzes shortcut learning theoretically in terms of margin maximization.\nI have not seen an analysis from this perspective before.\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning. The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models. It seems that this paper forcus on a theoretical analysis in a situation like background shortcuts, where shortcut features make up a large portion of the data as shown in term B. \nLearning  features with a large B preferentially is intuitively reasonable in such a simple situation; however, reading the proof in the Appendix, it seems to require a very tough proof to show that. \nI would like to know where the difficulty of the proof lies, what you devised in the Appendix proof ,and where you derived the key inequality.\n\nShortcut features do not always occupy as much space as stable features as background features. For example, in the following paper, the percentage of partial input is much smaller.\n>Overinterpretation reveals image classification model pathologies Brandon Carter, Siddhartha Jain, Jonas Mueller, David Gifford\nIsn't Bz>y important for the theoretical analysis?\nIf Bz<y, what part of the proof is more difficult? Or what other assumptions are necessary?\n\n\n\n The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.",
         "307",
         "0",
         "0",
         "0.8162",
         "0.0243987494",
         "0.946657896",
         "215",
         "159",
         "36.1512",
         "13.3014",
         "14.7013",
         "14.2653",
         "13.4733",
         "0.0671",
         "97",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "5",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_PgqC",
         "1688644377742",
         "1702411520475",
         "5",
         "3",
         "4",
         "4",
         "4",
         "This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM's inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method. -This paper presents a thorough analysis of the shortcut learning problem. \n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\n-The paper is well-written and easy to understand. -Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not. -How does MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated? Does this affect the effectiveness of MARG-CTRL?\n-What are the trade-offs involved in using MARG-CTRL versus two-stage shortcut-mitigating methods??\n-Are there specific scenarios or types of tasks for which MARG-CTRL may not be as effective? Please see the weaknesses part.",
         "288",
         "0",
         "0",
         "0.788",
         "0.15018518520000002",
         "0.9463365078",
         "215",
         "159",
         "41.9838",
         "11.8751",
         "12.2",
         "12.1617",
         "14.5053",
         "0.1376",
         "89",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_Xk5J",
         "1688686540169",
         "1702411520381",
         "6",
         "3",
         "3",
         "3",
         "3",
         "Having had my concerns addressed by the authors I have updated my score.\n-----------------------------------------------------------------------------------------\n\n\n\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\n* The authors propose a nice example and demonstrate the results on vision and language datasets. * The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \n* The comments and explanations are clear and concise, and follow a clear narrative.\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\n* The experiments are well conducted and clearly support their statements * I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm. * The examples in the paper tend to be restricted to linear models, which is not the case in most perception systems, do you have any intuition if these conclusions carry through to a non-linear case? I'm aware it makes the analysis harder, and I'm not asking you to perform it. But it would be nice to hear any issues that may arrise.\n* Are there any experiments in the non over-parameterised setting? As this is discussed in the paper, I would have expected to see them in the experiments.\n* Do you think these shortcuts are a bit artifificial? For instance in the waterbirds dataset, the background should be an important feature in the decision, but not the primary feature, does this method enable predictions from multiple features? Or do you think it will just rely on one? Not explicitly discussed",
         "397",
         "0",
         "1",
         "0.7687",
         "0.2258405483",
         "0.9238996506",
         "215",
         "158",
         "51.7726",
         "10.363",
         "13.4388",
         "13.0239",
         "10.8601",
         "0.08660000000000001",
         "34",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "7",
         "zyZkaqNnpa",
         "15594",
         "1683835167534",
         "['~Aahlad_Manas_Puli1', '~Lily_H_Zhang1', '~Yoav_Wald1', '~Rajesh_Ranganath2']",
         "Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy",
         "Common explanations for shortcut learning assume that the shortcut improves prediction only under the training distribution. Thus, models trained in the typical way by minimizing log-loss using gradient descent, which we call default-ERM, should utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM exhibits shortcut learning. Why are such solutions preferred when the loss can be driven to zero when using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin, even without overparameterization, leads to models that depend more on the shortcut than the stable feature. This insight suggests that default-ERM’s implicit inductive bias towards max-margin may be unsuitable for perception tasks. Instead, we consider inductive biases toward uniform margins. We show that uniform margins guarantee sole dependence on the perfect stable feature in the linear perception task and suggest alternative loss functions, termed margin control (MARG-CTRL), that encourage uniform-margin solutions. MARG-CTRL techniques mitigate shortcut learning on a variety of vision and language tasks, showing that changing inductive biases can remove the need for complicated shortcut-mitigating methods in perception tasks.",
         "Reviewer_8MoS",
         "1688704489779",
         "1702411520262",
         "6",
         "3",
         "3",
         "2",
         "3",
         "This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks. * Experiments show good results for their methods. * The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \n* The graphs are tough to read (too small) and the legends overlap with the plots. * How does the dimensionality (e.g., choosing $d=100$) come into play? The story setting up the analogy does not in principle rely on the dimensionality all, just the gradient sizes of the noisy and true signals. I'm guessing it has something to do with interpolation, but I think it'd be good to have further discussion of this.\n* What's the connection between the neural network trained in section 2.1 and the linear model theorems? What happens if you train a logistic regression model instead?\n* Similar toy settings as in this paper (such as (Sagawa et al., 2020)) have been examined in the past and seemed to rely on overparameterization for their phenomena. What are the particulars in this paper's setup that allow us to observe phenomena in the underparameterized setting?\n* How should I think of the different MARG-CTRL? What factors cause their difference in performance and how should I make the decision in which to pick? The authors adequately addressed the limitations.",
         "291",
         "1",
         "0",
         "0.7917000000000001",
         "0.0843567251",
         "0.8677315712",
         "215",
         "158",
         "53.0107",
         "9.3931",
         "11.5955",
         "11.6982",
         "9.6732",
         "0.2889",
         "95",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "8",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_Ai1a",
         "1687187527651",
         "1702410739080",
         "8",
         "4",
         "3",
         "3",
         "2",
         "The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\left(y^R | \\tilde x\\right)\\cdot p\\left(\\tilde x | x\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness.  The core idea of this paper is technically novel and clearly presented.\n\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\lambda_1$ and $\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\n\nThe authors also provide theoretical results to justify the rationality of the AIR term. The proposed method would require more tunning since it incorporates two more hyper-parameters $\\lambda_1$ and $\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\lambda_1=0,\\ \\lambda_2>0$), incorporating AIR with SIR (i.e., $\\lambda_1>0,\\ \\lambda_2>0$) could result in better **robust accuracy**.\n\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\n\n--- Update ---\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8. See \"Weaknesses\" part. N.A.",
         "228",
         "0",
         "2",
         "0.7698",
         "0.1875",
         "0.8994294405000001",
         "235",
         "176",
         "38.6184",
         "11.5496",
         "13.3074",
         "13.0239",
         "13.0732",
         "0.157",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "9",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_paeS",
         "1687405291359",
         "1702410738990",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released. 1. The idea is interesting and easy to understand.\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\n 1. The improvement of the proposed method is limited.\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet. Shown as Weaknesses. Shown as Weaknesses.",
         "138",
         "0",
         "7",
         "0.6733",
         "0.2161904762",
         "0.8820936084000001",
         "235",
         "173",
         "36.9973",
         "10.9559",
         "13.2957",
         "12.7451",
         "11.1124",
         "0.1149",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "10",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_ZaSM",
         "1688468187665",
         "1702410738918",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines. 1. The paper is well-written and easy to follow.\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\n3. The experiments on various datasets show improvement.\n I have several concerns:\n\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\n\nMinors:\n\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\tau_i$ and $\\tau_j$.\n\n 1. Please include the comparison with baseline in Table 4.\n2. Please include more evaluation on WideResNet.\n The authors have discussed the limitations.",
         "184",
         "0",
         "6",
         "0.7925000000000001",
         "0.0643939394",
         "0.9252514839",
         "235",
         "161",
         "32.6263",
         "11.3975",
         "13.0251",
         "12.3198",
         "10.8339",
         "0.22690000000000002",
         "90",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "11",
         "zuXyQsXVLF",
         "327",
         "1682066194522",
         "['~Xilie_Xu1', '~Jingfeng_Zhang1', '~Feng_Liu2', '~Masashi_Sugiyama1', '~Mohan_Kankanhalli1']",
         "Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization",
         "Adversarial contrastive learning (ACL) is a technique that enhances standard contrastive learning (SCL) by incorporating adversarial data to learn a robust representation that can withstand adversarial attacks and common corruptions without requiring costly annotations. To improve transferability, the existing work introduced the standard invariant regularization (SIR) to impose style-independence property to SCL, which can exempt the impact of nuisance style factors in the standard representation. However, it is unclear how the style-independence property benefits ACL-learned robust representations. In this paper, we leverage the technique of causal reasoning to interpret the ACL and propose adversarial invariant regularization (AIR) to enforce independence from style factors. We regulate the ACL using both SIR and AIR to output the robust representation. Theoretically, we show that AIR implicitly encourages the representational distance between different views of natural data and their adversarial variants to be independent of style factors. Empirically, our experimental results show that invariant regularization significantly improves the performance of state-of-the-art ACL methods in terms of both standard generalization and robustness on downstream tasks. To the best of our knowledge, we are the first to apply causal reasoning to interpret ACL and develop AIR for enhancing ACL-learned robust representations. Our source code is at https://github.com/GodXuxilie/Enhancing_ACL_via_AIR.",
         "Reviewer_fVht",
         "1688722500298",
         "1702410738854",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100. - Theoretically, it explained how the KL divergence can provide invariant regularization.\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations. - The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper \\[1\\], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\n\n\\[1\\] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021 - It would be good to mention y^R in the main text.\n- In equation 3, adversarial for x_k^i and x_k^j is expressed in one formula. I'm curious if x_k^j also gets its perturbation updated when creating the adversarial for x_k^i.\n- It would be great to mention how much performance difference there is, how much slower the speed is, and how much the transferability improves when compared to Supervised Adversarial Training (Madry, TRADES). - There is a limitation in the hyperparameter tuning of lambda1 and lambda2.\n- There is a limitation that the gain in performance is marginal.",
         "407",
         "2",
         "0",
         "0.8056000000000001",
         "0.1709677419",
         "0.9168287516",
         "235",
         "158",
         "29.5424",
         "13.7997",
         "16.3372",
         "14.8897",
         "13.9196",
         "0.1695",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "12",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_yZYM",
         "1687462207886",
         "1702410758348",
         "4",
         "4",
         "3",
         "2",
         "3",
         "This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach. The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models. 1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\n\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \n\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on \\[1\\], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\n\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\% on IN-1K with ViT-B).\n\nReferences\n\\[1\\] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet\\[J\\]. arXiv preprint arXiv:2212.06138, 2022. See weakness. The authors have included discussion on the limited gain over Distill-CLIP.",
         "605",
         "2",
         "8",
         "0.769",
         "0.0856869942",
         "0.8494880199",
         "230",
         "173",
         "47.6531",
         "10.0229",
         "12.4446",
         "12.1617",
         "10.673",
         "0.0376",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "13",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_dWYQ",
         "1688577265853",
         "1702410758259",
         "5",
         "5",
         "1",
         "1",
         "2",
         "This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes. The findings on the relationship between diversity and architecture are interesting 1. The presentation quality of this work is bad due to the following reasons:\n\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \n\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\n\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\n\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies \\[1\\]\\[2\\]\\[3\\]\\[4\\] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\n\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\n\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as \\[5\\]\\[6\\]\\[7\\], should have been included and compared.\n\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\n\n\n\\[1\\] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\n\n\\[2\\] DINOv2: Learning Robust Visual Features without Supervision\n\n\\[3\\] Masked Feature Prediction for Self-Supervised Visual Pre-Training \n\n\\[4\\] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\n\n\\[5\\] Mimco: Masked image modeling pre-training with contrastive teacher.\n\n\\[6\\] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\n\n\\[7\\] Contrastive Masked Autoencoders are Stronger Vision Learners See above None",
         "407",
         "14",
         "4",
         "0.7735000000000001",
         "0.0323340548",
         "0.8710070252000001",
         "230",
         "160",
         "28.8865",
         "13.6155",
         "16.716",
         "15.2184",
         "16.0264",
         "0.11520000000000001",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "14",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_CGRR",
         "1688582035480",
         "1702410758195",
         "4",
         "3",
         "2",
         "2",
         "2",
         "This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties. * Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\n* Explanation with analyses (NMI, AHD, and attention map visualization)\n* The paper is clearly written * When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\n\n* Some values in tables are different to original values in references.\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\n\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\n\n* Some points are not understandable\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\n * How much more inefficient is Hybrid Distill compared to MAE?\n* It may be better to remove unnecessary area in the right graph in Fig. 3(a)\n * Its computational inefficiency was my primary concern, and the authors addressed it in the limitations section.",
         "312",
         "0",
         "0",
         "0.6853",
         "0.1509199134",
         "0.845987916",
         "230",
         "160",
         "40.8168",
         "10.9426",
         "12.2591",
         "12.4048",
         "10.0477",
         "0.0917",
         "73",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "15",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_5Rvs",
         "1689767626743",
         "1702410758135",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\nThis hybrid distillation achieves significant improvement on downstream tasks.\n - The paper is well written, with sufficient experiments and analysis. \n- The accuracy improvement is significant. - The paper has some minor typo errors.\n 1. Figure 4 seems to be wrong, it should be NMI(normalized mutual information), not attention distance.\n2. For ViT-B, is the 300-epoch distillation saturated? Would more epochs of distillation bring larger gains? \n3. For ViT-L, is there an obvious difference between using ImageNet-21K dataset and ImageNet-1K dataset? Is the performance improvement due to using ImageNet-21K dataset? Can you provide evaluation results trained on the ImageNet-1K dataset?\n4. For the objective function, is it feasible to adjust the weight of the CL branch \\[e.g.$ \\alpha D ( T_{c}(x) \\odot M, S_{\\theta}(M \\odot x) ) $\\]?  Does the impact of branch CL have to be larger than branch MIM?\n5. Are the classification results fair(CIFAR-100, Cars, INaturalist19 )? Can you use a unified setting to finetune the models(MAE, DeiT)? - Hybrid Distill does not improve CLIP as much as DeiT after introducing the MAE teacher. The authors could spend more pages analyzing the relationship between the MIM branch and the CL branch, as well as the underlying reasons.",
         "230",
         "0",
         "5",
         "0.7703",
         "0.125",
         "0.8415295482",
         "230",
         "146",
         "44.4485",
         "9.9623",
         "12.962",
         "12.2092",
         "10.5219",
         "0.2071",
         "85",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "16",
         "ztqf6bzuqQ",
         "801",
         "1682507396411",
         "['~Bowen_Shi2', '~XIAOPENG_ZHANG7', '~Yaoming_Wang1', '~Jin_Li10', '~Wenrui_Dai1', '~Junni_Zou1', '~Hongkai_Xiong1', '~Qi_Tian3']",
         "Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners",
         "Representation learning has been evolving from traditional supervised training to Contrastive Learning (CL) and Masked Image Modeling (MIM). Previous works have demonstrated their pros and cons in specific scenarios, i.e., CL and supervised pre-training excel at capturing longer-range global patterns and enabling better feature discrimination, while MIM can introduce more local and diverse attention across all transformer layers. In this paper, we explore how to obtain a model that combines their strengths. We start by examining previous feature distillation and mask feature reconstruction methods and identify their limitations. We find that their increasing diversity mainly derives from the asymmetric designs, but these designs may in turn compromise the discrimination ability. In order to better obtain both discrimination and diversity, we propose a simple but effective Hybrid Distillation strategy, which utilizes both the supervised/CL teacher and the MIM teacher to jointly guide the student model. Hybrid Distill imitates the token relations of the MIM teacher to alleviate attention collapse, as well as distills the feature maps of the supervised/CL teacher to enable discrimination. Furthermore, a progressive redundant token masking strategy is also utilized to reduce the distilling costs and avoid falling into local optima. Experiment results prove that Hybrid Distill can achieve superior performance on different benchmarks.",
         "Reviewer_gLfn",
         "1690326191085",
         "1702410758029",
         "6",
         "5",
         "4",
         "3",
         "3",
         "This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\n\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy. The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive. - Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\n\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \n\n- Similarly, on line 156 the notation S' is introduced without explanation. Please consider defining or explaining how S' is derived.\n\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method. - -",
         "305",
         "0",
         "1",
         "0.808",
         "0.1030952381",
         "0.8639517426000001",
         "230",
         "139",
         "21.7635",
         "14.5932",
         "18.2728",
         "16.0526",
         "15.1145",
         "0.3007",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "17",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_rRxj",
         "1688626829175",
         "1702411111578",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner. (+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\n\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\n\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \n\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks.  (-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper's contribution and demonstrate the advantages of the proposed approach.\n\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\n\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\n    \n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\n\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \n\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\n\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\n\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\'a\\v{s}ek et al, below.\n\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\n\n- Ramp\\'a\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022. (-) It is mentioned that Equitable partitions imply an upper bound on the expressivity of Graph Neural Networks while citing references \\[26\\] and \\[43\\]. There is nothing of that sort in these papers. Could you point out where such results are mentioned in the said references. \n\n(-) As coarsest equitable partition is an important concept for the paper, an example to illustrate this concept or a proper reference to another paper is vital and missing in the draft.\n\n(-)  As mentioned in the \"weakness\", can you explain more rigorously the motivation for using equitable partitions for node role discovery.\n\n(-)  In Theorem 3, what is the interpretation of the parameter $\\delta$ and what is the computational complexity to calculate it?\n\n(A minor comment) There are minor grammatical errors, e.g.,\n\n-  \"Thus, from any node $v$ within in the same class ...\" (in is not needed).\n\n- \"This also allows for Gradient Descent approaches like e.g. GNNs.\" (like and e.g., are used simultaneously).\n\n The limitations and possibly approaches to tackle these limitations are presented in the paper.",
         "810",
         "2",
         "3",
         "0.8097000000000001",
         "0.125577812",
         "0.9384059906000001",
         "216",
         "159",
         "37.8687",
         "11.8256",
         "14.7024",
         "13.9801",
         "12.3945",
         "0.5343",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "18",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_nMtV",
         "1688663151312",
         "1702411111496",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks. - The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\n\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\n\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method. - Baseline selection. Some relevant and/or important baselines have not been compared.\n\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\n\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper. Most of my questions are related to the experiments:\n- There are some relevant baselines that are not compared, for example, MMSB \\[1\\] and RIDRs \\[2\\]. The first one you can also discuss the relation with your proposed method, e.g., if it is possible to extend the proposed method to soft role assignment like MMSB. The second method is also based on equitable partitions.\n\n- There are some commonly used datasets that can be used for evaluating role discovery, for example, these datasets used in \\[3\\].\n\n- In previous role discovery studies, different downstream tasks have been selected to show the effectiveness of the discovered roles, e.g., node classification and link prediction. For example, these tasks in RolX \\[4\\] and struc2vec \\[3\\]. Also, there is no evaluation of the discovered roles. For example, in RolX, the quantitative evaluation using clustering metric has been used.\n\n- Efficiency issue. Although the proposed method is technically sound, a question is how efficient the proposed method is, e.g., how large a graph this method can handle.\n\n\\[1\\] Airoldi E M, Blei D, Fienberg S, et al. Mixed membership stochastic blockmodels\\[J\\]. Advances in neural information processing systems, 2008, 21.\n\n\\[2\\] Gupte P V, Ravindran B, Parthasarathy S. Role discovery in graphs using global features: Algorithms, applications and a novel evaluation strategy\\[C\\]//2017 IEEE 33rd International Conference on Data Engineering (ICDE). IEEE, 2017: 771-782.\n\n\\[3\\] Henderson K, Gallagher B, Eliassi-Rad T, et al. Rolx: structural role extraction & mining in large graphs\\[C\\]//Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 2012: 1231-1239.\n\n\\[4\\] Ribeiro L F R, Saverese P H P, Figueiredo D R. struc2vec: Learning node representations from structural identity\\[C\\]//Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 2017: 385-394.\n\n==============================================\n\nAfter the rebuttal, I increased my overall rating.\n No potential negative societal impact.",
         "513",
         "9",
         "11",
         "0.7875000000000001",
         "0.1017504718",
         "0.9667627811",
         "216",
         "159",
         "35.5122",
         "11.9667",
         "15.5548",
         "14.2567",
         "13.0316",
         "0.1898",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "19",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_WiNY",
         "1688681107832",
         "1702411111399",
         "6",
         "4",
         "3",
         "3",
         "2",
         "The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs. * The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\n* The relaxation of the final WL partition with a fixed number of cells is novel.\n* The RIP model for graph generation is innovative. * Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method. * Could you explain whether Algorithm 1 can recover the cEP for a suitable choice of the parameter $k$? Limitations are sufficiently discussed.",
         "235",
         "0",
         "0",
         "0.7567",
         "0.1625",
         "0.9054954052",
         "216",
         "158",
         "39.8721",
         "11.4906",
         "14.8403",
         "13.6629",
         "10.8156",
         "0.4877",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "20",
         "ztDxO15N7f",
         "7411",
         "1683729208530",
         "['~Michael_Scholkemper1', '~Michael_T_Schaub1']",
         "An Optimization-based Approach To Node Role Discovery in Networks: Approximating Equitable Partitions",
         "Similar to community detection, partitioning the nodes of a complex network according to their structural roles aims to identify fundamental building blocks of a network, which can be used, e.g., to find simplified descriptions of the network connectivity, to derive reduced order models for dynamical processes unfolding on processes, or as ingredients for various network analysis and graph mining tasks. In this work, we offer a fresh look on the problem of role extraction and its differences to community detection and present a definition of node roles and two associated optimization problems (cost functions) grounded in ideas related to graph-isomorphism tests, the Weisfeiler-Leman algorithm and equitable partitions. We present theoretical guarantees and validate our approach via a novel “role-infused partition benchmark”, a network model from which we can sample networks in which nodes are endowed with different roles in a stochastic way.",
         "Reviewer_ZAin",
         "1688707829469",
         "1702411111310",
         "6",
         "3",
         "3",
         "4",
         "3",
         "The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model.  The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery. The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.   1) On the considered molecular datasets, does the approximate number of equitable partitions differ (the parameter \"k\" \\in {2,20}) differ significantly from the actual number of equitable partitions, on an average? Since the average number of nodes is 30, and since I would expect most graphs to have discrete equitable partitions (i.e. one node per class), it will be interesting to know if the optimal values of k were indeed small (say 2-6). Yes.",
         "226",
         "0",
         "1",
         "0.7503000000000001",
         "-0.0170454545",
         "0.9454556108000001",
         "216",
         "158",
         "24.1342",
         "14.5718",
         "17.9758",
         "16.1143",
         "14.8295",
         "0.1213",
         "82",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "21",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_Huoq",
         "1688427159321",
         "1702411021240",
         "7",
         "1",
         "3",
         "2",
         "3",
         "This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \n I think this paper is theoretically sound.  1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available? 1. Could you please give some examples or practical scenarios of the proposed method \n2. Could you please provide DAGs or any graphs that describing the data generating process? I want to see graphical settings that enables identification of post-interventional processes. 1. I believe that the paper's writing lacks motivation because it lacks examples or practical scenarios to describe practical importance.\n2. Without a graphical description of the data generating processes, it's difficult to assess how this result is related to causality.",
         "191",
         "0",
         "5",
         "0.7613000000000001",
         "0.054166666700000005",
         "0.9666213393",
         "216",
         "161",
         "25.023",
         "13.7233",
         "18.3038",
         "15.5797",
         "13.6786",
         "0.7285",
         "91",
         "1",
         "0",
         "0",
         "2"
        ],
        [
         "22",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_8vBF",
         "1689117977974",
         "1702411021146",
         "4",
         "2",
         "3",
         "2",
         "2",
         "This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases.  The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail.  My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference \\[16\\] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \n\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \n\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\n\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).   How the continuous time identifiability results relate to identifiability of equivalent discrete time models (Markov chains with additive/multiplicative noise in general state space)?  Limitations are addressed in the discussion. However, how restrictive is the interventional framework for concrete problems is not addressed (see \"weaknesses\" section).",
         "511",
         "1",
         "0",
         "0.7991",
         "0.0583035701",
         "0.9081530571",
         "216",
         "153",
         "33.4658",
         "14.6366",
         "17.0915",
         "15.5328",
         "15.8075",
         "0.050100000000000006",
         "90",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "23",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_5yfh",
         "1689578555570",
         "1702411021035",
         "4",
         "1",
         "3",
         "2",
         "2",
         "This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community. This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\n\nI thank the authors for their thoughtful discussion in the rebuttal process. This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\n\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, \\[4, 34, 45\\])\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\n- Line 69: I think you mean \"are commutative\"\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors \\[21\\], and clerical errors.\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  \\[13\\] and \\[24\\]. Why is this article relevant to the machine learning community? This article is written for pure-statisticans and it is not really legible for many in the ML community.",
         "530",
         "4",
         "1",
         "0.778",
         "0.14054687500000002",
         "0.8547609448",
         "216",
         "148",
         "48.1605",
         "10.4415",
         "14.4641",
         "13.4159",
         "10.3417",
         "0.7608",
         "97",
         "2",
         "2",
         "0",
         "0"
        ],
        [
         "24",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_GdBe",
         "1689916941492",
         "1702411020935",
         "5",
         "2",
         "2",
         "3",
         "2",
         "This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data. - The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \n- The paper is well-motivated and makes a technically solid contribution. - The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear. What are the situations where the derived conditions for identifying linear SDEs so useful in practice? N/A",
         "159",
         "0",
         "1",
         "0.7458",
         "0.2506493506",
         "0.8731790781000001",
         "216",
         "144",
         "21.6953",
         "13.7338",
         "17.2493",
         "14.6837",
         "12.809",
         "0.0917",
         "98",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "25",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_b8xq",
         "1690365639585",
         "1702411020852",
         "4",
         "3",
         "2",
         "3",
         "3",
         "The present work considers the problem of identifying the generators of autonomous linear\nstochastic differential equations (SDEs) with an additive or multiplicative\nnoise term from the law of its solution process (e.g., in case of additive noise\nthis is a Gaussian process) with a given fixed initial state. The authors derive\ngeneric sufficient conditions for this and use the knowledge gained to expand\nthe model interpretability from a geometric point of view. The applicability of\nthe theoretical results is shown in the context of causal inference using linear\nSDEs and empirical evidence is provided by a (small) set of simulations. In recent years, modeling random dynamics had great impact into deep learning by\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\nfor modelling real world data, research interest in NSDEs rapidly grew.\nHowever, we still know very little about the often hidden systematics of these\nmodels and in particular the design of problem-specific function classes is a\nchallenge without a deeper understanding of it. Therefore, I appreciate this\nwork's attempt to make a systematic contribution to solving the mystery behind\nrandom dynamic modeling.\n\nFurther, the content is well organized, with very few exceptions, has no\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\nexperiments on toy data. Code examples are included in the supplementary\nmaterial.  It is not the value of the approach I am concerning here, but the shortcomings\nrelated to the clarity of the submission and the technical soundness which I\nwill address with examples in the following:\n\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\n  contributor landscape in recent years, I would argue it still represents a\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\n  an advanced topic. Hence, in the context of its central role in this paper, it is\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\n  audience. To illustrate this deficiency with an example: In Sec. In Section\n  2.3 the authors talk about SDEs generators without giving a definition, and\n  later in Section 2.1 the reader discovers that it is an operator on function\n  spaces.\n\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\n  identifiability conditions from a geometric perspective, i.e., the generator\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\n  are confined to an $A$-invariant proper subspace of $\\mathbb{R}^d$, I found\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\n  Can you phrase the idea in an easier manner? I think what I'm saying\n  is that the amount of technical detail presented diminishes the value of the\n  result.\n\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\n  since this topic is more an example of the application of generator\n  identification of SDEs than a contribution to the problem definition of the\n  latter in general.\n\n- W4: Identifying the solution process of autonomous linear SDEs with additive\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\n  identification of generators by properties of the law of such Gaussian\n  solution processes with a given fixed initial state. I am wondering if the\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\n  term.\n\n- W5: Simulations are only presented in a very limited scenario on (very) low\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\n  series data, the state variable dimension $d$ is often significantly larger\n  than 10 (cf. I. Silva et al. \\[52\\]). In order to create added value for such models, e.g., NSDEs, the\n  approach has to be tested in this extended framework.\n\nHowever, I would like to reiterate my appreciation for the authors' interest in\nexpanding the field of modelling random dynamics. I'm sure that by working on\nthe deficiencies mentioned, the work will gain in value\nand will deliver an enriching contribution to the community. - l. 34f. Check wording.\n- l. 63 What type of solution?\n- l. 73 Can you provide a reference here?\n- l. 75 Can you provide a definition for the notion of a stochastic process\n  here?\n- l. 82 What do you mean by: \"..., we recover the notion of stochastic\n  process,...\" ?\n- l. 85 Do you mean: \"..., $S$-valued functions on $\\[0,\\infty)$?\n- l. 124 \"... can be identifiable from their ...\", check wording.\n- l. 129 What is that gap you are mentioning here?\n- l. 142 Eq. 10: how are $b$ and $\\sigma$ defined?\n- l. 147 Prop. 2.1: \"... denotes the space of **continuous** functions ...\"\n- l. 185 Can you provide reference for this statement?\n- l. 195 Lemma 3.2: How is $Q$ defined? Limitations are addressed (see e.g. Chapter 6) and mainly concern the practical\nverification of the identifiable conditions. From my perspective there are important aspects that need to be\ndiscussed additionally, e.g., computational limitations in the case of system\ndimension $d$, and Brownian motion dimension, $m$, greater 2. Further, the\nauthors consider the class of linear SDEs with either additive or multiplicative\nnoise in the autonomous setting (i.e., drift and diffusion do not explicitly\ndepend on time); can the presented results be transferred to the non-autonomous case?\n\nNo evidence was found that the authors addressed potential negative societal impact. Please make the effort to include this mandatory information in your work.",
         "1004",
         "1",
         "8",
         "0.7748",
         "0.0389152569",
         "0.8465107679",
         "216",
         "139",
         "46.5232",
         "10.574300000000001",
         "13.8801",
         "13.2279",
         "9.9498",
         "0.9305",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "26",
         "zsOOqjaj2z",
         "5668",
         "1683686700553",
         "['~Yuanyuan_Wang5', '~Xi_Geng1', '~Wei_Huang8', '~Biwei_Huang1', '~Mingming_Gong1']",
         "Generator Identification for Linear SDEs with Additive and Multiplicative Noise",
         "In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.",
         "Reviewer_eRyW",
         "1690401961859",
         "1702411020671",
         "7",
         "3",
         "3",
         "3",
         "3",
         "As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \n\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results. The paper is generally well-written and clearly structured and, although technical, well readable. \n\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely. The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \nI had to refer to \\[16\\] to find a clear explanation of how SDE can be used for causal inference. \n\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\n\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper. You are using MLE to estimate the system parameters (let’s call them $\\theta$) given discrete observational data $x$, i.e., you are obtaining a point for $\\theta$. Given there is uncertainty in the system and due to limited amount of observational data, there should be uncertainty w.r.t. to the estimate of $\\theta$ as well. Have you considered performing fully Bayesian inference over $\\theta$ instead, i.e., obtaining $p(\\theta | x)$ instead of performing $\\hat{\\theta}$ = MLE? \nFor example, you could use simulation-based inference (SBI) to obtain a approximate posterior from simulated data. \n\nThis would enable you add the uncertainty estimates to your analysis of the different “Identifiable” and “unidentifiable” cases reported in section 4. The authors discuss the limitations of their work. ",
         "463",
         "1",
         "0",
         "0.7532",
         "0.06302655680000001",
         "0.9268480539",
         "216",
         "138",
         "35.4205",
         "12.723700000000001",
         "16.3765",
         "14.9859",
         "12.7758",
         "0.31720000000000004",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "27",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_NzMT",
         "1688240864746",
         "1702411167395",
         "7",
         "3",
         "4",
         "4",
         "4",
         "This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\n 1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution. 1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \n2. The impact of \\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\gamma values (some ablation study would be helpful).\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting. 1. In the rebuttal, it would be interesting to see experimental results mentioned in the weakness.  See Weaknesses.",
         "369",
         "0",
         "9",
         "0.777",
         "0.1441088435",
         "0.9163020849",
         "216",
         "164",
         "20.9031",
         "15.1685",
         "17.6329",
         "16.1033",
         "16.3235",
         "0.1695",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "28",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Fgsj",
         "1688396827585",
         "1702411167288",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting. 1. The paper is well-written and easy to follow.\n2. The new reward functions designed for label balance are interesting. \n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting. 1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\n\nMinor:\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table. 1. Are there any datasets where BADGE does not perform well?\n2. Can BADGE be adapted for multi-label setting?\n3. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm? N/A",
         "220",
         "0",
         "10",
         "0.7563000000000001",
         "0.1606039794",
         "0.9120497704",
         "216",
         "162",
         "41.6487",
         "10.3267",
         "12.6316",
         "11.9208",
         "10.3715",
         "0.12",
         "98",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "29",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_LjXi",
         "1688408837735",
         "1702411167213",
         "6",
         "2",
         "3",
         "3",
         "3",
         "The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art. Originality:\n\nThe work is deemed original based on its discussion with related work.\n\nClarity & quality:\n\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \n\nSignificance:\n\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods. I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\n\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\n 1. As an active learning practitioner, my experience with active learning strongly signifies a non-stationarity in the effectiveness of different AL methods at different label levels (they are also path dependent, not only the number of labels but which labels were annotated till this iteration matters for the next round reward). Therefore I would like to ask how the authors bake this non-stationarity into the current formation.\n\n2. What exactly are the 40 algs in the uncertainty (40 algs)? I didn't find it in Appendix F.\n\n\n No potential negative social impact of this work is observed. The authors are encouraged to address their limitations more.",
         "321",
         "0",
         "2",
         "0.8039000000000001",
         "0.0723484848",
         "0.9104201794000001",
         "216",
         "162",
         "36.7352",
         "13.4187",
         "15.654",
         "14.8367",
         "13.9859",
         "0.1507",
         "88",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "30",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_4Aq9",
         "1689050502893",
         "1702411167124",
         "5",
         "4",
         "2",
         "3",
         "2",
         "Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy.  * Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof. * The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\n * For each iteration of acquisition, B samples are selected from B acquisition strategies, it sounds like an ensemble approach, doesn’t it? Different acquisition functions might capture, for example, different types of uncertainties, some to do with the model parameters, some to do directly with the model performance. Will this contribute to the performance difference?\n* The reward function focuses on the class diversity in order to deal with the class imbalanced issue. It would be interesting to design some reward function that is closely related to the model performance.\n* It is good to show the higher bound. However, can the author prove the convergence of the classifier, as done in WMOCU (Guang Zhao, Edward Dougherty, Byung-Jun Yoon, Francis Alexander, and Xiaoning Qian. Uncertaintyaware active learning for optimal Bayesian classifier. In International Conference on Learning Representations, ICLR 2021, 2021)\n* In figure 3, there is no substantial difference between TAILOR and some other methods, including BADGE, can the author explain this? Meanwhile, BADGE is a diversity-based method using clustering, how this can be adopted in TAILOR with Assumption 3.1? The author briefly touches on the limitations in section 6.3 and section 7. As mentioned above, it is also good to discuss more about the computational cost which could potential benefit the AL practitioners.",
         "663",
         "0",
         "0",
         "0.8072",
         "0.1367346939",
         "0.9023641944",
         "216",
         "154",
         "27.0804",
         "14.2534",
         "17.422",
         "15.9407",
         "15.3886",
         "0.1041",
         "104",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "31",
         "zrUEHZ6s9C",
         "8399",
         "1683746518064",
         "['~Jifan_Zhang1', '~Shuai_Shao5', '~saurabh_verma1', '~Robert_D_Nowak1']",
         "Algorithm Selection for Deep Active Learning with Imbalanced Datasets",
         "Label efficiency has become an increasingly important objective in deep learning applications. Active learning aims to reduce the number of labeled examples needed to train deep networks, but the empirical performance of active learning algorithms can vary dramatically across datasets and applications. It is difficult to know in advance which active learning strategy will perform well or best in a given application. To address this, we propose the first adaptive algorithm selection strategy for deep active learning. For any unlabeled dataset, our (meta) algorithm TAILOR (Thompson ActIve Learning algORithm selection) iteratively and adaptively chooses among a set of candidate active learning algorithms. TAILOR uses novel reward functions aimed at gathering class-balanced examples. Extensive experiments in multi-class and multi-label applications demonstrate TAILOR's effectiveness in achieving accuracy comparable or better than that of the best of the candidate algorithms. Our implementation of TAILOR is open-sourced at https://github.com/jifanz/TAILOR.",
         "Reviewer_Ra5K",
         "1690252533966",
         "1702411167025",
         "3",
         "3",
         "2",
         "1",
         "2",
         "This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms.  The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported.  The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \n\n\n1. The organization and content selection are unsatisfactory. \n\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \n\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \n\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \n\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\n\n\n\n2. The presentation of the paper lacks sufficient clarity.   \n\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \n\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \n\n(3) The Equations are not well explained. For example, the “\\lor” operator in the class diversity reward is not described. \n\n\n\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \n\n\n\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \n\n\n\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \n\n\n\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \n\n\n\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., \\[1,2,3\\]. \n\\[1\\] “Adaptive Active Learning for Image Classification”. 2013. \n\\[2\\] “Active Learning with Multi-label SVM Classification”. 2013. \n\\[3\\] “Meta-Learning for Batch Mode Active Learning”, 2018.\n Please see the weaknesses above. N/A",
         "533",
         "4",
         "10",
         "0.7563000000000001",
         "0.0305428049",
         "0.8611335754",
         "216",
         "140",
         "40.9473",
         "10.7776",
         "14.0555",
         "12.9025",
         "11.2445",
         "0.49920000000000003",
         "91",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "32",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_uA1P",
         "1687715443736",
         "1702410835214",
         "5",
         "3",
         "2",
         "3",
         "3",
         "This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\n\nBasically, the proposed method is based on \\[19\\], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\n\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\n * This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\n\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\n\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\n a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past \\[46\\], so the high-level novelty would be somewhat limited.\n\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\n\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\n\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\n\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\n\nf. Some typos: \n\nL10: pIrors -> prIors\n\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\n Among the weaknesses I listed, (b) performance evaluation when the number of classes is unknown, (d) reasons for performance degradation when using TCP alone, and (e) discussion of the number of superclasses and subclasses for different datasets are of particular importance. I look forward to getting responses for these points from the authors. Limitations are discussed in the paper.",
         "444",
         "2",
         "2",
         "0.7377",
         "0.0835497835",
         "0.9506004453",
         "220",
         "170",
         "34.147",
         "13.4538",
         "16.2734",
         "15.1863",
         "14.622",
         "0.2025",
         "71",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "33",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_Qvan",
         "1688548941955",
         "1702410835139",
         "6",
         "3",
         "3",
         "3",
         "2",
         "Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art. 1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\n2. The writing is clear. I like the figures in this paper.\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material. 1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet \\[1\\], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\n\n\\[1\\] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Some works, especially \\[2\\], on the taxonomic structure lack proper citation and comparison.\n\n\\[2\\] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\n\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section. 1. Can pre-defined taxonomic priors be utilized? Some datasets already have defined taxonomic priors, while WordNet can be used \\[1\\] to extract such priors among categories.\n\n\\[1\\] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\n\n2. Have other cluster algorithms been explored for obtaining taxonomic priors, besides the SK algorithm?\n\n3. Could you provide further clarification on why this work is suitable for open-world learning? I can understand its benefits for generating high-quality pseudo labels in semi-supervised learning.\n\n4. Can you compare with \\[2\\] in detail?\n\n\\[2\\] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023. In conclusion, this paper exhibits a clear motivation and comprehensive experimental verifications. However, the necessity of constructing taxonomic priors remains a main concern. It would be beneficial if the authors could provide specific scenarios where the construction of taxonomic priors is indeed essential. In addition, the comparison with \\[2\\] is essential.\n\nThis paper fully considers potential negative societal impact of their work.",
         "410",
         "9",
         "16",
         "0.8414",
         "0.046051423300000005",
         "0.9489502907",
         "220",
         "160",
         "14.7073",
         "14.2945",
         "17.9453",
         "14.769",
         "14.6504",
         "0.6214000000000001",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "34",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_k9he",
         "1688653581641",
         "1702410835057",
         "5",
         "4",
         "2",
         "2",
         "2",
         "This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions.  1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced. 1. Additional baselines are needed for comparison: \n\n\\[1\\] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery\\[C\\]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\n\n\\[2\\] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery\\[C\\]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\n\n\\[3\\] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery\\[C\\]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\n\n\\[4\\] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery\\[J\\]. arXiv preprint arXiv:2211.11727, 2022.\n\n\\[5\\] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery\\[J\\]. arXiv preprint arXiv:2212.00334, 2022.\n\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \n\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class. 1. The authors need to analyze the learned hierarchical tree of multi-granularity labels of each dataset. It could be the case that each super-class may contain different numbers of target-classes, and also each target-class may contain different numbers of sub-classes. Especially when the target-classes of one dataset are imbalanced in terms of similarity in semantic space. \n\n2. The learning of multi-granularity pseudo-labels could be heavily-biased when the class-distribution is imbalanced and the semantic distance of each target-class is imbalanced.  The number of novel classes needs to be known. The class-distribution needs to be balanced. These assumptions make TIDA not robust for practical usage. ",
         "385",
         "5",
         "13",
         "0.727",
         "-0.044117647100000004",
         "0.9325020313000001",
         "220",
         "159",
         "28.9525",
         "12.6369",
         "15.7857",
         "14.0859",
         "14.4757",
         "0.1213",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "35",
         "zrLxHYvIFL",
         "2448",
         "1683361520146",
         "['~Yu_Wang43', '~Zhun_Zhong1', '~Pengchong_Qiao1', '~Xuxin_Cheng3', '~Xiawu_Zheng1', '~Chang_Liu9', '~Nicu_Sebe1', '~Rongrong_Ji5', '~Jie_Chen15']",
         "Discover and Align Taxonomic Context Priors  for Open-world Semi-Supervised Learning",
         "Open-world Semi-Supervised Learning (OSSL) is a realistic and challenging task, aiming to classify unlabeled samples from both seen and novel classes using partially labeled samples from the seen classes. \nPrevious works typically explore the relationship of samples as priors on the pre-defined single-granularity labels to help novel class recognition. In fact, classes follow a taxonomy and samples can be classified at multiple levels of granularity, which contains more underlying relationships for supervision. We thus argue that learning with single-granularity labels results in sub-optimal representation learning and inaccurate pseudo labels, especially with unknown classes. In this paper, we take the initiative to explore and propose a uniformed framework, called Taxonomic context prIors Discovering and Aligning (TIDA), which exploits the relationship of samples under various granularity. It allows us to discover multi-granularity semantic concepts as taxonomic context priors (i.e., sub-class, target-class, and super-class), and then collaboratively leverage them to enhance representation learning and improve the quality of pseudo labels.\nSpecifically, TIDA comprises two components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. We demonstrate that these two components are mutually beneficial for an effective OSSL framework, which is theoretically explained from the perspective of the EM algorithm. Extensive experiments on seven commonly used datasets show that TIDA can significantly improve the performance and achieve a new state of the art. The source codes are publicly available at https://github.com/rain305f/TIDA.",
         "Reviewer_qAVC",
         "1688701236273",
         "1702410834962",
         "5",
         "3",
         "3",
         "2",
         "3",
         "In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision.  1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\n3. This paper is easy to follow. The hyper-parameter $\\alpha$ and $\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value.  Is it possible to set a init value of $\\alpha$ and $\\beta$, and then determine the specific value by dynamically decreasing or increasing? The authors addressed the limitations. ",
         "195",
         "0",
         "3",
         "0.7317",
         "0.1063360882",
         "0.9010543823",
         "220",
         "158",
         "13.9079",
         "16.7021",
         "19.5385",
         "17.5059",
         "17.615",
         "0.1213",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "36",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_uNQ9",
         "1688445958696",
         "1702411317487",
         "4",
         "4",
         "2",
         "3",
         "2",
         "This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges. + Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\n+ This paper is well-written and is easy to follow. - The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs. Q1：What is the relationship between invariant representations and cluster information and why is transferring a node to another cluster reasonable ?\nQ2: Can CIT possibly be scaled to larger graphs?  The reviewer does not see potential negative social impact of the work.",
         "305",
         "0",
         "0",
         "0.7436",
         "-0.0205645161",
         "0.9308603406",
         "215",
         "161",
         "38.0053",
         "11.8417",
         "13.3907",
         "13.196",
         "11.9742",
         "0.0364",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "37",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_5H2e",
         "1688448571574",
         "1702411317410",
         "6",
         "4",
         "2",
         "3",
         "2",
         "The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score.  - The paper is easy to understand.\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\n- The experiments are extensive and the results look promising.\n - **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. \\[1\\].\n\n**Minor:**\n\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\n\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\n\n\n\\[1\\] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu. - The method considers the embedding space only. Thus, it seems that the method can be extended to other domains, e.g., for images. If that is the case, are there any graph-specific properties that make this solution remains on the graph domain rather than other general domains?\n- What's the method's performance when removing/adding 5%, 20% edges and not removing/adding any edges? Does the improvement of the method decline with the decreasing ratios? The authors discussed the limitations on the fact that the method could only apply to node-level tasks directly and the theory remain to be fully developed, as well as the limitation that the transfer remains on embedding space but graph topology.",
         "670",
         "2",
         "2",
         "0.7798",
         "0.120959596",
         "0.9181414247",
         "215",
         "161",
         "42.0814",
         "11.4702",
         "14.4848",
         "13.9306",
         "12.7929",
         "0.2025",
         "91",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "38",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_Nbx4",
         "1688589616718",
         "1702411317319",
         "7",
         "4",
         "3",
         "3",
         "4",
         "This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism. Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\n No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently.  1. It seems that most of the graphs used here are not large enough, so what is the time complexity of the proposed model?\n3. The authors design several experiments to evaluate the model, e.g., perturbate edges, multiplex graphs. Do all these changes belong to the structure shift? Can the authors provide more discussions on what changes can be considered as structure shift?\n4. The paper proves that with CIT mechanism, the cluster information has less influence on the classifier, but what if the cluster information is related with the labels? \n N/A",
         "230",
         "0",
         "4",
         "0.7577",
         "0.1165249433",
         "0.9456864595000001",
         "215",
         "159",
         "39.3595",
         "11.5787",
         "14.4812",
         "13.7657",
         "11.814",
         "0.1041",
         "110",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "39",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_nmEc",
         "1688604914709",
         "1702411317217",
         "7",
         "5",
         "3",
         "3",
         "4",
         "The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective. 1.\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \n\n2.\tClear results on different scenarios, well-backed by experiments.\n\n3.\tThe CIT mechanism is interesting and with technical analysis.\n 1.\tIn section 2, why GAT performs worse than GCN?\n\n2.\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\n\n3.\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\n It would be beneficial to answer the questions in weakness. N/A",
         "170",
         "0",
         "7",
         "0.7752",
         "0.1777777778",
         "0.9243376255",
         "215",
         "159",
         "46.1476",
         "10.3421",
         "11.7843",
         "12.1617",
         "11.2259",
         "0.06570000000000001",
         "98",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "40",
         "zrCmeqV3Sz",
         "11147",
         "1683793236823",
         "['~Donglin_Xia1', '~Xiao_Wang2', '~Nian_Liu3', '~Chuan_Shi1']",
         "Learning Invariant Representations of Graph Neural Networks via Cluster Generalization",
         "Graph neural networks (GNNs) have become increasingly popular in modeling graph-structured data due to their ability to learn node representations by aggregating local structure information. However, it is widely acknowledged that the test graph structure may differ from the training graph structure, resulting in a structure shift. In this paper, we experimentally  find that the performance of GNNs drops significantly when the structure shift happens, suggesting that the learned models may be biased towards specific structure patterns. To address this challenge, we propose the Cluster Information Transfer (\\textbf{CIT}) mechanism, which can learn invariant representations for GNNs, thereby improving their generalization ability to various and unknown test graphs with structure shift. The CIT mechanism achieves this by combining different cluster information with the nodes while preserving their cluster-independent information. By generating nodes across different clusters, the mechanism significantly enhances the diversity of the nodes and helps GNNs learn the invariant representations. We provide a theoretical analysis of the CIT mechanism, showing that the impact of changing clusters during structure shift can be mitigated after transfer. Additionally, the proposed mechanism is a plug-in that can be easily used to improve existing GNNs. We comprehensively evaluate our proposed method on three typical structure shift scenarios, demonstrating its effectiveness in enhancing GNNs' performance.",
         "Reviewer_QyZE",
         "1688742468644",
         "1702411317111",
         "7",
         "5",
         "4",
         "3",
         "4",
         "The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence. - The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors. - The experiments in section 2 are not sufficient.\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\n- There are some typos present in the paper that should be addressed for improved clarity and readability. - In Section 2, the authors focus on presenting results specifically for the GCN and GAT models, but they do not mention the evaluation of other GNN models. It would be beneficial for the authors to clarify if they have considered or conducted experiments with other GNN models as well.\n- The authors introduce different structure shifts in their experiments, but it would be helpful to provide a clearer distinction between their approach and the OOD graph benchmarks proposed in \\[1\\]. Additionally, the paper could benefit from providing standard settings for structure shifts and including information on the label rate used in training the models.\n- There are several typos in the paper, such as \"less affect\" in line 321, \"bulids\" in line 315, and \"Initial residual and Identity mapping two effective techniques on GCN\" in line 305. These errors should be addressed to improve the clarity and accuracy of the paper.\n\n\\[1\\] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. Good: A graph out-of-distribution benchmark. arXiv preprint arXiv:2206.08452, 2022. The authors have discussed the limitation and potential negative societal impact.",
         "367",
         "2",
         "1",
         "0.779",
         "0.1302469136",
         "0.9419665337",
         "215",
         "158",
         "31.0458",
         "13.3759",
         "15.8751",
         "14.6258",
         "13.6881",
         "0.4867",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "41",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_QuJp",
         "1688225043645",
         "1702410758906",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated. The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\n The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating. I would replace the non-standard notations of multi-sets and multi-sets of multi-sets with standard notations of 1D and 2D arrays, as these are the objects you actually deal with in this paper. For example:\n\nLine 65: the node features should be represented as a vector (ordered sequence) of feature values, which is equivalent to a mapping from the nodes to features, not as a multiset. A multiset does not have the information of which feature belongs to which node.  Same in line 99, and throughout the paper. For example, 3 in line 130 is a 2D array, not a multiset of multisets, since nodes i and j have identities.\n\nTheorem 1 is important and correct, but it cannot directly be called an expressivity theorem.\nThe logic in the paragraph of line 133 is backwards in a sense. In condition 1 of Theorem 1 you ASSUME a condition on the input of pooling that is similar, or at least stronger, than “two feature vectors on which pooling gives two different outputs.’’ It is almost like giving a condition for the injectivity of a function f by saying “the function f(x) gives different values on points such that $f(x)\\neq f(y)$.’’ Injectivity is not a property of specific inputs, it is a property of the function. An appropriate injectivity analysis should say that, under some assumptions on the model of pooling, for ANY two distinct graphs+node features, the pooling of the two gives two distinct graphs+node features. The theorem you stated is a theorem about which inputs can be separated by pooling, not about which pooling method can separate any pair of inputs. \nThe theorem is still meaningful, as it is used later to discuss expressivity in case features are computed in such a way that sum is injective, but it should be described in the correct context.\nIn this context: in Line 135:\n“there are theorems for functions defined on sets that guarantee condition 1 to be met. In particular, the sum over a multiset that is countable is an injective function”\nThere are indeed very specific (using very high dimensional feature spaces) ways to design by hand specific MP mappings that satisfy this, but when training a MP-GNN there is no known (at least to my knowledge) practical way to guarantee this property.\nHence, this paragraph should also be put in the right context. Namely, there is a way to predefine the MP functions such that POOL is injective (when combined with these predefined MP functions). This is different from saying that POOL is injective on a trained network, or a network with generic weights.\nTo make this clear, it would be good to write an appendix that explains in detail the description around line 133, that is currently quite implicit, citing results from \\[37\\] and \\[40\\] and formulating the results in a mathematical language. The appendix should show that there exists a construction of MP-GNN with pooling which separates points. This is a type of analysis that directly extends the expressivity analysis of \\[37\\] to GNNs with pooling.\n\nIn the new dataset, what feature is put on the nodes of the graphs?\n\nTable 1 - can you add for comparison non expressive networks like GCN (without pooling), so we see what the “baseline” is, and how hard it is to separate graphs when you do not use pooling?\n\n\nMinor comments and suggestions:\n\nLine 129 : (suggested terminology) this is called a right stochastic matrix up to the global constant $\\lambda$.\n\nLine 3: this is the multiplication of the feature vector from the left by the right stochastic matrix S.\n\n The paper should clarify that expressivity does not mean that POOL is injective for some class of MP function, but that there is a specific choice of the parameters of the MP function such that POOL is injective, similarly to the analysis of \\[37\\] and \\[40\\].",
         "909",
         "5",
         "0",
         "0.7543000000000001",
         "0.12186849150000001",
         "0.9009177685",
         "230",
         "164",
         "50.8104",
         "11.8054",
         "14.8032",
         "13.8167",
         "12.9653",
         "0.1958",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "42",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_UT1a",
         "1688466543628",
         "1702410758835",
         "7",
         "4",
         "4",
         "4",
         "3",
         "The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries. 1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\n2. The theoretical portion of the work is effectively presented and explained.\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\n 1. The discussion on the limitations of the work is absent.\n2. Figure 3 is missing std bars.\n \n1. In line 128 of Theorem 1, it is unclear what the inequality refers to. Could you please clarify if each element of the vector needs to be different or if it is sufficient for only one of them to be different?\n\n2. Regarding the limitations, I would like to inquire whether the results apply universally to cases where the features of the nodes are continuous. \n\n3. In Figure 3, if my understanding is correct, each bar represents the average accuracy (in blue) and runtime (in gray) across six different datasets. It would be beneficial to include the standard deviation of these averages. Specifically, the accuracy values may exhibit significant variability between datasets.\n\nMINOR POINTS\n\n- There is a typo in Equation (2), with a missing opening curly bracket. The authors have not explicitly mentioned the limitations of their work, particularly in terms of the cases where their theory does not apply and any potential limitations of the proposed EXPWL1 method. It would be beneficial for the authors to address these aspects in order to provide a comprehensive understanding of the scope and potential constraints of their research.",
         "303",
         "0",
         "8",
         "0.7494000000000001",
         "0.0836666667",
         "0.9435138106000001",
         "230",
         "161",
         "32.77",
         "13.1018",
         "15.9801",
         "14.7214",
         "12.6345",
         "0.5933",
         "89",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "43",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_KM5y",
         "1688531384966",
         "1702410758770",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \n\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \n\nb) All nodes in the original graph must contribute to the creation of supernodes.\n\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\n\nThe paper presents controlled experiments along with theoretical support to validate and support their findings. 1 - The paper is well-written and easy to follow. \n2 - The hypothesis is nicely executed in a controlled set of experiments. \n3 - Theoretical analysis has been provided to support the findings. \n4 - Sufficient review of the literature and pooling operators is provided. \n5 - Clear categorization and analysis of the pooling operators are provided. 1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.   1 - I found the figure 2 slightly difficult to understand. I believe that adding some additional information, if applicable, could be helpful in making it easier to comprehend.\n\n2 - I appreciate that the running times are provided, but I was wondering if it would be possible to derive their computational complexities (pooling operators) and include them in Table 2.\n\n3 - The quality of Figure 3 could potentially be improved. - ",
         "287",
         "0",
         "1",
         "0.7439",
         "0.2067708333",
         "0.9592400789000001",
         "230",
         "160",
         "32.6936",
         "12.9846",
         "16.1754",
         "14.8193",
         "12.0743",
         "0.8077000000000001",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "44",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_DheR",
         "1690491959653",
         "1702410758696",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs. **Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\n\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \n\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\n\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators. - Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\n\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in \\[1\\] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\n\n\n\\[1\\] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020. - I'm wondering why only choosing a pooling ratio of 0.1 in the experiment. Would using larger pooling ratios affect the alignment between theoretical analysis and empirical findings? If using larger pooling ratios (e.g. 0.5), it is possible to compare the pooling operators more fairly in Table 1. Besides, a larger pooling ratio that doesn't reduce the graph size so aggressively can be possibly applied on the EXP dataset as an extension.\n\n- For the claim in section 3.3: \"Notably, this might not affect certain classification tasks, e.g., when the goal is to detect small structures that are already captured by the MP layers before pooling.\", are there deeper investigations to support this when analyzing the empirical results? The authors have not explicitly discussed the potential negative societal impacts of their work, which is not directly applicable.",
         "669",
         "2",
         "1",
         "0.7637",
         "0.12499415",
         "0.9655532241",
         "230",
         "137",
         "26.589",
         "13.4723",
         "16.45",
         "14.7234",
         "13.0895",
         "0.1213",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "45",
         "zqyVjCjhYD",
         "813",
         "1682515100473",
         "['~Filippo_Maria_Bianchi1', '~Veronica_Lachi1']",
         "The expressive power of pooling in Graph Neural Networks",
         "In Graph Neural Networks (GNNs), hierarchical pooling operators generate local summaries of the data by coarsening the graph structure and the vertex features. Considerable attention has been devoted to analyzing the expressive power of message-passing (MP) layers in GNNs, while a study on how graph pooling affects the expressiveness of a GNN is still lacking. Additionally, despite the recent advances in the design of pooling operators, there is not a principled criterion to compare them. In this work, we derive sufficient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. These conditions serve as a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. Based on our theoretical findings, we analyze several existing pooling operators and identify those that fail to satisfy the expressiveness conditions. Finally, we introduce an experimental setup to verify empirically the expressive power of a GNN equipped with pooling layers, in terms of its capability to perform a graph isomorphism test.",
         "Reviewer_utJZ",
         "1690766417890",
         "1702410758593",
         "4",
         "4",
         "2",
         "2",
         "2",
         "Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\n\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \n 1. This paper first studied on the expressive power of graph pooling in graph neural networks.\n\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\n 1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\n\n\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\n\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \n\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\mathcal{X}_1^L \\neq \\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\n Could you please clarify the relationship between preserving all information after pooling, as defined in this paper, and the ability to distinguish graphs, which is the common definition of expressiveness? In this paper, the diff-pool aims to retain all information. However, from my perspective, the clustering process might lead to a loss of the graph's inherent structural information, which aligns with the description provided in line 244  (arguments against the evaluation approach in Paper \\[27\\]). yes",
         "384",
         "1",
         "7",
         "0.7825000000000001",
         "0.1956845238",
         "0.9658693075",
         "230",
         "134",
         "33.9863",
         "12.6558",
         "15.5382",
         "14.4923",
         "13.5984",
         "0.4152",
         "89",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "46",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_1V93",
         "1688541118141",
         "1702410854876",
         "6",
         "5",
         "3",
         "3",
         "2",
         "This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model. - Clear research motivation, well-structured writing, and provides ample theoretical support. \n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\n - Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\n\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\n\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\n\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\n\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP \\[1\\].\n\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\n\n\\[1\\] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\n Refer to the weaknesses mentioned above. Refer to the weaknesses mentioned above.",
         "506",
         "2",
         "0",
         "0.795",
         "0.1399054207",
         "0.8918016553",
         "219",
         "160",
         "25.6579",
         "14.2719",
         "16.0499",
         "14.7643",
         "15.6239",
         "0.088",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "47",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_mKLw",
         "1688677891394",
         "1702410854754",
         "4",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label. - This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\n\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\n\n- The paper is well written and easy to read. - Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning \\[1,2,3\\]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\n\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\n\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\n\n     \\[1\\] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\n\n     \\[2\\] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\n\n     \\[3\\] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022. - Compare the proposed method with existing works that study provable/certified robustness against backdoor attacks or data poisoning.\n\n- How to achieve good performance when the trigger magnitude is larger than the assumed norm?\n\n- Does the quality of the clean dataset affect the performance of the proposed method? How to obtain the dataset with high quality in practice?\n The authors have discussed the limitations.",
         "348",
         "4",
         "3",
         "0.7529",
         "0.2095739348",
         "0.9313436151000001",
         "219",
         "158",
         "44.6358",
         "10.6951",
         "12.5033",
         "12.5085",
         "11.5333",
         "0.07200000000000001",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "48",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_Do9c",
         "1688690695941",
         "1702410854663",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper analysed the relationship between adversarial examples and poisoned examples. \nThen, this paper proposed a fine-tuning strategy to purify the poisoned model.  1 This paper is easy to follow. \n\n2 This paper provides some experiments that support the proposed method. \n\n3 This paper has some experimental analyses that can lead to the proposed method.  1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \n\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\n\n3 The key reference is missing. This paper also need to compared with the paper \\[1\\]. \nPrevious work \\[1\\] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks \\[2\\] or perceptual adversarial attacks \\[3\\].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \n\n\\[1\\] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\n\n\\[2\\] Spatially Transformed Adversarial Examples. ICLR 2018.\n\n\\[3\\] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021. Can the proposed method mitigate the backdoor issues of the contrastive learning \\[4\\], which is a more practical setting. \n\n\\[4\\] Poisoning and backdooring contrastive learning, ICLR2022 After the part of conclusion, the authors discussed the limitation of this work. ",
         "268",
         "9",
         "4",
         "0.7637",
         "0.2275595238",
         "0.8652505875000001",
         "219",
         "158",
         "36.728",
         "11.8353",
         "13.4182",
         "12.7451",
         "12.7455",
         "0.11",
         "87",
         "0",
         "2",
         "1",
         "0"
        ],
        [
         "49",
         "zqOcW3R9rd",
         "2649",
         "1683428990794",
         "['~Shaokui_Wei1', '~Mingda_Zhang2', '~Hongyuan_Zha1', '~Baoyuan_Wu1']",
         "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples",
         "Backdoor attacks are serious security threats to machine learning models where an adversary can inject poisoned samples into the training set, causing a backdoored model which predicts poisoned samples with particular triggers to particular target classes, while behaving normally on benign samples. In this paper, we explore the task of purifying a backdoored model using a small clean dataset. By establishing the connection between backdoor risk and adversarial risk, we derive a novel upper bound for backdoor risk, which mainly captures the risk on the shared adversarial examples (SAEs) between the backdoored model and the purified model. This upper bound further suggests a novel bi-level optimization problem for mitigating backdoor using adversarial training techniques. To solve it, we propose Shared Adversarial Unlearning (SAU). Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs such that they are either correctly classified by the purified model and/or differently classified by the two models, such that the backdoor effect in the backdoored model will be mitigated in the purified model. Experiments on various benchmark datasets and network architectures show that our proposed method achieves state-of-the-art performance for backdoor defense. The code is available at https://github.com/SCLBD/BackdoorBench (PyTorch) and https://github.com/shawkui/MindTrojan (MindSpore).",
         "Reviewer_qs3i",
         "1688783633741",
         "1702410854548",
         "5",
         "3",
         "3",
         "2",
         "2",
         "summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk \\[adversarial examples and poisoned samples\\] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\n\n The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \n \n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\n\n *  Type I adv. examples where hθbd and hθ can be misled to the same class represents an upper bound for back door examples. How do you account for false positives? Or is it assumed to be always 100%? \n\n* How does ASR vary in comparison to other unlearning techniques for backdoor mitigation such as I-BAU.\n\n* What are the tradeoffs associated with this approach in terms of implementation - specifically around the cost of identifying the SAEs and SAU?\n\n * Writing flow can be improved. Adding a toy example would definitely improve the overall understanding of the paper. \n",
         "303",
         "0",
         "1",
         "0.7872",
         "0.0666666667",
         "0.9156908989",
         "219",
         "157",
         "37.1925",
         "12.9906",
         "14.9234",
         "14.0682",
         "13.7299",
         "0.077",
         "81",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 15175
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_AvJq</td>\n",
       "      <td>1688368213177</td>\n",
       "      <td>1702411303415</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8720</td>\n",
       "      <td>15.9897</td>\n",
       "      <td>14.4442</td>\n",
       "      <td>13.2649</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_7E4k</td>\n",
       "      <td>1688505633161</td>\n",
       "      <td>1702411303319</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0922</td>\n",
       "      <td>15.3049</td>\n",
       "      <td>14.1918</td>\n",
       "      <td>12.6374</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_hHZH</td>\n",
       "      <td>1688552936677</td>\n",
       "      <td>1702411303221</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>7.7200</td>\n",
       "      <td>10.1878</td>\n",
       "      <td>10.7063</td>\n",
       "      <td>7.5081</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zyhxRc9bew</td>\n",
       "      <td>10819</td>\n",
       "      <td>1683789038840</td>\n",
       "      <td>[~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...</td>\n",
       "      <td>What is Flagged in Uncertainty Quantification?...</td>\n",
       "      <td>Uncertainty quantification (UQ) is essential f...</td>\n",
       "      <td>Reviewer_sVgx</td>\n",
       "      <td>1688657604892</td>\n",
       "      <td>1702411303144</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3916</td>\n",
       "      <td>17.9549</td>\n",
       "      <td>16.1666</td>\n",
       "      <td>14.5827</td>\n",
       "      <td>0.5533</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zyZkaqNnpa</td>\n",
       "      <td>15594</td>\n",
       "      <td>1683835167534</td>\n",
       "      <td>[~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...</td>\n",
       "      <td>Don’t blame Dataset Shift! Shortcut Learning d...</td>\n",
       "      <td>Common explanations for shortcut learning assu...</td>\n",
       "      <td>Reviewer_9QKU</td>\n",
       "      <td>1688617232745</td>\n",
       "      <td>1702411520565</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.3014</td>\n",
       "      <td>14.7013</td>\n",
       "      <td>14.2653</td>\n",
       "      <td>13.4733</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15170</th>\n",
       "      <td>00EKYYu3fD</td>\n",
       "      <td>6838</td>\n",
       "      <td>1683719044332</td>\n",
       "      <td>[~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>In generative modeling, numerous successful ap...</td>\n",
       "      <td>Reviewer_ssMC</td>\n",
       "      <td>1688676041356</td>\n",
       "      <td>1702411081106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0714</td>\n",
       "      <td>13.0114</td>\n",
       "      <td>12.5486</td>\n",
       "      <td>10.1760</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15171</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_UdXn</td>\n",
       "      <td>1688449656890</td>\n",
       "      <td>1702411268900</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7042</td>\n",
       "      <td>14.5675</td>\n",
       "      <td>13.9100</td>\n",
       "      <td>11.9698</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15172</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_ZgSr</td>\n",
       "      <td>1688485585833</td>\n",
       "      <td>1702411268818</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.2691</td>\n",
       "      <td>13.9387</td>\n",
       "      <td>13.4543</td>\n",
       "      <td>11.2038</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15173</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_HGb9</td>\n",
       "      <td>1688665406904</td>\n",
       "      <td>1702411268706</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9547</td>\n",
       "      <td>18.5308</td>\n",
       "      <td>16.4682</td>\n",
       "      <td>16.3810</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>009LK0vLcY</td>\n",
       "      <td>10107</td>\n",
       "      <td>1683778565991</td>\n",
       "      <td>[~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...</td>\n",
       "      <td>Finite Population Regression Adjustment and No...</td>\n",
       "      <td>The design and analysis of randomized experime...</td>\n",
       "      <td>Reviewer_zpw6</td>\n",
       "      <td>1688755793651</td>\n",
       "      <td>1702411268608</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1560</td>\n",
       "      <td>17.2540</td>\n",
       "      <td>15.6161</td>\n",
       "      <td>13.6344</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15175 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "0        zyhxRc9bew              10819             1683789038840   \n",
       "1        zyhxRc9bew              10819             1683789038840   \n",
       "2        zyhxRc9bew              10819             1683789038840   \n",
       "3        zyhxRc9bew              10819             1683789038840   \n",
       "4        zyZkaqNnpa              15594             1683835167534   \n",
       "...             ...                ...                       ...   \n",
       "15170    00EKYYu3fD               6838             1683719044332   \n",
       "15171    009LK0vLcY              10107             1683778565991   \n",
       "15172    009LK0vLcY              10107             1683778565991   \n",
       "15173    009LK0vLcY              10107             1683778565991   \n",
       "15174    009LK0vLcY              10107             1683778565991   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "0      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "1      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "2      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "3      [~Hao_Sun1, ~Boris_van_Breugel2, ~Jonathan_Cra...   \n",
       "4      [~Aahlad_Manas_Puli1, ~Lily_H_Zhang1, ~Yoav_Wa...   \n",
       "...                                                  ...   \n",
       "15170  [~Tianyang_Hu1, ~Fei_Chen8, ~Haonan_Wang1, ~Ji...   \n",
       "15171  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15172  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15173  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "15174  [~Mehrdad_Ghadiri2, ~David_Arbour1, ~Tung_Mai1...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      What is Flagged in Uncertainty Quantification?...   \n",
       "1      What is Flagged in Uncertainty Quantification?...   \n",
       "2      What is Flagged in Uncertainty Quantification?...   \n",
       "3      What is Flagged in Uncertainty Quantification?...   \n",
       "4      Don’t blame Dataset Shift! Shortcut Learning d...   \n",
       "...                                                  ...   \n",
       "15170  Complexity Matters: Rethinking the Latent Spac...   \n",
       "15171  Finite Population Regression Adjustment and No...   \n",
       "15172  Finite Population Regression Adjustment and No...   \n",
       "15173  Finite Population Regression Adjustment and No...   \n",
       "15174  Finite Population Regression Adjustment and No...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "0      Uncertainty quantification (UQ) is essential f...  Reviewer_AvJq   \n",
       "1      Uncertainty quantification (UQ) is essential f...  Reviewer_7E4k   \n",
       "2      Uncertainty quantification (UQ) is essential f...  Reviewer_hHZH   \n",
       "3      Uncertainty quantification (UQ) is essential f...  Reviewer_sVgx   \n",
       "4      Common explanations for shortcut learning assu...  Reviewer_9QKU   \n",
       "...                                                  ...            ...   \n",
       "15170  In generative modeling, numerous successful ap...  Reviewer_ssMC   \n",
       "15171  The design and analysis of randomized experime...  Reviewer_UdXn   \n",
       "15172  The design and analysis of randomized experime...  Reviewer_ZgSr   \n",
       "15173  The design and analysis of randomized experime...  Reviewer_HGb9   \n",
       "15174  The design and analysis of randomized experime...  Reviewer_zpw6   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "0      1688368213177           1702411303415              6  ...   \n",
       "1      1688505633161           1702411303319              6  ...   \n",
       "2      1688552936677           1702411303221              6  ...   \n",
       "3      1688657604892           1702411303144              6  ...   \n",
       "4      1688617232745           1702411520565              6  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "15170  1688676041356           1702411081106              6  ...   \n",
       "15171  1688449656890           1702411268900              7  ...   \n",
       "15172  1688485585833           1702411268818              5  ...   \n",
       "15173  1688665406904           1702411268706              4  ...   \n",
       "15174  1688755793651           1702411268608              4  ...   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "0                   12.8720      15.9897     14.4442   \n",
       "1                   13.0922      15.3049     14.1918   \n",
       "2                    7.7200      10.1878     10.7063   \n",
       "3                   14.3916      17.9549     16.1666   \n",
       "4                   13.3014      14.7013     14.2653   \n",
       "...                     ...          ...         ...   \n",
       "15170               10.0714      13.0114     12.5486   \n",
       "15171               11.7042      14.5675     13.9100   \n",
       "15172               11.2691      13.9387     13.4543   \n",
       "15173               14.9547      18.5308     16.4682   \n",
       "15174               13.1560      17.2540     15.6161   \n",
       "\n",
       "       automated_readability_index politeness_score  hedge_C  hedge_D  \\\n",
       "0                          13.2649           0.0948       86        0   \n",
       "1                          12.6374           0.0690       94        0   \n",
       "2                           7.5081           0.1601       73        0   \n",
       "3                          14.5827           0.5533       90        0   \n",
       "4                          13.4733           0.0671       97        0   \n",
       "...                            ...              ...      ...      ...   \n",
       "15170                      10.1760           0.0667       94        0   \n",
       "15171                      11.9698           0.1450       93        0   \n",
       "15172                      11.2038           0.1508      107        0   \n",
       "15173                      16.3810           0.1249      107        0   \n",
       "15174                      13.6344           0.1932       98        0   \n",
       "\n",
       "       hedge_E  hedge_I  hedge_N  \n",
       "0            0        0        0  \n",
       "1            0        0        0  \n",
       "2            0        0        0  \n",
       "3            0        0        0  \n",
       "4            1        0        0  \n",
       "...        ...      ...      ...  \n",
       "15170        0        0        0  \n",
       "15171        1        1        0  \n",
       "15172        0        0        0  \n",
       "15173        0        0        0  \n",
       "15174        0        0        0  \n",
       "\n",
       "[15175 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_iclr = pd.read_json('data/processed/openreview_iclr2024_v8.json')\n",
    "df_neurips = pd.read_json('data/processed/openreview_neurips2023_v8.json')\n",
    "\n",
    "# Display the dataframes\n",
    "display(df_iclr)\n",
    "display(df_neurips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "202c318e-7986-4908-ac61-cbe54be4d97c",
       "rows": [
        [
         "1446",
         "wfzXa8e783",
         "1940",
         "1695136750006",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "Reviewer_EGJf",
         "1698648757307",
         "1701662567826",
         "6",
         "3",
         "3",
         "3",
         "2",
         "**Summary:** \nThis paper presents an open-source toolkit based on LoRa. I believe this work might be more appropriate for the \"benchmarking and datasets\" track. Positioned here, it's challenging for me to evaluate the innovation this paper offers. **Remarks:** \nWhile the improvements and variants on LoRa are relatively straightforward, the theoretical part of the paper seems sound. **Recommendation:** \nI would advise the authors to provide clear insights through experiments and offer some specific suggestions. I cannot evaluate this paper because I believe it is proper for a benchmarking and dataset track, not the main track.",
         "94",
         "0",
         "0",
         "0.7561",
         "0.2401515152",
         "0.7697365284000001",
         "75",
         "34",
         "42.4333",
         "11.2328",
         "14.7773",
         "13.5591",
         "13.3105",
         "0.2025",
         "77",
         "1",
         "2",
         "0",
         "0"
        ],
        [
         "1447",
         "wfzXa8e783",
         "1940",
         "1695136750006",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "Reviewer_DWom",
         "1698746208577",
         "1699636125239",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a comprehensive library for evaluating text-to-image finetuning methods, typically based on LoRA. In addition to different algorithms, it also provides comprehensive evaluation criteria. Finally, some experimental results provide some insight about different finetuning methods. 1. This is a good engineering paper that provides a library for text-to-image finetuning methods evaluation.\n2. It support different matrix factorization techniques such as LoRA, LoHa, LoKr, DyLoRA, GLoRA, GLoKr and so on.\n3. This paper also consider comprehensive evaluation metrics, including fieldity, controllability, diversity, base model preservation and image quality. 1. This paper mainly focus on LoRA-based finetuing strategies, can it be expanded to other parameter-efficient finetuning methods such as \\[1\\] and \\[2\\]? It doesn't provide a clear explanation.\n2. The conclusion about the performance of different finetuning methods is not clearly presented in the experimental section. Maybe some tables can more straightforwardly represent your final conclusions. \n\n\\[1\\] Qiu, Zeju, et al. \"Controlling Text-to-Image Diffusion by Orthogonal Finetuning.\" arXiv preprint arXiv:2306.07280 (2023).\n\\[2\\] Xie, Enze, et al. \"DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning.\" arXiv preprint arXiv:2304.06648 (2023). Please refer to the weakness section.",
         "187",
         "6",
         "9",
         "0.8365",
         "0.053061224500000004",
         "0.9117403030000001",
         "52",
         "10",
         "16.9695",
         "13.6251",
         "15.3091",
         "13.6811",
         "14.7228",
         "0.2131",
         "78",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1448",
         "wfzXa8e783",
         "1940",
         "1695136750006",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "Reviewer_PnHf",
         "1698822869626",
         "1699636125143",
         "6",
         "4",
         "4",
         "4",
         "3",
         "This author introduces LyCORIS, an open source library dedicated to fine-tuning of Stable Diffusion, which integrates a comprehensive range of finetuning methods. For rigorous comparisons between the implemented methods, the author proposes a comprehensive evaluation framework that incorporates a wide range of metrics. Based on the evaluation framework, the author performs extensive experiments to compare different fine-tuning algorithms and to assess the impact of the hyperparameters (i.e, training epochs, learning rate, trained layers, et al). Overall, the experiments, comparisons, analyses, and results of the entire paper are very well-rounded and thorough. 1. Developing an open-source library is of great significance in fostering the advancement of a particular field. After comparing the existing open-source libraries available online, the LyCORIS library offers a relatively more comprehensive set of algorithms.\n\n2. The author has developed a comprehensive benchmark to evaluate various algorithms from multiple perspectives, addressing a significant gap in the text-to-image field. This thorough evaluation and comparison of existing finetuning methods have been lacking in the domain until now.\n\n3. The author conducted comprehensive experiments for different algorithms and parameters; in addition, the author also provided a detailed analysis of the current mainstream fine-tuning algorithms. 1. HuggingFace has also released the PEFT library, which supports a wider range of pre-trained models and includes the methods mentioned in the paper. Therefore, what are the advantages of the LyCORIS library compared to PEFT?\n\n2. The paper conducted a multitude of experiments and comparisons on existing methods and various hyperparameters, leading to certain conclusions. Based on these findings, could there be a more optimal algorithm or design compared to previous ones? For this kind of paper that builds benchmarks based on a certain field, I would recommend the author to submit to a journal.",
         "289",
         "0",
         "5",
         "0.7676",
         "0.17214285710000002",
         "0.8675829172",
         "52",
         "9",
         "20.4212",
         "15.1974",
         "18.2257",
         "16.5672",
         "16.3167",
         "0.1213",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1449",
         "wfzXa8e783",
         "1940",
         "1695136750006",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "Reviewer_ekPo",
         "1699260725548",
         "1699636125075",
         "8",
         "4",
         "3",
         "3",
         "4",
         "The authors propose LyCORIS, an open-source library that contains multiple fine-tuning techniques for Stable Diffusion. The authors also explore many improved fine-tuning techniques such as LoCon, LoHa and LoKr. This paper also presents evaluations for different fine-tuning techniques using multiple metrics and prompt types. (1) The theory and experiments are both solid. The paper has over 57 pages devoted to analyzing the fine-tuning techniques.\n(2) The details for experiments are very clear.\n(3) In addition to the framework, the authors also explore other fine-tuning techniques. (1) The results of this framework combined with ControlNet can be presented in this paper.\n(2) Efficiency (time and GPU memory cost) of different approaches are not provided and analyzed. (1) Please refer to the main questions in the weakness section.\n(2) A minor question: It will be better if the authors provide the results on other versions of stable diffusion, such as SD2.0 and SDXL.",
         "151",
         "0",
         "0",
         "0.7539",
         "0.0711904762",
         "0.7818619609",
         "52",
         "4",
         "48.9543",
         "9.5572",
         "10.8611",
         "11.3747",
         "10.6575",
         "0.1844",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1642",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_HFRa",
         "1697955924532",
         "1699636992453",
         "3",
         "4",
         "2",
         "2",
         "1",
         "This paper introduces ν-ensembles, a novel deep ensemble algorithm that achieves both efficiency and conceptual simplicity. When presented with an unlabeled dataset, ν-ensembles generate distinct labelings for each ensemble member and subsequently fit both the training data and the randomly labeled data. The strength of ν-ensembles lies in their ability to enhance deep ensemble diversity and calibration without significantly increasing computational demands. Key strengths include improved calibration in both in-distribution and out-of-distribution settings, achieved without complex implementation or extensive hyperparameter tuning. This method maintains the efficiency of standard deep ensembles, ensuring diversity through a straightforward process of assigning random labels to unlabeled data points. The theoretical grounding via PAC-Bayesian analysis provides a guarantee of diversity, accuracy, and calibration on test data, making ν-ensembles a promising and efficient technique for enhancing deep neural network ensembles. 1. The paper lacks the related works of other calibration method such as train time calibration loss, and post hoc calibration which is very important in this domain.\n2. From my experience, the ECE measurement could be very unstable when classification accuracy is low. For experiments in table 1 for CIFAR100, the accuracy is very low, and the results may not reliable.\n3. The experiments lack the comparison with SOTA methods such as Focal Loss Calibration and Adaptive Label Smoothing. In table 1, how many times does the author run the experiments? Since the ECE measurement can be very stable among low prediction accuracy models, the ECE reported in Table can have very large variance. Please report the variance of multiple runs to verify the effectiveness of your method.\n\nThe experiment is limited to CIFAR10 datasets. Since the authors mention that the small dataset regime often happens in medical area. It is better to verify your algorithm on the small medical datasets.",
         "296",
         "0",
         "3",
         "0.7848",
         "0.052918367300000005",
         "0.9382253885",
         "47",
         "19",
         "22.8589",
         "14.6669",
         "18.2108",
         "15.9828",
         "15.2685",
         "0.2519",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1643",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_bec4",
         "1698206643703",
         "1699636992323",
         "3",
         "3",
         "2",
         "2",
         "1",
         "This paper introduces an ensembling technique for making use of unlabeled data in $k$-class classification. Namely, the authors suggest training $k$ models, each of which see a different (randomly selected without replacement) label for each unlabeled data point. In this way, at least one model is guaranteed to have trained on a correct data point (since we exhaust all labels). The authors show that this approach can have benefits with respect to calibration metrics such as ECE when compared to other ensembling approaches on small-scale datasets. - **Originality:** Although the proposed method is quite simple, to the best of my knowledge I have not seen a similar approach analyzed empirically or theoretically in the literature on ensembling. \n- **Quality:** The paper motivates the proposed method with a simple example and attempts to provide theoretical justification with a PAC-Bayes bound and related analysis. The algorithm and associated experiments in the paper are described well, but I have reservations about the quality of experiments as detailed in weaknesses below.\n- **Clarity:** The experiments in the paper are easy to follow, but the theoretical aspect of the work is not as clear.\n- **Significance:** Improving ensembles is an important problem, and the idea of diversifying ensembles has received much attention over the past few years. As such, the paper considers a significant problem, but I question the progress made on this problem by the proposed method. ## Main Weaknesses\n1. **Insufficient experimental setup for proposed method.** \n    The authors claim that for small-scale datasets their method preserves the performance boost of standard ensembling but results in better calibration, while maintaining the same level of efficiency (as opposed to joint training methods that are compared to). However, this comparison seems incomplete - firstly, my understanding is that the compared-to ensembling approaches do not make use of the additional unlabeled data (at least standard ensembling does not). In Table 1 (the main table in the paper) the results are with respect to a training size of 1000 data points, but the unlabeled data size and validation size are 5000 points each. As a result, this comparison seems unfair - one should at least consider some other pseudo-labeling scheme for the unlabeled data, since it makes up the majority of the data being considered.\n\n    Additionally, even this part aside, the authors should compare the method to training ensembles with some kind of data augmentation (label smoothing \\[1\\], Mixup \\[2\\], etc.) since these methods are not only known to improve feature learning diversity but also regularize predicted confidences. Furthermore, training with these methods is going to be even more efficient than the proposed approach, and I expect would perform better. My reasons for expecting this are two-fold: firstly, the proposed approach intuitively regularizes confidence by having the ensemble uncertainty be high on the unlabeled data (essentially these points should be predicted uniformly randomly based on how the ensembles are trained), but Mixup and label smoothing are approaches that can do this as well. Additionally, and more importantly, the authors themselves note that their approach does not work (and can even hurt) for larger dataset sizes, but the aforementioned data augmentations are known to improve calibration even in that regime.\n\n2. **Theoretical approach needs greater clarity.** The theory here needs significantly more clarification in my view. For example, the authors define $\\hat{\\rho}$ to be a uniform combination of point masses on different weights (and even here the notation should be made more precise, $\\delta$ is not defined a priori) and then claim that $\\hat{V}$ is the empirical variance of $\\hat{\\rho}$, but that is not what it represents from Equation (2), which is the variance of the predictive distribution of the ensemble when evaluated with respect to the true labels of data points in $U$. Furthermore, for the predictive distribution the authors use $p(y \\mid x, f)$ in Equation (2) and it should be clarified at this point that $y$ corresponds to the true label of $x$ (which the authors mention later). More importantly, the proof of Proposition 1 is very hard to make sense of. What is the indicator variable of $y$ not being in the random labels? Aren't the random labels supposed to be exhaustive? Even ignoring this, how does the second term become zero when passing from the first line to the second line? \n\n## Recommendation\nOverall I do not think the merits of the proposed approach are significant enough to merit acceptance, so my recommendation is **reject**. It is possible I misunderstood some aspects of the theory and I am happy to correct some of my statements here upon author clarification, but I feel even with that the authors would need more comprehensive experimental comparisons to emphasize the usefulness of the approach. My main questions are stated above as part of weaknesses.",
         "796",
         "2",
         "3",
         "0.7691",
         "0.11389269410000001",
         "0.9224106073",
         "47",
         "16",
         "35.7231",
         "14.3942",
         "17.0581",
         "15.4976",
         "15.9236",
         "0.1932",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1644",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_i38b",
         "1698692174281",
         "1699636992166",
         "6",
         "4",
         "4",
         "4",
         "4",
         "The paper proposes a very neat method for improving the diversity of deep ensembles: It assigns random labels to a set of unlabelled data and lets each ensemble component fit different random labels such that these ensemble components can be diverse. The paper further provides theoretical guarantees for the resulting ensembles' behavior on test samples. The empirical results further show that the method acquires significantly better calibration on small training dataset regime, without sacrificing accuracy. Importantly, the method only introduces little extra training overhead while outperforming baseline approaches that are way more complicated. Overall, I think the proposed idea is novel, interesting, easy-to-use, and could be of great impact. - The proposed method is easy! It is much easier and efficient to implement than other methods for enhancing ensemble diversity, such as Stein-based methods.\n\n- The proposed method comes with theoretical guarantees: Although the method sounds like some heuristic, the author provides PAC-Bayes bounds for its performance on test data.\n\n- The empirical performance improvement is significant: The results show that the proposed method improves the calibration error to a great extent for both in-distribution test data and out-of-distribution data (i.e. corrupted data), without hurting the accuracy. - The method \"Sample y randomly without replacement\", however, when the number of ensemble is larger than the number of classes, it is unclear to me how the method should be applied.\n\n- Since the method assumes having access to a validation dataset, a baseline worth considering would be temperature scaling.\n\n- The presentation of the results can be improved: There is no legend for the lines in Figure. 2; The usage of bold font is not consistent and confusing in Table. 1 Why the method becomes less effective when we have access to more data?\n\nIf I understand correctly, the method assigns random labels to **in-distribution** data, this sounds weird to me, as it implies that the ensemble would have high uncertainty on these in-distribution samples. I think one can also consider introducing OOD samples into training and assigning random labels to them for each ensemble member.",
         "345",
         "0",
         "0",
         "0.7883",
         "0.061763565900000005",
         "0.9469445348000001",
         "47",
         "10",
         "33.8655",
         "13.4897",
         "15.7641",
         "14.8858",
         "14.3705",
         "0.1932",
         "99",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "1645",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_My8L",
         "1698833708470",
         "1699636992048",
         "5",
         "4",
         "3",
         "4",
         "2",
         "The authors present a method for improving the calibration of deep neural network ensembles in the small data regime when access to an unlabelled data set is assumed. In particular, they propose the counterintuitive idea of randomly labelling the unlabelled dataset (distinctly for each ensemble member) and training the deep ensemble on the joint supervised and randomly labelled data. The randomly labelled data promotes ensemble diversity. A PAC bound which relates generalisation performance to ensemble diversity is derived while the diversity of the ensemble is demonstrated to be related to the ensemble size. Experiments on various slices of CIFAR-10 and CIFAR-100 show that while the method does not improve accuracy relative to standard ensembles, there are substantial gains on calibration. Calibration does not improve consistently over more complicated/expensive diversity promoting ensemble methods. - The paper is very well written and clear.\n- The idea for the method, of using randomly labelled unsupervised data to promote ensemble diversity is simple, cheap and easy to implement and in so far as promoting diversity makes sense.\n- Some theoretical results are presented in which the ensemble diversity is related via a PAC bound to the generalization performance (I have some other comments on these results below).\n- The experimental results are convincing that at least in the small data regime with relatively little unsupervised data the calibration relative to standard ensembles is significantly improved. Please see my questions in the section below for potential weaknesses that can be addressed through further experiments.\n\n- The method is targeted solely at the small data regime, gains in calibration go to zero as the amount of labelled data increases.\n- The method introduces a new $\\beta$ hyperparameter which must be tuned.\n- The experiments are presented without error bars and it is unclear if they come from a single run or are averaged over multiple seeds, standard practice, especially when considering the relative small datasets considered in this paper is to run experiments with multiple random seeds and present averages and standard deviations of the metrics of interest (or better yet other forms of statistical test of the significance of the results).\n- Experiments are conducted on small slices of CIFAR-10 and CIFAR-100, while performance in the large data regime is alluded to in the paper, an experimental evaluation of this setting (for example ImageNet is fairly standard in the ensemble literature) would be much appreciated.\n- From equation 3, it seems to be the case that as the number of classes (c) increases the gains in ensemble diversity go to zero, so the method is both likely to give no gains in the large data and large number of classes regime.\n- The primary theoretical motivation for the method is equation 1, which is a PAC bound on the generalization performance, it is difficult to get a sense of how tight this bound is and to what extent there is a competition between the various terms in the bound.\n\nSmall things (didn't effect rating):\n- Typo: \"coincides we standard weight decay\" -> \"coincides with standard weight decay\"\n- It took me a while when reading the paper printed out to realise that there are two colours plotted in the left hand side of Figure 2 - as the orange is almost fully hidden by the red, making this clear in the figure or caption would be helpful to readers. - While the experimental results do not show big drops in accuracy, I am quite concerned that given vastly more unlabelled data the method would lead to overfitting the random labels and thereby harm test set accuracy (as is a well known phenomenon in the noisy label literature). More formally one could imagine that vast amounts of unlabelled data would promote the diversity term in the RHS of equation 1, but I given results in the noisy labels literature, I would find it hard to believe that this would not come at a corresponding cost in the first term on the RHS of equation 1. Could the authors please comment on this concern? Experimentally, I would be interested in seeing an experiment on ImageNet, for example, where the labelled set is of size 50k and the unlabelled set is 950k examples, a standard resnet50 or similar capacity model is used with 4 ensemble members (as per other papers in the literature) and a comparison to standard ensembles in terms of accuracy and calibration is given. This is a significant concern for me, as usually with methods that make use of an unsupervised dataset, the expectation is that as the unlabelled dataset grows, the gains from using it grow to. I fear this will not be the case for this method, which would limit the method to the small dataset, small number of classes and small unlabelled dataset regime. I recognise that the $\\beta$ hyperparameter can to a certain extent control this trade-off, so if further experiments are conducted to address this concern, please report the results over the $\\beta$ hyperparameter range.",
         "835",
         "0",
         "0",
         "0.7756",
         "0.0024741462",
         "0.9451873302",
         "47",
         "9",
         "28.0723",
         "17.4922",
         "20.681",
         "17.4907",
         "18.7118",
         "0.5162",
         "99",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1646",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_3iBP",
         "1698897134942",
         "1699636991904",
         "5",
         "4",
         "3",
         "3",
         "2",
         "The paper introduces a method to enhance the calibration of deep ensembles, particularly in situations where there is a small amount of labeled data and some unlabeled data. For each point in the unlabeled dataset, the ensemble members are trained with different randomly selected labels. The authors provide a theoretical justification for this approach, drawing on PAC-Bayes bounds to argue that it leads to lower negative log-likelihood and higher ensemble diversity on test samples. Empirically, they demonstrate that ν-ensembles outperform standard ensembles in terms of diversity and calibration, especially when the training dataset is small or moderate in size. - The paper gives a method to improve calibration error for deep ensembles using unlabeled data. The use of unlabeled data to improve calibration error of deep ensembles has not been explored much before as most of the works have focused on joint training approaches which can be memory and computationally expensive.\n- The paper is overall well written and easy to understand. \n- The paper presents supports their method with both theoretical and experiments. - One major weakness of the paper is that their method only improves calibration error not accuracy but they have not compared to any other calibration technique like temperature sampling. \n- The other issue is that the method appears very similar to the Agree to disagree work mentioned in the paper where they also use unlabeled data to maximize diversity and the idea seem incremental. Can the authors please explain in detail how exactly Agree to disagree maximizes diversity on the unlabeled set?\n- Another limitation is that this method only improves calibration in the small data regime. \n- Another limitation is that there are only two datasets used in the paper - CIFAR-10 and CIFAR-100. It would be nice to have additional datasets. - The paper says that the labels for unlabeled data points are chosen without replacement. What happens if we sample with replacement? One should expect the same empirical results to hold but maybe the theoretical argument will not hold?\n- I understand the text written at bottom of the Figure 1 but I don’t understand the figure. What are the 3 columns in the figure?\n- One part that is not clear to me is when we are forcing the models to make random predictions on unlabeled data which is from the same distribution, why we are not hurting the accuracy or the cross entropy loss of the model? When training data is small and unlabeled data set is bigger, can the authors share their regularization parameters and if they had to give small weights on the regularization term?\n- The colors used in figure 2 and 3 are very similar and it is hard to distinguish different lines. \n- There are other works which also use this idea of diversifying using unlabeled datapoint for other problems. For example, DIVERSIFY AND DISAMBIGUATE: OUT-OF-DISTRIBUTION ROBUSTNESS VIA DISAGREEMENT. Can the authors please compare to this work also?\n- Did the authors try using the unlabeled data from different distributions like random Gaussian noise. One benefit would be that fitting random labels on this dataset will not interfere with the learning on the original distribution.",
         "530",
         "0",
         "0",
         "0.7822",
         "-0.026552287600000002",
         "0.9537856579",
         "47",
         "8",
         "40.043",
         "12.4219",
         "14.9313",
         "14.341",
         "12.1643",
         "0.12560000000000002",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2116",
         "vRyp2dhEQp",
         "1283",
         "1695036218168",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "Reviewer_tXy3",
         "1698113315631",
         "1699636055179",
         "6",
         "4",
         "3",
         "2",
         "2",
         "The submission focuses on the backdoor attacks in data-constrained scenarios. By leveraging CLIP-based technologies, the proposed CLIP-CFE (CLIP for Clean Feature Erasing) suppresses clean features while amplifying poisoning features to achieve more efficient attack with limited poisoning samples. + The submission presents a novel method, which introduces the optimized feature erasing noise to effectively suppress benign features. Besides, it enhances the poisoning features through contrastive learning and amplifies the existing backdoor attacks efficiently in data-constrained scenarios.\n\n+ The experimental results demonstrate the effectiveness of the CLIP-based attacks in data-constrained scenarios. Across various real-world constraints such as *number-constrained, class-constrained*, and *domain-constrained* conditions, the proposed backdoor attack consistently achieves a high attack success rate while maintaining the benign accuracy. + **Insufficient experimental results**\n\nThe submission should take more recent backdoor attack and defense mechanisms into consideration while discussing the adaptive defenses more thoroughly, e.g., the noise used for erasing benign features might be unlearned \\[1, 2\\]. Besides, it is necessary to compare the effectiveness of utilizing different proxy extractors other than CLIP.\n\n\n+ **Ambiguous expressions**\n\nSeveral points in the submission need further explanation, e.g., the reason and effect of choosing the overall attack process relying on the style of CLIP within the feature space, and the analysis of erasing benign features compared to the semantic-agnostic out-of-domain samples.\n\nReferences:\n\n\\[1\\]: Li Y, Li Y, Wu B, et al. Invisible backdoor attack with sample-specific triggers. Proceedings of the IEEE/CVF international conference on computer vision. 2021: 16463-16472.\n\n\\[2\\]: Akhtar N, Liu J, Mian A. Defense against universal adversarial perturbations. Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 3389-3398. Given that the submission's motivation is related to data-constrained scenarios, the author may provide more empirical evidence regarding to the occurrence of these backdoor attacks in real-world scenarios.",
         "295",
         "3",
         "2",
         "0.8060",
         "0.15949633700000002",
         "0.8649680018",
         "53",
         "17",
         "17.1557",
         "14.8827",
         "18.7003",
         "15.9032",
         "17.3402",
         "0.0999",
         "79",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2117",
         "vRyp2dhEQp",
         "1283",
         "1695036218168",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "Reviewer_kSYS",
         "1698236409147",
         "1699636055090",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper proposes a new backdoor attack that performs well in data-constraint conditions that are more akin to real-world scenarios. The attack uses the CLIP model as a feature extractor to diminish the entanglement between benign and poison features. The experiment results show significant improvement compared to previous methods in these more realistic conductions. - A novel approach to backdoor attack\n- Comprehensive evaluations - CLIP limits the application domain\n- Defense discussion missing\n- Runtime information missing The authors present a novel backdoor attack that utilizes the pre-trained CLIP model as a feature extractor to suppress benign features and accentuate poison features. The attack also relaxes previous assumptions that having knowledge of the training datasets and the target models trained on datasets from one distribution. The authors show previous methods do not perform well in these more realistic scenarios but their new method is consistently effective and the trigger is hard to detect visually. Overall, the paper is well-written and the evaluation is comprehensive. However, there are a few points I would like to see the authors to further address.\n\n- The usage of the CLIP model for backdoor attacks is indeed novel. However, this also limits the domains of possible application of the attack. While the method seems to perform well on datasets with natural sceneries, such as CIFAR-100, CIFAR-10, and ImageNet-50, the performance cannot be guaranteed on datasets where the domain drastically differs from CLIP’s training set, such as medical scans, satellite imageries, etc. Additionally, even for similar domains, it would be interesting to see if the feature extraction capabilities transfer onto fine-grained datasets, such as CUB-200-2011, Stanford-Cars, Oxford-Flowers, etc. The authors should consider including results on more diverse datasets.\n\n- The target models used in this paper are all relatively simple/small (experimental settings focused). They also differ drastically from the CLIP model both in terms of architecture and performance. The authors have already pointed out the effect of model architecture in Section 5.1. Evaluating the attack on more advanced and larger architectures, such as ViT, can further prove the author’s claim for applicability in real-world scenarios.\n\n- Discussion regarding potential defenses is also missing. It would be interesting to see how this new attack performs against backdoor detection or defense methods. Since the optimization suppresses the clean features and augments the poison features, defense/detection methods that rely on optimization, such as Neural Cleanse\\[1\\] could potentially be more effective (compared to defending against traditional backdoor attacks). Furthermore, a recent work\\[2\\] on backdoor defense seems to use similar intuition (detangling benign and poison features). It would be interesting to see how this defense performs against an attack that is intuitively similar.  \n\\[1\\]Wang et al. Neural cleanse: Identifying and mitigating backdoor attacks in neural networks. 2019. In IEEE Symposium on Security and Privacy (S&P).  \n\\[2\\]Min et al. Towards Stable Backdoor Purification through Feature Shift Tuning. 2023. arXiv preprint arXiv:2310.01875.\n\n- Considering the optimization process needed to conduct this attack, the authors should consider including relevant runtime information. Since the focus of this paper is on presenting a backdoor attack that is applicable in real-world scenarios, the computing resource required can be another limiting factor. \n\nMinors:\n\n- Fonts in figures are too small to be legible\n- Page 8, VGG-16 datasets? (should be models)",
         "544",
         "4",
         "5",
         "0.8294",
         "0.1282828283",
         "0.8720514774",
         "53",
         "16",
         "30.8873",
         "13.0891",
         "15.2929",
         "14.3292",
         "14.0499",
         "0.1262",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2118",
         "vRyp2dhEQp",
         "1283",
         "1695036218168",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "Reviewer_nLdg",
         "1698654858453",
         "1699636055014",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper assumed a threat model for backdoor attacks, so-called as ‘data-constrained backdoor attacks’, where the attacker doesn’t have access to the entire training dataset. Then, the authors claimed that the exiting backdoor attacks are inefficient in this new threat model. The authors considered an interesting topic on AI security, specifically, how to improve the backdoor efficiency in a data-constrained scenario. First, the authors only provided the empirical results to support the performance decline when the exiting backdoor attack in the new threat model, as shown in Fig.2. I highly recommend that the authors give a possible theoretical analysis to this phenomenon.\n\nSecondly, the new proposed 'clip-guided backdoor attack' method includes two components: clean feature suppression and poisoning feature augmentation. Specifically, the main idea is to exploit adversarial example to generate the noise to suppress the clean feature or amplify the poison feature. Unfortunately, as far as I know this idea has been exploited by many published papers, for instance, as shown as follows. The main difference of this paper is that it is based on a novel pre-trained model CLIP.\n\n\\[1\\] Zhao, Shihao, et al. \"Clean-label backdoor attacks on video recognition models.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\\[2\\] Turner, D. Tsipras, and A. Madry, “Label-consistent backdoor attacks,” arXiv preprint arXiv:1912.02771, 2019.\n\nIn summary, the main idea has been exploited already, which will significantly reduce the contribution of this paper. What is the main difference between the 'clip-guided backdoor attack' with the existing references which have been mentioned in the 'weaknesses'",
         "258",
         "2",
         "2",
         "0.7959",
         "0.1806709957",
         "0.8726058006",
         "53",
         "11",
         "38.9541",
         "11.5963",
         "13.3574",
         "13.4046",
         "13.2499",
         "0.0795",
         "86",
         "2",
         "0",
         "0",
         "0"
        ],
        [
         "2119",
         "vRyp2dhEQp",
         "1283",
         "1695036218168",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "Reviewer_rJBe",
         "1698840789932",
         "1699636054933",
         "6",
         "4",
         "3",
         "2",
         "2",
         "This paper addresses an important and practical backdoor attack scenario called data-constrained backdoor attacks. The key insight is that in real-world settings, attackers often do not have full access to a victim's entire training dataset, which spans multiple sources. The paper clearly defines three variants of data-constrained attacks based on restrictions on the number of poisoning samples, classes, or domains.\nA thorough set of experiments on CIFAR and ImageNet datasets demonstrates that existing backdoor methods like BadNets and Blended attacks fail under data constraints, due to entanglement between benign and poisoning features. The analysis of this entanglement issue is a nice contribution. To address this limitation, the authors cleverly utilize CLIP in two ways: 1. Clean feature suppression via CLIP-CFE to erase benign features.\n2. Poisoning feature augmentation via CLIP-UAP and CLIP-CFA to amplify poisoning features.\nThe introduction of CLIP for backdoor attacks is novel. Results show CLIP-UAP and CLIP-CFA consistently outperform baseline triggers across constraints, architectures, and datasets. CLIP-CFE provides further improvements in attack success rate. The attacks remain stealthy and do not impact benign accuracy. 1.\tAddresses a highly practical attack scenario of data-constrained backdoor attacks that reflects real-world training environments where attackers have limited data control.\n2.\tProvides a clear taxonomy of data-constrained attacks based on restrictions to number of samples, classes, and domains.\n3.\tIdentifies through analysis and experiments that existing attacks fail under data constraints due to entanglement of benign and poisoning features. This is an important insight. 1.\tWhile the data-constrained scenario is practical, the specific sub-variants of number, class, and domain constraints may not fully capture all real-world limitations an attacker could face. More complex constraints could be studied.\n2.\tThe computational overhead and time required for the CLIP optimization process is not extensively analyzed. This could be a limitation for realistic attacks.\n3.\tThe stealthiness metrics mainly rely on signal processing based measures like PSNR and SSIM. More rigorous stealthiness analysis like visualizations and defense evaluations may be beneficial. see in weakness",
         "330",
         "0",
         "8",
         "0.8079",
         "0.10107993200000001",
         "0.9159598351",
         "53",
         "9",
         "30.2501",
         "12.6044",
         "15.1937",
         "13.8498",
         "14.4178",
         "0.0999",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2133",
         "vQiD6v1w41",
         "3932",
         "1695328069592",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "Reviewer_XYg3",
         "1698710426902",
         "1699636353905",
         "3",
         "4",
         "3",
         "1",
         "2",
         "The paper presents a new framework for semi-supervised domain adaptation (SSDA) that establishes an upper bound on target error. This framework introduces a method called Joint Error-based Triplet Alignment (JTA), which performs alignments not only between the labeled source domain and the unlabeled target domain but also between the labeled source domain and the labeled target domain. As a result, their empirical studies demonstrate that JTA can reduce domain gaps and enhance feature learning by explicitly considering the alignment for the labeled target data. The paper also introduces a dissimilarity metric known as Maximum Cross Margin Discrepancy (MCMD) to bridge the gap between theory and algorithm, ensuring the consistency of the target error bound. The main problem of this paper is the lack of sufficient details to understand and follow their motivation and derivation. Given the promising empirical results presented in the paper, I strongly recommend that the authors consider a complete rewrite of the paper, focusing on delivering a clear and well-motivated presentation. This should involve providing comprehensive derivations with sufficient details or citations, ensuring that each step of each equation is transparently explained for the benefit of the reader's understanding. The performance of the proposed work is promising. 1. I find the paper's motivation unclear. To be specific, the upper bound of the hypothesis regarding the unlabeled target domain should be the most crucial starting point for readers to comprehend what the proposed method aims to address. However, the lack of an explanation for the proof of Equation (1) makes it extremely difficult for me to grasp and follow. Concerning D.1, I am unsure how the first equation of the unlabeled target error bound was derived. If it stems from Ben David's theorem (assuming my recollection is accurate, Ben David did not derive any error bound under semi-supervised settings) or the work of others, it would be beneficial to provide citations so that readers can fully contextualize and understand the subject matter.\n\n2. What is the source of the intractability, particularly for f_{S} and f_{V}? Given that both S and V are fully labeled, it seems reasonable to assume that a straightforward optimization approach like empirical risk minimization (ERM) could yield a reasonable approximation for f_{S} and f_{V). The mention of intractability is often made within the framework of variational inference, where certain integrations cannot be feasibly solved. Providing a clear explanation of this intractability would significantly enhance the paper's motivation.\n\n3. How is the reduction of the error term achieved between two fixed true labeling functions? I want to emphasize that \"true\" here means unchanging or fixed. The paper is proving a complex upper bound derivation, and its clarity is hindered by inconsistent definitions throughout, making it difficult to follow.\n\n4. The t-SNE visualization, without any indications of the class labels for each data sample, fails to convey meaningful information. In fact, I find the t-SNE visualization rather perplexing. I recommend that the authors consider sharing the code for their implementation with the reviewers. This would serve not only to confirm the reproducibility of their work but also to enhance the reviewers' understanding of the proposed methodology.\n\n5. The experimental setup lacks clarity, particularly in the context of semi-supervised domain adaptation, where the number of labeled target samples and the way to select the labeled target sample are crucial. It is important to provide sufficient details regarding the sample selection process. \n\n6. The authors assert that \\[1\\] violates the triangle inequality without providing a thorough explanation or derivation. This is a strong claim, as it implies \\[1\\] is a departure from well-established theoretical foundations, especially considering that \\[1\\] is published on a top tire. To support their claim, the authors should conduct in-depth elaboration and studies.\n\n### Reference\n\n\\[1\\] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for domain adaptation. In Proceedings of the 36th International Conference on Machine Learning, volume 97, pp. 7404–7413. PMLR, 2019. 1. Could you please clarify what is meant by the conditional distribution referred to in Section 3.1? To be specific, which random variables are conditioned on which other random variables? Based on the authors’ preliminary at the beginning of the section that both f_{S} and f_{V} are true labeling functions (true means fixed and deterministic). Meanwhile, I am confused by the idea of describing a mapping function (mapping function is normally deterministic) as a distribution (sampling from a distribution is stochastic). How come a stochastic term can be used to describe a deterministic notation? Can you elaborate on this?\n\n2. To me, the loss introduced in this work appears to be an extension of the one (MDD) presented in \\[1\\] to the semi-supervised setting. I would appreciate it if the authors could offer a comprehensive discussion outlining the primary distinctions between \\[1\\] and their proposed approach, excluding the consideration of the semi-supervised setting and the violation of the triangle inequality. \n\n### Reference\n\n\\[1\\] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for domain adaptation. In Proceedings of the 36th International Conference on Machine Learning, volume 97, pp. 7404–7413. PMLR, 2019.",
         "849",
         "7",
         "12",
         "0.7813",
         "0.0869150691",
         "0.9562900662",
         "49",
         "10",
         "35.4208",
         "13.2123",
         "16.0491",
         "14.7848",
         "14.7039",
         "0.9511000000000001",
         "96",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2134",
         "vQiD6v1w41",
         "3932",
         "1695328069592",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "Reviewer_tePx",
         "1698782026911",
         "1699636353828",
         "3",
         "3",
         "2",
         "2",
         "1",
         "The paper at hand proposes a method for domain adaptation by including some labeled data from the target domain. A \"triplet alignment\" is introduce which aims for aligning feature distributions as well as minimizing classification error. + relevant problem - The paper is quite hard to read and understand. Figures are rather small. Honesty speaking Fig. 1 even confused me more than it helped me to understand the approach.\n- Experimental results are hard to interpret and judge. If I read it correctly, the effect of data augmentation seems significant. When comparing without data augmentation  (ours* in Tab. 1) the advantages over previously proposes approaches seems marginal (if at all). I also miss confidence intervals. - What are clear advantages of the approach -- e.g., the claim that \"data augmentation is not nessaccary for our approach\" (besides still having a significant impact) is not well motivated.\n- What are limitation of the approach?",
         "153",
         "0",
         "1",
         "0.8190",
         "0.0409090909",
         "0.9198144674000001",
         "49",
         "9",
         "44.2428",
         "9.6968",
         "12.6354",
         "11.8999",
         "8.5706",
         "0.1932",
         "97",
         "0",
         "1",
         "0",
         "1"
        ],
        [
         "2135",
         "vQiD6v1w41",
         "3932",
         "1695328069592",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "Reviewer_hsiV",
         "1698808420540",
         "1699636353732",
         "1",
         "5",
         "3",
         "3",
         "1",
         "This paper proposed a joint error based triplet alignment approach to solve the semi-supervised domain adaptation problem. They evaluated on several cross-domain benchmarks by comparing with several methods. Generally, the paper is easy to follow. However, the novelty is not enough. This paper proposed a joint error based triplet alignment approach to solve the semi-supervised domain adaptation problem. They evaluated on several cross-domain benchmarks by comparing with several methods. Generally, the paper is easy to follow. They show various results to examine their methods. The novelty is not enough. The joint error based triplet alignment is not new, which is an extension of maximum cross margin discrepancy to three subsets, source, labeled target and unlabeled target. Eventual model is also very complicated. \n\nThe model performance is not good enough. Especially compared with DECOTA in Table 1 & 2, it is very comparable. Also for semi-supervised setting, the selected target samples are very essential. There is no standard variance. Also t-test is needed to examine the significance. The clarification of model novelty.\nThe performance improvement.",
         "174",
         "0",
         "0",
         "0.7846",
         "0.0049242424",
         "0.9568377137",
         "49",
         "9",
         "38.6381",
         "10.2578",
         "12.8618",
         "11.645199999999999",
         "10.255",
         "0.0999",
         "100",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2136",
         "vQiD6v1w41",
         "3932",
         "1695328069592",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "Reviewer_TnGf",
         "1698960672685",
         "1699636353588",
         "3",
         "3",
         "3",
         "3",
         "2",
         "This work introduces a Triplet Alignment approach for semi-supervised domain adaptation. It simultaneously minimizes the joint error among different domains and the error rate on labeled data. 1.\tThe motivation for this work is clear. It aims to address the challenge of semi-supervised domain adaptation, particularly when only a limited number of annotated examples are available in the target domain. The proposed method optimizes both the classification loss and the joint error across source, labeled, and unlabeled target domains simultaneously.\n2.\tThe proposed models are presented in a clear and comprehensible manner. 1.\tThe proposed model, to the best of my knowledge, lacks significant novelty as it closely resembles the approach in \\[2\\]. It would be helpful to explicitly identify the main difference.\n2.\tThe choice of baseline methods in this work appears to be less competitive. Given the recent progress in semi-supervised domain adaptation (SSDA), including \\[1\\]\\[2\\], it is advisable to compare the proposed method with these contemporary approaches. Furthermore, while the use of t-SNE for feature space visualization is commendable, the comparisons are made with older methods like ENT (Grandvalet & Bengio, 2005), MJE (Zhang & Harada, 2019), and MME (Saito et al., 2019). It is imperative to include comparisons with more recent methods to provide a comprehensive evaluation.\n\\[1\\]  Yu, Yu-Chu, and Hsuan-Tien Lin. \"Semi-Supervised Domain Adaptation with Source Label Adaptation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\\[2\\] Rahman, Md Mahmudur, Rameswar Panda, and Mohammad Arif Ul Alam. \"Semi-Supervised Domain Adaptation with Auto-Encoder via Simultaneous Learning.\" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2023. Please see \"Weaknesses\"",
         "270",
         "6",
         "7",
         "0.7760",
         "0.1943277311",
         "0.9432914257",
         "49",
         "7",
         "34.3667",
         "11.97",
         "14.4481",
         "13.3652",
         "13.0976",
         "0.1719",
         "94",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2686",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_pc5v",
         "1698547649041",
         "1699636458715",
         "5",
         "5",
         "2",
         "3",
         "2",
         "This paper presents the Ranking-Constrained Actor-Critic algorithm, an offline reinforcement learning approach for optimizing Mixed Integer Linear Programs (MILPs). Traditional MILP solvers depend on hand-crafted heuristics for branching, limiting their efficiency and generalizability. Recent deep learning methods rely on high-quality training data, which can be scarce, particularly for large problems. The key contributions of the paper are the development of the new RL algorithm and its ability to efficiently learn branching strategies even from sub-optimal training data. The algorithm outperforms previous methods in terms of prediction accuracy and computational efficiency across various MILP problems, addressing the limitations of traditional solvers. This paper claims to be innovative by being the first to apply offline reinforcement learning algorithms in branch-and-bound methods. Furthermore, the essence of the proposed method lies in further refining the dataset, specifically selecting the top-k actions in the set Gω for Bellman operator operations. This can effectively enhance the performance of the branching strategy. I believe this perspective can also be inspiring for similar problems in other domains. This paper proposes training branch-and-bound strategies using offline reinforcement learning. However, in practice, interacting with solvers is relatively straightforward, and under these circumstances, using online reinforcement learning may yield better performance. The authors need to clarify the necessity of utilizing offline reinforcement learning. •\tConsidering that interacting with solvers online is convenient, is there a necessity to use offline reinforcement learning to train branch-and-bound strategies?\n•\tIn Equation 7, when k is small, the distribution of Q-values over the dataset will be centered around -δ, which is unfavorable for training. How do the authors ensure training effectiveness in this scenario?\n•\tI believe that the essence of the method proposed by the authors lies in further refining the dataset, specifically selecting the top-k actions in Gω for Bellman operator operations. I am curious to know if, after obtaining the top-k actions in Gω, simple imitation learning on these state-action pairs would yield similar results as the current approach. In other words, my question is whether the key to the effectiveness of this algorithm lies in the dataset refinement rather than offline reinforcement learning. I suggest that the authors conduct further ablation experiments to validate this idea.",
         "365",
         "0",
         "0",
         "0.8040",
         "0.07807720060000001",
         "0.9679618478",
         "49",
         "12",
         "20.8673",
         "15.082",
         "18.2288",
         "16.1033",
         "16.537",
         "0.1507",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2687",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_s5Ux",
         "1698571655333",
         "1699636458619",
         "3",
         "4",
         "3",
         "2",
         "2",
         "This work proposes the usage of offline reinforcement learning for variable selection in the branch-and-bound algorithm. To do so, they introduce a novel offline algorithm that uses a classifier to determine whether a state-action pair is in the offline dataset. Their offline Q-values are now restricted towards picking only the top-k most likely actions for each state. The usage of offline reinforcement learning seems more fitting than current imitation learning algorithms due to its lack of reliance on high quality demonstrations. - The paper is a little unclear at some points. For instance, in the last paragraph of Section 2.2: Which variables are the selected ones? Just from the node chosen by the node selection policy, or all variables across the entire tree? In general, the distinction between node selection and variable selection doesn’t become clear: Does the method also do node selection (by picking variables from the entire tree), or just variable selection?\n- Further, it is not exactly clear whether there is a single model trained and evaluated on all instances, or multiple independent models trained on and evaluated on individual datasets.\n- One missing benchmark is the utilization of an off-the-shelf offline RL algorithm, such as conservative Q-learning as a baseline for the specific utility of RCAC over more established offline-RL algorithms (I.e. is the improvement in performance due to offline-RL or RCAC specifically?).\n- The testing set is also rather small: 10k training instances, 2k validation instances and, 20 test instances is a strange ratio.\n- The reward function is also a little bit strange: Why consider the dual bound, but ignore the primal one completely? Further, these bounds are not scale-invariant, meaning that the same problem, modulo a constant scalar, could have different dual bound improvements. Even if one takes care to normalize the objective vector c beforehand, most solvers like SCIP rescale this vector for increased numerical stability. Depending on which problems are chosen, the range of rewards across different instances might also be massive depending on the duality gap. However, we agree with the authors that this metric is still better than tree-size or number of nodes.\n\nSome minor points:\n- Abstract: hand-craft\\[ed\\]\n- Intro: The sentence “All of these models are trained…” needs a re-write\n- Intro: “To our knowledge, … to apply offline RL to MILP solving” (re-write)\n- Sec. 2: typo pseudocsot\n- Sec. 2.2. A\\[n\\] MDP\n- Equation 4: one closing brace is too much (after $Q_\\theta$)\n- Sec. 3.1: when a\\[n\\] MILP instance\n- Sec 3.1: discounted factor $\\rightarrow$ discount factor\n- Sec 3.3: citation of Gasse et al.: use cite instead of citep; same again happened in Sec. 4.1\n- Sec. 4.1: please use cite and citep depending on how you add these citations into the text\n- Sec. 5.2 does not add any benefit to the paper and can be omitted in its current state - Which set of variables if being selected from?\n- What is the performance of other offline-RL algorithms?\n- Can you evaluate on a larger testset?\n- Why only look at the dual bound improvement (alternative: optimality gap between primal and dual)?\n- In Sec 3.2. “In fact, a good action does no harm to policy optimization even if it is an OOD action” – can you please elaborate on this a bit more?",
         "553",
         "0",
         "4",
         "0.8156",
         "0.0484206349",
         "0.8696163893000001",
         "49",
         "12",
         "48.758",
         "10.5731",
         "13.5684",
         "13.0239",
         "10.5035",
         "0.25670000000000004",
         "96",
         "0",
         "2",
         "2",
         "0"
        ],
        [
         "2688",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_3oNR",
         "1698766364331",
         "1699636458528",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper studies the problem of learning variable selection policies for mixed-integer linear programming (MILP). The authors propose an offline reinforcement learning (RL) approach to learn branching strategies from sub-optimal or inadequate training signals. Experiments demonstrate the proposed method outperforms baselines on various benchmarks. 1.\tThe paper is easy to follow.\n2.\tExperiments demonstrate the proposed method outperforms baselines on various benchmarks. 1.\tThe novelty of the proposed method is incremental, as the proposed method is a simple application of offline reinforcement learning methods to branching strategies learning.\n2.\tThe authors claim that the proposed method is the first attempt to apply the offline RL algorithms to MILP solving. However, I found one previous work \\[1\\] applies offline RL methods to branching strategies learning as well. \n3.\tThe authors may want to explain the novelty of their method over the work \\[1\\] in detail.  \n4.\tThe experiments are insufficient. First, the authors may want to evaluate their method on the load balancing dataset from the ML4CO competition as well. Second, the baselines are insufficient. The authors may want to compare their method to the work \\[1\\]. Third, the authors may want to evaluate the generalization ability of the learned models.\n\n\\[1\\] Huang, Zeren, et al. \"Branch Ranking for Efficient Mixed-Integer Programming via Offline Ranking-Based Policy Learning.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Cham: Springer Nature Switzerland, 2022. Please refer to Weaknesses for my questions.",
         "239",
         "4",
         "8",
         "0.6839",
         "0.0766666667",
         "0.89818573",
         "49",
         "10",
         "40.7962",
         "10.694",
         "13.0651",
         "12.3033",
         "11.9765",
         "0.1719",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2689",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_nNZN",
         "1699130159488",
         "1699636458444",
         "8",
         "3",
         "3",
         "3",
         "2",
         "The paper considers the problem of learning to select branching strategies while solving mixed integer programs via branch and bound algorithm. The key idea is to collect offline training dataset using full strong branching as behavior policy and learn an offline RL algorithm to generate the learned branching policy. Improvement of the dual bound is chosen as the reward function. Experiments are performed on four synthetic and two real world problems. - Using offline RL for branching policies seems like a natural idea that should do better than pure imitation learning. I am surprised that this wasn't tried earlier and commend the paper for making this simple but natural idea work well. \n\n- The description of the problem and solution is written clearly and easy to understand.\n\n- The proposed approach performs well on multiple benchmarks. - A large part of the paper talks about sub-optimality of the FSB policy. For example, this statement \"Although FSB generally achieves high-quality branching, it could still become sub-optimal when the linear programming relaxation is uninformative or there exists dual degeneracy\" Is there more justified argument for this backed by some evidence?\n\n- why choose the proposed algorithm over any existing offline RL algorithm like CQL\\[1\\], IQL etc.?\n\n\\[1\\] Kumar, A., Zhou, A., Tucker, G., & Levine, S. (2020). Conservative q-learning for offline reinforcement learning. Advances in Neural Information Processing Systems, 33, 1179-1191. - What are connections of equation 6 to reward weighed regression?",
         "240",
         "3",
         "2",
         "0.8317",
         "0.1780952381",
         "0.9082451463000001",
         "49",
         "5",
         "39.297",
         "11.6371",
         "14.282",
         "13.6629",
         "11.9277",
         "0.12",
         "109",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2690",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_9gri",
         "1699190885255",
         "1699636458378",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The authors propose an offline Reinforcement Learning (RL) framework for learning to branch (L2B) which reportedly exhibits superior performance with a sub-optimal dataset compared to existing methods that require extensive, high-quality datasets. This advantage is particularly notable in reducing the time to collect datasets for training the models. The reported performance on the MIP instances also indicates the effectiveness of the framework. 1. **Innovative Formulation:** The novel formulation of L2B as an Offline RL approach using a sub-optimal dataset is a significant departure from traditional methods.\n2. **Efficiency in Data Collection:** The framework requires significantly less time to collect its dataset, enhancing its practicality.\n3. **Performance:** The proposed framework improved performance compared to the GGCN framework on smaller dataset sizes, which is commendable. Despite the novelty of the work, I have reservations about the robustness of its results. These concerns are expanded upon in this section and further detailed in the questions that follow. \n\n1. **Lack of Scaling-Generalization Results:** A key aim of collecting datasets on smaller instances is to develop policies that excel on larger, more complex instances. It would be beneficial to see how various models perform on scaled-up versions of instances in various problem categories like SC, MIS, CA, or CFL. How do these policies perform on Medium or Hard instances (scaled-up versions) in SC, MIS, CA, or CFL? Does RCAC retain its performance advantage on scaling up to larger instances?\n\n2. **Insufficient Comparison with Existing Methods:** \n- The paper lacks a thorough comparison with recent advancements in the GGCN framework, particularly the augmented loss function introduced in \"Lookback for Learning to Branch\" (Gupta et al. 2022, https://arxiv.org/abs/2206.14987). It would be insightful to see how RCAC compares to this improved GGCN variant. \n - If I understand correctly, RCAC (S) and GGCN (S) primarily differ in their approach to training despite similarities in other aspects, such as dataset collection. Specifically, GGCN (S) employs a Cross-Entropy loss function, while RCAC (S) is focused on learning a Q-function (and a corresponding policy). The distinctiveness of the RCAC framework lies in its utilization of rewards instead of directly using FSB selections, as is the case with GGCN. However, an alternative comparison could involve integrating rewards into the GGCN framework as an additional signal. This could be achieved, for instance, by employing rewards to modulate the Cross-Entropy loss at each node, similar to how node depth might be used. Demonstrating RCAC's superior performance in this modified context would further reinforce the effectiveness of its RL-based approach as formulated in the study. \n    - It would be valuable to have the values of \\( k \\) specified for each model. I am particularly curious to know whether \\( k > 1 \\) for RCAC(S).\n- Comparisons with other RL methods, especially in terms of dataset size and time efficiency, would also be valuable. Clarifications:\n\n1. **Section 3.3:** Should \"representation of the B&B tree\" be replaced with \"representation of the B&B node\" for accuracy? \n2. **Training Dataset for GGCN (H) and RCAC (H):** Are these models trained on the same dataset? Is GGCN (H) trained on a separate dataset collected as specified in the Appendix?\n3. **VHB Dataset Transitions:** Could the authors clarify what constitutes a 'transition' in this context? Does the transition include (s,a,s’) even when FSB is not employed in VHB, which is 0.05 times? Do you discard any transition? How is it ensured that you explore a wide array of instances before 100K transitions are collected?\n4. **S Method Training:** Is the S method trained with only 5K transitions? \n5. **Reward Distribution:** Could the authors provide details on the distribution of reward values in the dataset, perhaps in the Appendix? Information on how this varies with tree depth and how normalization is handled would be valuable.\n6. **Figure 3 Clarity:** What is the specific problem family represented in Figure 3?\n7. **Practicality of H dataset collection:** Given that VHB takes longer than FSB (as indicated in column 2), is it still a practical choice since the performance is worse than S?\n8. **GGCN Expansion:** Could the authors clarify the abbreviation GGCN? It seems to be a variation of GCNN (Graph Convolutional Neural Networks) as used in Gasse et al. 2019.\n9. **Inference Procedure in RCAC:** Are there two forward passes $G_\\omega\\$ and $\\pi_\\phi$ during inference in RCAC? How does this differ from the inference process in GGCN?\n10. **Hyperparameter \\(k\\):** Figure 3 suggests that \\(k\\) has a significant impact on RCAC's performance. Could the authors provide the \\(k\\) values used for each model and dataset?\n\n11. **Aggregation in Table 4:** How are scores aggregated across 20 instances in Table 4? Assuming this is a cumulative sum, RCAC appears to outperform in WA but not against RPB in AP. Can the authors speculate on which problem types might be more amenable to improvement by RCAC?\n\n12. **Reward Ablation:** Could the authors discuss the rationale behind choosing dual bound improvement over primal-dual gap improvement? Understanding the preference for one metric over the other would be enlightening.\n\n\nSuggestions:\n1. **Dataset Comparison:** I think it will be pretty helpful to have a section or a figure demonstrating the difference (transition vs. individual nodes) between the dataset collected using the standard IL methods and the one proposed in this work. \n2. **Statistical Significance:** Please include p-values to indicate the statistical significance of differences in Tables 2 and 3.\n3. **Evaluation Methodology:** Given that 20 seems a relatively small sample size for testing, it's common practice to evaluate each instance with multiple seeds, as demonstrated in Gasse et al. 2019. Could the authors clarify whether a similar approach can be employed in their study?",
         "936",
         "1",
         "23",
         "0.7754",
         "0.0670068027",
         "0.8958138227",
         "49",
         "5",
         "40.0849",
         "12.1838",
         "15.6848",
         "14.5266",
         "13.367",
         "0.30210000000000004",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3122",
         "tQ8gcygV4p",
         "1080",
         "1695005759142",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "Reviewer_MDsd",
         "1698325660933",
         "1699636034553",
         "3",
         "5",
         "2",
         "3",
         "1",
         "Offline reinforcement learning (RL) suffers from the extrapolation error. There are numerous model-free and model-based offline RL algorithms that aim to tackle this challenge. Among them, model-based offline RL algorithms often learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, such quantifications are often inaccurate. This paper addresses this issue by training bidirectional dynamics models and rollout policies, and design a conservative rollout method that selects those synthetic transitions with the smallest reconstruction loss. The authors provide some theoretical analysis of their method and build their method upon some off-the-shelf model-free offline RL algorithms. # Strengths\n\nThe strengths can be summarized below:\n\n- this paper is well-motivated, and the whole paper structure is clear\n\n- the logic flow of this paper is clear, and it is easy to follow and understand\n\n- the authors provide theoretical analysis to support their method # Weaknesses\n\nDespite the aforementioned strengths, this paper has some flaws in novelty, empirical evaluation, and theoretical analysis. Based on these considerations, I can confirm that this paper is clearly under the acceptance bar of this venue. Please see the detailed comments below.\n\n- (major) The core idea presented in this paper is NOT new. A highly relevant paper is published previously \\[x\\]. In \\[x\\], the authors also train bidirectional dynamics models and bidirectional rollout policies for offline data augmentation. Thus, the technical parts of this paper have a huge overlap with \\[x\\], making the contribution and significance of this paper quite weak. The differences are, that this paper selects the transitions with reconstruction loss while \\[x\\] selects reliable transitions via the proposed double check mechanism. It is doubtable whether the data selection approach adopted in this paper is better than the double check method, as intuitively, the reconstruction loss may not be reliable for forward/backward horizon larger than 1 (where no true next/previous states are available)\n\n\\[x\\] Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination. NeurIPS 2022.\n\n- (major) The empirical evaluations are limited and somewhat weak. The baseline algorithms this paper adopts are very old. It is somewhat confusing why the authors only choose to compare against these very weak algorithms. More advanced and recent offline RL algorithms ought to be included as the baselines (e.g., TD3BC, IQL, Decision Transformer, LAPO, etc.). The authors build their method upon CQL, BCQ, and BEAR. Can your method benefit more advanced offline RL algorithms?\n\n- (major) This paper does not consider statistical significance. Written statements and the presentation of the results as tables (often without standard deviations) obscure this flaw. In fact, ALL tables in this paper does not include any signal of statistical significance, e.g., std, IQM. We have reached a point of maturity in the field where claims need to be made in reference to actual statistical evidence, which seems to be lacking in the current presentation.\n\n- (major) The theoretical analysis is also not new. Similar techniques are adopted in the MBPO paper. Specifically, one online model-based RL algorithm BMPO \\[y\\] theoretically shows that the error of the bidirectional models is smaller than unidirectional models, making the theoretical insights of this paper less appealing and unsurprising.\n\n\\[y\\] Bidirectional model-based policy optimization. ICML 2020.\n\n- (minor) The authors ought to specify the version of the D4RL datasets they use in the paper. In Table 1, your evaluated scores in halfcheetah-medium-expert are questionably low, why is that?\n\n- (minor) This paper does not do a good job in the related work part, the authors include too few recent offline model-based/model-free offline RL papers Please refer to the the weaknesses part.",
         "603",
         "0",
         "3",
         "0.7867",
         "0.0567165212",
         "0.9565235972",
         "53",
         "15",
         "32.288",
         "13.2124",
         "15.5541",
         "14.3361",
         "14.0344",
         "0.3178",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3123",
         "tQ8gcygV4p",
         "1080",
         "1695005759142",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "Reviewer_qiBS",
         "1698549177482",
         "1699636034488",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a new model-based method for offline reinforcement learning. The key technical contributions of the proposed model include: 1) It learns the bidirectional rollouts of the state transitions and the reward functions; 2) It learns forward and backward offline policies, following the BCQ method. With the learned bidirectional dynamics model and the corresponding policies, given a pivotal data point drawn from the offline dataset, the replay buffer can be augmented with the generated data trajectories. \n\nAdditionally, the paper provides a theoretical analysis, establishing a tighter bound on the rollout error for the conservative bidirectional rollouts compared to unidirectional approaches. \n\nFinally, the empirical findings on the D4RL benchmark demonstrate the effectiveness of the proposed method. 1. The proposed method is simple, reasonable, and effective on the existing D4RL benchmark, showing great potential for practical offline RL applications. \n2. The paper is well-written and easy to follow. The overall design of the proposed method is presented in a clear and thoroughly motivated manner. \n3. The method seems to be a highly versatile framework. As shown in the paper, it can be easily integrated with existing model-free offline RL approaches. 1. My primary concern with this paper is about the novelty of the proposed bidirectional rollout technique. At NeurIPS 2022, a paper titled \"Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination\" by Lyu et al. introduces a conceptually similar idea. In both papers, forward and backward models are trained to augment the offline dataset. It is crucial for the authors to address this similarity and provide a comprehensive comparison between COBiMO and the method presented by Lyu et al., considering aspects such as model design and empirical results.\n2. In the experiment section, the authors present averaged results of 6 random seeds. To enhance the statistical robustness of their findings, it would be better to include the standard deviations over multiple runs in Tables 1-3. \n3. The paper primarily compares COBiMO with approaches that were proposed 2-3 years ago. It would be beneficial for the authors to extend their comparisons to include more recent advances in offline RL to provide a comprehensive evaluation of COBiMO's performance in the context of the most current state of the field.\n4. In Section 5.3, there is an absence of an explanation regarding the factors that lead to performance degradation in certain tasks when COBiMO is applied (which can be reasonable but needs more analysis). Besides, as claimed in Section 5.3, the proposed method outperforms the original algorithms significantly in 10/12 tasks. However, it's essential to ensure that all relevant results supporting this claim are presented, as only a partial subset of the results is currently shown in Table 3.\n5. Typos:\n- In the first paragraph of Section 5.1, \"...from three domain\" should be corrected to \"...from three domains\".\n- In the third paragraph of page 4, \"...represents a gaussian distribution...\" should be \"...represents a Gaussian distribution...\". In summary, my primary concerns include the technical novelty in comparison to the missing reference (major), and some finer details of the provided experimental results (minor).",
         "513",
         "0",
         "8",
         "0.7682",
         "0.1505058522",
         "0.9512968659000001",
         "53",
         "12",
         "35.9958",
         "12.2057",
         "14.9981",
         "13.9117",
         "12.7486",
         "0.30110000000000003",
         "96",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3124",
         "tQ8gcygV4p",
         "1080",
         "1695005759142",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "Reviewer_7BFv",
         "1698807801456",
         "1699636034401",
         "3",
         "4",
         "2",
         "3",
         "1",
         "This paper studies the model-based offline reinforcement learning problem. The authors propose to learn bidirectional model and bidirectional behavioral policies and use them to generate rollout trajectories. The output policy is obtained by a model-free offline reinforcement learning on the augmented dataset. The paper provides theory and empirical study to justify the proposed algorithm. 1. The paper is clearly written and easy to follow. 1. The Related Work misses important paper. For instance, this paper is not the first to use bidirectional model in offline learning. Confidence-aware Bidirectional Offline Model-based Imagination is the first to apply this idea to the best of my knowledge.\n2. I cannot recognize the algorithmic novelty of the algorithm. Forward imagination is widely used in model-based offline learning and Reverse Imagination was first proposed in ROMI. This paper seems to just combine these two ideas directly without justifying why it can substantially improve the performance\n3. The theory seems to be trivial.\n4. The experiment misses important baselines, such as ROMI and Confidence-aware Bidirectional Offline Model-based Imagination which share similar ideas. Besides, the performance does not seem compelling if one also look at the performance in ROMI and Confidence-aware Bidirectional Offline Model-based Imagination paper. 1. What is the main intuition behind using bidirectional imagination? Why should we expect it provide substantial improvement?\n2. What does the theory part tell us, is there any interesting insight?\n3. How does the algorithm perform compared to other later model-based algorithms? How does the algorithm perform on other tasks in D4RL?",
         "252",
         "0",
         "7",
         "0.7828",
         "0.1666666667",
         "0.9260005355",
         "53",
         "9",
         "30.2158",
         "12.3398",
         "14.5116",
         "13.4487",
         "12.3402",
         "0.1199",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3581",
         "sKPzAXoylB",
         "8965",
         "1695531697040",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "Reviewer_KmBd",
         "1698096053419",
         "1699637128872",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "487",
         "0",
         "1",
         "0.7320",
         "0.1304191468",
         "0.9185432792",
         "47",
         "17",
         "29.0538",
         "13.6602",
         "16.2613",
         "15.0211",
         "14.0811",
         "0.1695",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3582",
         "sKPzAXoylB",
         "8965",
         "1695531697040",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "Reviewer_3zCE",
         "1698692987251",
         "1699637128739",
         "3",
         "4",
         "4",
         "3",
         "1",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "480",
         "0",
         "0",
         "0.8331",
         "0.09343537410000001",
         "0.9183989763",
         "47",
         "10",
         "39.3732",
         "11.51",
         "13.8202",
         "13.2344",
         "11.9386",
         "0.1932",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3583",
         "sKPzAXoylB",
         "8965",
         "1695531697040",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "Reviewer_y5kB",
         "1698706759624",
         "1699642867494",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "10",
         "41.9389",
         "11.9311",
         "14.8075",
         "13.9683",
         "12.4911",
         "0.050100000000000006",
         "104",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3584",
         "sKPzAXoylB",
         "8965",
         "1695531697040",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "Reviewer_XNx6",
         "1699165868969",
         "1700672717423",
         "6",
         "4",
         "2",
         "2",
         "3",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.9159082770000001",
         "59",
         "17",
         "42.2021",
         "12.1002",
         "14.7586",
         "13.9683",
         "12.0852",
         "0.929",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3590",
         "sK2A7Ve2co",
         "5473",
         "1695387922229",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "Reviewer_XKu5",
         "1698340335396",
         "1699672907827",
         "1",
         "3",
         "1",
         "1",
         "1",
         "The paper proposes a method to obtain Gaussian approximations of posterior distributions in Bayesian deep learning. The experiments compare the proposed method against several related approaches on toy experiments as well as classification on CIFAR-10/100 and ImageNet. The authors report that their method tends to produce samples quicker than competitor methods. The paper is definitely still a work in progress and not ready for publication at a conference like ICLR.\nThus, I vote for rejection and encourage the authors to completely revise their manuscript and submit to another venue.\n\nThe writing style and organization of the paper is very bad, which makes it extremely hard to follow. In particular, the theoretical exposition is lacking:\n- The theory is mixed with the related work (Eqs. (1)-(3), last Sec. of 1.1)\n- Central notions and symbols are not introduced, the exposition remains very handwavy. To name only a few examples:\n  - what do the authors mean by \"transforming a pretrained into a Bayesian model\"?\n  - background on MCMC, Metropolis-Hastings corrections\n  - definition of a \"perfect sampler\"\n  - how do the authors define a \"mode-specific MH\"\n  - it remains unclear in which sense the proposed method better deals with multi-modal posteriors than related work\n  - definition of notion of time step $t$ and $\\theta_t$ in Eq. (4)\n  - definition of $D_x$, $D_y$ in Eq. (15, 16)\n  - definition of $\\mathrm{Conf}$ in Eq. (20)\n  - ...\n- The experimental evaluation is not convincing.\n  - While the authors report fast sampling, their approach is outperformed by competitor methods most of the time.\n  - On the simplest toy example (unimodal Gaussian posterior), the authors report good results in terms of effective sample size (which is not very surprising because they use the correct approximation). However, they do not report ESS on the mixture model (Figure 2 RHS). \n  - The authors argue that their method deals well with multi-modal posteriors. Thus, they should compare\n against other methods that capture multiple modes, i.p., Deep Ensembles \\[1\\] and Multi-SWAG \\[2\\].\n  - As the authors employ a Gaussian posterior approximations, they should compare against variational Gaussian approximations, e.g., BayesByBackprop \\[3\\].\n\n\\[1\\] Lakshminarayanan et al., \"Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles\", NeurIPS 2017\n\n\\[2\\] Wilson & Izmailov, \"Bayesian Deep Learning and a Probabilistic Perspective of Generalization\", NeurIPS 2020\n\n\\[3\\] Blundell et al., \"Weight Uncertainty in Neural Networks\", ICML 2015 Please elaborate on the concerns raised below \"Weaknesses\".",
         "399",
         "6",
         "1",
         "0.8017",
         "0.055785256400000004",
         "0.9074112773",
         "49",
         "15",
         "40.3959",
         "11.5687",
         "14.224",
         "13.3617",
         "12.3358",
         "0.2383",
         "104",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3591",
         "sK2A7Ve2co",
         "5473",
         "1695387922229",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "Reviewer_xaq1",
         "1698616789279",
         "1699636558195",
         "3",
         "5",
         "2",
         "2",
         "2",
         "This paper proposes an adaptive proposal sampling (APS), a mode seeking sampler that adapts the proposal to match a posterior mode. The proposed ``adaptive proposal sampler'' appears to be new in the literature. 1. Extension of the proposed sampler to high-dimensional problems is questionable. As mentioned in the paper, the parameters are regarded as independent of each other, making the proposed sampler less accurate and thus less attractive. \n\n2. When the modes of the target distribution are well separated, it is difficult to believe that the proposed sampler can efficiently traverse the entire energy landscape because, similar to the Metropolis-Hastings algorithm, the proposed sampler lacks a mode-escaping mechanism. \n\n3. For the exact Gaussian proposal sampler, the acceptance rate can be low when the dimension of \\theta is high. 1. If the exact GPS is applied to the numerical examples of the paper, will the reported results be improved? How much?   \n\n2. The proposed method needs to compare with more baseline methods, such as SGHMC \\[1\\]  and adaptively weighted SGLD \\[2\\], on multi-modal and high-dimensional problems.\n\nReferences: \n\n\\[1\\] Chen et al. (2014) Stochastic Gradient Hamiltonian Monte Carlo. ICML 2014. \n\n\\[2\\]  Deng et al. (2022) An adaptively weighted stochastic gradient MCMC algorithm\nfor Monte Carlo simulation and global optimization. Statistics and Computing, 32:58.",
         "211",
         "6",
         "9",
         "0.7536",
         "0.06515948960000001",
         "0.9111343622",
         "49",
         "11",
         "38.8025",
         "11.8793",
         "15.971",
         "14.332699999999999",
         "12.8694",
         "0.0751",
         "96",
         "2",
         "1",
         "0",
         "0"
        ],
        [
         "3592",
         "sK2A7Ve2co",
         "5473",
         "1695387922229",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "Reviewer_zCTz",
         "1698618917865",
         "1699636558088",
         "3",
         "4",
         "1",
         "2",
         "2",
         "The paper proposes a new sampling algorithm for multi-modal distributions, especially deep neural network posteriors. Specifically, the authors learn an adaptive Gaussian proposal along with sampling. Several experiments, including synthetic distributions and deep learning tasks, are conducted to test the proposed method. 1.\tThe studied topic of sampling on multi-modal distributions is important.\n2.\tThe proposed algorithm is simple to implement in practice. 1.\tThe proposed method does not achieve what it claims to “having both exactness and effectiveness”. Apparently, the method is not exact without the MH correction step. The method is only exact when the target distribution is a Gaussian with a diagonal covariance, which is a trivial case. I’m not sure what “perfect sampler” means in the paper. Overall, I think many claims need to be modified in order to be accurate and rigorous. \n2.\tThe methodology of the proposed method is confusing. The algorithm does not have a component to encourage exploring multiple modes. It is unclear to me how the method manages to find diverse modes. \n3.\tAlgorithm 1 seems to find a Gaussian distribution to approximate the target distribution. How is it different from variational inference? What are the advantages?\n4.\tWhy does the proposed method require a pretrained solution, theta_MAP? Will it work if training from scratch? \n8.\tI do not follow the reason for introducing the variance limit lambda. Why does the method need it?\n9.\tThe experimental setups and results are confusing. It is unclear if the authors also use a pre-trained solution for the baseline NUTS in S3.1. If not, then it is unfair to claim faster convergence of the proposed method than NUTS. Besides, given that the method uses a pre-trained solution, it is unsurprising that “We found that a-GPS converges so fast that a burn-in period was unnecessary”. For the time comparison, it is unclear if the authors include pre-training time.\n10.\tFor deep learning experiments, it will be better to include MCMC baselines, e.g. Zhang et al, as the proposed method belongs to MCMC methods. To show the samples are from diverse modes, the authors can visualize weight space and function space, similar to those in Zhang et al.\n\n\nZhang et al, Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning, ICLR 2020 1.\tWhy is LA’s inference time even less than MAP? Why is the proposed method’s inference time less than SWAG? Does the proposed method use Bayesian model averaging during inference?",
         "405",
         "0",
         "9",
         "0.7441",
         "0.0309343434",
         "0.9304510951",
         "49",
         "11",
         "53.1978",
         "8.9835",
         "12.1736",
         "11.8164",
         "9.3087",
         "0.1932",
         "96",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3593",
         "sK2A7Ve2co",
         "5473",
         "1695387922229",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "Reviewer_RZPX",
         "1698652042813",
         "1699636557963",
         "3",
         "4",
         "3",
         "2",
         "2",
         "The paper proposes a sampler that samples weights via traversing the loss landscape of a pre-trained deep neural network via a series of normal distributions. The approach is evaluated on a series of classification and out-of-distribution detection tasks. The paper proposes a sampler that samples weights via traversing the loss landscape of a pre-trained deep neural network via a series of normal distributions. The approach is evaluated on a series of classification and out-of-distribution detection tasks. - The main weakness of the paper is in the experimental evaluation. The experiments show convincingly that the proposal works with several architectures and several classification data sets (no regression tasks were evaluated). What it does not show is that it works better than its baselines, i.e., why should it be used instead of SWAG, or SGD-MC? E.g., SGD-MC almost always outperforms it (it is missing from Table 4, but the results in Table 13, show that it clearly performs better), except for the strange behavior in Table 6.   \n\n\n- The presentation of the paper is rather sub-optimal. E.g.,\n    - parameters such as $c$ and $\\lambda$ appear in the text long before they are even introduced, if at all. The important $\\lambda$, e.g., only is further detailed in Algorithm 1.\n    - The writing contains a lot of typos, e.g., for the first paragraph on the second page\n        - \"full-gradient MCMC similar **to** SG-MCMC\"\n        - \"SGLD **has** fast computations but **suffers** form inefficient explorations\"\n        - \"Previous **works** on state dependent\"\n    - Dropout's absence in most of the results is not explained in the main text but only appears in the one table where it is present rather than absent\n    - The writing is somewhat repetitive\n    - The reference list is full of arxiv preprints instead of the actual publications \n    - Table 4 contains wrong highlights in two columns (ECE and NLL), the same is true for several tables in the appendix.\n    - On the positive side, however, other details, like definitions of performance metrics are highlighted prominently\n\n### Minor\n- SGD-MC is mentioned in the text for Table 4 but not in the actual results\n- LA is missing in Table 3 without an explanation\n- Sec 2.1: \"the loss function, ..., typically cross-entropy is interpreted as the negative log-likelihood\". Cross-entropy is typical for classification tasks, but not for any other tasks. And in this case, it is not just interpreted as a negative log-likelihood, _it is_ the negative of a categorical distribution. \n- For the posterior in  (15). A Gaussian prior is $\\exp(-||\\theta||)$, similarly for the loss factor. This directly provides you with (17) instead of having to redefine anything.\n- Sec 3.2.2 \"separated by high loss area\". As Draxler et al. (2018) and Garipos et al. (2018) show there are a lot of paths of similar loss between a lot of maxima instead of a clear separation. (These motivated the SWA baseline of the present work)\n\n\n\n_____\nDraxler et al., _Essentially no Barriers in Neural Network Energy Landscape_, ICML 2018  \nGaripov et al., _Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs_, NeurIPS 2018 - The conclusion only discusses a-GPS' performance with respect to SWAG and Laplace. Can the authors additionally provide a deeper discussion on their relation to SGD-MC and in general summarize why their approach should be picked instead of these established baselines?\n- SGLD is mentioned in the related work, but never used in the experiments. Can the authors comment on this lack of comparison? Especially since they cite Izmailov et al. (2021) who showed good results for this approach.\n- A lot of approaches and networks diverged or failed otherwise throughout the experiments. Can the authors give further details? E.g., it seems rather strange that a simple model such as VGG should diverge on a straight-forward classification task such as CIFAR100.\n- The method was only tested on classification tasks. What about regression problems? Do the authors expect a similar performance? \n- How is the split in CIFAR10 and CIFAR 100 in 5/50 classes decided? _(Apologies if I missed it somewhere in the appendix)_",
         "675",
         "3",
         "1",
         "0.7542",
         "0.0275083022",
         "0.8832126856",
         "49",
         "11",
         "51.8979",
         "9.7817",
         "12.2617",
         "12.0985",
         "10.234",
         "0.077",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "5623",
         "nxPTSDp9xK",
         "6136",
         "1695409971904",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "Reviewer_Uwik",
         "1698715047173",
         "1699636664998",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper introduces the Cross-Guided Ensemble of Tokens (CrossGET), which is designed to enhance the efficiency of vision-language Transformers. It tackles the significant challenge of mitigating the computational costs and latency associated with vision-language models. Within this framework, two essential components come into play: Cross-Guided Matching and Ensemble, orchestrating the fusion of tokens guided by cross-modal cues, and Complete-Graph Soft Matching, contributing to the refinement of token matching outcomes. 1.Comprehensive Experimentation and Solid Theoretical Foundation: The paper's strength lies in its extensive and well-documented experiments, combined with a rigorous theoretical underpinning for the proposed method. This makes the work sound and reliable, both in terms of its theoretical framework and practical applicability.\n2. Relevance of the Addressed Problem: The choice of the problem addressed in the paper holds significant value, especially in the context of the substantial computational overhead associated with many state-of-the-art multimodal models. This highlights the practical importance of the research. However, it is recommended that the authors extend their analysis and experimentation to encompass a broader range of models, moving beyond the initial exploration with BLIP-2. This would further enhance the paper's contribution and generalizability. 1. Cross-Modal Guidance Utilization: In the paper, the emphasis is placed on the ability of CrossGET to be applied to modality-dependent models like BLIP and BLIP2. The approach involves learning a cross-token to serve as guidance for another modality. However, there are concerns about this approach. Taking BLIP as an example, it appears that it may not fully harness textual guidance. In scenarios like visual grounding, where different textual descriptions highlight various aspects of the same image, it raises questions about how CrossGET selects tokens from different texts to focus on.\n2. Unfair Experimental Comparisons: The paper contains instances of unfair comparisons in the experiments. For example, in section 4.1, the authors directly compare retrieval results of models such as TRIPS and UPOP. Yet, these models vary significantly in terms of training data and model parameter sizes, making the comparison less meaningful. To provide a clearer perspective, the paper should emphasize how much TRIPS, or similar acceleration methods, improve over the baseline, and how much the proposed method accelerates and enhances performance compared to the baseline.\n3. Limited Model Performance Improvement: The paper reports only marginal improvements in model performance while introducing a relatively complex method. Moreover, the acceleration achieved by the proposed method appears similar to that of ToMe. Given the relative complexity of the proposed approach, the effectiveness of this work may be questioned, especially if the gains in performance and acceleration are not substantial. 1. Implementation of Token Reduction in BLIP-2: It would be beneficial for the authors to provide more detailed information on how they specifically implemented token reduction in BLIP-2 within the context of their method. A more elaborate explanation of the process and its impact on BLIP-2's performance would enhance the clarity and completeness of the paper.\n2. Impact of CrossGET on OPT in BLIP-2: A notable aspect of this work is the introduction of CrossGET into the frozen OPT component of BLIP-2 for token reduction. However, it's important to consider that OPT is a decoder-only model. The paper should address how this approach might affect the inference capabilities of OPT and whether any experiments were conducted to analyze and verify why image captioning performance appears to be minimally impacted. Further insight into this aspect of the methodology would enhance the paper's robustness and contribute to a better understanding of the results.Im glad to improve my score if my   concerns be addressed.",
         "586",
         "0",
         "6",
         "0.7977",
         "0.1171066253",
         "0.94465065",
         "48",
         "10",
         "25.0653",
         "14.7832",
         "17.2295",
         "15.7704",
         "16.3387",
         "0.1262",
         "77",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "5624",
         "nxPTSDp9xK",
         "6136",
         "1695409971904",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "Reviewer_4d9L",
         "1698744941721",
         "1702028039451",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper introduces CrossGET, a token reduction-based strategy, to accelerate vision-language transformers. The key contributions of CrossGET can be summarized as follows: 1) CrossGET incorporates cross-modal guided information through cross-modal tokens. 2) CrossGET employs the Complete-Graph Soft Matching (CGSM) strategy, which offers more reliable token-matching results compared to existing bipartite soft matching strategies. Experimental evaluations conducted across multiple models, datasets, and tasks demonstrate the superior performance of the proposed method. The acceleration of VL models is highly relevant for their practical deployment. While this paper presents promising results and extensive evaluations, there are important concerns that should be addressed before publication.\n1. Some experimental results are perplexing. Table 1 suggests that ToMe performs worse when equipped with Adapter or ExtraToken. However, Adapter and VPT are parameter-efficient tuning methods that enhance performance with minimal additional parameters. It is unclear how they could instead degrade performance. I suspect there may be errors in the implementations. It is recommended to double-check the results or provide convincing explanations. Additionally, the upper-right subfigure in Figure 4 is also confusing. In my understanding, CrossGET and ToMe have close GFLOPs under the same configuration (as evident from the left subfigure). Therefore, the significant differences in GFLOPs for each data point pair in the upper-right subfigure indicate that they are compared under different configurations. A reasonable explanation should be provided here. Moreover, the down-right subfigure seems to be unusual as well. How is it possible for the model to achieve even better performance (nearly 86) with only 1/10 GFLOPs? Are the settings the same as in other figures?\n\n2. The contribution of the Complete-Graph Soft Matching (CGSM) appears to be minor. For instance, Table 1 suggests that ToMe and CrossGET $\\Delta$ perform similarly in different metrics, indicating that the proposed CGSM may have little impact. ToMe employs the bipartite soft matching strategy for its efficiency and simplicity, and the ToMe paper demonstrates that this strategy can approximate optimal matching through extensive combination experiments. This paper should provide more evidence (visualizations, analytical experiments) to justify the effectiveness of the proposed CGSM.\n\n3. Most experiments in this paper focus on Image-Text retrieval tasks. Is the proposed method equally effective in other VL tasks, such as the CoOP benchmark or open vocabulary segmentation?\n\n4. This paper lacks an important comparison. \\[1\\] proposes reducing the number of tokens through clustering and demonstrates better performance than ToMe in accelerating transformers. However, this paper only briefly mentions it in the introduction without further discussion or comparisons. It is recommended to include more comparisons (\\[1\\] vs. CrossGET $\\Delta$, \\[1\\] + CGM&CGE vs. CrossGET $\\star$, etc., better in dense prediction tasks) with \\[1\\].\n\nI am glad to increase my rating if my concerns are addressed.\n\n\\[1\\]. Weicong Liang, Yuhui Yuan, Henghui Ding, Xiao Luo, Weihong Lin, Ding Jia, Zheng Zhang, Chao Zhang, and Han Hu. \"Expediting large-scale vision transformer for dense prediction without fine-tuning.\" Advances in Neural Information Processing Systems, 35:35462–35477, 2022a. No other questions.",
         "489",
         "5",
         "6",
         "0.8278",
         "0.1423076923",
         "0.9290834665000001",
         "76",
         "37",
         "31.5291",
         "12.1382",
         "15.0298",
         "13.6713",
         "13.8195",
         "0.1507",
         "76",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "5625",
         "nxPTSDp9xK",
         "6136",
         "1695409971904",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "Reviewer_oYGw",
         "1698817237524",
         "1699636664735",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes cross guided matching and cross guided ensemble as cross-modal importance indicator. Besides, a Complete-Graph Soft Matching algorithm is proposed as an improved version of ToME's bipartite soft matching. 1. Both Cross Guided Matching (CGM) and Complete-Graph Soft Matching (CGSM) is well motivated and proved to be effective.\n2. Extensive experiments are conducted on several vision language tasks for both modal indenpendent VL model (CLIP) and modal dependent VL model (BLIP2). I do recognize the amount of work that went into this submission. 1. The proposed approach is named as Cross-Guided Ensemble of Tokens, however, I find that the proposed Cross-Guided Ensemble (CGE) is not that useful as illustrated in Table 1. So, I think the paper should re-organize the structure and highlight the really useful designs.\n2. The proposed Complete-Graph Soft Matching is not specialized for cross-modal tasks, so does it outperform the ToMe algorithm in general visual recognition tasks? The proposed method can improve the model efficiency after training with little performance loss, and I am curious if the proposed method can also accelerate the training of multi-modal tasks.",
         "183",
         "0",
         "4",
         "0.7942",
         "0.08515625",
         "0.9441901445",
         "48",
         "9",
         "40.5737",
         "12.6515",
         "15.565",
         "14.5546",
         "14.8862",
         "0.0529",
         "73",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "5626",
         "nxPTSDp9xK",
         "6136",
         "1695409971904",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "Reviewer_Yt1v",
         "1698832481643",
         "1701806853489",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper proposes CrossGET to accelerate VLM by token merging. Specifically, this work introduces complete-graph matching to partition tokens and merge/reduce tokens based on similarities. The experimental results on common vision-language tasks demonstrate some effectiveness of the proposed method. The paper is well-organized and the presentation is good. The motivation of accelerating VLMs is clear. 1. The major issue is novelty. CrossGET is incremental over ToMe by replacing ToMe's matching algorithm, adding learnable tokens and adapt unimodal ToMe to the multimodal setting.\n2. As shown in Table 1, the newly proposed matching algorithm has marginal improvements.\n3. CrossGET is proposed to accelerate heavy VLMs. However, majority of experiments are carried out on relatively light-weighted BLIP. There's only a small section for the truly heavy BLIP2, which is a stronger VLM that really needs acceleration.\n4. CrossGET requires fine-tuning of VLMs. (1) In most cases, when models need fine-tuning, they are relatively small (acceleration is not demanding). (2) Huge VLMs that are really heavy can be used as zero-shot in different tasks or different datasets of a same task. In this sense, CrossGET which does not apply to pre-training stage is a bottleneck.\n5. The paper fails to compare or adapt relevant works \\[1\\]\\[2\\].\n\n\\[1\\] DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification, NeurIPS 2021\n\n\\[2\\] Not all patches are what you need: Expediting vision transformers via token reorganizations. ICLR 2022\n\n**Final recommendation**: I agree the paper is improved by additional experiments and extensive analysis, and thus I raise my rating to 5. When CrossGET is applying to Flamingo or BLIP2 which uses frozen LLMs, it reduces to accelerating only vision encoders? Then, there will be a bunch of alternative approaches in accelerating ViTs?",
         "283",
         "4",
         "5",
         "0.8172",
         "0.0279545455",
         "0.9102016687000001",
         "74",
         "34",
         "38.8176",
         "11.3603",
         "13.9992",
         "13.1874",
         "12.0743",
         "0.049",
         "81",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6459",
         "m3xVPaZp6Z",
         "8871",
         "1695527592497",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Reviewer_AWzJ",
         "1697814581368",
         "1700464672733",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This work considers training an agent without online interaction or abundant offline data but only with the reward function of the target environment. Borrowing the idea of rehearsal from the cognitive mechanism, this work proposes policy rehearsal. In detail, this work hopes to train an array of models to imitate the target model. Theoretical analyses indicate that the target environment performance gap between the policy trained in these imitated models and the optimal policy can be bounded by three terms, which are further summarized as diversity and eligibility. Based on these two criteria, this work proposes two corresponding reward functions for training imitated models and then uses these models to train the policy. Also, the proposed ReDM can easily combined with offline datasets. Extensive results show the effectiveness of ReDM. - The ideas about the setting are novel and important, minimizing interaction with the environment as much as possible is an important problem in the RL community. Also, introducing rehearsal into RL is novel and enlightening.\n\n- The writing of Sec 3.2 is clear and solid, I have roughly read all the proofs, which are written quite clearly.\n\n- The proposed ReDM utilizes two novel terms for learning an imitated model, which is interesting and helpful.\n\nCurrently, my evaluation of this paper is really Boardline. If authors can address my concerns in Weaknesses and Questions, or point out what I have misunderstood, I'd like to update my scores accordingly. Also, I will keep active in the following discussion stage. - The connection between diversity and controlling $\\epsilon_e, \\epsilon_a$ is unclear. For example, if all environments are the same, i.e., there is no diversity, it is obvious that $\\epsilon_a=0$ is minimal. There also needs more explanation about why $\\epsilon_e$ can be controlled via diversity.\n\n- Based on the previous points, one of my major concerns is why the proposed methods can help optimize the gap calculated in Thm 3.3. The authors have summarized the three errors in Thm 3.3 as diversity and eligibility, which indeed provides insights for analyzing this problem. But I think a more direct connection, like whether the objective in Sec 3.3 can be proven to directly control the three errors in Thm 3.3, will make the analyses more solid.\n\n- In experiments, providing the results directly trained in the target environments as the reference will better show the results.\n\n- Lack of some related works, like utilizing model-based methods for improving generalization \\[1-3\\], and finding diverse skills for unsupervised RL \\[4-6\\] as this work hopes to find diverse models.\n\n\\[1\\] Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning\n\n\\[2\\] Task Aware Dreamer for Task Generalization in Reinforcement Learning\n\n\\[3\\] The Benefits of Model-Based Generalization in Reinforcement Learning\n\n\\[4\\] Diversity is All You Need: Learning Skills without a Reward Function\n\n\\[5\\] Effective diversity in population based reinforcement learning - In my opinion, the considered setting is that the agent can only get the reward function of the target task but has no knowledge about the dynamic of the target task. Is it right? Given the offline data, it is understandable that the agent can learn the dynamic to some degree. But without an offline dataset, it seems that there is no idea for the agent to learn the dynamic of the target task. \n\n- Based on the previous question, I'm confused about the setting of Experiment 4.1 \" ReDM With no Interaction Data\". As there are no data about the environment and the agent can not interact with the environment, how does the agent to learn about the environment?\n\n- As Unsupervised RL considers training an agent in the environment without reward, in my opinion, the setting in this work is like training an agent and models in the environment with reward but without dynamic. As the dynamic of the target environment will vary a lot, whether finetuning the agent (as well as the model) in the target environment with few steps will be more reasonable?\n\n- About $r_e$ for Eligibility. The proposed method is to randomly sample N trajectories and estimate the biggest return. Is this inefficient as the state space and action space are continuous in experiments? Also, what is the choice of N in experiments?\n\n- I'm curious about the performance of ReDM in the D4RL setting (Sec. 4.3) but without any Interaction Data.",
         "720",
         "5",
         "0",
         "0.7541",
         "0.0956459436",
         "0.9084495306",
         "57",
         "30",
         "42.3274",
         "11.5374",
         "14.2015",
         "13.5218",
         "11.3151",
         "0.0512",
         "109",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "6460",
         "m3xVPaZp6Z",
         "8871",
         "1695527592497",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Reviewer_GFGi",
         "1698672856727",
         "1699637116619",
         "8",
         "3",
         "4",
         "2",
         "4",
         "This paper presents a pretty interesting idea called rehearsal, which is able to **initialize or warm up a generalizable policy with zero interaction data or limited mismatched offline data**. Concretely, the proposed method, *ReDM*, takes as input a reward function and a termination function and generates a set of transition functions or models. Imaginary trajectories can thus be generated by rolling out these transition models and used to warm up the policy. As some of the models may produce data close to the target environment dynamics, the policy warmed up with these data can have a good initialization when deployed to the target environment, which is helpful for subsequent fine-tuning. Additionally, the method can be modified for offline-RL settings, allowing it to learn a robust and generalizable policy even with a small amount of offline data mismatched with target environment dynamics. \n\nThe method is motivated theoretically and contains lots of analysis like performance bound, laying foundations for future study in this new direction. Besides, the experiments on the standard gym and D4RL environment empirically prove the effectiveness of the method for both online and offline policy learning. 1. The idea is novel unlike traditional model-based RL, this new idea suggests learning a bunch of transition models from reward function and termination functions, exempting the need for interaction data. \n2. In terms of soundness, it proves empirically and theoretically that the transition models learned in this way can help warm up the policy and improve its performance when deployed in environments with diverse transition dynamics. 1. The paper writing is not attractive. In my perspective, the main paper contains too much tedious content regarding the theoretical analysis and lacks an explanation for the rehearsal framework. My suggestion would be to move some theoretical content to the appendix and include at least one figure to explain the procedures of this new rehearsal framework and what it can achieve or why we need it. People don't care about the theoretical stuff until they are attracted by the idea and want to dive into it. Thus I suggest making some figures to explain the idea or the method.\n2. No standard deviation is included for experiments in Table 1. Also, there is no error bar in Figure 7. \n3. What is the $D_{TV}$ should be explained in the main paper. It is strongly related to your main theorem but without definition.\n4. What is relative performance? Is it calculated through minus the baseline performance?\n5. The axis *Number of models* in Figure 3 should be \\[0, 10, 20, 30, 40\\], right? 1. How about replacing the random model for calculating the eligible reward with a human-crafted planner? It is supposed to be helpful for improving the performance as well. I guess this can be a good direction for exploration and to make this method more practical. A simple rule-based planner is also as easily accessible as a reward function in most practical settings like robotics. \n2. In the zero interaction data setting, the method indeed works well in three simple gym environments. I wonder if the method still works well in the more complex Mujoco environment without any pre-collected interaction data. I am curious about its performance on high-dimensional control tasks.",
         "537",
         "1",
         "9",
         "0.7805",
         "0.12279079620000001",
         "0.9027240276",
         "47",
         "11",
         "39.5944",
         "12.5012",
         "14.9712",
         "14.2443",
         "12.6653",
         "0.2889",
         "94",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "6461",
         "m3xVPaZp6Z",
         "8871",
         "1695527592497",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Reviewer_anZu",
         "1698734618441",
         "1700596735397",
         "8",
         "3",
         "3",
         "2",
         "3",
         "The paper proposes a method for offline model-based reinforcement learning. The idea is to generate a set of candidate dynamics models and learn an adaptive policy that optimizes the original reward on this candidate set. If the true dynamics are in the distribution of the candidate set, the adaptive policy should perform well on the true task. The central problem lies in generating a candidate set of dynamics models. The authors propose optimizing over dynamics models with RL using a reward that incentivizes (1) diversity among the set and (2) the tendency for random trajectories to achieve high reward. The method alternates between optimizing for a new dynamics model to add to the set and optimizing for a new adaptive policy given the current set. When interaction data from the true task is available, it is used to regularize the optimization over dynamics models. Experiments show the method can work with no interaction data on low-dimensional continuous control tasks (inverted pendulum, mountain car, acrobot). On two D4RL tasks (hopper, half-cheetah) with a small amount of random interaction data, the method outperforms prior offline model-free and model-based RL methods. The method is similar to MAPLE but replaces the dynamics model generation process with a more directed procedure (RL on a custom reward vs learning an ensemble of models). The reward used in the dynamics model generation process is well motivated by formal analysis of error bounds. The different components of the method are analyzed/ablated. My main concern is the limited applicability of this method beyond low-dimensional benchmark tasks due to some significant assumptions. The method assumes access to a query-able reward/termination function and the initial state distribution. Though more importantly, the method assumes that the dynamics can be easily parameterized and optimized over with RL. Additionally, the method assumes that random plans through the candidate dynamics models will achieve some non-zero reward (to optimize the dynamics models for the eligibility reward). These assumptions makes the method difficult to apply (if not impossible) in sparse-reward or high-dimensional (e.g image-based) environments. In principle these issues could be solved by providing the method with enough interaction data to learn a good dynamics model initialization. However, then prior offline model-based or model-free methods might also work well. Additionally, this still wouldn't make the method applicable to sparse reward problems. \n\nAnother concern is the limited scope of the experiments relative to prior work. The evaluations on InvertedPendulum, MountainCar, and Acrobot are good for analyzing the method, however for the comparison to prior work, experiments are only shown for HalfCheetah and Hopper. It would be good to additionally include at least Walker2d. Additionally, the experiments with interaction data only test random interaction data and relatively small amounts of data (200 and 5000 transitions). While it is understandable that this is the setting where the proposed method would excel, it would be good to also show comparison to prior work with interaction data of varying optimality and amounts (including the full D4RL datsets). \n\nThere is no discussion of MAPLE in the related work section. MAPLE is very related (just a different model generation process) so the similarities and differences should be addressed here. It would also be good to include a brief mention of meta-learning in the related work as the proposed method uses similar concepts when optimizing for the adaptive policy.\n\nSmaller comments:\n- Algorithm 1 does not say a lot about the method. It could be replaced by algorithms 5/6 from the appendix. \n- Figure 1 should use a more descriptive x-axis label like \"Tasks\".\n- Figure 3 needs a more descriptive caption that explains what \"model loss\" means here.\n- The locations of Figure 2 and 3 should be switched. - The explanation of the optimal policy gap is confusing. Specifically this sentence: \"This discrepancy highlights the candidate model set’s capability to derive a proficient policy in the model itself.\" Does \"model\" here mean the true dynamics?\n- \"we conjecture that a diversified dynamics model set will correspond to a smaller ϵa since recognizing the dynamics is much easier\" It's not clear to me why a more diverse candidate model would lower the adaptation cost. Could you explain this?\n- In Figure 6, what is the shown performance relative to? Is this the performance of the policy at each iteration in the model at that iteration minus the performance of the policy at that iteration in the ground truth model?\n- Figure 7: Are these results averaged over Hopper and HalfCheetah and averaged over each gravity level?",
         "752",
         "0",
         "0",
         "0.7605",
         "0.1021203666",
         "0.8813570142",
         "58",
         "21",
         "35.9155",
         "12.6506",
         "15.7954",
         "14.5885",
         "12.6808",
         "0.5623",
         "98",
         "0",
         "0",
         "0",
         "2"
        ],
        [
         "6462",
         "m3xVPaZp6Z",
         "8871",
         "1695527592497",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Reviewer_YzNF",
         "1698848293497",
         "1700708716647",
         "8",
         "3",
         "2",
         "3",
         "3",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, the authors introduce the idea of *rehearsal* into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, they propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to natually generalize to previously unseen environments. Their experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with zero interaction data. Besides, they further extend ReDM to scenarios where limited or mismatched interaction data is available. The provided empirical results reveal that ReDM produces high-performing policies compared with other offline RL baselines. 1. The problem of policy rehearsing in offline reinforcement learning is interesting and challenging as an academic topic.\n2. The description to the problem modeling and the methods is clear and generally easy-understanding.\n3. The proposed method is well motivated by comprehensive preliminary theoretical analysis.\n4. The experiment analysis is in-depth and insightful, which helps the readers bettere understand the effectiveness and underlying mechanism of the propose methods. 1. The environments used in the experiments are still limited. I encourage to supplement more environments to demonstrate the applicability of your proposed method is possible. Otherwise, we may argue if the solution can only be effective on some specific kinds of tasks.\n2. Considering the proposed method needs to train the new dynamics models and meta-policy simultaneously, the complexity of this method and the training stability/convegence are encouraged to be clarified and analyzed.\n3. The assumed accessibility to the task reward function and initial state distribution is often unrealistic in the real applications. 1. I am curious if totally no interaction data, how can the generated dynamics model approximates the real dynamics in the target environment. It seems there lacks enough grounding points to support this potential. Does there exist the probability that the generated dynamics models are far from the dynamics in the target environment? I hope to see more analysis on this during the rebuttal.\n2. The D4RL benchmark in your experiments is all Mujoco tasks with low input dimensions. Could you please consider incorporating some more high-dimensional task, in which the hypothesis space is too large to narrow down?\n3. In the paper, you claim that the interaction data is only used to narrow down the hypothesis space. But could you please consider how to utilize these interaction data in a more direct way to better facilitate the policy learning as the complement to the purely dynamics model learning, like finetuning the learned meta policy? Besides, I cannot agree the statement that the biasedness in the interaction data will somehow hinder the policy optimization in traditional offline RL methods. If such pre-collected trajectories are expert ones or near-optimal ones, such *biasedness* can actually help avoid some low-value and dangerous states.\n4. Considering your method encourages the diversity in the model learning part, some learned dynamics models may be unreasonable though the meta policy can still achieve high returns via planning in such models, like violating the physics laws or economics laws. And I can hardly expect the *eligibility* part in your method can help alleviate this 'short-path' issue. More explanations and discussions are encouaged during the rebuttal phase.",
         "614",
         "0",
         "11",
         "0.7928",
         "0.0638390498",
         "0.9844013453",
         "59",
         "21",
         "22.4917",
         "15.0427",
         "18.6066",
         "16.5463",
         "15.3218",
         "0.4435",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6545",
         "lr806pdNZa",
         "8208",
         "1695500772032",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "Reviewer_BZEx",
         "1698149520614",
         "1699637019167",
         "5",
         "4",
         "2",
         "4",
         "2",
         "The paper focuses on the problem of \"censorship\" in large language models (LLM). Specifically, the paper argues that it is unfeasible to address this issue by relying on ancillary \"machine learning\" (ML) techniques, and that it should rather be tackled via mechanisms belonging to the security domain. To support such a position, the paper presents detailed theoretical arguments demonstrating that LLM censorship is an \"undecidable problem\", thereby revealing that using ML-based techniques, such as, e.g., another language model (LM), will never provide a foolproof solution. ## High-level\n\n+ Outstanding writing\n+ Relevant Problem (for both research and practice)\n+ The theoretical arguments are well-founded\n\n## Comment\n\nI deeply thank the authors for writing this piece and submitting it to ICLR'24. I've loved reading it, and I was genuinely pleased by the outstanding writing quality: out of the papers I reviewed for ICLR'24, this one is by far the best written one. Moreover, the paper tackles a very open issue and the \"conclusion\" can be leveraged by researchers and practitioners alike: the latter can benefit by integrating additional security mechanisms in their products, whereas the former would be provided with \"clear evidence\" that tackling censorship by means of traditional ML methods will never provide a foolproof solution. Indeed, the theoretical arguments made in this paper are well-rooted, and I particularly appreciated connecting LLM to Turing Machines and the application of the Rice Theorem as a scaffold to support the paper's main claims. \n\nHowever, despite all such strengths, the paper also presents (imho) various weaknesses, which are discussed below. ## High-level\n- It suffers from an \"identity crisis\" (it feels more like a \"position\" paper)\n- Lack of a concrete experiment \n- Some statements require further evidence to be supported\n- The paper is built on a strong assumption that does not seem to have been accounted for\n- The \"mosaic prompts\" are not really novel\n- Some pieces of the text are unclear\n\n\n## Comment \n\nDespite my appreciation, I do have concerns about the suitability of this paper to ICLR'24. Before I discuss such concerns, however, I want to emphasize that my remarks are _my opinions_. I couldn't spot any technical or methodological flaw in the paper (which is also well-written): hence, my critiques are mostly directed at the \"significance\" aspect of the paper, and I endorse the authors to reflect on the following remarks. Ultimately, my goal is to help them make this paper as a noteworthy contribution to the state-of-the-art (be it for ICLR'24, or for any other venue).\n\n### **Identity Crisis (Lack of a concrete experiment)**\n\nThe most prominent weakness is that, IMHO, the paper suffers from an \"identity crisis\" -- which is rooted on the fact that the paper touches both the \"security\" and \"ML\" domains.\n\nOn the \"security\" hand, all the considerations made in the paper are \"obvious\". The fact that, e.g., an attacker can bypass censorship mechanisms by inducing a LLM to output a \"malicious set of actions\" through individual prompts is \"not new\", and the fact that a similar strategy can fool essentially any precaution is \"not surprising\". Indeed, this is a well-known problem in reality, and the only way to solve this problem is by reading the attacker's minds. Plus, ultimately, LLM are just \"tools\": whether they are used in good- or bad-will is a different manner (and this had been known since the development of cryptographic protocols, since they also aid attackers in preventing their messages from being interpreted). So, to summarise, as a \"security\" researcher, the conclusion of this paper was already known, and the supporting theoretical arguments were hence somewhat redundant.\n\nOn the \"ML\" hand, the paper lacks a clear experiment that demonstrates at least one of the scenarios described in the ```practical implications```. Indeed, after introducing some definitions and demonstrating a given theorem, the paper merely limits to provide \"thought experiments\" discussing how an hypothetical attacker can achieve their goal. Yet, all such discussions are textual: there is an excessive usage of the words \"can\" \"could\" \"may\" \"it is possible that\". The paper does provide some references (e.g., \"The authors of... showed that this can be done\") but the lack of a concrete experiment is still hard to overlook. Such a lack is further aggravated by the additional what-ifs which project LLM into the future (e.g., ```these risks could become even more problematic```). I acknowledge that \"anything can happen\", but this is a weak argument. \n\nHence, I feel that the lack of a \"hard\" experiment is a significant weakness of this paper, which affects both its appeal to the security domain, as well as the one to the ML domain. For instance, I would have appreciated a clear demonstration of Figure 2 (I've spent ~30 minutes trying to have ChatGPT to process similar instructions, but I've never been successful).\n\nPut differently, the paper currently reads as a \"visionary paper\" or a \"position paper\" rather than a true research paper. **However** do note that I am not saying that the paper is devoid of merit: providing \"theoretical evidence\" that it is not possible to craft \"perfect\" ML-based censorship mechanisms is a strong message.\n\n\n### **Lack of evidence for some statements**\n\nOne of the major points in support of the \"value\" of this paper is that the current way to address censorship in LLM is by means of \"ML-based mechanisms\", and --after demonstrating that doing so will never guarantee 100% protection-- the suggestion that censorship should be treated as a security problem.\n\nIndeed, to quote the abstract:\n\n> Commonly employed censorship approaches treat the issue as a machine learning\nproblem and rely on another LM to detect undesirable content in LLM outputs.\n\nThe following was also stated in the Introduction:\n\n> Such methods range from fine-tuning LLMs (OpenAI, 2023) to make them more aligned, to employing external censorship mechanisms to detect and filter impermissible inputs or outputs (Markov et al., 2023; Chockalingam and Varshney, 2023; Greshake et al., 2023).\n\nHowever, I only see 4 works listed here. Hence, I wonder: is it really true that ML-based methods are the \"way-to\" address censorship problems? For instance, even Greshake et al. state ```Unfortunately, it is currently hard to imagine a foolproof solution for the adversarial prompting vulnerability```; moreover, the authors of NeMo Guardrails (used by NVIDIA (Chockalingam and Varshney, 2023)) state the following in their \\[GitHub repo\\](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/security/guidelines.md):\n\n> Integrating external resources into LLMs can dramatically improve their capabilities and make them significantly more valuable to end users. However, any increase in expressive power comes with an increase in potential risk. To avoid potentially catastrophic risks, including unauthorized information disclosure all the way up to remote code execution, the interfaces that allow LLMs to access these external resources must be carefully and thoughtfully designed from a security-first perspective.\n\nTo me, the impression is that these mechanisms are proposed as a \"partial\" solution, since even the respective authors advocate for security principles to be followed. In light of this, the underlying \"message\" of the paper partially loses its value (at least imho). It would be enticing to carry out of more profound analysis of current works on approaches for LLM censorship, and pinpointing how many of such works truly claim to address censorship in an ML-only way, without making any security consideration: doing so would dramatically improve the contribution of this paper.\n\n\n### **A strong assumption**\n\nBy looking at the definition of \"censorship mechanism\", the impression I have is that the paper assumes that censorship is always applied \"a-posteriori\". That is: the LLM receives an input, elaborates a response, and then --right before providing the response to the user-- it checks whether the response is permissible or not by means of some censorship. I wonder: is this really true?\n\nBecause, if this is not the case (i.e., there is some censorship applied to some \"intermediate process\" of the response), then the censorship would work, since it would be applied before the application of the transformation which makes the text encrypted. \n\nIn light of this, I invite the authors to provide evidence that this assumption holds _in reality_ (plus, I conjecture that such an observation CAN be used to develop some more effective defenses!). Otherwise, the authors should acknowledge that their analysis only applies to a specific use-case of censorship (do note that, however, this would decrease the impact of the paper). Alternatively, the authors can provide evidence (theoretical and, possibly, practical) that the envisioned analysis/findings hold even in these intermediate cases.\n\n### **Naming of Mosaic prompts**\n\nWhile I appreciate the name \"Mosaic Prompts\", I feel the way it is presented to be \"excessive\". Indeed, the described procedure is exactly the same as the \"divide et impera\" (or \"divide and conquer\") which is the de-facto praxis in computer science (and already associated to LLM, see \\[here\\](https://medium.com/@finomeno/exploring-large-language-models-insights-for-architects-393600dae131) and \\[here\\](https://medium.com/@digitalmiike/chatgpt-guide-10-effective-prompt-strategies-for-enhanced-output-979c8032eaaa)).\n\nHence, I endorse the authors to tone down this name, or at least acknowledge that it is just a renaming of a popular technique in computer science. (I am stating this also in light of the \"acknowledgment\" made in Footnote-1 -- which I greatly appreciated!)\n\n### **Some pieces of text are unclear**\n\nAlthough the paper is excellently written, I had issues in understanding some parts of the text. In what follows, I will directly quote each of these \"problematic\" parts, and explain the problems I encountered---starting from the Introduction.\n\n> Such constraints can be semantic, e.g. does not provide instructions on how to perform illegal activities, or syntactic, e.g. does not contain any ethnic slurs from a provided set.\n\nI did not understand the provided examples -- or rather, it is hard to determine the subject of the examples. I recommend rephrasing to, e.g., \"the output must not provide...\"\n\n> methods against malicious attackers.\n\nAre there attackers who are not malicious? (this redundancy occurs many times in the paper)\n\n> restricting the string x to the set of permissible strings P\n\nI recommend being more specific: \"the string x to the set of permissible strings P that can be constructed by the LLM model\" (otherwise, it may be confused with a string written by an user)\n\n> demonstrated in Fig. 1\n\nThe caption states \"Figure\" (and not Fig.)\n\n> typically defined by the language recognised it recognises\n\nThis is unclear \n\n> descriptions of Turing machines can be viewed as a programming language, capable of being interpreted by a universal Turing machine capable of emulating them.\n\nPlease revise this statement as it is very confusing.\n\n> As the semantic censorship impossibility result that we established by connecting the problem of semantic censorship to Rice’s Theorem doesn’t fully capture real world censorship settings where inputs and outputs are bounded we seek to provide another result on the impossibility of censorship that does.\n\nMake this shorter, especially since the same message was written two lines before.\n\n> we assert that given an invertible string transformation g\n\nIs this \"g\" supposed to be the \"bijective transformation\"? Still, I am slightly confused about this \"g\" here; perhaps an example would be useful.\n\n> it is capable of applying g to its output x to instead output g(x).\n\nThis is very unclear. Do you mean g(g(x))?\n\n> either nothing is be permissible\n\nTypo\n\n> While existing LLMs are good at \\[...\\] Yuan et al. (2023)\n\nThis paragraph appers to be disconnected from the \"Practical Implications\". Or rather, it does not align well with the way the previous paragraph ended. Actually, I do not see any \"practical implications\" that are truly compellling here.\n\n> While our results describe adversaries which can instruct\n\nWhich results? \n\n> For example, users could provide \\[...\\] running the model\n\nIt would be wonderful if the authors showcased a way to do so in practice _today_. \n\n> In an extreme setting where there exist only 2 permissible output strings\n\nWhy this assumption? To me, the following example holds even without this (perhaps I missed something?)\n\n> converting text to ACII\n\nTypo\n\n> Subsequently, the user can request the model to output i’th bit\n\nWhat is the ```i'th bit```? Plus, how can the user do so?\n\n> our Mosaic Prompting results\n\nGiven that no experiments have been carried out, it is a bit of a stretch to define this as a \"result\" (even the Appendix does not provide \"empirical results\")\n\n\n\nFinally, I report that the bibliography often does not provide the venue of a given work (e.g., the paper by Markov et al. (2023) was published in AAAI; whereas the one from Greshake et al. was accepted at AISec). This is annoying as a reader, as I could not ascertain the quality of a given referenced work. I liked the paper, and I am willing to improve my score if presented with compelling evidence that some of my remarks are flawed. Nonetheless, I invite the authors to answer the following questions (most of which are drawn from my \"Weaknesses\" section): depending on the answer, my rating will likely change.\n\n1) Can the authors provide more evidence that LLM censorship is truly \"commonly treated as a ML problem\" (and that security-based approaches are not taken in consideration)?\n\n2) Would the proposed theoretical analysis, as well as the proposed \"attack\", still apply if censorship is carried out during the process of crafting a response by the LLM? (Please elaborate)\n\n3) How could the \"attack\" shown in Figure 2 be realized _today_? \n\nThen, I have one last question. Assume that this paper is accepted to ICLR'24 as a spotlight. How would the authors present this work? Would the talk include only \"what-ifs\", or would it also showcase some concrete evidence that the envisioned scenarios are truly a security issue that cannot be countered with ML-only ways$^1$?\n\n$^{\\text{1: E.g., how do I make ChatGPT tell me \"howdoibuildabomb\"?}}$",
         "2281",
         "5",
         "1",
         "0.8001",
         "0.0992714858",
         "0.7997633219",
         "47",
         "17",
         "41.5888",
         "12.6065",
         "15.223700000000001",
         "14.314",
         "13.9864",
         "0.8282",
         "84",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6546",
         "lr806pdNZa",
         "8208",
         "1695500772032",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "Reviewer_ST3b",
         "1698230841205",
         "1699637019047",
         "5",
         "2",
         "3",
         "2",
         "2",
         "This paper investigates the theoretical limitations of the current external censorship mechanisms in LLMs from the view of computing theory. Given these inherent limitations, the authors argue that LLM censorship should be addressed more as a security problem than a machine learning problem. - Trendy topic\n- A novel perspective to study LLM censorship - Implications can be extended\n- Readability can be improved In this paper, the authors first focus on the semantic censorship mechanisms, proving that the current mechanisms cannot reliably detect if LLM output is \"semantically impermissible.\" They further show that such limitations are inherent and can extend beyond semantic censorship mechanisms by designing Mosaic prompts.\n\nOverall, the authors study a trendy topic and offer a novel perspective to understand LLM censorship. However, I have the following concerns.\n\n- The authors prove the impossibility of semantic censorship using string transformation by showing how the transformed string might break the \"invariance of semantic censorship.\" Here, I have some doubts regarding the invariance property. In my opinion, the semantics of a string often change after the transformation. Thus, it is reasonable for the transformed string to bypass semantic censorship mechanisms. Moreover, LLMs do not necessarily output harmful texts with the transformed string. Why does the invariance property hold? Is this property an important goal considered by LLM censorship developers when designing their mechanisms?\n\n- Implications can be extended. It appears to me that the current implication discussion stops at showing LLM censorship is more of a security problem than a machine learning problem. What are the direct implications for model developers when building censorship? Are there any defensive measures against the Mosaic prompts? The authors only briefly mention that there are standard approaches, such as access controls and user monitoring, to build censorship from the security view. However, there is no further analysis showing that these approaches can indeed overcome the theoretical limitations of current external censorship mechanisms and surpass them in censorship performances.\n\n- Readability can be improved. Many sentences are too long and difficult to read. For example, \"Thus, we can understand censorship as a method of determining permissibility of a string and censorship mechanisms can be described as a function, f(x), restricting the string x to the set of permissible strings P by transforming it to another string x' ∈ P if necessary, e.g. x' ='I am unable to answer.'\"",
         "394",
         "0",
         "0",
         "0.7870",
         "0.08387096770000001",
         "0.8256777525000001",
         "47",
         "16",
         "29.8058",
         "13.2713",
         "16.9721",
         "15.3932",
         "13.4282",
         "0.1199",
         "100",
         "0",
         "0",
         "2",
         "0"
        ],
        [
         "6547",
         "lr806pdNZa",
         "8208",
         "1695500772032",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "Reviewer_3fNc",
         "1698538750067",
         "1699637018926",
         "3",
         "3",
         "2",
         "2",
         "1",
         "The paper's topic studying censorship and its effectiveness is interesting, ie. what kinds of knowledge can be extracted from LLMs and whether protection mechanisms can be circumvented. But the paper contributes little of practical value. It also lacks a proper evaluation to claims and conceptual illustrations. The theoretical treatment would be interesting, but the paper claims are mostly direct implications of existing theorems or require minor enhancements. Overall, the contribution appears marginal.\n\nDetails:\n* abstract:  LM -> LLM or define it.\n*  The example, Figure 1 is not of any practical value and might be conceptually it is flawed - the three steps are the least challenge in making successful ransomware attack (deploying it is much more of an issue, avoiding being detected too). The Mosaic prompt is also not very convincing. Both should be shown to be actually working.\n* The idea to use encryption (Appendix A) is interesting, but is this a practical concern? Does it add to the discussion of how protection mechanisms can be circumvented? It might, if it was shown to work. But as is, it seems incomplete.\n* On a high level, the paper argues that censorship cannot work because a malicious person might not directly asked for censored actions, but for steps needed for these actions, which might not be censored. But this holds for almost anything in our world and is nothing new. Any technological knowledge can be abused.  A knife can be used to kill or to save a life (doctor during surgery).  A motor can power an ambulance saving life or a truck performing a terrorist act. This is general knowledge. The paper seems to sell this as a novel aspect. The fundamental question is: Should knowledge and technology be made available that can be abused?  This is also not really a security question as the paper argues. Obviously any abuse relates to security, but I don't see, why the paper's claim to say \"LLM censorship (ie. avoiding censorship through attacks) is a security concern\" should be a new insight. see above see above see above",
         "346",
         "0",
         "1",
         "0.7665",
         "0.09049690690000001",
         "0.7391343713",
         "47",
         "12",
         "52.9766",
         "9.1188",
         "11.819",
         "11.950800000000001",
         "8.4543",
         "0.0291",
         "95",
         "0",
         "1",
         "1",
         "1"
        ],
        [
         "6548",
         "lr806pdNZa",
         "8208",
         "1695500772032",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "Reviewer_xHLz",
         "1698608286944",
         "1699637018817",
         "5",
         "3",
         "2",
         "4",
         "3",
         "This paper explores some of the theoretical limitations of LLM censorship, the problem of identifying permissible inputs and outputs to language models. In particular, the paper focuses on the limitations of semantic censorship, or filtering of strings based on their meaning. First, the paper shows that determining whether a “program” output by an LLM is permissible is an undecidable problem. Then, the paper discusses the impossibility of semantic censorship by showing that strings can undergo transformations which preserve their semantic meaning but are otherwise unintelligible except to a user who knows how to invert the transformation. Finally, the paper introduces Mosaic Prompts, a way of breaking up an impermissible prompt into permissible pieces. This paper’s primary strength is that it identifies an important issue to focus on that has been unexplored in the literature - what are the theoretical limits on the ability to filter LLM inputs or outputs based on their semantic meaning? The paper is a good exposition of this problem and the theoretical settings it considers highlight some important limitations for the task. The figures and tables also do a good job of clarifying some of the concepts in the text. Overall, the authors’ assertion that syntactic censorship is likely to be more successful than semantic censorship is well-taken from this work. This paper’s primary weakness is the number of assumptions and limitations that come into the different theoretical treatments that the paper covers. First, the paper itself admits that the treatment of Rice’s theorem for programs on Turing Machines is not generally applicable to the bounded inputs and outputs case of LLMs. Second, in the section 2.2 on the invertible transform, I believe there may be a flaw in the reasoning of the proof. Under assumption 1, the authors assume that the model is capable of following instructions such that it can produce the transformation $g$. This assumption is explicitly stated. It seems that the proof also requires that the LLM (or corresponding companion LLM that is doing censorship) is unable to compute the inverse transformation $g^{-1}$. If it were, then it could check the semantics of the un-transformed string for permissibility. This assumption weakens the power of the impossibility result in my opinion. Finally, while I think that the Mosaic Prompt approach is interesting, I do think the paper underestimates the LLM’s ability to attend to previous prompts. While in the mosaic approach the model is likely to answer early prompts, it is conceivable that once enough of the pieces of the impermissible prompt are present, one would be able to detect the impermissibility of the conversation overall. Does the impossibility result in Section 2.2 require an assumption that $g^-1$ is not computable by the permissibility model?\n\nIs the problem space simplified at all by considering the compositionality of strings? For example, if there is an impermissible substring within a larger string, does that make the larger string automatically impermissible as well?\n\nDoes something like “fuzzy” permissibility fit into this framework at all? For example, many prompts and outputs would be considered “borderline” or have some level of “toxicity” if sent to a human rater, rather than a bright-line permissible vs. not rule. Does that make the problem any easier or harder?",
         "537",
         "0",
         "0",
         "0.7747",
         "0.1567073171",
         "0.8508368134000001",
         "47",
         "11",
         "36.7413",
         "13.0664",
         "15.4781",
         "14.6074",
         "13.6159",
         "0.06570000000000001",
         "99",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "6582",
         "lmShn57DRD",
         "1208",
         "1695022608110",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "Reviewer_qMLP",
         "1697955080810",
         "1699636047386",
         "6",
         "2",
         "3",
         "3",
         "3",
         "This paper delves into the challenges presented by multivariate long-term time series forecasting (MLTSF), specifically the difficulty of capturing cross-channel dependencies and temporal order information using current Transformer-based models. Despite the achievements of Transformer models in various fields, their application in MLTSF reveals certain inadequacies. Models like Informer, Autoformer, and FEDformer, while advanced, still face challenges in understanding intricate channel relationships in multivariate time series. \n\nTo address these issues, the authors propose the GRformer model. This innovative solution combines the strengths of Graph Neural Networks (GNN) and position encoding derived from Recurrent Neural Networks (RNN). The inclusion of a mix-hop propagation layer within a feedforward neural network promotes efficient interaction between different time series data points. Additionally, by leveraging a multi-layer RNN, the model recursively generates positional embeddings, emphasizing the importance of sequence order. \n\nThe paper's empirical tests, conducted on eight real-world datasets, demonstrate the GRformer's superior predictive accuracy in MLTSF tasks, underlining its potential as a novel solution in the field of time series forecasting. **Strengths**:\n\n1. **Originality**: \n   - The GRformer presents a unique fusion of GNN and RNN-based position encoding within a Transformer framework, addressing gaps in MLTSF.\n   - The incorporation of the Pearson correlation coefficient for graph structure is a notable innovation.\n\n2. **Quality**: \n   - Rigorous empirical validation is conducted on eight real-world datasets, ensuring robustness.\n   - The model's design is comprehensive, with the mix-hop propagation layer and RNN-based position encoding as highlights.\n\n3. **Clarity**: \n   - The paper delineates complex concepts coherently, facilitating reader understanding.\n   - Distinctive features and advantages of GRformer over existing models are clearly articulated.\n\n4. **Significance**: \n   - The GRformer's advancements in capturing cross-channel dependencies have potential broad impacts in time series forecasting.\n   - The paper paves the way for future research by highlighting existing challenges and areas of improvement.\n\nIn essence, the paper excels in its innovative methodology, thorough validation, lucid presentation, and relevance in the field. 1. **Mathematical Notation Consistency**:\n   - The authors' use of mathematical notation appears inconsistent. For instance, function names should ideally be presented in regular typeface rather than italic. Proper notation ensures clarity and avoids potential confusion.\n\n2. **Graph Construction Using Pearson Coefficient**:\n   - While the authors opted for the Pearson correlation coefficient for graph construction, which subsequently serves as the foundational structure for the GNN, one might question the exclusion of making GNN parameters learnable. This adaptability could potentially offer more flexibility to the model.\n\n3. **Assumption of Homoscedasticity**:\n   - The Pearson coefficient assumes homoscedasticity in the data. It's unclear if the authors verified this assumption across their datasets. Such checks are crucial to ensure the validity of the chosen coefficient.\n\n4. **Alternative Correlation Metrics**:\n   - The paper doesn't seem to explore or discuss other potentially beneficial correlation coefficients like Time-Lagged Cross-Correlation (TLCC) or Dynamic Time Warping (DTW). An exploration or justification of the chosen metric over others could have added depth to their methodology. **Hyperparameter Selection in Graph Construction**:\n   - The methodology introduced by the authors involves several hyperparameters, which seemingly have a significant impact on the model's outcomes. Specifically, when constructing the graph structure:\n     - How was the threshold value of 0.8 determined?\n     - Regarding the 'topk' selection, how was the value of \\( k \\) chosen, and does it correlate with the number of variables?\n\n **Mix-hop Propagation Parameter**:\n   - How was the value for the EMA parameter \\( \\alpha \\) in the mix-hop propagation process determined?",
         "562",
         "0",
         "9",
         "0.8096",
         "0.1543367347",
         "0.9348136187",
         "53",
         "19",
         "12.8649",
         "15.8084",
         "19.5397",
         "16.5463",
         "17.2062",
         "0.1041",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6583",
         "lmShn57DRD",
         "1208",
         "1695022608110",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "Reviewer_Evwp",
         "1698032964680",
         "1699636047317",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper enhances Transformer with GNN and position embedding generated by RNN for multivariate time series forecasting. The proposed GRformer constructs graph by pearson correlation and uses a mix-hop propagation GNN layer to capture cross-channel dependency. For temporal dependency, it uses an RNN to recursively generate positional embeddings. Experiments on eight real-world datasets show that the proposed GRformer is on compare with SOTA model, PatchTST. - This paper is well-written and easy to follow.\n- Using pearson correlation for graph constructing is reasonable and efficient. My main concern is that the novelty is limited:\n\n- For RNN-based position embedding: \n  1. The idea of enhance Transformer with RNN is not new\\[1\\].\n  2. RNN operates recursively and cannot be parallelized, which offsets the efficiency advantages of Transformers that can be highly parallelized.\n  3. Ablation study in Table 3 shows that the improvement of RNN against previous learnable position embedding is not significant.\n- For Mix-hop propagation: \n    1. The mix-hop propagation layer is **exactly the same** as that in \\[2\\] and there is no explicit reference to it in Section 3.2.3.\n    2. Besides the graph construction via Pearson correlation, this is a direct combination of PatchTST and \"Connecting the dots\".\n\n\\[1\\] Qin, Yao, et al. \"A dual-stage attention-based recurrent neural network for time series prediction.\" arXiv preprint arXiv:1704.02971 (2017).\n\n\\[2\\] Wu, Zonghan, et al. \"Connecting the dots: Multivariate time series forecasting with graph neural networks.\" Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining. 2020. - What is the authors' primary objective in visualizing the weights of the MLP in Figure 1(b), given that it only reflects the correlation among hidden states? \n- Could you provide a comparison of the computational efficiency between your RNN-based position embedding and a learnable position embedding, particularly in relation to varying sequence lengths?\n- How were the hyperparameters (0.8 and $k$) in Equations (2) and (3) chosen, and what impact do these specific values have on the model's performance and behavior?",
         "329",
         "5",
         "7",
         "0.7978",
         "0.0755532213",
         "0.936165452",
         "53",
         "18",
         "36.6467",
         "11.615",
         "15.9253",
         "14.0465",
         "12.0187",
         "0.38480000000000003",
         "74",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6584",
         "lmShn57DRD",
         "1208",
         "1695022608110",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "Reviewer_rJkP",
         "1698711813614",
         "1699636047246",
         "3",
         "4",
         "1",
         "2",
         "1",
         "This paper proposes GRformer, a new neural architecture for multivariate long-term time series forecasting (MLTSF). The authors propose a hybrid architecture that consists of a Transformer-based graph neural network to model cross-channel dependencies and a recurrent neural network to model temporal dependencies. The proposed model shows promising performance on eight benchmarks. However, the motivation and reasoning behind the criticism of the Transformer-based approach are difficult to understand. Some of the claims are made without proper evidence, or by simply citing previous work, without providing any further detailed study or analysis. Additionally, the performance improvements on the benchmarks seem to outperform the baselines. However, I believe the claim of achieving a performance improvement with a 5.7% decrease in MSE and 6.1% decrease in MAE is misleading. These numbers are calculated by averaging MSE and MAE without considering the scales between different benchmarks and metrics. ILI has much higher mean squared errors (MSEs) and mean absolute errors (MAEs) than other benchmarks. This means that if you compute the average score in this way, the average score can be dominated by the relative improvement in this specific dataset. The tone reporting the improvement suggests that the model showed around a 6% decrease in errors on all benchmarks, but the average relative improvement for each benchmark at different metrics is actually 2.55% for MSE and 4.96% for MAE. The model achieves improvements over 7 different benchmarks using 4 metrics for each benchmark dataset. The experiments are done extensively with ablation on different positional encoding strategies. This however raises a question on why the RNN is needed (Table 3. R: the first column vs L: the second column show a very minor difference). I am not sure what I am seeing in Figure 1(b), and I don’t understand how to interpret the authors' claim that cross-channel interaction is chaotic based on simply visualizing the weight matrices of the Transformer's dense layer (internal MLP).\n\nI am not sure I understand the authors' point about positional encoding not being able to represent temporal orders well. RNNs have their own problems, such as vanishing gradients when modeling long-term temporal dependencies. Are you suggesting that RNNs outperform Transformers in multivariate long-term time series forecasting (MLTSF)?\n-> Are the ablation results in Table 3 the experiments to back this claim? If that's the case, the performance difference between an RNN-based positional encoding (?) vs a learned positional embedding is almost 0.\n\nWhat exactly is the RNN-based position encoding method? In the caption for Figure 2, it says \"The multi-layer RNN injects temporal order information.\" However, RNNs are not just injecting temporal order information as some sort of advanced positional encoding method; they can actually learn temporal dependencies. I am not sure if you are distinguishing between positional encoding and learning temporal representation.\n\nFigure 2 (b) is hard to understand, at least explain the operator signs in the caption, arrows are not clear. What is the main evidence that Transformer-based models are ineffective at capturing cross-channel dependencies and temporal orders? If Transformers were bad at capturing temporal orders, they would not have become as popular as they are today. I am curious why the authors make such claims, as I do not see any plausible supporting evidence in the manuscript.\n\nThe authors mentioned that they used multi-layered RNNs, however in the appendix, it's said 1-layer RNN was used. Can you clarify the details of the RNN architecture?\n\n“To properly capture temporal dependencies, we consider using a multilayer RNN to encode the positions in the time series.” Why deep RNNs can properly capture temporal dependencies while Transformers can’t?",
         "596",
         "0",
         "0",
         "0.7782",
         "0.0033277217000000003",
         "0.9233770967",
         "53",
         "10",
         "40.7114",
         "11.4642",
         "15.2089",
         "14.4033",
         "12.5358",
         "0.1958",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "6756",
         "lOwkOIUJtx",
         "8429",
         "1695510038947",
         "['~Jiayang_Liu2', '~Yiming_Bu1', '~Daniel_Tso1', '~Qinru_Qiu1']",
         "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling",
         "High accuracy, low latency and high energy efficiency represent a set of contradictory goals when searching for  system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduce camera refresh rates, and increase the volume of data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, saccade mechanism observed in the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from foveal and peripheral vision, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90\\% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our study demonstrates a 5\\% higher image recognition accuracy compared to state-of-the-art foveal-peripheral vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches.",
         "Reviewer_7Zf9",
         "1698696716802",
         "1699637050853",
         "8",
         "3",
         "3",
         "3",
         "3",
         "This paper presents a new algorithm for sequential foveated visual sampling of an image.\n\nThe main claims of the paper are that \n\n- the required input pixels per frame are reduced by 90% without losing image recognition performance\n- 5% higher recognition accuracy compared to existing foveal sampling models with matching pixel number input\n- higher data efficiency in training\n\nI find the algorithm to be interesting and novel, and that the second and third claims above are supported.\nI am confused where to find evidence for the first claim.\n\nOverall I think this paper is a borderline accept. I find the method simple and useful, with interesting potential application. \nIt is appealing that the method seems to be suitable for existing classification models (no retraining). ## Major\n\nI am confused how the image information from the sequential glimpses is passed and integrated in the predictive reconstruction model. Much more space is spent on the background to the hybrid loss function than actually making explicit how the sequential image information is used to improve reconstruction.\n\nIn addition, the abstract states \"our model reduces the required input pixels by over 90% per frame while maintaining the same level of performance in image recognition as with the original images.\" I don't understand where to find support for this claim in the results. For example, in Figure 3, all subsampled models perform worse than the original. The data in Figure 4 are coming closest to the original; is this what is meant?\n\nAlso, please clarify whether the experiments in Figure 3 are conducted with the trained saccade control model (which one?). \n\n\n## Minor\n\n- Instead of \"continuous saccades\" a better terminology would be \"sequential saccades\" or \"scanpaths\". See e.g. \\[2, 3, 4\\]\n- There are now known to be three types of photosensitive cells: rods, cones and intrinsically-photosensitive ganglion cells \\[1, 8\\]\n- You use SSIM but the relevant paper(s) are not cited (e.g. \\[7\\]).\n- Heading 3.1 \"Periphrl\"\n\n## Literature\n\n1. Do, M. T. H., & Yau, K.-W. (2010). Intrinsically Photosensitive Retinal Ganglion Cells. Physiol Rev, 90.\n\n1. Hoppe, D., & Rothkopf, C. A. (2019). Multi-step planning of eye movements in visual search. Scientific Reports, 9(1), 144. https://doi.org/10.1038/s41598-018-37536-0\n\n1. Kümmerer, M., & Bethge, M. (2021). State-of-the-Art in Human Scanpath Prediction (arXiv:2102.12239). arXiv. http://arxiv.org/abs/2102.12239\n\n1. Kümmerer, M., Bethge, M., & Wallis, T. S. A. (2022). DeepGaze III: Modeling free-viewing human scanpaths with deep learning. Journal of Vision, 22(5), 7. https://doi.org/10.1167/jov.22.5.7\n\n1. Rosenholtz, R. (2016). Capabilities and Limitations of Peripheral Vision. Annual Review of Vision Science, 2(1), 437–457. https://doi.org/10.1146/annurev-vision-082114-035733\n\n1. Watson, A. B. (2014). A formula for human retinal ganglion cell receptive field density as a function of visual field location. Journal of Vision, 14(7), 15. https://doi.org/10.1167/14.7.15\n\n1. Wang, Z., Simoncelli, E. P., & Bovik, A. C. (2003). Multiscale structural similarity for image quality assessment. The Thirty-Seventh Asilomar Conference on Signals, Systems & Computers, 2003, 1398–1402. https://doi.org/10.1109/ACSSC.2003.1292216\n\n1. Zele, A. J., Feigl, B., Adhikari, P., Maynard, M. L., & Cao, D. (2018). Melanopsin photoreception contributes to human visual detection, temporal and colour processing. Scientific Reports, 8(1), 3842. https://doi.org/10.1038/s41598-018-22197-w - I would like to see how the hybrid reconstruction loss changes over timestep, and not just classification accuracy.\n- The sampling of the periphery of individual pixels with small probability is not very like human vision. Effectively this is providing low pass information. Have the authors considered how the sampling density could be approximated more plausibly (e.g. \\[6\\])?\n- Have the authors considered comparing scanpath strategies learned in this model to human scanpaths (e.g. \\[3, 4\\])?",
         "591",
         "20",
         "22",
         "0.8122",
         "0.1227193813",
         "0.9176356196000001",
         "47",
         "10",
         "42.1304",
         "11.3233",
         "14.4005",
         "13.4718",
         "13.597",
         "0.3629",
         "108",
         "1",
         "0",
         "0",
         "0"
        ],
        [
         "6757",
         "lOwkOIUJtx",
         "8429",
         "1695510038947",
         "['~Jiayang_Liu2', '~Yiming_Bu1', '~Daniel_Tso1', '~Qinru_Qiu1']",
         "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling",
         "High accuracy, low latency and high energy efficiency represent a set of contradictory goals when searching for  system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduce camera refresh rates, and increase the volume of data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, saccade mechanism observed in the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from foveal and peripheral vision, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90\\% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our study demonstrates a 5\\% higher image recognition accuracy compared to state-of-the-art foveal-peripheral vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches.",
         "Reviewer_rEUv",
         "1698697040175",
         "1700663753570",
         "6",
         "4",
         "2",
         "3",
         "3",
         "This paper aims to reconstruct the original image from multiple subsampled views, using reinforcement learning and neural network models for scan control and image reconstruction, respectively. The paper conducts numerous experiments to demonstrate that the proposed algorithm can maintain detection task accuracy, reasonable saccade control, and high reconstruction quality under high data efficiency. However, the motivation for the work is not well-founded, and there are possible improvements in the experiments. 1. The task addressed in the paper is novel, as it is the first in the industry to reconstruct an image from continuous central foveal subsampled images. Other methods focus on single-sample images and proceed directly to downstream tasks without reconstructing the original image, making this work unique.\n2. The methods used are innovative, employing an actor-critic model for saccade control, which can achieve near-original image classification accuracy in just five scans.\n3. The writing style of the paper is easy to understand, especially in describing the proposed methods. 1. While the task is novel, it lacks a convincing real-world application, as it simulates the process of multiple eye samplings without addressing practical problems.\n2. The experimental comparisons are not entirely fair. The uniform control group uses an 8% sampling probability, while the 1/16+2% group differs by 0.25%, indicating an unequal amount of information that might affect performance.\n3. Using classification model metrics to assess the quality of reconstruction is questionable, as classification tasks do not focus on texture details. If this method was to downsample the original image with the same number of sampled pixels, how much better is the method in terms of performance compared to this? see weaknesses",
         "271",
         "0",
         "7",
         "0.7977",
         "0.1371333333",
         "0.8944661021",
         "59",
         "22",
         "26.1536",
         "14.7902",
         "17.6374",
         "16.0982",
         "16.0539",
         "0.0999",
         "95",
         "0",
         "1",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 199
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>wfzXa8e783</td>\n",
       "      <td>1940</td>\n",
       "      <td>1695136750006</td>\n",
       "      <td>[~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>Reviewer_EGJf</td>\n",
       "      <td>1698648757307</td>\n",
       "      <td>1701662567826</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>11.2328</td>\n",
       "      <td>14.7773</td>\n",
       "      <td>13.5591</td>\n",
       "      <td>13.3105</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>wfzXa8e783</td>\n",
       "      <td>1940</td>\n",
       "      <td>1695136750006</td>\n",
       "      <td>[~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>Reviewer_DWom</td>\n",
       "      <td>1698746208577</td>\n",
       "      <td>1699636125239</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.6251</td>\n",
       "      <td>15.3091</td>\n",
       "      <td>13.6811</td>\n",
       "      <td>14.7228</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>wfzXa8e783</td>\n",
       "      <td>1940</td>\n",
       "      <td>1695136750006</td>\n",
       "      <td>[~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>Reviewer_PnHf</td>\n",
       "      <td>1698822869626</td>\n",
       "      <td>1699636125143</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>15.1974</td>\n",
       "      <td>18.2257</td>\n",
       "      <td>16.5672</td>\n",
       "      <td>16.3167</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>wfzXa8e783</td>\n",
       "      <td>1940</td>\n",
       "      <td>1695136750006</td>\n",
       "      <td>[~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>Reviewer_ekPo</td>\n",
       "      <td>1699260725548</td>\n",
       "      <td>1699636125075</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5572</td>\n",
       "      <td>10.8611</td>\n",
       "      <td>11.3747</td>\n",
       "      <td>10.6575</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>wHgu98u8Sc</td>\n",
       "      <td>8035</td>\n",
       "      <td>1695494318474</td>\n",
       "      <td>[~Konstantinos_Pitas1, ~Julyan_Arbel1]</td>\n",
       "      <td>$\\nu$-ensembles: Improving deep ensemble calib...</td>\n",
       "      <td>We present a method to improve the calibration...</td>\n",
       "      <td>Reviewer_HFRa</td>\n",
       "      <td>1697955924532</td>\n",
       "      <td>1699636992453</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6669</td>\n",
       "      <td>18.2108</td>\n",
       "      <td>15.9828</td>\n",
       "      <td>15.2685</td>\n",
       "      <td>0.2519</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27555</th>\n",
       "      <td>1GUTzm2a4v</td>\n",
       "      <td>7910</td>\n",
       "      <td>1695490280188</td>\n",
       "      <td>[~Kyriakos_Axiotis1, ~Sami_Abu-El-Haija1, ~Lin...</td>\n",
       "      <td>Greedy PIG: Adaptive Integrated Gradients</td>\n",
       "      <td>Deep learning has become the standard approach...</td>\n",
       "      <td>Reviewer_dYDX</td>\n",
       "      <td>1699449672782</td>\n",
       "      <td>1699636970353</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0166</td>\n",
       "      <td>12.5762</td>\n",
       "      <td>12.2435</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27648</th>\n",
       "      <td>11WAKGH8uv</td>\n",
       "      <td>4689</td>\n",
       "      <td>1695358811203</td>\n",
       "      <td>[~Samiul_Alam1, ~Tuo_Zhang2, ~Tiantian_Feng1, ...</td>\n",
       "      <td>FedAIoT: A Federated Learning Benchmark for Ar...</td>\n",
       "      <td>There is a significant relevance of federated ...</td>\n",
       "      <td>Reviewer_hEF2</td>\n",
       "      <td>1698455516741</td>\n",
       "      <td>1699636450427</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5956</td>\n",
       "      <td>15.4394</td>\n",
       "      <td>13.7717</td>\n",
       "      <td>13.0917</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27649</th>\n",
       "      <td>11WAKGH8uv</td>\n",
       "      <td>4689</td>\n",
       "      <td>1695358811203</td>\n",
       "      <td>[~Samiul_Alam1, ~Tuo_Zhang2, ~Tiantian_Feng1, ...</td>\n",
       "      <td>FedAIoT: A Federated Learning Benchmark for Ar...</td>\n",
       "      <td>There is a significant relevance of federated ...</td>\n",
       "      <td>Reviewer_N2ym</td>\n",
       "      <td>1698725100234</td>\n",
       "      <td>1699636450328</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>15.2165</td>\n",
       "      <td>18.4087</td>\n",
       "      <td>16.0888</td>\n",
       "      <td>16.1376</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27650</th>\n",
       "      <td>11WAKGH8uv</td>\n",
       "      <td>4689</td>\n",
       "      <td>1695358811203</td>\n",
       "      <td>[~Samiul_Alam1, ~Tuo_Zhang2, ~Tiantian_Feng1, ...</td>\n",
       "      <td>FedAIoT: A Federated Learning Benchmark for Ar...</td>\n",
       "      <td>There is a significant relevance of federated ...</td>\n",
       "      <td>Reviewer_Vfdi</td>\n",
       "      <td>1698798393099</td>\n",
       "      <td>1700674345074</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8648</td>\n",
       "      <td>13.0958</td>\n",
       "      <td>12.6741</td>\n",
       "      <td>11.9940</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27651</th>\n",
       "      <td>11WAKGH8uv</td>\n",
       "      <td>4689</td>\n",
       "      <td>1695358811203</td>\n",
       "      <td>[~Samiul_Alam1, ~Tuo_Zhang2, ~Tiantian_Feng1, ...</td>\n",
       "      <td>FedAIoT: A Federated Learning Benchmark for Ar...</td>\n",
       "      <td>There is a significant relevance of federated ...</td>\n",
       "      <td>Reviewer_MJiJ</td>\n",
       "      <td>1699550943464</td>\n",
       "      <td>1699636450179</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>16.6079</td>\n",
       "      <td>19.2861</td>\n",
       "      <td>17.6001</td>\n",
       "      <td>18.3138</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "1446     wfzXa8e783               1940             1695136750006   \n",
       "1447     wfzXa8e783               1940             1695136750006   \n",
       "1448     wfzXa8e783               1940             1695136750006   \n",
       "1449     wfzXa8e783               1940             1695136750006   \n",
       "1642     wHgu98u8Sc               8035             1695494318474   \n",
       "...             ...                ...                       ...   \n",
       "27555    1GUTzm2a4v               7910             1695490280188   \n",
       "27648    11WAKGH8uv               4689             1695358811203   \n",
       "27649    11WAKGH8uv               4689             1695358811203   \n",
       "27650    11WAKGH8uv               4689             1695358811203   \n",
       "27651    11WAKGH8uv               4689             1695358811203   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "1446   [~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...   \n",
       "1447   [~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...   \n",
       "1448   [~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...   \n",
       "1449   [~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...   \n",
       "1642              [~Konstantinos_Pitas1, ~Julyan_Arbel1]   \n",
       "...                                                  ...   \n",
       "27555  [~Kyriakos_Axiotis1, ~Sami_Abu-El-Haija1, ~Lin...   \n",
       "27648  [~Samiul_Alam1, ~Tuo_Zhang2, ~Tiantian_Feng1, ...   \n",
       "27649  [~Samiul_Alam1, ~Tuo_Zhang2, ~Tiantian_Feng1, ...   \n",
       "27650  [~Samiul_Alam1, ~Tuo_Zhang2, ~Tiantian_Feng1, ...   \n",
       "27651  [~Samiul_Alam1, ~Tuo_Zhang2, ~Tiantian_Feng1, ...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "1446   Navigating Text-To-Image Customization: From L...   \n",
       "1447   Navigating Text-To-Image Customization: From L...   \n",
       "1448   Navigating Text-To-Image Customization: From L...   \n",
       "1449   Navigating Text-To-Image Customization: From L...   \n",
       "1642   $\\nu$-ensembles: Improving deep ensemble calib...   \n",
       "...                                                  ...   \n",
       "27555          Greedy PIG: Adaptive Integrated Gradients   \n",
       "27648  FedAIoT: A Federated Learning Benchmark for Ar...   \n",
       "27649  FedAIoT: A Federated Learning Benchmark for Ar...   \n",
       "27650  FedAIoT: A Federated Learning Benchmark for Ar...   \n",
       "27651  FedAIoT: A Federated Learning Benchmark for Ar...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "1446   Text-to-image generative models have garnered ...  Reviewer_EGJf   \n",
       "1447   Text-to-image generative models have garnered ...  Reviewer_DWom   \n",
       "1448   Text-to-image generative models have garnered ...  Reviewer_PnHf   \n",
       "1449   Text-to-image generative models have garnered ...  Reviewer_ekPo   \n",
       "1642   We present a method to improve the calibration...  Reviewer_HFRa   \n",
       "...                                                  ...            ...   \n",
       "27555  Deep learning has become the standard approach...  Reviewer_dYDX   \n",
       "27648  There is a significant relevance of federated ...  Reviewer_hEF2   \n",
       "27649  There is a significant relevance of federated ...  Reviewer_N2ym   \n",
       "27650  There is a significant relevance of federated ...  Reviewer_Vfdi   \n",
       "27651  There is a significant relevance of federated ...  Reviewer_MJiJ   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "1446   1698648757307           1701662567826              6  ...   \n",
       "1447   1698746208577           1699636125239              6  ...   \n",
       "1448   1698822869626           1699636125143              6  ...   \n",
       "1449   1699260725548           1699636125075              8  ...   \n",
       "1642   1697955924532           1699636992453              3  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "27555  1699449672782           1699636970353              3  ...   \n",
       "27648  1698455516741           1699636450427              6  ...   \n",
       "27649  1698725100234           1699636450328              3  ...   \n",
       "27650  1698798393099           1700674345074              5  ...   \n",
       "27651  1699550943464           1699636450179              5  ...   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "1446                11.2328      14.7773     13.5591   \n",
       "1447                13.6251      15.3091     13.6811   \n",
       "1448                15.1974      18.2257     16.5672   \n",
       "1449                 9.5572      10.8611     11.3747   \n",
       "1642                14.6669      18.2108     15.9828   \n",
       "...                     ...          ...         ...   \n",
       "27555               10.0166      12.5762     12.2435   \n",
       "27648               12.5956      15.4394     13.7717   \n",
       "27649               15.2165      18.4087     16.0888   \n",
       "27650               10.8648      13.0958     12.6741   \n",
       "27651               16.6079      19.2861     17.6001   \n",
       "\n",
       "       automated_readability_index politeness_score  hedge_C  hedge_D  \\\n",
       "1446                       13.3105           0.2025       77        1   \n",
       "1447                       14.7228           0.2131       78        0   \n",
       "1448                       16.3167           0.1213       86        0   \n",
       "1449                       10.6575           0.1844       84        0   \n",
       "1642                       15.2685           0.2519       90        0   \n",
       "...                            ...              ...      ...      ...   \n",
       "27555                       9.4292           0.0622       89        0   \n",
       "27648                      13.0917           0.0680       73        0   \n",
       "27649                      16.1376           0.1211       88        0   \n",
       "27650                      11.9940           0.1443       92        0   \n",
       "27651                      18.3138           0.1041       92        0   \n",
       "\n",
       "       hedge_E hedge_I  hedge_N  \n",
       "1446         2       0        0  \n",
       "1447         0       0        0  \n",
       "1448         0       0        0  \n",
       "1449         0       0        0  \n",
       "1642         0       0        0  \n",
       "...        ...     ...      ...  \n",
       "27555        0       0        0  \n",
       "27648        0       0        0  \n",
       "27649        0       0        0  \n",
       "27650        0       0        0  \n",
       "27651        0       0        0  \n",
       "\n",
       "[199 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "14dc2559-8945-4950-a0dd-8ca267f610b5",
       "rows": [
        [
         "1522",
         "tp2nEZ5zfP",
         "501",
         "1682301203358",
         "['~Ulyana_Piterbarg1', '~Lerrel_Pinto1', '~Rob_Fergus1']",
         "NetHack is Hard to Hack",
         "Neural policy learning methods have achieved remarkable results in various control problems, ranging from Atari games to simulated locomotion. However, these methods struggle in long-horizon tasks, especially in open-ended environments with multi-modal observations, such as the popular dungeon-crawler game, NetHack. Intriguingly, the NeurIPS 2021 NetHack Challenge revealed that symbolic agents outperformed neural approaches by over four times in median game score. In this paper, we delve into the reasons behind this performance gap and present an extensive study on neural policy learning for NetHack. To conduct this study, we analyze the winning symbolic agent, extending its codebase to track internal strategy selection in order to generate one of the largest available demonstration datasets. Utilizing this dataset, we examine (i) the advantages of an action hierarchy; (ii) enhancements in neural architecture; and (iii) the integration of reinforcement learning with imitation learning. Our investigations produce a state-of-the-art neural agent that surpasses previous fully neural policies by 127% in offline settings and 25% in online settings on median game score. However, we also demonstrate that mere scaling is insufficient to bridge the performance gap with the best symbolic models or even the top human players.",
         "Reviewer_83YB",
         "1688501358606",
         "1702410746791",
         "6",
         "4",
         "3",
         "4",
         "2",
         "This paper seeks to study and better understand the large performance gap between neural and symbolic agents in the NeurIPS 2021 NetHack Challenge. The main hypothesis is that symbolic agents advantage derives from hierarchical reasoning, which was not an element in participating neural agents. To test this hypothesis, a new dataset is generated using the winning symbolic agent that records both actions and higher-level strategic labels and a neural behavior cloning agent was trained with this augmented data. Beyond this, the paper also explores the impact of increased model size and dataset size, changes to the neural architecture, and the addition of a policy fine-tuning step using a reinforcement learning algorithm. The results suggest that hierarchical training improves the neural agent's performance significantly more than increased model capacity but that more powerful model architectures (i.e. a transformer-based model) could overfit to the augmented data. Quality/Soundness\n\nThe hypotheses and claims of the paper were laid out clearly and the experiments were well-designed to evaluate them. \n\nClarity/Presentation\n\nI found the paper to be clearly presented and well-written. At each stage I had a clear understanding of the question under investigation and the methodology for studying it.\n\nOriginality/Contribution\n\nThe paper is explicit that its main contribution is not algorithmic but scientific. Since the scientific questions posed here are grounded in the performance of agents from a specific competition that happened last year, I expect that this analysis is original.\n\nSignificance/Contribution\n\nIncreasing understanding of the performance gap in the NetHack problem, as a proxy for complex, long-horizon problems in general, could be important. Symbolic approaches make use of quite a lot of domain expertise applied to constructing the symbolic structure, making them effective in their target problem but inflexible. Neural networks seem to be quite flexible and capable of learning without a lot of structure engineering, but don't seem to be able to take advantage of structure in the environment. It seems sensible to study the primary factors preventing neural approaches from building the same long-range structures.\n\nI think it is worthwhile to see the comparison between this structural change and the alternative interventions of more data, more parameters, or more sophisticated/expensive architecture. The finding that, in a time-constrained setting (true of many decision-making problems), model structure may be more important than model capacity seems likely to at least spark interesting conversations within the community. The fact that there is plenty of performance gap still to cover, even with this built-in domain knowledge may also inspire further investigation into what measures could come closer to closing the gap and how those insights might be applied to more general practice.\n\nOverall\n\nOverall, I find this to be a clearly written paper with a reasonable scientific question and sound methodology to address it (modulo some missing statistical analyses). The findings are not revolutionary but, to my eyes, they do provoke further questions about neural approaches to learning in complex, long-horizon problems and may inspire follow-up work either in the NetHack testbed specifically or in studying these questions more generally. Quality/Soundness\n\nMy main concern in this area is the small number of independent samples per model class (6). I do understand that these results are generated at great expense and that it may not be feasible to generate more trials, but the small number of samples diminishes the statistical power of these analyses. I can see that the error bars are quite small; assuming those are showing the standard error, that's encouraging. Nevertheless, whether more samples can be generated or not, I think it's important that the paper include the findings of low-sample hypothesis testing (e.g. t-test) on these results; without that, we can't confidently distinguish between noise and meaningful differences.\n\nOriginality/Contribution\n\nThe paper acknowledges that behavior cloning, hierarchical policies, and transformer-represented policies have all been studied in prior work. \n\nSignificance/Contribution\n\nNetHack is not, in and of itself, an intrinsically important problem to solve. \n\nThe results presented here are not conclusive or enormously surprising. The main result is fairly predictable: adding explicit supervision about high-level strategy and explicit hierarchical structure in the model helps the model take advantage of hierarchical structure in the environment.\n\nOverall\n\nOverall, I find this to be a clearly written paper with a reasonable scientific question and sound methodology to address it (modulo some missing statistical analyses). The findings are not revolutionary but, to my eyes, they do provoke further questions about neural approaches to learning in complex, long-horizon problems and may inspire follow-up work either in the NetHack testbed specifically or in studying these questions more generally.\n\n---After discussion---\n\nI have considered the other reviews and the authors' responses. I continue to feel confident about my overall assessment. n/a Since the paper does not propose significantly new algorithmic ideas, the main source of limitations would be in the methodology and analysis. I generally found the paper to avoid overclaiming. I've already discussed one area where this aspect of the paper could be improved: acknowledgement of the small sample sizes and proper statistical analysis to inform the conclusions. The other area might be in the conclusions where perhaps the summary of the findings might be a bit too general and could be toned down and/or stated clearly as hypotheses (e.g. \"Hierarchy hurts overfitting models\" is an overly broad conclusion from a limited set of experiments but seems like a reasonable hypothesis given these results).",
         "891",
         "0",
         "0",
         "0.8149000000000001",
         "0.1703429133",
         "0.9050506353000001",
         "232",
         "160",
         "26.5592",
         "15.3798",
         "17.8189",
         "16.235",
         "17.1793",
         "0.25520000000000004",
         "100",
         "2",
         "0",
         "1",
         "0"
        ],
        [
         "1523",
         "tp2nEZ5zfP",
         "501",
         "1682301203358",
         "['~Ulyana_Piterbarg1', '~Lerrel_Pinto1', '~Rob_Fergus1']",
         "NetHack is Hard to Hack",
         "Neural policy learning methods have achieved remarkable results in various control problems, ranging from Atari games to simulated locomotion. However, these methods struggle in long-horizon tasks, especially in open-ended environments with multi-modal observations, such as the popular dungeon-crawler game, NetHack. Intriguingly, the NeurIPS 2021 NetHack Challenge revealed that symbolic agents outperformed neural approaches by over four times in median game score. In this paper, we delve into the reasons behind this performance gap and present an extensive study on neural policy learning for NetHack. To conduct this study, we analyze the winning symbolic agent, extending its codebase to track internal strategy selection in order to generate one of the largest available demonstration datasets. Utilizing this dataset, we examine (i) the advantages of an action hierarchy; (ii) enhancements in neural architecture; and (iii) the integration of reinforcement learning with imitation learning. Our investigations produce a state-of-the-art neural agent that surpasses previous fully neural policies by 127% in offline settings and 25% in online settings on median game score. However, we also demonstrate that mere scaling is insufficient to bridge the performance gap with the best symbolic models or even the top human players.",
         "Reviewer_qyRc",
         "1688628255357",
         "1702410746731",
         "7",
         "4",
         "3",
         "3",
         "3",
         "# Problem Statement\nThe paper addresses the challenge of neural policy learning methods struggling in long-horizon tasks, particularly in open-ended environments with multi-modal observations, such as the game NetHack. It was observed that symbolic agents significantly outperformed neural approaches in the NeurIPS 2021 NetHack Challenge.\n\n# Main Contribution\nThe paper's main contribution is an extensive study on neural policy learning for NetHack. The authors analyzed the winning symbolic agent and extended its codebase to generate one of the largest available demonstration datasets. They examined the advantages of an action hierarchy, enhancements in neural architecture, and the integration of reinforcement learning with imitation learning. Their investigations resulted in a state-of-the-art neural agent that surpassed previous fully neural policies by 127% in offline settings and 25% in online settings on median game score. However, they also demonstrated that mere scaling is insufficient to bridge the performance gap with the best symbolic models or even the top human players.\n\n# Methodology and Experiments\n\n## The Hierarchical HiHack Dataset\nThe authors create the HiHack dataset, which is a hierarchically-informed version of the NetHack Learning Dataset (NLD-AA), containing 3 billion recorded game transitions from over a hundred thousand games played by the AutoAscend agent.\n\n## Hierarchical Behavioral Cloning\nThe authors extend the ChaoticDwarvenGPT5 (CDGPT5) model, a top-performing open-source neural model for NetHack, by introducing a hierarchical decoding module. The model consists of three separate encoders for different types of observations and an LSTM core module. The hierarchical extension replaces the linear decoder of the CDGPT5 model with a hierarchical decoder that predicts the strategy label and selects the appropriate low-level MLP for action prediction. The hierarchical LSTM policy and the baseline non-hierarchical LSTM CDGPT5 policy are trained using a simple cross-entropy loss. The results show that the introduction of hierarchy significantly improves the performance of LSTM policies trained with behavioral cloning, yielding a 40% gain over the baseline in mean NLE score and a 50% improvement in median score across seeds. The authors confirm that this improvement is due to hierarchy and not simply a result of the increased parameter count of the hierarchical LSTM policy.\n\n## Architecture and Data Scaling\nThe authors explored scaling as a potential solution to improve the performance of the model, which was significantly behind the symbolic policy used to generate the HiHack demonstrations. They developed a novel base policy architecture for NetHack that introduces a Transformer module into the previous CDGPT5-based architecture. They also conducted data scaling experiments using subsets of the HiHack dataset to examine the relationship between dataset size and the test-time performance of BC policies. The results showed that both the non-hierarchical and hierarchical variants of the combined transformer-LSTM policy architecture yielded gains, but the larger model performed worse than the smaller one due to overfitting. This suggested that scaling of model capacity alone would not be sufficient to close the neural-symbolic gap. Additionally, brute force scaling of the dataset alone could not viably close the gap to symbolic methods.\n\n## Combining Imitation with Reinforcement Learning\nThe authors explored combining imitation learning with reinforcement learning (RL) to bridge the performance gap with AutoAscend. They used a combination of behavioral cloning (BC) and asynchronous proximal policy optimization (APPO) for training. The results showed that RL fine-tuning significantly improved the performance of all models. The best-performing approach was APPO + BC using the hierarchical LSTM model, which achieved a new state-of-the-art for neural policies on NLE, surpassing the previous best result by 48% in mean NLE score and 25% in median NLE score. The Transformer-LSTM models performed worse due to their slower training speed and the fixed training time budget. The authors also observed that fine-tuning with RL improved the error-correction capability of models across all model classes compared to their purely offline counterparts. # Originality\nThe problem is interesting and the approaches are insightful.\n\n# Quality\nThe analysis and experiments are comprehensive.\n\n# Clarity\nThe article is overall well written and clear. 1. The current focus of the study is quite narrow, being primarily centered on the application of imitation learning for NetHack, limiting its influence. In the context of mastering the game, while this approach is interesting, it is unlikely to exceed the performance of experts that generate demonstrations, not to mention that the experts are already algorithms that can scale well. Furthermore, NetHack, despite being an excellent game, is somewhat niche and its real-world implications are relatively minimal. The techniques proposed in this study are specifically tailored for this game, which limits their potential for inspiring more universally applicable methods that could have a broader impact.\n  - The availability of hierarchical labels is a strong assumption that does not often hold, which further limits the applicability of the proposed methods.\n\n2. Even just for bridging the performance gap between neural models and AutoAscend, there is no promising direction revealed by the work as the various augmenting components seem to contradict each other. 1. When introducing Transformer to augment the capacity of the neural model, why did authors choose the architecture as shown in the article? Specifically, transformers are best known for their NLP and CV capacity, which could make them good replacement for the CNN and MLP encoders.\n2. Why do the authors enforce the 48 hour training time cap instead of training all models till convergence? Given that this study does not appear to prioritize data efficiency or training efficiency, the necessity of such a computational time constraint is unclear. It would be beneficial to understand the rationale behind this choice, as it may not directly align with the study's primary objectives. The authors note that possible avenues for future exploration include: (a) methods for increasing the Transformer context length to give the agent a longer memory to aid exploration; (b) addressing the multi-modal nature of the demonstration data (i.e. quite different trajectories can lead to the same reward), which is a potential confounder for BC methods. Some forms of distributional BC (e.g. GAIL, BeT) could help alleviate this issue.\n\nThe aforementioned two points do not address the limitations raised in the \"Weakness\" section.",
         "1010",
         "0",
         "4",
         "0.7969",
         "0.0384225531",
         "0.9721859097000001",
         "232",
         "159",
         "26.3989",
         "15.0868",
         "18.3701",
         "16.5131",
         "16.7018",
         "0.0751",
         "92",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1524",
         "tp2nEZ5zfP",
         "501",
         "1682301203358",
         "['~Ulyana_Piterbarg1', '~Lerrel_Pinto1', '~Rob_Fergus1']",
         "NetHack is Hard to Hack",
         "Neural policy learning methods have achieved remarkable results in various control problems, ranging from Atari games to simulated locomotion. However, these methods struggle in long-horizon tasks, especially in open-ended environments with multi-modal observations, such as the popular dungeon-crawler game, NetHack. Intriguingly, the NeurIPS 2021 NetHack Challenge revealed that symbolic agents outperformed neural approaches by over four times in median game score. In this paper, we delve into the reasons behind this performance gap and present an extensive study on neural policy learning for NetHack. To conduct this study, we analyze the winning symbolic agent, extending its codebase to track internal strategy selection in order to generate one of the largest available demonstration datasets. Utilizing this dataset, we examine (i) the advantages of an action hierarchy; (ii) enhancements in neural architecture; and (iii) the integration of reinforcement learning with imitation learning. Our investigations produce a state-of-the-art neural agent that surpasses previous fully neural policies by 127% in offline settings and 25% in online settings on median game score. However, we also demonstrate that mere scaling is insufficient to bridge the performance gap with the best symbolic models or even the top human players.",
         "Reviewer_PtAe",
         "1688673902510",
         "1702410746634",
         "7",
         "5",
         "2",
         "3",
         "3",
         "The paper improves the existing solutions in the NetHack Learning Environment (NLE). This is done by taking earlier solutions from a competition around NLE, collecting more data with the best available (symbolic) agent, and using that data to improve a neural only solution. The paper provides experiments with imitation learning (with or without RL tuning), larger models, hierarchical memory setup (LSTM + Transformers) as hierarchical behavioural cloning setup, using labels of the newly collected dataset. While there are improvements, it is still below the demonstrator results, which is then studied by scaling the model sizes and amount data collected. Paper concludes by providing the state of the art results in the task, but also noting that scaling alone is not enough to reach the expert demonstrator level (symbolic agent). - Provides more detailed dataset than the previous works (with hierarchical action labels)\n- Sets an interesting premise/task for trying to reach the demonstrators' (AutoHack agent) performance with neural solutions.\n- Different ablations to try to answer questions (data/model scaling, model architecture with hierarchy)\n- Proposed hierarchical approach to imitate the demonstrator agent. While I enjoyed reading the paper, overall I think the results are interesting or applicable to most of the NeurIPS audience, even in the limited scope. The paper presents many results and provides some explanations for them, but does not verify these explanations with further experiments. I think proper answers to these issues would be insightful to many, and others could then use these insights in their work (e.g., where the trained agent failed to imitate the demonstrator? What was the cause of poorer performance? Why did bigger model perform worse?). Creating such insight in one environment would be sufficient, as by focusing on a single environment, you can create very specific scenarios to tease out these answers. \n\n- Limited scope of the work: experiments done in a single environment. Most of the paper is framed in a way that this is not a huge issue (e.g., ablations), but proposing new method just for playing NLE has limited impact. If a new method is proposed to generally improve RL/IL performance, it should be tested at least in two distinct environments.\n- Limited improvement in the context of SOTA solutions: 2x over the baseline used in the paper with RL and proposed architecture included, but other neural agents in the NetHack Challenge had higher score. To be interesting in terms of performance, it should at least outperform the NetHack Challenge Neural solutions.\n- Proposed method is limited in novelty, as evident by the previous work listed in the paper. If the hierarchical BC figured out the hierarchy automatically (or, if it was an emergent behaviour of the model), that would be more interesting.\n- Paper outlines some assumptions on why things failed (e.g., \"model overfitted\" or \"learned to self-correct\"), but these claims were not verified with results. The paper would be much stronger if you can give solid, verified answer that indeed, overfitting was to blame or that RL trained the model to \"self-correct\". Questions:\n1) In multiple occasions paper says that the lower performance of bigger model is due to overfitting (e.g., line 229). However there are no results/experiments to show that this indeed was the case. A simple way to find this out is to do train-validation (or even train/validation/test) split, and testing on held out data as training progresses.\n2) Regarding data scaling experiments: did you change any other settings of the training setup when increasing data amount? Previous work has demonstrated that the optimal model size and/or training compute depends on the amount of data (Hoffmann et al. 2020).\n3) Regarding model scaling experiments: I assume only the number of layers in the transformer was changed? The bottleneck of the network may be elsewhere, e.g., one of the input layers or output layers. I would recommend scaling the whole network, similar to what OpenAI VPT work did, where ResNet blocks were \"widened\" in terms of filters, as well as increasing transformer size (Baker et al. 2022). Also, Hoffmann et al. (2020) changed number of layers, number of attention heads and transformer dimensionality when scaling models. This might be something you want to try.\n4) Instead of LSTM + Transformer model, did you experiment with transformer model only? E.g., akin to VPT work (Baker et al. 2022), embed all inputs into one vector, stack vectors over timesteps, apply causal transformer, and predict actions from the transformer outputs. This type of model might scale better, as it reduces the amount of components that might interfere.\n\n#### Comments (not questions)\n- Fig1 right: weird scale. Any chance to get more points?\n- Line 205: grammar error at the start of the line\n- Explain/rename \"Dlvl\" and why \"Turns\" is good metric\n- Figure 3: \"LSTM + XXL Dec\" is bit confusing naming, since \"decoder\" is not commonly used term in the paper. I'd recommend using something like \"LSTM (bigger)\" to simply reflect that it is the LSTM baseline but with bigger network\n- Figure 3 (and others): add explanation to caption what is the error bar of the bar plots. Is it standard deviation or standard error (or something else)?\n- Table 2 caption: starts with weird \"\\[V4\\]\"\n\n#### References\n\n- Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas et al. \"Training compute-optimal large language models.\" arXiv preprint arXiv:2203.15556 (2022).\n- Baker, Bowen, Ilge Akkaya, Peter Zhokov, Joost Huizinga, Jie Tang, Adrien Ecoffet, Brandon Houghton, Raul Sampedro, and Jeff Clune. \"Video pretraining (vpt): Learning to act by watching unlabeled online videos.\" Advances in Neural Information Processing Systems 35 (2022): 24639-24654. No explicit sections for limitations or broader/societal impact was given. Authors bring up the future work ideas in the conclusion. While I think the work does not require societal impact section (no immediate impact), I urge authors still think through of any cases where the work or the insights could impact others. Or alternatively, what impact would _not_ including some results do (e.g., skipping some analysis).\n\n\n## Rebuttal acknowledgement\n\nI have read authors' rebuttal which did address my concerns, and I increased my rating from 4 to 7 to signal my vote to accept this paper (change was done before discussion period closed).",
         "1043",
         "3",
         "5",
         "0.8198000000000001",
         "0.08608553890000001",
         "0.8613269329000001",
         "232",
         "158",
         "48.5199",
         "10.865",
         "13.3097",
         "12.8228",
         "12.1907",
         "0.1278",
         "88",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1525",
         "tp2nEZ5zfP",
         "501",
         "1682301203358",
         "['~Ulyana_Piterbarg1', '~Lerrel_Pinto1', '~Rob_Fergus1']",
         "NetHack is Hard to Hack",
         "Neural policy learning methods have achieved remarkable results in various control problems, ranging from Atari games to simulated locomotion. However, these methods struggle in long-horizon tasks, especially in open-ended environments with multi-modal observations, such as the popular dungeon-crawler game, NetHack. Intriguingly, the NeurIPS 2021 NetHack Challenge revealed that symbolic agents outperformed neural approaches by over four times in median game score. In this paper, we delve into the reasons behind this performance gap and present an extensive study on neural policy learning for NetHack. To conduct this study, we analyze the winning symbolic agent, extending its codebase to track internal strategy selection in order to generate one of the largest available demonstration datasets. Utilizing this dataset, we examine (i) the advantages of an action hierarchy; (ii) enhancements in neural architecture; and (iii) the integration of reinforcement learning with imitation learning. Our investigations produce a state-of-the-art neural agent that surpasses previous fully neural policies by 127% in offline settings and 25% in online settings on median game score. However, we also demonstrate that mere scaling is insufficient to bridge the performance gap with the best symbolic models or even the top human players.",
         "Reviewer_Ub8t",
         "1689161570330",
         "1702410746563",
         "7",
         "2",
         "3",
         "3",
         "4",
         "This is an emergency review, and I regret that the paper is out of my expertise, which is why my review will rather stay at the surface level.\n\nThe paper is concerned with the NetHack challenge, a complex AI challenge that in 2021 reached headlines, because symbolic agents considerably outperformed neural agents. I see three main contributions in the paper:\n - The construction of a large-scale dataset, based on the best symbolic agent and its policy choices, that can enable training better neural agents\n - The training of better neural agents based on this dataset, and other improvements\n - A systematic analysis of the effect of different technical improvements (hierarchical BC, larger Transformer models, larger datasets, online fine-tuning with RL), notably finding that scaling training sets or model size alone will not bridge the gap to the best symbolic agent.\n\nThe problem is of very high interest to the AI community, and the technical investigation, results, and discussion appear thorough and insightful. The dataset might also enable further research. I find especially the results regarding scaling interesting, i.e., that performance increases logarithmic, and so more data or bigger models alone will not enable achieving parity with the symbolic approach.\n\nQuality of writing is very good, and so the paper is easy to follow (subject to my lack of technical background).\n\nMinor notes:\n - The paper appears to be missing a link to the dataset\n - The related work is not easy to access for someone not close to the field. E.g., paragraphs on \"imitation learning\" and \"hierarchical policy learning\" give too little detail about the basic ideas (do not start with descriptions of what they are for, but what they do)\n - \"The full observation space of NLE is far richer and more informed than the view afforded to human players of NetHack, who observe only the more ambiguous “text-based” components of NLE observations\" - I do not fully understand this sentence, please expand. What can systems observe in NLE, that humans don't receive in the original interface? Or do you mean that NLE aggregates the Ascii terminal characters into something more high-level?\n - Showing an excerpt from the dataset would be helpful, especially, as it is not quite clear what is added there, both strategies and substrategies? Or the more specific one only?\n See above. See above. See above. Yes, the authors critically discuss that scaling alone will not bridge the gap to symbolic agents on this challenge.",
         "409",
         "0",
         "3",
         "0.7943",
         "0.1541088435",
         "0.8796135187",
         "232",
         "153",
         "39.1929",
         "14.434",
         "17.3766",
         "15.47",
         "16.0279",
         "0.241",
         "107",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1526",
         "tp2nEZ5zfP",
         "501",
         "1682301203358",
         "['~Ulyana_Piterbarg1', '~Lerrel_Pinto1', '~Rob_Fergus1']",
         "NetHack is Hard to Hack",
         "Neural policy learning methods have achieved remarkable results in various control problems, ranging from Atari games to simulated locomotion. However, these methods struggle in long-horizon tasks, especially in open-ended environments with multi-modal observations, such as the popular dungeon-crawler game, NetHack. Intriguingly, the NeurIPS 2021 NetHack Challenge revealed that symbolic agents outperformed neural approaches by over four times in median game score. In this paper, we delve into the reasons behind this performance gap and present an extensive study on neural policy learning for NetHack. To conduct this study, we analyze the winning symbolic agent, extending its codebase to track internal strategy selection in order to generate one of the largest available demonstration datasets. Utilizing this dataset, we examine (i) the advantages of an action hierarchy; (ii) enhancements in neural architecture; and (iii) the integration of reinforcement learning with imitation learning. Our investigations produce a state-of-the-art neural agent that surpasses previous fully neural policies by 127% in offline settings and 25% in online settings on median game score. However, we also demonstrate that mere scaling is insufficient to bridge the performance gap with the best symbolic models or even the top human players.",
         "Reviewer_eWjQ",
         "1689665510650",
         "1702410746491",
         "6",
         "2",
         "3",
         "3",
         "2",
         "The paper explores reasons for this performance gap between neural and symbolic methods in NetHack:\nSymbolic agents use hierarchical policies and parsers to extract high-level features\nSymbolic agents have handcrafted heuristics and error correction\nNeural agents lack inductive biases like hierarchy that may be needed for sparse rewards\nExperiments show hierarchy, scale, and combining imitation and RL help improve neural agents:\nHierarchical behavior cloning improves over flat BC\nLarger Transformer-based architectures improve over LSTMs\nRL fine-tuning provides gains, especially for underfitting models\nBut significant gaps to symbolic agents remain The experimental design is very clever, the chart is very clear, and the experimental effect is obvious. The paper explores a novel problem domain of applying neural networks to master the game NetHack, where current methods struggle compared to symbolic AI. The authors introduce a new large-scale dataset of NetHack demonstrations called HiHack to facilitate this analysis. The idea of using demonstrations to help neural networks learn better policies in sparse, long-horizon environments like NetHack is creative.The methods are detailed appropriately to replicate experiments. Results are presented logically and incorporate useful visualizations. The conclusion summarizes takeaways concisely.Mastering complex environments like NetHack with sparse rewards and long time horizons remains an open challenge for deep RL. This paper provides significant evidence and analysis characterizing the limitations of current neural network methods in these settings, and points the way towards progress, whether via incorporating stronger inductive biases like hierarchy or combining neural and symbolic approaches. The insights will broadly impact research in sparse reward RL, imitation learning, and integrating neural and classical AI. This model is based on the nethack, and the results hold up on the above models, and whether the above results can still hold up on the other models。The authors recognize the limited generality so far of methods tested on NetHack to other complex environments.No obvious harmful biases or problematic data sources are introduced in this work. The NetHack environment itself seems relatively innocuous.\n Can you add some experiments, add some theoretical derivation, whether the contribution of this article is more. The model is not so representative, can switch a more popular model。Overall, the authors demonstrate good care and thoughtfulness regarding the limitations and potential negative impacts of this research direction. The discussion seems sufficient without being overreaching or distracting from the primary technical contributions. I do not have any major suggestions for improvement.",
         "394",
         "0",
         "0",
         "0.8136",
         "0.0944551101",
         "0.9210098386000001",
         "232",
         "147",
         "17.9759",
         "16.5097",
         "19.6259",
         "17.2589",
         "18.8127",
         "0.3146",
         "80",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "1579",
         "tdyLryDebq",
         "5583",
         "1683684292729",
         "['~Zuhao_Yang1', '~Yingfang_Yuan1', '~Yang_Xu6', '~SHUO_ZHAN1', '~Huajun_Bai1', '~Kefan_Chen4']",
         "FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy",
         "Measuring the distance between machine-produced and human language is a critical open problem. Inspired by empirical findings from psycholinguistics on the periodicity of entropy in language, we propose FACE, a set of metrics based on Fourier Analysis of the estimated Cross-Entropy of language, for measuring the similarity between model-generated and human-written languages. Based on an open-ended generation task and the experimental data from previous studies, we find that FACE can effectively identify the human-model gap, scales with model size, reflects the outcomes of different sampling methods for decoding, correlates well with other evaluation metrics and with human judgment scores.",
         "Reviewer_wEMM",
         "1688654659245",
         "1702411017030",
         "3",
         "4",
         "2",
         "3",
         "2",
         "In order to distinguish between human-generated text and machine-generated text, the authors propose the use of the periodicity of cross entropy for discrimination. More specifically, they suggest analyzing cross entropy through the Fourier transform. 1. This paper is well-written and easy to follow.\n2. The experimental section of this paper is fairly comprehensive.  The authors' experimental objects have broadly encompassed the latest open-source large models. Although it lacks large language models like GPT-3.5 (the cross entropy can still be obtained through APIs).\n\n 1. Motivation. The motivation of the paper is not clear, as the authors do not clearly explain why the CE of human language would exhibit periodicity. In the related work section, they briefly mention previous works, but in my view, dialogue tasks are just a specific case of text generation. Overall, skipping the motivation part significantly reduces the soundness of this paper.\n\n2. Method. The authors' method simply involves applying a FFT to the CE sequences, which I believe lacks substantial novelty. Why haven't the authors considered using the information in the frequency domain as input to a deep neural network to incorporate a powerful NN? Why only analyze information in the frequency domain using spectral similarity metrics? Additionally, most of these metrics have already been presented in \\[1\\]. Which method would better utilize this information for discrimination? In conclusion, the proposed method by the authors lacks both sufficient contribution and profound insight.\n\n3. Experiments.  In the experimental section, the authors did not compare against sufficient baselines. For instance, could we achieve good results by only training a contrastive model using human-generated text and LLM-generated text? How helpful is the frequency domain information in discriminating texts?\n\n\\[1\\] Y. Xu and D. Reitter. Spectral analysis of information density in dialogue predicts collaborative task performance. ACL see weakness  the authors adequately addressed the limitations",
         "304",
         "2",
         "8",
         "0.8037000000000001",
         "0.1702938988",
         "0.8712091446",
         "216",
         "159",
         "32.5148",
         "12.157",
         "14.0799",
         "13.0985",
         "12.67",
         "0.1199",
         "89",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "1580",
         "tdyLryDebq",
         "5583",
         "1683684292729",
         "['~Zuhao_Yang1', '~Yingfang_Yuan1', '~Yang_Xu6', '~SHUO_ZHAN1', '~Huajun_Bai1', '~Kefan_Chen4']",
         "FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy",
         "Measuring the distance between machine-produced and human language is a critical open problem. Inspired by empirical findings from psycholinguistics on the periodicity of entropy in language, we propose FACE, a set of metrics based on Fourier Analysis of the estimated Cross-Entropy of language, for measuring the similarity between model-generated and human-written languages. Based on an open-ended generation task and the experimental data from previous studies, we find that FACE can effectively identify the human-model gap, scales with model size, reflects the outcomes of different sampling methods for decoding, correlates well with other evaluation metrics and with human judgment scores.",
         "Reviewer_s437",
         "1688836311175",
         "1702411016954",
         "6",
         "4",
         "3",
         "4",
         "3",
         "This paper proposes a new measure of natural language generation (NLG) quality based on similarity between the spectrum of cross-entropy in natural vs. generated text. Fourier Analysis of the Cross-Entropy of language (FACE) is inspired by NLP and psycholinguistic studies suggesting that surprisal is not uniformly distributed in natural text (e.g., content words tend to be more surprising than function words), occurring periodically. For a given generated text, FACE computes a discrete Fourier transform of the token-level cross-entropy sequence (under a separate FACE evaluation LM). Similarity between the vector of frequency magnitudes and that from a randomly selected, natural text corpus are then computed. The paper considers several definitions of FACE metrics, including spectral overlap, cosine similarity, and Pearson/Spearman’s rank correlation coefficients.\n\nLMs from 125 million to over 7 billion parameters are evaluated on NLG of Wikipedia articles, news articles, and stories (with a short prompt of 35 subword tokens provided). Ultimately, FACE is found to be correlated with human judgments of how “human-like”, “sensible”, and “interesting” the generations are. The relationship is not as strong as an existing intrinsic measure, MAUVE. The relative ranking of decoding methods according to FACE agrees with prior works (e.g., greedy decoding < nucleus), as do model size (smaller models produce lower quality generations than larger models). The metric is well-motivated, evaluating whether generated text matches the surprisal statistics of natural text. The algorithm is simple and described sufficiently clearly. FACE is an automatic measure of NLG quality that is, on the face of it, complementary to existing measures. This paper would be of interest to many who work on (large) language models. While FACE is motivated by the desire to match surprisal statistics of natural text, it was not clear how different FACE is from existing metrics. Computing correlation between FACE and existing metrics would help alleviate this, as would providing anecdotes of cases with high/low FACE score vs. high/low MAUVE score, for instance. Have you also considered the spectrum of hidden LM embeddings rather than cross-entropy, and considered how such a metric might differ from FACE? Yes",
         "345",
         "0",
         "1",
         "0.8233",
         "0.0747350351",
         "0.9425024986",
         "216",
         "157",
         "31.0628",
         "13.4245",
         "16.777",
         "15.283",
         "14.4355",
         "0.1585",
         "82",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "1581",
         "tdyLryDebq",
         "5583",
         "1683684292729",
         "['~Zuhao_Yang1', '~Yingfang_Yuan1', '~Yang_Xu6', '~SHUO_ZHAN1', '~Huajun_Bai1', '~Kefan_Chen4']",
         "FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy",
         "Measuring the distance between machine-produced and human language is a critical open problem. Inspired by empirical findings from psycholinguistics on the periodicity of entropy in language, we propose FACE, a set of metrics based on Fourier Analysis of the estimated Cross-Entropy of language, for measuring the similarity between model-generated and human-written languages. Based on an open-ended generation task and the experimental data from previous studies, we find that FACE can effectively identify the human-model gap, scales with model size, reflects the outcomes of different sampling methods for decoding, correlates well with other evaluation metrics and with human judgment scores.",
         "Reviewer_mMGf",
         "1689168431622",
         "1702411016873",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a set of metrics based on Fourier Analysis of the estimated Cross-Entropy (FACE) of language. The main idea is to compute the similarity between the spectra of cross-entropy in model-generated texts and human-written texts. Experimental results show that FACE as a computationally efficient metric can scale with model size and reflect the outcomes of different sampling methods for decoding. 1. The idea to introduce the spectra of cross-entropy into the evaluation task of open-ended text generation is interesting since it may include some patterns (e.g. periodical patterns) to identify the difference between model-generated texts and human-written texts.\n\n2. This paper is overall well-written and easy to follow. 1. The proposed method lacks deeper analysis on the spectrum of cross entropy in the evaluation task. The authors only use the spectrum of cross entropy as a feature vector of texts to compute similarities without clearly describing the characteristics of texts it can reflect. This seems like an empirical try without definite intuitions or theoretical supports. In comparison, the features which are commonly used in the existing metrics such as n-gram statistics (in BLEU) and contextual hidden vectors (in BERTScore) intuitively indicate the surface-level and semantic-level representation of texts, respectively.\n\n2. From Table 5, the performance of SO is still worse than that of MAUVE proposed in 2021. I understand that pursuing SOTA is not necessary for each paper. But the authors should provide more insights into the advantages of SO over MAUVE in other aspects.\n\n3. In Section 4.4, the authors mention that they use GPT-2 of different scales to compute the spectra of GPT-2 output data. I wonder whether this setting can introduce potential bias because the cross entropy may be exceptionally low when using GPT-2 to evaluate its own output data from my experience.\n I have included my questions in the weaknesses part. The authors have adequately addressed the limitations.",
         "314",
         "0",
         "5",
         "0.8096",
         "0.0682098765",
         "0.9098261595",
         "216",
         "153",
         "36.0945",
         "12.5586",
         "14.2389",
         "13.9012",
         "12.9422",
         "0.11",
         "88",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "1582",
         "tdyLryDebq",
         "5583",
         "1683684292729",
         "['~Zuhao_Yang1', '~Yingfang_Yuan1', '~Yang_Xu6', '~SHUO_ZHAN1', '~Huajun_Bai1', '~Kefan_Chen4']",
         "FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy",
         "Measuring the distance between machine-produced and human language is a critical open problem. Inspired by empirical findings from psycholinguistics on the periodicity of entropy in language, we propose FACE, a set of metrics based on Fourier Analysis of the estimated Cross-Entropy of language, for measuring the similarity between model-generated and human-written languages. Based on an open-ended generation task and the experimental data from previous studies, we find that FACE can effectively identify the human-model gap, scales with model size, reflects the outcomes of different sampling methods for decoding, correlates well with other evaluation metrics and with human judgment scores.",
         "Reviewer_AtQ2",
         "1690207770969",
         "1702411016795",
         "4",
         "3",
         "3",
         "3",
         "1",
         "This paper proposes a new language generation evaluation metric.\nPrior work in psycholinguistics has shown that surprisal changes periodically in natural language, with natural utterances displaying moments of high and low surprisal.\nThis paper thus proposes to evaluate natural language generation models by quantifying how similar its surprisal frequency patterns are to natural language's.\nMore specifically, this paper proposes to: (1) estimate the surprisal of natural and model-generated text using a separate pretrained language model; (2) get frequency spectra for this surprisals using discrete fourier transforms; (3) compute 4 different metrics of similarity between the frequency spectra of model- and human-generated surprisals.\nThey then experiment with this metric, showing how it evaluates models of different sizes, and with different decoding strategies.\nIn a final experiment, they present the correlation between their metric and human judgment scores for 8 gpt2-based language generation systems (small, medium, large, xl with either ancestral or nucleus sampling); this experiment shows that while the proposed method does better then some prior metrics (e.g. self-bleu) it produces worse correlations than mauve.\n I found this paper quite interesting.\nThe motivation was relatively clear and the proposed metric is well-motivated.\nIn particular, operationalising a psycholinguistic hypothesis of what consists human-like text, and then using it to evaluate language generation systems seems like a promising approach.\nFurther, I appreciate the idea of using Fourier transforms to analyse the frequency spectra of information/surprisal in text. I believe that the evaluation part of the paper could be improved:\n* First, section 4.1 discusses how the proposed metric evaluates models of different sizes. (They generate text while prompting models with a few initial tokens from sentences of three datasets.) These results, however, seemed confusing to me; sometimes smaller or larger models are better with no clear explanation, and the main comparison point used is whether or not the proposed metric agrees with mauve. If mauve was to be considered a gold standard, however, we would not need a new metric.\n* Second, section 4.2 evaluates the impact of decoding strategy on the evaluated scores. In these experiments, the authors (coherently) find that their proposed metric always evaluates contrastive decoding as the best strategy. How their evaluation metric fares when comparing other decoding strategies (e.g. nucleus vs ancestral sampling), however, is less clear. Further the table does not show any scores for human text, which I believe could work as an interesting sanity test. These could be computed by evaluating the proposed metric using half of this dataset against its other half.\n* Third, the correlations with human judgement scores in section 4.3 are worse than mauve's. While I do not believe a paper needs to have state-of-the-art scores to be published, the paper does not put forward other reasons why it should be accepted besides these correlations, and treats these negative results as positive in its discussion.\n\nIn summary, this paper focuses on how its proposed evaluation metric produces good scores of what is human-like text, but does not demonstrate to be better than mauve at this. Further, it does not offer any other justifications (besides being a good metric of human-like text) for why one should use it. Together, this makes me think the impact of this paper might be quite limited.\n\nAdding a longer and more detailed comparison between this proposed metric and previously proposed ones could help improve this paper's impact.\n Questions:\n* Which model was used to compute $m_{\\text{est}}$ in the experiments?\n* Line 21 cites Piantadosi (2014) for the claim that \"For example, Zipf’s law can be used to distinguish between human and model distributions.\" I don't think this is a conclusion of Piantadosi (2014), however. Could you clarify where in the paper he reaches that conclusion? If this is about their comparison with \"random typing models\", those are qualitatively different from language models. When examining proper language models, Meister et al. (2021) reach the opposite conclusion (that language models follow a similar rank-frequency relationship to natural language).\n\nLarger Suggestions: \n* From the paper's text in section 2.2, I interpret that the discrete Fourier transform operates in a single sentence at a time, and thus the proposed metric was developed to compare the spectra of two sentences; not of two corpora. Figure 1, however, implies the Fourier transform takes as input all sentences in a dataset at once. Explaining section 2.2 in more detail could be helpful.\n* Although the authors do discuss this in their paper, I believe the word cross-entropy is not accurate to describe what is being measured here. The word surprisal is the correct one. The authors themselves note this in line 62, but decide to use the term \"cross-entropy\" anyway because it was used this way before, as in, e.g. Genzel and Charniak (2002). Personally, I do not believe this to be a good reason—it's not because prior work used the wrong terminology that you should propagate it.\n\nSmaller Suggestions:\n* Line 156 states that Mauve \"straightforwardly computes\" the similarity of the model- and human-text distributions. However, computing this divergence is actually intractable (starting from the fact that human-text distributions are unknown), and so this is not actually straightforward. They just approximate this using clusters of word embeddings. I’d rewrite this as “attempt to compute” or “estimate”.\n* Line 158 states that reference-based metrics are suited for close-ended generation settings, putting Mauve in that group. Mauve, however, was actually developed to analyse open-ended generation settings. \n* Figure 4 is too small. At the current scale this figure is unreadable.\n\nMeister et al. (2021). Language Model Evaluation Beyond Perplexity.\n I believe the paper doesn't mention at any point which language their data is in (i.e., English) and that most of the cited psycholinguistics research is English-centric (or at least Indo-European-centric). Addressing that as a potential source of limitation is important.",
         "966",
         "5",
         "3",
         "0.8291000000000001",
         "0.0564856657",
         "0.9367425442",
         "216",
         "141",
         "42.2587",
         "11.3234",
         "13.5281",
         "13.295",
         "12.5392",
         "0.9014000000000001",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1583",
         "tdyLryDebq",
         "5583",
         "1683684292729",
         "['~Zuhao_Yang1', '~Yingfang_Yuan1', '~Yang_Xu6', '~SHUO_ZHAN1', '~Huajun_Bai1', '~Kefan_Chen4']",
         "FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy",
         "Measuring the distance between machine-produced and human language is a critical open problem. Inspired by empirical findings from psycholinguistics on the periodicity of entropy in language, we propose FACE, a set of metrics based on Fourier Analysis of the estimated Cross-Entropy of language, for measuring the similarity between model-generated and human-written languages. Based on an open-ended generation task and the experimental data from previous studies, we find that FACE can effectively identify the human-model gap, scales with model size, reflects the outcomes of different sampling methods for decoding, correlates well with other evaluation metrics and with human judgment scores.",
         "Reviewer_v6cq",
         "1690310578076",
         "1702411016704",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a set of metrics to measure the distance between model-generated and human-written languages. Specifically, this paper uses FFT to analyze the cross-entropy sequences of the language data. 1. This new metric is efficient. Given the fact that our models are getting exponentially bigger, it is essential that we do not waste energy during evaluation.\n2. This new metric correlates well with human judgment, and is statistically sound.\n\nI personally really like the authors' attempt to interpret the metric. Understanding the why is sometimes much more important than understanding the how. 1. The related work on psycholinguistic motivation is limited. Entropy is also a popular metric in computational linguistics, which is probably worth citing.\n2. The model size categorization seems to be very coarse.   1. Could the authors be more specific about their motivations for using spectral similarity as a metric? This paper is a good step towards addressing some of the problems brought by generative AI.",
         "159",
         "0",
         "5",
         "0.8219000000000001",
         "0.2167388167",
         "0.9213043451",
         "216",
         "140",
         "39.0844",
         "11.0995",
         "13.6019",
         "12.7451",
         "10.7297",
         "0.11080000000000001",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1872",
         "sgCrNMOuXp",
         "15244",
         "1683832873421",
         "['~Sai_Srivatsa_Ravindranath2', '~Yanchen_Jiang1', '~David_C._Parkes1']",
         "Data Market Design through Deep Learning",
         "The  _data market design_ problem is a problem in economic theory to find a set of signaling schemes (statistical experiments) to maximize expected revenue to the information seller, where each experiment reveals some of the information known to a seller and has a corresponding price. Each buyer has their own decision to make in a world environment, and their subjective expected value for the information associated with a particular experiment comes from the improvement in this decision and depends on their prior and value for different outcomes. In a setting with multiple buyers, a buyer's expected value for an experiment may also depend on the information sold to others. We introduce the application of deep learning for the design of revenue-optimal data markets, looking to expand the frontiers of what can be understood and achieved. Relative to earlier work on deep learning for auction design, we must learn signaling schemes rather than allocation rules and handle  _obedience constraints_  &mdash; these arising from modeling the downstream actions of buyers &mdash; in addition to incentive constraints on bids.  Our experiments demonstrate that this new deep learning framework can almost precisely replicate all known solutions from theory, expand to more complex settings, and be used to establish the optimality of new designs for data markets and make conjectures in regard to the structure of optimal designs.",
         "Reviewer_nspR",
         "1687323720073",
         "1702411512019",
         "5",
         "3",
         "2",
         "2",
         "2",
         "This paper studies the market design problem, specifically for data markets. In particular, different from existing analytic approaches, the proposed approach is based on (deep) learning to recover/discover market designs. They adopt and extend an existing RochetNet architecture to both single- and multi-buyer setting and empirically demonstrate the effectiveness of the approach in recovering/discovering the market design. - The paper studies the problem of market design and it is relevant for data market.\n- The proposed learning-based approach is interesting in that it can recover some analytic solutions.\n- There are relatively extensive empirical results. - The motivation and justification of a (deep) learning-based approach can be made stronger.\n    \n    In lines 40-42, \"The difficulty of using analytical tools for this problem of data market design is highlighted by this example, and it remains an open problem to obtain theoretical results for richer multi-buyer settings. This motivates the need for computational approaches.\" While it is perceived that analytic solutions are difficult, and computational approaches seem a viable alternative. Is it really necessary to use deep learning? In other words, are there less complex computational approaches that can be tried first or reasons why they would not work as well? \n\n    In particular, (how) can the assumption of i.i.d. samples from $\\mathcal{P}$ for training the deep learning model be satisfied? It requires the type of the buyer (i.e., both belief and the $v$) to remain fixed throughout observing the signals. Does this assumption have conflicts with \"Upon receiving a signal, the buyers update their prior beliefs and choose an optimal action accordingly\" (lines 143-144)?\n\n\n- The inline equations in the paper can break the flow of the writing and make it more difficult for the reader to catch the most important points.\n\n    For instance, equations (1)-(4) are used to discuss (different variants of) incentive compatbility. It is not so clear which equation the reader should pay most attention to. Furthermore, it seems that equation (4) (i.e., ex post incentivie compatible) is not interpreted after the equation.\n\n- Some experimental results can be difficult to interpret (or understand their significance), due to the lack of (existing) analytic characterization of optimum solution. \n\n    For instance, in lines 294-296, \"We are aware of no theoretical characterization of optimal data market designs when both $v$ and $\\theta$ vary. In such cases, we can use RochetNet to conjecture the structure of an optimal solution.\" As a result, it is not clear to the reader how to understand whether the proposed method is effective. It further goes to the first point regarding the motivation/justification of a learning based approach: There lacks a solution or ground truth (i.e., analytic optimum or approixmate optimum) to evaluate the approach. Hence, it seems appealing to first establish such a solution before a computational approach, otherwise, how to effectively evaluate the proposed computational approach?\n - In lines 20-22, \"... hold vast quantities of data about individuals. In turn, this has led to data markets, where information about an individual can be purchased in real-time to guide decision-making (e.g., LiveRamp, Segment, Bloomreach).\" This seems to hint at that the aforementioned companies are selling data about individuals, is it what it means?\n\n- In lines 60-62, \"Further, we give a training method that enables the efficient reuse of computed interim allocations and payments from other samples to swiftly calculate the interim utility of misreporting, dramatically speeding up training.\" Is this empirically or theoretically demonstrated, specifically about \"dramatically speeding up training\"? What is it comparing against, in terms of speed of training?\n\n- In line 122, \"The state of the world, $\\omega$, is unknown and is drawn from a finite state space ... \" Is there an assumption on the distribution of this?\n\n- In line 127, \"where each $v_i$ is drawn independently from a distribution $\\mathcal{V}_i$\". What is the interpretation of $v_i$ and what does the distribution $\\mathcal{V}_i$ depend on?\n\n- In lines 137-138, it seems that the negative externality is in the form of decreasing payment for one buyer $i$ as the gain for some other buyers. In other words, if another buyer $j$ gains (in ex post payoff), this buyer $i$ \"loses\" (i.e., has a lower utility), is this correct? How should this be interpreted in an example? \n\n- In line 139, \"There is a data seller who observes the world state ... \" How to justify or realize this assumption that the actual world state is exactly known by the data seller?\n\n- In line 159 (5-th bulletin point), \"$u_i(a,\\omega, V_i, \\theta_i)$\", is it meant to be $V_i$ or $v_i$?\n\n- In line 192, \"... an unsupervised learning problem.\" Is it referring to optimizing the softmax version of Equation (9)? If so, it looks more like an optimization problem (i.e., parametric fitting) instead of a learning problem. Often, unsupervised learning is to learn about the inter or intra structure of the data instead of to fit a functional form. Please help interpret why the loss function in line 222 is an unsupervised learning problem.\n\n - Typically in an optimization approach, if the objective is non-convex (or more complex), it is difficult to establish theoretical guarantees in terms of the optimality or quality of the final solution obtained. This is also mentioned by the authors in lines 374 - 375. The implication is that, it is difficult to obtained a principled understanding of how good the solution (i.e., learnt market design) is, obtained from the gradient-based optimization.\n\n- With regard to lines 378-380, \"we return to where we started, and underline that markets for trading data about individuals raise a number of ethical concerns.\" In light of the potential ethical concerns of data trading, a (deep) learning-based approach potentially makes it even more difficult to manage and parse the working mechanism of the data trading. As a result, such an approach can make it even more difficult to reliably/verifably address those concerns.\n",
         "977",
         "0",
         "0",
         "0.768",
         "0.09073920270000001",
         "0.9176636934",
         "215",
         "174",
         "44.2756",
         "10.9064",
         "13.7859",
         "13.156",
         "11.3225",
         "0.0665",
         "101",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1873",
         "sgCrNMOuXp",
         "15244",
         "1683832873421",
         "['~Sai_Srivatsa_Ravindranath2', '~Yanchen_Jiang1', '~David_C._Parkes1']",
         "Data Market Design through Deep Learning",
         "The  _data market design_ problem is a problem in economic theory to find a set of signaling schemes (statistical experiments) to maximize expected revenue to the information seller, where each experiment reveals some of the information known to a seller and has a corresponding price. Each buyer has their own decision to make in a world environment, and their subjective expected value for the information associated with a particular experiment comes from the improvement in this decision and depends on their prior and value for different outcomes. In a setting with multiple buyers, a buyer's expected value for an experiment may also depend on the information sold to others. We introduce the application of deep learning for the design of revenue-optimal data markets, looking to expand the frontiers of what can be understood and achieved. Relative to earlier work on deep learning for auction design, we must learn signaling schemes rather than allocation rules and handle  _obedience constraints_  &mdash; these arising from modeling the downstream actions of buyers &mdash; in addition to incentive constraints on bids.  Our experiments demonstrate that this new deep learning framework can almost precisely replicate all known solutions from theory, expand to more complex settings, and be used to establish the optimality of new designs for data markets and make conjectures in regard to the structure of optimal designs.",
         "Reviewer_u4po",
         "1688464473495",
         "1702411511929",
         "5",
         "3",
         "3",
         "2",
         "2",
         "This paper introduces a deep learning application to the data market designs that find optimal signaling schemes to maximize the revenue of data sellers. The proposed method is designed to handle truthfulness and obedience (i.e., buyers following recommendations). The overall approach follows the prior frameworks of RochetNet and RegretNet for auction design. The authors are able to demonstrate the method’s ability to recover existing analytical optimal solutions and extend to cases where analytical results are not available. Some experimental results are provided for both single-buyer and multiple-buyer settings. 1. The paper applies deep learning to the new domain of data market design, illustrating the feasibility of learning solutions to optimal data market design.\n2. It considers the obedience of data buyers in the design. This makes the approach more practical.\n3. The paper provides a sound analysis of Individual Rationality for the mechanism and payments. 1. The writing could be improved. Preliminaries could be better structured to explain essential terms like menu entry, signaling, state of the world, how the mechanism works, etc. Interpretations could be added after Lemmas and computation equations (e.g., (10)) to improve clarity.\n2. The scales of the experiments are not large enough to be convincing. If larger experiments are not possible, challenges and limitations should be clearly stated. **Major**\n\n1. Are there any references to support the assumptions made in the preliminaries section? For example, why is the matching utility payoff reasonable in data market design? How do you interpret that in the binary-state setting in the real world? How about a more complex non-binary setting?\n2. For the single buyer setting Lemma 3.1, it is claimed that the mechanism is Incentive Compatible as it is agent optimizing. Why is it agent optimizing when the objective is to maximize the payment by the agents?\n3. How to access the validity of the results from the networks when there is no analytical solution (more complex settings)? For example, for the price of 0.14 outputted for setting C, how do you know whether it is close to optimal? Also, could you provide a more intuitive interpretation of the price and results?\n4. What are the challenges in conducting experiments on binary states, actions? Also, can you perform experiments on more than two buyers? Can the method be extended to much more complex scenarios with a large number of players, actions and states?\n\n**Minor**\n\n5. Grammar. Lines 80, 103, 242. Punctuations and formats: Lines 146, 153-160, 239.\n6. Some notations can be confusing, especially the subscripts, superscripts and brackets.\n7. What is $\\Delta$ in Line 129, never explained before. The authors have sufficiently discussed the limitations of the approach in the limitation section. Additionally, I wonder how well this framework applies in real-world scenarios. Could the author clarify the limitations of adopting the method in real life for data pricing, or provide a practical example/application?",
         "477",
         "0",
         "14",
         "0.7548",
         "0.11801520850000001",
         "0.9419704676",
         "215",
         "161",
         "41.0441",
         "10.7372",
         "13.2071",
         "12.4264",
         "10.5408",
         "0.3841",
         "98",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1874",
         "sgCrNMOuXp",
         "15244",
         "1683832873421",
         "['~Sai_Srivatsa_Ravindranath2', '~Yanchen_Jiang1', '~David_C._Parkes1']",
         "Data Market Design through Deep Learning",
         "The  _data market design_ problem is a problem in economic theory to find a set of signaling schemes (statistical experiments) to maximize expected revenue to the information seller, where each experiment reveals some of the information known to a seller and has a corresponding price. Each buyer has their own decision to make in a world environment, and their subjective expected value for the information associated with a particular experiment comes from the improvement in this decision and depends on their prior and value for different outcomes. In a setting with multiple buyers, a buyer's expected value for an experiment may also depend on the information sold to others. We introduce the application of deep learning for the design of revenue-optimal data markets, looking to expand the frontiers of what can be understood and achieved. Relative to earlier work on deep learning for auction design, we must learn signaling schemes rather than allocation rules and handle  _obedience constraints_  &mdash; these arising from modeling the downstream actions of buyers &mdash; in addition to incentive constraints on bids.  Our experiments demonstrate that this new deep learning framework can almost precisely replicate all known solutions from theory, expand to more complex settings, and be used to establish the optimality of new designs for data markets and make conjectures in regard to the structure of optimal designs.",
         "Reviewer_wNRV",
         "1688564404306",
         "1702411511841",
         "6",
         "4",
         "4",
         "2",
         "3",
         "The authors are concerned with a problem of \"data market design\". In such a setting, a mechanism designer with access to an unknown world state interacts with buyers who have private types, and need to take actions whose payoffs vary depending on the world state. These buyers purchase (in the single buyer case) or bid on (in the multi-buyer case) access to a signaling scheme which, given reports from the agents and the world state, sends a signal to the buyers (which without loss of generality can just be a recommended action). This mechanism, treated as a direct-revelation mechanism, needs to be both truthful (incentivizing honest reporting by the buyers) and obedient (once the buyers receive their signal, they should be incentivized not to deviate from the recommendation). Subject to those constraints (either Bayesian or ex post), the mechanism designer wants to maximize their revenue.\n\nThis problem shares some similarities to truthful revenue-maximizing auction design. In that domain, there has been recent progress using the tools of \"differentiable economics\" to approximately learn high-performing (and sometimes even provably optimal) auctions, in both single- and multi-bidder settings.\n\nThe authors apply very similar techniques to this data market problem. In single-buyer settings (as in auctions) they are able to ensure exact IC; for multi-buyer settings they use a Lagrangian during training to approximately enforce IC constraints. They experiment on a relatively wide variety of problem instances, reproducing known results, finding new optimal mechanisms, and conjecturing optimal mechanisms where they cannot find them. The paper comprehensively shows how to successfully apply differentiable economics to a new domain where it has not previously been applied. The authors are able to reproduce optimal mechanisms and find new ones, showing that their adaptation of these technique is in fact useful in producing novel results. This helps to further push these techniques towards being practically helpful tools for theorists and modelers. The network architectures here are essentially the same as those used in previous work for auctions, only adapted slightly for the data market setting. This is fine, but it does mean that from the perspective of differentiable economics, there is no novel methodological contribution.\n\nThe experiments appear to consider at most 2 buyers. While (as in the case of multi-parameter auctions) even selling to just two buyers may be a very challenging case, it would be more interesting to consider a slightly larger number of buyers. Can the method in fact scale to larger (even just 3-5 buyers) settings, or not? This should be discussed. See questions.",
         "420",
         "0",
         "1",
         "0.8172",
         "0.1425933442",
         "0.9128888845",
         "215",
         "160",
         "37.1539",
         "13.5687",
         "15.5088",
         "14.1724",
         "15.4379",
         "0.0499",
         "101",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "1875",
         "sgCrNMOuXp",
         "15244",
         "1683832873421",
         "['~Sai_Srivatsa_Ravindranath2', '~Yanchen_Jiang1', '~David_C._Parkes1']",
         "Data Market Design through Deep Learning",
         "The  _data market design_ problem is a problem in economic theory to find a set of signaling schemes (statistical experiments) to maximize expected revenue to the information seller, where each experiment reveals some of the information known to a seller and has a corresponding price. Each buyer has their own decision to make in a world environment, and their subjective expected value for the information associated with a particular experiment comes from the improvement in this decision and depends on their prior and value for different outcomes. In a setting with multiple buyers, a buyer's expected value for an experiment may also depend on the information sold to others. We introduce the application of deep learning for the design of revenue-optimal data markets, looking to expand the frontiers of what can be understood and achieved. Relative to earlier work on deep learning for auction design, we must learn signaling schemes rather than allocation rules and handle  _obedience constraints_  &mdash; these arising from modeling the downstream actions of buyers &mdash; in addition to incentive constraints on bids.  Our experiments demonstrate that this new deep learning framework can almost precisely replicate all known solutions from theory, expand to more complex settings, and be used to establish the optimality of new designs for data markets and make conjectures in regard to the structure of optimal designs.",
         "Reviewer_QSAL",
         "1688605969331",
         "1702411511719",
         "5",
         "3",
         "3",
         "3",
         "3",
         "This paper introduces a deep learning framework for the automated design of data markets, a novel and timely application in the field of economics. The authors address the data market design problem, which involves designing a set of signaling schemes to maximize expected revenue. The paper extends previous work on deep learning for auction design by learning signaling schemes and handling obedience constraints that arise from the actions of agents. - Innovative Application: The paper introduces a novel application of deep learning to the data market design problem, expanding the scope of machine learning in the field of economics.\n\n- The paper is well-written overall. -Incremental work: It seems that the core contribution, the proposed neural network architecture, is a simple extension of existing model called RochetNet, by slightly modifying the loss function.\n\n-Lack of comparison with baselines: mechanism design for information acquisition is a long standing problem. I was surprised to see no baseline comparison in the experiments, and no discussion on how/why existing approaches may not work in the methodology.  What are some baseline methods to compare with? For example, how does the standard rochetnet perform on the proposed market settings? Yes.",
         "194",
         "0",
         "1",
         "0.799",
         "0.0097222222",
         "0.957269609",
         "215",
         "159",
         "33.5689",
         "13.347",
         "15.805",
         "14.4109",
         "14.2935",
         "0.12490000000000001",
         "106",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1876",
         "sgCrNMOuXp",
         "15244",
         "1683832873421",
         "['~Sai_Srivatsa_Ravindranath2', '~Yanchen_Jiang1', '~David_C._Parkes1']",
         "Data Market Design through Deep Learning",
         "The  _data market design_ problem is a problem in economic theory to find a set of signaling schemes (statistical experiments) to maximize expected revenue to the information seller, where each experiment reveals some of the information known to a seller and has a corresponding price. Each buyer has their own decision to make in a world environment, and their subjective expected value for the information associated with a particular experiment comes from the improvement in this decision and depends on their prior and value for different outcomes. In a setting with multiple buyers, a buyer's expected value for an experiment may also depend on the information sold to others. We introduce the application of deep learning for the design of revenue-optimal data markets, looking to expand the frontiers of what can be understood and achieved. Relative to earlier work on deep learning for auction design, we must learn signaling schemes rather than allocation rules and handle  _obedience constraints_  &mdash; these arising from modeling the downstream actions of buyers &mdash; in addition to incentive constraints on bids.  Our experiments demonstrate that this new deep learning framework can almost precisely replicate all known solutions from theory, expand to more complex settings, and be used to establish the optimality of new designs for data markets and make conjectures in regard to the structure of optimal designs.",
         "Reviewer_zvsA",
         "1688731262697",
         "1702411511596",
         "6",
         "2",
         "4",
         "3",
         "3",
         "The authors present a novel approach to the problem of data market design, which seeks to find a set of signaling schemes, each revealing some of the information known to a seller and having a corresponding price, where the goal is to maximize expected revenue. Then, the authors introduce the application of a deep learning framework to the automated design of the data market. The paper discusses the importance of data market design and its potential applications in real-world settings, such as data marketplaces where sellers sell data to buyers for ML tasks. The authors demonstrate that their new learning framework can replicate known solutions from theory, expand to more complex settings, and establish the optimality of new designs. The paper also highlights some limitations of the approach, such as the need for interpretability of the mechanisms learned by the RegretNet approach for larger problems, the potential for local optima in non-convex problems, and the challenge of achieving exact incentive alignment in multi-buyer settings. + The paper presents a novel approach to the problem of data market design, which uses deep learning to automate the design of data markets.\n\n+ The authors demonstrate that their new learning framework can almost precisely replicate all known solutions from theory, which shows that the approach is effective and reliable.\n\n+ The paper shows that the new learning framework can be used to establish the optimality of new designs and conjecture the structure of optimal designs, which is a significant contribution to the field.\n\n + The paper acknowledges that for the approach to provide insights into the theoretically optimal design for larger problems, it will be important to provide interpretability to the mechanisms learned by the approach. However, the RegretNet approach used in the paper is not immediately interpretable, which limits its usefulness in this regard.\n\n+ The paper notes that the approach uses gradient-based approaches, which may suffer from local optima in non-convex problems. This suggests that the approach may not always find the global optimum and may be limited in its ability to handle more complex problems.\n\n+ The paper attains in the multi-buyer setting approximate and not exact incentive alignment, which leaves the question as to how much alignment is enough for agents to follow the intended advice of a market design. This suggests that the approach may not be able to achieve exact incentive alignment in all settings, which could limit its effectiveness.\n + Could you provide more details on how the RegretNet approach can be made more interpretable for larger problems? Are there any specific techniques or methods that could be used to achieve this?\n\n+ Have you considered using other optimization techniques besides gradient-based approaches to address the potential for local optima in non-convex problems? If so, what are some alternative approaches that could be used?\n\n+ What are some potential ways to provide more practical or theoretical guidance on how much alignment is enough for agents to follow the intended advice of a market design? Are there any existing frameworks or approaches that could be used to address this issue?\n The authors acknowledge the ethical concerns raised by markets for trading data about individuals and suggest that machine learning frameworks such as those introduced in this paper can be used to strike new kinds of trade-offs, such as allowing individuals to benefit directly from trades on data about themselves. This shows that the authors are aware of the broader implications of their work and are thinking critically about its potential impact.",
         "584",
         "0",
         "0",
         "0.7766000000000001",
         "0.1128884508",
         "0.9413257241",
         "215",
         "158",
         "35.3831",
         "14.8171",
         "17.4111",
         "15.4299",
         "16.5915",
         "0.16160000000000002",
         "109",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2073",
         "rnKgbKmelt",
         "10485",
         "1683784252480",
         "['~Haotian_Sun1', '~Yuchen_Zhuang1', '~Lingkai_Kong1', '~Bo_Dai1', '~Chao_Zhang15']",
         "AdaPlanner: Adaptive Planning from Feedback with Language Models",
         "Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the agent to plan and refine with fewer task demonstrations. Our experiments in the ALFWorld and MiniWoB++ environments demonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and 4.11% while utilizing 2x and 600x fewer samples, respectively. The implementation of AdaPlanner is available at https://github.com/haotiansun14/AdaPlanner.",
         "Reviewer_aJpk",
         "1687709342467",
         "1702411287590",
         "7",
         "3",
         "3",
         "2",
         "3",
         "LLMs have shown success as autonomous agents that make and execute plans in sequential decision problems. Existing methods either make open-loop plans, limiting adaptability to the environment, or closed-loop plans. Existing closed-loop methods, apart from DEPS, keep the plan static but simply modify immediate actions according to environment feedback, leading to potentially sub-optimal policies. The authors introduce AdaPlanner, a closed-loop LLM planner that additionally allows for *plan* refinement during the episode. The success of their method not only relies on this, but additionally code-style prompts and a skill-discovery mechanism for few-shot exemplars. AdaPlanner outperforms existing works while relying on far fewer demonstration examples from similar tasks.  - Empirically the authors show strong results with respect to sample efficiency and asymptotic performance.\n\n- Many ablations make it easy to understand which components of the model lead to overall success. \n\n- Conceptually simple approach.\n - In the evaluation section, the baselines are glossed over. This makes it hard to comprehend the distinction between their approach and the baselines. \n   - I’d recommend adding some of the Appendix descriptions to the evaluation section, and potentially referencing Table 1 more often.\n\n- The authors use the term ‘hallucination’ a lot but do not define it.\n\n- The authors discuss in- and out-of- plan refiners a lot before providing intuitive examples for when either would be necessary. Could the authors provide more examples earlier on in the paper?\n\n- DEPS appears to be a relevant baseline. Could the authors include it or at least delve deeper into its limitations and why it is not appropriate?\n\n- It appears that the largest contributor to the success of AdaPlanner, over existing approaches, is code style prompts and skill prompts. Wouldn’t it be worthwhile to apply those modifications to existing approaches, like Reflextion (Fig 4), and contrast?\n\n- AdaPlanner prompts the LLM to correct any syntax errors. How important is this? Would be nice to include this ablation.\n - Line 80, could you define the output of pi, in the same way that you did for the planner?\n- Line 81, shouldn’t it be P_t rather than P_{t - 1}?\n- Lines 114 - 144 I think you’ve repeated the sentence twice.\n- Line 216, what are the 6 task types?\n- Line 132, how is N chosen and what’s its effect on performance?\n AdaPlanner still requires demonstrations for learning. Would be worthwhile comparing with RL agents trained directly on the task, without any expert demonstrations.",
         "407",
         "0",
         "1",
         "0.8075",
         "0.19765625",
         "0.8522759080000001",
         "215",
         "170",
         "45.2435",
         "10.2897",
         "13.687",
         "12.7937",
         "10.3717",
         "0.464",
         "84",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2074",
         "rnKgbKmelt",
         "10485",
         "1683784252480",
         "['~Haotian_Sun1', '~Yuchen_Zhuang1', '~Lingkai_Kong1', '~Bo_Dai1', '~Chao_Zhang15']",
         "AdaPlanner: Adaptive Planning from Feedback with Language Models",
         "Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the agent to plan and refine with fewer task demonstrations. Our experiments in the ALFWorld and MiniWoB++ environments demonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and 4.11% while utilizing 2x and 600x fewer samples, respectively. The implementation of AdaPlanner is available at https://github.com/haotiansun14/AdaPlanner.",
         "Reviewer_oy34",
         "1688001381621",
         "1702411287513",
         "6",
         "4",
         "2",
         "2",
         "2",
         "Briefly summarize the paper and its contributions. This is not the place to critique the paper; the authors should generally agree with a well-written summary.\n\nThe paper proposes AdaPlanner, an LLM-based adaptive planner for text-based sequential decision-making tasks. The planner is adaptive in the sense that it can refine the generated plan/policy based on feedback. \n\nThe contributions made in this paper include the following\n1. interacting with the environment with LLM in the loop\n2. a code-style prompt is engineered for LLMs to output a policy \n3. refining the LLM policy for the current task based on feedback\n4. prompt tuning for new tasks based on previous interaction (termed skill discovery)\n\nThe proposed AdaPlanner is evaluated on two text-based sequential decision-making environments ALFWorld and MiniWoB++. Their experiments indicate that with feedback, LLMs can adapt the plan.\n \n* The paper is well written.\n* The paper focuses on extremely relevant and signifcant problems. \n * I find the paper lacks significant details. Please see the next section for the list of questions.\n* The paper employs sloppy mathematical notations.\n* The paper lacks the rigor of scientific evaluation. \n* Paper misses all references to LLM-based approaches for planning with PDDL. The one that I find most relevant for code generation is \"Generalized Planning in PDDL Domains with Pretrained Large Language Models, Tom Silver, Soham Dan, Kavitha Srinivas, Joshua B. Tenenbaum, Leslie Pack Kaelbling, Michael Katz”\n \n**Major**\n\n1. How is the programmatic response from LLM converted to action responses? Did the conversion require manual intervention? For instance, Figure 2 has an indentation error which would result in a wrong plan. Were such indentation errors evaluated manually? Can authors provide a list of errors made by LLMs? \n1. In line 167, what does an alignment between ‘anticipated plan’ and environment mean? How does the AdaPlanner observe the alignment? \n1. Can authors provide details about the size of the task used in the prompt (for samples) vs the size of the task that was successfully solved by AdaPlanner? To establish the claim of sample efficiency, it is important to understand if the planner is able to efficiently plan for tasks that are significantly different from the prompts.\n1. The X-axis in Figure 3 indicates `# Samples per task`. Is this the number of samples provided for each trajectory? Or sum?  \n1. What was the length of plans or length of trajectories generated by AdaPlanner vs other approaches? To claim the effectiveness of the AdaPlanner, it is important to compare the length of successful trajectories.\n1. For skill discovery, how is the solution converted to the skill? How are skills represented? How large is the skill memory?  Were the discovered skills included in the count of samples used for training as they are training samples for the next set of trajectories?\n1. It is not clear how skills are filtered and what criteria are used for the evaluation and ranking of skills.\n1. What is the connection between skill discovery and prompt tuning?\n1. The success rate of \"With SD\" in Figure 4d looks significantly reduced from  Figure 4a. Were different settings used for theses experiments?\n1. At various places, the paper mentions \"environment feedback\". In my opinion, this is a misnomer. The feedback is not from the environment. The environment just provides the next observation, the feedback is generated by the agent itself. And the use of observation to refine a plan or next action is quite standard practice in RL. I would highly recommend dropping the term feedback from the title. \n1. The use of term plan and policy is a little confusing. A plan is a sequence of actions. A policy is a mapping from states to actions. By this definition, the `solution()` function is as a policy. In preliminaries, the planning policy ($\\rho$) is conditioned on a previous plan $P_t$. However, the appendix describes the refinement prompt using the assertion error (instead of `solution()`). Isn't the assertion error providing information about the policy (the `solution()` function)? So I am confused by the terminologies. Is the $\\rho$ refined conditioned on the policy or the plan? The usage of these terms is also confusing in the Preliminary section. Request authors to precisely define the mathematical notations and highlight what they represent in the examples.\n\n**Minor**\n\n12. In line 387, there are extra curly braces.\n12. The notation $\\rho$ is used in line 73 but introduced much later.\n12. As the context $c_t$ is defined as a sequence of action and observations from time step $0$ to $t$, it is not clear what $c_{>t}$ means (in line 116).  \n12. Open-Loop system in Figure 1 should have an arrow going from env to planner with $o_1$.\n12. Statement in Line 144 \"To generate a plan ..\" looks like a repetition of Line 141 \"To generate an initial plan...\"\n12. In line 116, if $h_t$ is obtained from $c_t$ then would it not be captured in $c_{>t}$? An example of $h_t$ would help better understand the proposed update.\n12. In line 73, as $\\rho$ is defined using $\\Delta(A^{T})$. But the length $T$ is not fixed. \n12. In line 73 $\\rho$ is defined where a plan is conditioned only on observation and goal. However, later it is conditioned on the context, plan, and goal. \n\n\n\n \n* The evaluations are restricted to text-based sequential decision-making problems and task where the inadmissible actions do not cause drastic changes in the environment. On the contrary, inadmissible actions are like no-ops. Further, the paper does not present analysis of plan length. Hence, the analysis is limited to zero risk environments. \n* The claim made in the abstract about skill discovery mechanism enabling agent to plan with fewer task demonstration is not substantiated in the evaluations. Evaluation in Fig. 4d only established improvement in success rate, not sample efficiency. ",
         "965",
         "0",
         "17",
         "0.7161000000000001",
         "0.0723501082",
         "0.8610098362",
         "215",
         "166",
         "54.1142",
         "8.8332",
         "11.9792",
         "11.7979",
         "8.974",
         "0.11040000000000001",
         "89",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2075",
         "rnKgbKmelt",
         "10485",
         "1683784252480",
         "['~Haotian_Sun1', '~Yuchen_Zhuang1', '~Lingkai_Kong1', '~Bo_Dai1', '~Chao_Zhang15']",
         "AdaPlanner: Adaptive Planning from Feedback with Language Models",
         "Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the agent to plan and refine with fewer task demonstrations. Our experiments in the ALFWorld and MiniWoB++ environments demonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and 4.11% while utilizing 2x and 600x fewer samples, respectively. The implementation of AdaPlanner is available at https://github.com/haotiansun14/AdaPlanner.",
         "Reviewer_GDYQ",
         "1688455158023",
         "1702411287432",
         "5",
         "4",
         "3",
         "3",
         "2",
         "The paper presents AdaPlanner, a closed-loop planning method that uses a large language model (LLM) to solve tasks in text-based environments. AdaPlanner operates by decomposing a complex task into manageable sub-goals and predicting environmental feedback for each. During execution, it refines its actions based on the feedback received from the environment. AdaPlanner operates solely via prompting, eliminating the need for a dedicated training phase and reducing its computational cost. The paper demonstrates that AdaPlanner consistently outperforms existing baselines, achieving state-of-the-art performance in ALFWorld tasks and MiniWoB++ tasks. - AdaPlanner introduces a novel approach to task-solving in text-based environments using a large language model. It stands out for its closed-loop planning method and its ability to decompose tasks into manageable sub-goals.\n- The paper is well-written and clear. The authors have done a good job of explaining complex concepts and methodologies in an understandable manner.\n- The work presents a new way of leveraging large language models for task-solving in text-based environments. The results show that AdaPlanner can effectively leverage feedback to refine its plans and enhance its performance. - The part about skill discovery is not described very clearly, and I still cannot understand the details of the skill discovery module well.\n- The author compared the version without a code interface in the experiment, but it seems that they did not specifically show the prompt after removing the code interface. At the same time, as an ablation experiment, it is also necessary to analyze the effects of specific components in the code interface.\n- The phenomenon that GPT-3 performs better than GPT-3.5 is interesting, but it seems that the paper only compares GPT-3 and GPT-3.5 in Alfworld, without conducting the same experiments in MiniWoB++ to further support the conclusion. And the author's hypotheses about this phenomenon (the smaller scale of GPT3.5) lacks specific analysis or literature references to support it. - In the experiment, what is the proportion of in-plan and out-of-plan occurrences? How will this proportion change over time? This should be a necessary indicator for understanding the two refiners.\n- On MiniWoB++, will there be better performance from GPT-3 than GPT-3.5?\n- Is there still a necessity for AdaPlanner in larger-scale LLMs, such as models like GPT4 with better self-refining capabilities? - As mentioned above, this paper still needs more experiments and analysis to further validate the rationality of its methods, as well as the observed phenomena and corresponding hypotheses.",
         "403",
         "0",
         "0",
         "0.8062",
         "0.15925788500000002",
         "0.9227041602",
         "215",
         "161",
         "34.8105",
         "12.3092",
         "15.5501",
         "14.1474",
         "13.0538",
         "0.0468",
         "81",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2076",
         "rnKgbKmelt",
         "10485",
         "1683784252480",
         "['~Haotian_Sun1', '~Yuchen_Zhuang1', '~Lingkai_Kong1', '~Bo_Dai1', '~Chao_Zhang15']",
         "AdaPlanner: Adaptive Planning from Feedback with Language Models",
         "Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the agent to plan and refine with fewer task demonstrations. Our experiments in the ALFWorld and MiniWoB++ environments demonstrate that AdaPlanner outperforms state-of-the-art baselines by 3.73% and 4.11% while utilizing 2x and 600x fewer samples, respectively. The implementation of AdaPlanner is available at https://github.com/haotiansun14/AdaPlanner.",
         "Reviewer_4ZaS",
         "1688713014244",
         "1702411287349",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper looks at explicit closed-loop systems with LLMs for adaptive planning utilizing environmental feedback. They showcase better planning performance on ALFWorld and MiniWOB++ environments over existing state-of-the-art works like ReAct and Reflexion. The paper is well written and the experiments are thorough. They present an interesting improvement over the current works like ReAct and Reflexion.\n 1. The kind of tasks in these domains don’t seem to have interaction resolution where there are multiple conflicting causal links from the initial to the goal state which have to be resolved (including negative interactions between subgoals). This could also lead to the human demonstrations helping significantly with the  It would be useful to analyze the performance of AdaPlanner specifically in such cases. \n\n2. I think non-ergodic environments could clearly pose danger to such agents. It would be interesting to see how AdaPlanner can perform against ReAct or Reflexion in such environments. \n 1. Given that the LLM seems to verify the plan to determine its feasibility, what was its efficiency in those assessments? Are there any results pertaining to that?\n\n2. Is there any classification of the tasks with respect to their hardness?\n\n3. For how many of these tasks did the human expert demonstration solve the task? \n The authors have addressed some of the limitations. I have provided some limitations in the weaknesses section.",
         "222",
         "0",
         "5",
         "0.789",
         "0.1708333333",
         "0.7852613926",
         "215",
         "158",
         "44.4049",
         "11.0051",
         "14.2708",
         "13.4843",
         "12.3187",
         "0.12490000000000001",
         "89",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2173",
         "r9fzp8eyhZ",
         "3508",
         "1683554984085",
         "['~Xiang_Zhuang1', '~Qiang_Zhang6', '~Keyan_Ding1', '~Yatao_Bian1', '~Xiao_Wang2', '~Jingsong_Lv1', '~Hongyang_Chen2', '~Huajun_Chen1']",
         "Learning Invariant Molecular Representation in Latent Discrete Space",
         "Molecular representation learning lays the foundation for drug discovery. However, existing methods suffer from poor out-of-distribution (OOD) generalization, particularly when data for training and testing originate from different environments. To address this issue, we propose a new framework for learning molecular representations that exhibit invariance and robustness against distribution shifts. Specifically, we propose a strategy called  ``first-encoding-then-separation'' to identify invariant molecule features in the latent space, which deviates from conventional practices. Prior to the separation step, we introduce a residual vector quantization module that mitigates the over-fitting to training data distributions while preserving the expressivity of encoders. Furthermore, we design a task-agnostic self-supervised learning objective to encourage precise invariance identification, which enables our method widely applicable to a variety of tasks, such as regression and multi-label classification. Extensive experiments on 18 real-world molecular datasets demonstrate that our model achieves stronger generalization against state-of-the-art baselines in the presence of various distribution shifts.  Our code is available at https://github.com/HICAI-ZJU/iMoLD.",
         "Reviewer_gGdj",
         "1687548753758",
         "1702410902965",
         "6",
         "3",
         "4",
         "2",
         "4",
         "This paper presents a new graph neural network architecture and objective function that encourages models to identify features that are invariant to distribution shifts in the data. The proposed method, iMoLD performs invariant feature extraction in the latent embedding space and leads to improved performance across an extensive set of molecular property prediction tasks. - The presented idea is novel and leads to improved performance across a variety of datasets and tasks.\n- Experimentation is extensive with good results.\n- The ablation analysis is Section 5.3 and sensitivity analysis from Appendix C are useful. #### **Incorrect definitions in Section 3.1**\n- I believe there is some issue in the notation of Section 3.1. Specifically, the definitions of $P_{train}, P_{test}, P_{all}$ as collections of distributions, means that they are not themselves valid probability distributions. I believe some re-normalization would be required here.\n\n---\n\n#### **Use of term “Discrete Latent space” is unclear**\n- Why do the authors claim they have a **“discrete”** latent space? The residual connection between $\\mathbf{H}$ and the quantized representation means that embeddings are continuous. Additionally the element-wise gating to create $\\mathbf{H}^{\\mathrm{Inv}}$ and $\\mathbf{H}^{\\mathrm{Spu}}$ means the model does not have a discrete latent representation.\n\n---\n\n#### **Unclear elements about the learning objective**\n- The notation in Equation (11) is confusing. Specifically, what is the dimensionality of the $\\tilde{\\mathbf{z}}_i^{\\mathrm{Inv}}$? Are you concatenating multiple batch samples from $\\mathbf{z}^{\\mathrm{Spu}}$ to $\\mathbf{z}_i^{\\mathrm{Inv}}$ or just one random one? \n- There seems to be an inherent tension between the residual connection and the commitment loss $\\mathcal{L}_{\\mathrm{cmt}}$. That is, if this loss were perfectly minimized, then the residual connection would be negated.\n- The role of $\\gamma$ in the scoring regularization is not well described. \n\n---\n\n#### **Baseline presentation is confusing**\n- It seems that the authors are conflating baselines in terms of loss objectives and in terms of model/architecture designs. It would be good to clarify which baselines rely on the same architecture but have different objectives (e.g. ERM) and which constitute an entirely different modeling scheme (e.g., CIGA). For the baselines that simply differ in objective, it would be good to also make explicit (could go in Appendix) if any model / architecture adjustments were also applied.\n\n---\n\n#### **Other minor comments**\n- In line 147, the notation for edges $\\mathcal{E}$ is overloaded, since the same variable is used to denote environments in Section 3.1.\n- At the end of Section 5.4 (lines 341-345), the authors seem to be mixing the meaning of low/high in terms of whether low = “good” or low = ”bad”.\n- $D$ and $Score$ should be defined explicitly in Figure 4 caption.\n Q1) It is not clear to me why vector quantization (VQ) is the right “bottleneck” to use here. Other than restricting the model’s expressivity, which can be done in other ways such as weight regularization, why is VQ particularly suited for this setup?\n\nQ2) Why is the stop gradient applied in equation 12? Is this simply for computation efficiency / stability? If so, this should be made explicit in the text.\n\nQ3) For the GOOD-PCBA experiment, why is average precision (vs. average accuracy, recall, or ROC-AUC) used?\n\nQ4) I know that there is an extensive sensitivity analysis in the appendix, but what are the hyperparameter configurations for the reported results in the main text (Tables 1 and 2)? Are the “best” iMoLD models sensitive to hyperparameter choice or do you see a general trend as to which configurations perform best? \n - The current methodology does seem quite intricate with many loss terms that are justified in a somewhat ad hoc manner.\n- There is no real discussion of limitations / potential pitfalls relative to previous work.\n",
         "610",
         "0",
         "0",
         "0.7554000000000001",
         "0.1054946789",
         "0.8403213024",
         "218",
         "172",
         "40.4049",
         "11.4285",
         "14.7861",
         "13.6954",
         "12.0943",
         "0.30110000000000003",
         "97",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2174",
         "r9fzp8eyhZ",
         "3508",
         "1683554984085",
         "['~Xiang_Zhuang1', '~Qiang_Zhang6', '~Keyan_Ding1', '~Yatao_Bian1', '~Xiao_Wang2', '~Jingsong_Lv1', '~Hongyang_Chen2', '~Huajun_Chen1']",
         "Learning Invariant Molecular Representation in Latent Discrete Space",
         "Molecular representation learning lays the foundation for drug discovery. However, existing methods suffer from poor out-of-distribution (OOD) generalization, particularly when data for training and testing originate from different environments. To address this issue, we propose a new framework for learning molecular representations that exhibit invariance and robustness against distribution shifts. Specifically, we propose a strategy called  ``first-encoding-then-separation'' to identify invariant molecule features in the latent space, which deviates from conventional practices. Prior to the separation step, we introduce a residual vector quantization module that mitigates the over-fitting to training data distributions while preserving the expressivity of encoders. Furthermore, we design a task-agnostic self-supervised learning objective to encourage precise invariance identification, which enables our method widely applicable to a variety of tasks, such as regression and multi-label classification. Extensive experiments on 18 real-world molecular datasets demonstrate that our model achieves stronger generalization against state-of-the-art baselines in the presence of various distribution shifts.  Our code is available at https://github.com/HICAI-ZJU/iMoLD.",
         "Reviewer_zQUd",
         "1687940014541",
         "1702410902887",
         "7",
         "3",
         "3",
         "3",
         "3",
         "While significant advances have been made in molecular representation approaches, conventional approaches typically assume that data sources are independent and sampled from the same distribution. However, molecules in real-world drug development often show different characteristics, which might be from a different distribution. This issue is called the out-of-distribution (OOD) problem. OOD challenges the generalization capability of molecular characterization methods and can degrade the performance of downstream tasks. Unlike previous studies' \"first-separation-then-encoding\" approach, this study proposes a \"first-encoding-then-separation\" molecular graph representation paradigm. Specifically, the authors first employ a GNN to encode the molecules and then employ a residual vector quantization module to alleviate the overfitting of the training data distribution while preserving the expressiveness of the encoder. Then, they score molecular representations using another GNN that measures the contribution of each dimension to the target in the latent space, thus clearly distinguishing between invariant and spurious representations. Finally, the authors propose a self-supervised learning objective that encourages the recognition of invariant features and effectively preserves label-relevant information while discarding environment-relevant information. The authors conducted experiments on real-world datasets. The experimental results show that the proposed method outperforms the SOTA methods. - Unlike the traditional \"first-separation-then-encoding\" approach, the authors propose a \"first-encoding-then-separation\" paradigm that uses an encoding GNN and a scoring GNN to identify invariant features from a graph. The authors use the residual vector quantization module to make a balance between the model's expressivity and generalization. The quantization is used as a bottleneck to strengthen the generalization, and the residual connection complements the model's expressivity. Moreover, the authors design a self-supervised invariant learning objective to facilitate the precise capture of invariant features. This objective is generic, task-independent, and applicable to a variety of tasks.\n\n- The model is cleared described.\n\n- The authors conducted comprehensive experiments on 18 real-world datasets. The experimental results show that the proposed model achieved stronger generalization against SOTA baselines.\n\n- Code has been released and will be valuable for future related research. - There are some typos in the paper. For example, a lack of space before references in line 31.\n\n- OOD is repeatedly defined in lines 29 and 90. In addition, please use \"OOD\" for \"out-of-distribution\" that appears later in the text, such as lines 130 and 353. Could the authors show 3D visualization graphs representing the extracted features, as in Fig. 4? None.",
         "390",
         "0",
         "1",
         "0.7569",
         "0.060367063500000005",
         "0.9123204947",
         "218",
         "167",
         "13.2434",
         "15.387",
         "17.65",
         "15.5797",
         "16.6657",
         "0.1091",
         "85",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "2175",
         "r9fzp8eyhZ",
         "3508",
         "1683554984085",
         "['~Xiang_Zhuang1', '~Qiang_Zhang6', '~Keyan_Ding1', '~Yatao_Bian1', '~Xiao_Wang2', '~Jingsong_Lv1', '~Hongyang_Chen2', '~Huajun_Chen1']",
         "Learning Invariant Molecular Representation in Latent Discrete Space",
         "Molecular representation learning lays the foundation for drug discovery. However, existing methods suffer from poor out-of-distribution (OOD) generalization, particularly when data for training and testing originate from different environments. To address this issue, we propose a new framework for learning molecular representations that exhibit invariance and robustness against distribution shifts. Specifically, we propose a strategy called  ``first-encoding-then-separation'' to identify invariant molecule features in the latent space, which deviates from conventional practices. Prior to the separation step, we introduce a residual vector quantization module that mitigates the over-fitting to training data distributions while preserving the expressivity of encoders. Furthermore, we design a task-agnostic self-supervised learning objective to encourage precise invariance identification, which enables our method widely applicable to a variety of tasks, such as regression and multi-label classification. Extensive experiments on 18 real-world molecular datasets demonstrate that our model achieves stronger generalization against state-of-the-art baselines in the presence of various distribution shifts.  Our code is available at https://github.com/HICAI-ZJU/iMoLD.",
         "Reviewer_GuEJ",
         "1688046711660",
         "1702410902809",
         "5",
         "2",
         "3",
         "3",
         "2",
         "This paper proposes a molecular self-supervised learning method for out-of-distribution generalization. The authors introduces a \"first-encoding-then-separation\" framework to learn invariant features. For doing so, the authors design discrete latent space with VQ-VAE. The experimental results show that their method improves previous baselines in various out-of-distribution downstream tasks. - The paper is well written and easy to understand.\n\n- The pre-training objective to separate invariant and spurious features seems to make sense to me. - The complexity of the proposed method is high. The loss function contains several tunable parameters and the ablation study (in Figure 5) shows that the performance is quite dependent on the choice of hyperparameters. \n\n- It seems vague why discrete latent space is needed.  - How are the hyperparameters chosen in Table 1, 2?\n\n- Is there specific intuition why discrete latent space is useful for out-of-distribution molecular representation learning? Yes, the authors addressed the limitations.",
         "150",
         "0",
         "0",
         "0.8085",
         "0.0326666667",
         "0.9109832048000001",
         "218",
         "166",
         "29.5675",
         "12.1164",
         "13.1333",
         "12.458",
         "12.5474",
         "0.0751",
         "87",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2176",
         "r9fzp8eyhZ",
         "3508",
         "1683554984085",
         "['~Xiang_Zhuang1', '~Qiang_Zhang6', '~Keyan_Ding1', '~Yatao_Bian1', '~Xiao_Wang2', '~Jingsong_Lv1', '~Hongyang_Chen2', '~Huajun_Chen1']",
         "Learning Invariant Molecular Representation in Latent Discrete Space",
         "Molecular representation learning lays the foundation for drug discovery. However, existing methods suffer from poor out-of-distribution (OOD) generalization, particularly when data for training and testing originate from different environments. To address this issue, we propose a new framework for learning molecular representations that exhibit invariance and robustness against distribution shifts. Specifically, we propose a strategy called  ``first-encoding-then-separation'' to identify invariant molecule features in the latent space, which deviates from conventional practices. Prior to the separation step, we introduce a residual vector quantization module that mitigates the over-fitting to training data distributions while preserving the expressivity of encoders. Furthermore, we design a task-agnostic self-supervised learning objective to encourage precise invariance identification, which enables our method widely applicable to a variety of tasks, such as regression and multi-label classification. Extensive experiments on 18 real-world molecular datasets demonstrate that our model achieves stronger generalization against state-of-the-art baselines in the presence of various distribution shifts.  Our code is available at https://github.com/HICAI-ZJU/iMoLD.",
         "Reviewer_czws",
         "1688570718068",
         "1702410902736",
         "6",
         "3",
         "2",
         "2",
         "2",
         "The paper presents an invariant and robust representation learning approach for molecules to improve the out-of-distribution generalization performance of the predictive models. Specifically, they first map the molecule to the latent representation and then do a separation step where they separate the latent word into invariant and spurious representations.\nThey also propose using residual vector quantization on the latent representation to avoid over-fitting while preserving the expressiveness power of the encoder. 1. The paper tries to address an interesting problem.\n2. The proposed idea is novel. \n3. They included a detailed ablation study which helps identify the effectiveness of each component. 1)  The experimental results when compared to the baseline do not have noticeable improvement. \n2)  Some more details on the experiment section would be helpful, for example in Figure 4. 1) Intuitively, what is the difference between applying the Frobenius norm directly to the S matrix versus the regularization defined in equation (14)?\n\n2) It is a bit confusing to use \"h\" in equation (2) and equation (12) to represent different meanings.\n\n3) It is not clear what effect the discrete term Q(h) has on the learned final note representation H', since H' is the sum of the discrete and continuous representations. Is it possible for the model to completely ignore the discretization step and focus only on the continuous representation?\n\n4) In line 191, it is mentioned that \"It is worth noting that our separation is not only performed at the node dimension but also takes into account the feature dimension in the latent space.\" I didn't quite understand this. Could you provide more explanation?\n\n5) Could you explain the intuition behind what S is learning in equation 8? Essentially, it seems  S is just reweighing every element in H'. Intuitively, for the parts of H' that are not very important/invariant/main motif, S should be low so that those elements mainly contribute to the spurious representation, and vice versa. But how does the model enforces this?\n\n6) I'm not sure if the learned high-level representation can be seen as the sum of the invariant and spurious representations. In other words, can we really break down the abstract learned representation of such a complex structure into invariant and spurious parts? Would each of these components eventually represent some substructures if decoded?\n\n7) The paper states that the model learns discrete latent representation, but according to equation 6, the continuous representation is added back to the discretized representation. Can we still claim that the final learned representation is discrete?\n\n8) It would be very helpful to provide a brief explanation of how the dataset is split, how the out-of-distribution is represented in the training/test/validation data, and what the terms \"covariates\" and \"concepts\" refer to in Table 1. This would provide context, especially for readers who are not familiar with the dataset. The paper did not discuss the limitations of the work and there is no potential negative societal impact of the work.",
         "492",
         "0",
         "3",
         "0.7717",
         "0.0418543544",
         "0.8898085952",
         "218",
         "160",
         "39.2577",
         "12.3106",
         "14.9312",
         "14.2327",
         "12.7915",
         "0.1714",
         "98",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2177",
         "r9fzp8eyhZ",
         "3508",
         "1683554984085",
         "['~Xiang_Zhuang1', '~Qiang_Zhang6', '~Keyan_Ding1', '~Yatao_Bian1', '~Xiao_Wang2', '~Jingsong_Lv1', '~Hongyang_Chen2', '~Huajun_Chen1']",
         "Learning Invariant Molecular Representation in Latent Discrete Space",
         "Molecular representation learning lays the foundation for drug discovery. However, existing methods suffer from poor out-of-distribution (OOD) generalization, particularly when data for training and testing originate from different environments. To address this issue, we propose a new framework for learning molecular representations that exhibit invariance and robustness against distribution shifts. Specifically, we propose a strategy called  ``first-encoding-then-separation'' to identify invariant molecule features in the latent space, which deviates from conventional practices. Prior to the separation step, we introduce a residual vector quantization module that mitigates the over-fitting to training data distributions while preserving the expressivity of encoders. Furthermore, we design a task-agnostic self-supervised learning objective to encourage precise invariance identification, which enables our method widely applicable to a variety of tasks, such as regression and multi-label classification. Extensive experiments on 18 real-world molecular datasets demonstrate that our model achieves stronger generalization against state-of-the-art baselines in the presence of various distribution shifts.  Our code is available at https://github.com/HICAI-ZJU/iMoLD.",
         "Reviewer_d9FY",
         "1688649750485",
         "1702410902647",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a new approach to obtain robust molecular representation through a first-encoding-then-separation method. The proposed method utilizes a graph neural network (GNN) as a molecule encoder and applies a residual vector quantization module to modify the representation. Additionally, a scoring GNN is employed to separate the resulting representations into spurious and invariant categories. The learning process involves contrastive-based self-supervised learning (SSL) loss and task prediction losses. Experimental results on three molecule-related benchmarks demonstrate the superiority of the proposed method over traditional debiasing techniques and recent methods designed specifically for molecule debiasing. Ablation studies and visualization techniques are conducted to provide further insights and analysis. 1. The proposed first-encoding-then-separation approach is novel.\n2. Experiments on various datasets have shown that the proposed method has the ability to achieve better results. 1. The motivation is not clear. Why the first-encoding-then-separation approach is reasonable? \n2. The reason to combine different components is also not clear, making the technical contribution not strong. The current version is like a straight forward combination without sufficient insight or understanding on the problem. For example, why we need a RVQ module in the molecule representation?\n3. It is not clear why the proposed method has the ability to mitigate spurious biases to achieve better OOD results. Is there any theory to support that?\n3. The experiments are not sufficient. For example, only improved results have been demonstrated, without sufficient analysis. In the ablation study of different modules are not consistent on different data, making the technique very ad hoc. Though some visualization have been provided, they are not sufficient to support the claim that the proposed method obtain better invariant features. What does it mean by a uniform distribution? Is the uniform distribution equivalent to a good feature? See above in the weakness part. N/A",
         "299",
         "0",
         "7",
         "0.7771",
         "0.0858537296",
         "0.8752020597",
         "218",
         "159",
         "26.3867",
         "12.9553",
         "14.3996",
         "13.5354",
         "13.657",
         "0.09480000000000001",
         "91",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2258",
         "qlJoo2y3gY",
         "6751",
         "1683717044008",
         "['~David_Liu4', '~Máté_Lengyel1']",
         "Bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability",
         "Neural spiking activity is generally variable, non-stationary, and exhibits complex dependencies on covariates, such as sensory input or behavior. These dependencies have been proposed to be signatures of specific computations, and so characterizing them with quantitative rigor is critical for understanding neural computations. Approaches based on point processes provide a principled statistical framework for modeling neural spiking activity. However, currently, they only allow the instantaneous mean, but not the instantaneous variability, of responses to depend on covariates. To resolve this limitation, we propose a scalable Bayesian approach generalizing modulated renewal processes using sparse variational Gaussian processes. We leverage pathwise conditioning for computing nonparametric priors over conditional interspike interval distributions and rely on automatic relevance determination to detect lagging interspike interval dependencies beyond renewal order.  After systematically validating our method on synthetic data, we apply it to two foundational datasets of animal navigation: head direction cells in freely moving mice and hippocampal place cells in rats running along a linear track. Our model exhibits competitive or better predictive power compared to state-of-the-art baselines, and outperforms them in terms of capturing interspike interval statistics. These results confirm the importance of modeling covariate-dependent spiking variability, and further analyses of our fitted models reveal rich patterns of variability modulation beyond the temporal resolution of flexible count-based approaches.",
         "Reviewer_C2R4",
         "1687961950477",
         "1702411077293",
         "5",
         "5",
         "3",
         "3",
         "3",
         "In this paper, the authors introduce the Bayesian nonparametric non-renewal (NPNR) process to model variability in neural spike trains with covariate dependence. The method generalizes modulated renewal processes using sparse variational Gaussian processes. Tested on synthetic data, as well as mouse head direction cell data and rat hippocampal place cell data, NPNR shows its superiority in terms of capturing interspike interval statistics and predictive power. + Bayesian nonparametric non-renewal (NPNR) process to model variability in neural spike trains;\n+ Validation of the approach on synthetic data and mouse head direction cell data and rat hippocampal place cell data;\n - There are some aspects that while they may be hard to analyze theoretically at least in the experimental part can be investigated through simulations. For example, how is the inference affected by the dimension of x_t, number of unmeasured or unknown neurons  that can act as perturbations, the number of samples and number of units/channels? I.e., how much data (in space and time) is needed for an efficient inference?\n- Within the experimental investigation, it is unclear what ELL values can be considered as good predictions. For example, if NPNR is used for k-step ahead forecasts, how many steps can it achieve with at least 50% accuracy?\n- Although this is a minor issue, the reader has some difficulties at seeing all the plots well from Figure 2 in particular the ISI probability plots. I assume they fit well gamma or exponential distribution.\n- A major issue is to check the literature and in unbiased way provide an accurate description even if the problems considered by prior work have a different or more advanced setup. \n 1. The authors mention that the variational inference framework is scalable. In the synthetic and real-world experiments, the number of neurons/units are relatively small (less than 50). I wonder if there's any limitation of the method to scale up to larger ensemble systems with much more neurons?\n2. How does the proposed model perform in terms of predictive power when applied to synthetic data?\n3. The experiments on mouse head direction cell data and rat hippocampal place cell data shows the predictive performance of NPNR and baseline models by showing the expected log-likelihood. For the two datasets, the range of ELL for the models vary a lot and is hard to interpret. I wonder what value of ELL can be considered as a good prediction? For example, if NPNR is used for k-step ahead forecasts, how many steps can it achieve with at least 50% accuracy?\n4. The manuscript states that “Extending point process models with input-dependent variability has not been widely explored…” Multivariate auto-regressive frameworks and multiple covariates based models have been considered in \"A Granger causality measure for point process models of ensemble neural spiking activity.\" PLoS computational biology 7, no. 3 (2011): e1001110. \"Data-driven perception of neuron point process with unknown unknowns.\" In Proceedings of the 10th ACM/IEEE International Conference on Cyber-Physical Systems, pp. 259-269. 2019. \"Variance as a signature of neural computations during decision making.\" Neuron 69, no. 4 (2011): 818-831. In general the prior work needs to be more exhaustively checked and discussed, as of now it is biased and solely based on one group while there are similar and related works from other groups.\n5. Within the context of multiple neuronal recordings there is always the issue of interference and the problem that we cannot with certainty measure exactly N number of neurons. The activity of N neurons may be influenced by another P neurons so the question is how we can subtract the effect or perturbations in order to accurately model the N neurons and their covariates, etc. This again has been tackled in the neuroscience literature and the authors should check this related problem of understanding neural computations with unknown influences.\n6. In the experiments, 1-D, 2-D and 3-D x_t are considered for the NPNR modeling. I wonder if and how the inference can be affected by the dimension of x_t, number of samples and number of units/channels? I.e., how much data (in space and time) is needed for an efficient inference?\n Not applicable in my opinion, this is a mathematical modeling paper with applications in neuroscience.",
         "699",
         "2",
         "10",
         "0.8144",
         "0.0921401515",
         "0.9341231585",
         "216",
         "167",
         "39.8783",
         "12.616",
         "15.9431",
         "14.7568",
         "13.2127",
         "0.1932",
         "78",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2259",
         "qlJoo2y3gY",
         "6751",
         "1683717044008",
         "['~David_Liu4', '~Máté_Lengyel1']",
         "Bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability",
         "Neural spiking activity is generally variable, non-stationary, and exhibits complex dependencies on covariates, such as sensory input or behavior. These dependencies have been proposed to be signatures of specific computations, and so characterizing them with quantitative rigor is critical for understanding neural computations. Approaches based on point processes provide a principled statistical framework for modeling neural spiking activity. However, currently, they only allow the instantaneous mean, but not the instantaneous variability, of responses to depend on covariates. To resolve this limitation, we propose a scalable Bayesian approach generalizing modulated renewal processes using sparse variational Gaussian processes. We leverage pathwise conditioning for computing nonparametric priors over conditional interspike interval distributions and rely on automatic relevance determination to detect lagging interspike interval dependencies beyond renewal order.  After systematically validating our method on synthetic data, we apply it to two foundational datasets of animal navigation: head direction cells in freely moving mice and hippocampal place cells in rats running along a linear track. Our model exhibits competitive or better predictive power compared to state-of-the-art baselines, and outperforms them in terms of capturing interspike interval statistics. These results confirm the importance of modeling covariate-dependent spiking variability, and further analyses of our fitted models reveal rich patterns of variability modulation beyond the temporal resolution of flexible count-based approaches.",
         "Reviewer_Mj1g",
         "1688498103563",
         "1702411077193",
         "8",
         "4",
         "3",
         "4",
         "4",
         "This paper proposes the Bayesian nonparametric non-renewal process (NPNR) for inferencing both neural spiking intensity and variability. The tuning curve is based on a sparse variational Gaussian process (GP) prior, considering both spatial and temporal factors. They compare NPNR with other competitors on a synthetic dataset showing the capability of NPNR in inferencing the rate map and renewal density. On the two real-world neural datasets, they show that NPNR outperforms lots of competitors in terms of event prediction and interspike interval (ISI) recovery by different statistics combined with visualizations. * Clear logical flow and presentation. Key maths are derived elegantly with lots of necessary details in the Appendix.\n* Both synthetic and real-world experiments are good and solid, and also supported by the code.\n* The literature review by the authors are exhaustive so that the comparison between different kind of models are clear and in detail.\n* The idea is new and intuitive, both preserve the interpretability and are not too simple. * I'm very excited when seeing the model part. But when I get to Section 3.2, I feel a bit pity that we still need to do time discretization (convert the continuous timestamps TPP data to spike counts in time bins). * I think Eq. 15 should be $=$ rather than $\\propto$.\n* I'm wondering if this model can report a predictive log-likelihood using the mean as the estimation for the intensity in each time bin. In such a case, we can compare this model with other models (especially the simple GLM) to show that the proposed NPNR outperforms GLM? I'm expecting that this model will be slow but if the firing rates (tuning curve) recovery is better than GLM, the predictive log-likelihood (which is actually a golden criterion in neural latent variable models) should be better.\n* Can this model get information on the causal relationships between neurons? Is this model only dependent on time $t$ and external input $\\boldsymbol x$, but does not consider influences between neurons? From my understanding, this is not a latent variable model doing information extraction from coupled neurons (like dimensionality reduction), but getting the firing rate for each neuron, and the firing rate is mainly affected by the neuron itself and the external input $\\boldsymbol x$. /",
         "377",
         "0",
         "2",
         "0.7764000000000001",
         "0.11260101010000001",
         "0.9173252583",
         "216",
         "161",
         "41.1395",
         "12.0799",
         "15.0784",
         "14.1918",
         "12.157",
         "0.07010000000000001",
         "82",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2260",
         "qlJoo2y3gY",
         "6751",
         "1683717044008",
         "['~David_Liu4', '~Máté_Lengyel1']",
         "Bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability",
         "Neural spiking activity is generally variable, non-stationary, and exhibits complex dependencies on covariates, such as sensory input or behavior. These dependencies have been proposed to be signatures of specific computations, and so characterizing them with quantitative rigor is critical for understanding neural computations. Approaches based on point processes provide a principled statistical framework for modeling neural spiking activity. However, currently, they only allow the instantaneous mean, but not the instantaneous variability, of responses to depend on covariates. To resolve this limitation, we propose a scalable Bayesian approach generalizing modulated renewal processes using sparse variational Gaussian processes. We leverage pathwise conditioning for computing nonparametric priors over conditional interspike interval distributions and rely on automatic relevance determination to detect lagging interspike interval dependencies beyond renewal order.  After systematically validating our method on synthetic data, we apply it to two foundational datasets of animal navigation: head direction cells in freely moving mice and hippocampal place cells in rats running along a linear track. Our model exhibits competitive or better predictive power compared to state-of-the-art baselines, and outperforms them in terms of capturing interspike interval statistics. These results confirm the importance of modeling covariate-dependent spiking variability, and further analyses of our fitted models reveal rich patterns of variability modulation beyond the temporal resolution of flexible count-based approaches.",
         "Reviewer_hah4",
         "1688525611082",
         "1702411077084",
         "6",
         "3",
         "3",
         "3",
         "2",
         "The authors proposed a scalable Bayesian approach which generalizes modulated renewal processes using sparse variational Gaussian processes. They applied the proposed method to simulated and two real neural datasets and showed that the proposed method is effective on these datasets and outperforms other baseline methods. The paper is well written. The authors have done extensive experiments to show the effectiveness of the proposed method.  The proposed method doesn't incorporate any latent variables in the model. (see more in the questions section below.) - Method section: all the formulas are described for 1 neuron. It might be clearer to write likelihood and loss function in terms of multiple neurons.\n\n- I wonder if the authors have done any comparisons to the parametric methods? e.g. Gao Y*, Archer E*, Paninski L, Cunningham JP (2016) Linear dynamical neural population models through nonlinear embeddings. NIPS 2016.\n\n- The proposed method doesn't incorporate any latent variables. It might be worth adding the latents to discover useful representations from the data and fit the data variability better. I wonder if the model would fit data worse if miss one covariate in the inputs? (e.g. only includes location and direction in covariate not theta phase in the hippocampus data.) I feel that adding latents might help with this as well. The authors have discussed the limitations and future work of their proposed method.",
         "226",
         "1",
         "3",
         "0.7946000000000001",
         "0.1910714286",
         "0.8267437816000001",
         "216",
         "160",
         "42.8364",
         "10.747",
         "12.5705",
         "12.274000000000001",
         "10.8185",
         "0.2025",
         "94",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2261",
         "qlJoo2y3gY",
         "6751",
         "1683717044008",
         "['~David_Liu4', '~Máté_Lengyel1']",
         "Bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability",
         "Neural spiking activity is generally variable, non-stationary, and exhibits complex dependencies on covariates, such as sensory input or behavior. These dependencies have been proposed to be signatures of specific computations, and so characterizing them with quantitative rigor is critical for understanding neural computations. Approaches based on point processes provide a principled statistical framework for modeling neural spiking activity. However, currently, they only allow the instantaneous mean, but not the instantaneous variability, of responses to depend on covariates. To resolve this limitation, we propose a scalable Bayesian approach generalizing modulated renewal processes using sparse variational Gaussian processes. We leverage pathwise conditioning for computing nonparametric priors over conditional interspike interval distributions and rely on automatic relevance determination to detect lagging interspike interval dependencies beyond renewal order.  After systematically validating our method on synthetic data, we apply it to two foundational datasets of animal navigation: head direction cells in freely moving mice and hippocampal place cells in rats running along a linear track. Our model exhibits competitive or better predictive power compared to state-of-the-art baselines, and outperforms them in terms of capturing interspike interval statistics. These results confirm the importance of modeling covariate-dependent spiking variability, and further analyses of our fitted models reveal rich patterns of variability modulation beyond the temporal resolution of flexible count-based approaches.",
         "Reviewer_yMLW",
         "1688659740159",
         "1702411076991",
         "7",
         "3",
         "3",
         "3",
         "3",
         "The variability of neural data is widely observed in many neuroscience experiments. Using statistical model to capture the variability structure plays an essential role in understanding neural computations. Generally, the variability of neural data is a result of non-stationary activities and dependencies on behavioral covariates. To tackle these challenges, the authors proposes a scalable Bayesian approach generalizing modulated renewal processes (NPNR) to analyze neural data variability. They develops a nonparametric generalization of modulated renewal processes beyond renewal order, which makes their method flexibly model irreducible “intrinsic” neural stochasticity and input-dependent variability. Furthermore, the authors apply stochastic variational inference and can fit the model to long time neural data given cubic time complexity in the number of inducing points. The performace of NPNR is evaluated on both synthetic and real neural datasets. * The proposed method can model two types of neural variability: (1) capturing spiking statistics from non-stationary data; (2) capturing modulation by behavioral covariates.\n* To achieve the desired non-stationarity, the proposed method uses time warping on $\\tau$, which avoids the use of non-stationary kernls and maintains the ability to draw samples by pathwise conditioning.\n* The proposed inference method provides an elegant approach to determine the spike-history dependence in ISI statistics.\n* The authors' exposition of their motivation, contribution, and conclusions from the experiments are comprehensive and clear.\n* The proposed method would provide an important set of contributions to the field of neural coding. The proposed method is clearly written and well supported by experiments. I have nothing further to add here. * The proposed method captures ISI statistics using a spatio-temporal GP prior over CIF. Could the Neural Temporal Point Process (NTPP) perform similarly to your method in capturing ISI statistics? The CIF in NTPP is usually modeled by neural networks, and could this be more powerful to represent ISI distributions and capture ISI statistics? N/A",
         "310",
         "0",
         "1",
         "0.7909",
         "0.1055555556",
         "0.9147011042000001",
         "216",
         "159",
         "15.5884",
         "15.5275",
         "18.3372",
         "16.0526",
         "15.5129",
         "0.3224",
         "85",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2262",
         "qlJoo2y3gY",
         "6751",
         "1683717044008",
         "['~David_Liu4', '~Máté_Lengyel1']",
         "Bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability",
         "Neural spiking activity is generally variable, non-stationary, and exhibits complex dependencies on covariates, such as sensory input or behavior. These dependencies have been proposed to be signatures of specific computations, and so characterizing them with quantitative rigor is critical for understanding neural computations. Approaches based on point processes provide a principled statistical framework for modeling neural spiking activity. However, currently, they only allow the instantaneous mean, but not the instantaneous variability, of responses to depend on covariates. To resolve this limitation, we propose a scalable Bayesian approach generalizing modulated renewal processes using sparse variational Gaussian processes. We leverage pathwise conditioning for computing nonparametric priors over conditional interspike interval distributions and rely on automatic relevance determination to detect lagging interspike interval dependencies beyond renewal order.  After systematically validating our method on synthetic data, we apply it to two foundational datasets of animal navigation: head direction cells in freely moving mice and hippocampal place cells in rats running along a linear track. Our model exhibits competitive or better predictive power compared to state-of-the-art baselines, and outperforms them in terms of capturing interspike interval statistics. These results confirm the importance of modeling covariate-dependent spiking variability, and further analyses of our fitted models reveal rich patterns of variability modulation beyond the temporal resolution of flexible count-based approaches.",
         "Reviewer_3xxY",
         "1688680225769",
         "1702411076897",
         "6",
         "2",
         "3",
         "3",
         "3",
         "This paper proposes a Bayesian nonparametric approach using modulated renewal process to model neural spike train, and capable of modeling the covariability. The method includes a nonparametric priors on conditional interspike interval distribution and automatic relevance determination for lagging interspike interval based on renewal order. The method is evaluated on one synthetic data and two real datasets on animal navigation. It demonstrates better performance than the current SOTA baselines in its capability of capturing the interspike interval statistics.   1. Motivation: the paper is well-motivated, modeling the spike train statistics is an important question, and the interspike interval statistics is an important property of neural dynamics, and potentially leads to identification of cell types, and functionality, etc. Designing a model that captures this property well is important.\n\n2. Method: it uses Bayesian nonparameteric approach that could fit complex data structures and patterns well, and it could infer the spike-history dependence using a data-driven approach.\n\n3. Results: the method demonstrate better accuracy than the current SOTA methods in multiple tasks and datasets. 1. Method: the model requires hyperparameter tuning of critical components includes $\\tau_w$  $K$, which might be hard to optimize, given its variability across neurons and datasets.\n\n2. Evaluation: the scalability of the method is a major concerns, as the datasets evaluated in this paper only has 9 neurons, ~30 units in each datasets. It's important to show how well the model performs in larger neural datasets.\n\n3. Complexity and computational cost: add evaluations based on the cost and speed of the proposed model and other baselines.\n\n 1. Give a detailed introduction about the parameters that would be optimized under eqn 18. and list other hyper-parameters for reproducibility. \n\n2. Evaluate the method on larger scale neural datasets.  1. There is no potential negative societal impact of their work.\n2. The limitations about scalability of the proposed approach should be carefully addressed.  ",
         "310",
         "0",
         "10",
         "0.7794000000000001",
         "0.1008012821",
         "0.9359926581",
         "216",
         "158",
         "20.7636",
         "14.8934",
         "17.6167",
         "15.9032",
         "14.8689",
         "0.0999",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2723",
         "ouLe91yibj",
         "5834",
         "1683691555299",
         "['~Yufeng_Zhang5', '~Jialu_Pan1', '~Kenli_Li1', '~Wanwei_Liu1', '~Zhenbang_Chen2', '~Xinwang_Liu1', '~J_Wang1']",
         "On the Properties of Kullback-Leibler Divergence Between Multivariate Gaussian Distributions",
         "Kullback-Leibler (KL) divergence is one of the most important measures to calculate the difference between probability distributions. In this paper, we theoretically study several properties of KL divergence between multivariate Gaussian distributions. Firstly, for any two $n$-dimensional Gaussian distributions $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we prove that when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\leq \\varepsilon\\ (\\varepsilon>0)$ the supremum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ is $(1/2)\\left((-W_{0}(-e^{-(1+2\\varepsilon)}))^{-1}+\\log(-W_{0}(-e^{-(1+2\\varepsilon)})) -1 \\right)$, where $W_0$ is the principal branch of Lambert $W$ function.\tFor small $\\varepsilon$, the supremum is $\\varepsilon + 2\\varepsilon^{1.5} + O(\\varepsilon^2)$. This quantifies the approximate symmetry of small KL divergence between Gaussian distributions. We further derive the infimum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\geq M\\ (M>0)$. We give the conditions when the supremum and infimum can be attained. Secondly, for any three $n$-dimensional Gaussian distributions $\\mathcal{N}_1$, $\\mathcal{N}_2$, and $\\mathcal{N}_3$, we theoretically show that an upper bound of $KL(\\mathcal{N}_1||\\mathcal{N}_3)$ is $3\\varepsilon_1+3\\varepsilon_2+2\\sqrt{\\varepsilon_1\\varepsilon_2}+o(\\varepsilon_1)+o(\\varepsilon_2)$ when $KL(\\mathcal{N}_1||\\mathcal{N}_2)\\leq \\varepsilon_1$ and $KL(\\mathcal{N}_2||\\mathcal{N}_3)\\leq \\varepsilon_2$ ($\\varepsilon_1,\\varepsilon_2\\ge 0$). This reveals that KL divergence between Gaussian distributions follows a relaxed triangle inequality. Note that, all these bounds in the theorems presented in this work are independent of the dimension $n$. Finally, we discuss several applications of our theories in deep learning, reinforcement learning, and sample complexity research.",
         "Reviewer_8dDm",
         "1687218515206",
         "1702411032047",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper explores and proves some properties of KL divergence between multivariate Gaussian distributions. One of the motivations is that as a statistical distance, KL divergence does not satisfy the properties of a metric, that is, symmetry and triangle inequality. In spite of these issues, this paper proposes the relaxed versions. To be specific, it proves the lower bound (resp. upper bound) for reverse KL divergence given the lower bound (resp. upper bound) of forward KL divergence, and the summation upper bound of two bounded KL divergences. Finally, the proposed techniques are applied to anomaly detection with flow based model and reinforcement learning.  (1) This paper proves the lower bound (resp. upper bound) for reverse KL divergence given the lower bound (resp. upper bound) of forward KL divergence, and the summation upper bound of two bounded KL divergences.  \n(2) The theoretical results can be applied to some applications in deep learning and reinforcement learning.  \n(3) This paper is well-written and easy to understand. \n (1) Theorem 1 and Theorem 3 hold when two conditions are satisfied. For example, for the mean, it requires $\\mu_1 = \\mu_2$, which is too strong in practice.  \n(2) Since the KL divergence has a wide range of applications, the two applications shown in this paper are kind of limited and not convincing.  The KL divergence is widely used in machine learning and statistics, etc. Can the theoretical results in this paper be used to some other tasks in machine learning? See Weaknesses. ",
         "246",
         "0",
         "1",
         "0.7462000000000001",
         "0.0794890873",
         "0.8437820673",
         "216",
         "175",
         "49.9409",
         "9.8739",
         "12.9484",
         "12.526299999999999",
         "10.3215",
         "0.0945",
         "90",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2724",
         "ouLe91yibj",
         "5834",
         "1683691555299",
         "['~Yufeng_Zhang5', '~Jialu_Pan1', '~Kenli_Li1', '~Wanwei_Liu1', '~Zhenbang_Chen2', '~Xinwang_Liu1', '~J_Wang1']",
         "On the Properties of Kullback-Leibler Divergence Between Multivariate Gaussian Distributions",
         "Kullback-Leibler (KL) divergence is one of the most important measures to calculate the difference between probability distributions. In this paper, we theoretically study several properties of KL divergence between multivariate Gaussian distributions. Firstly, for any two $n$-dimensional Gaussian distributions $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we prove that when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\leq \\varepsilon\\ (\\varepsilon>0)$ the supremum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ is $(1/2)\\left((-W_{0}(-e^{-(1+2\\varepsilon)}))^{-1}+\\log(-W_{0}(-e^{-(1+2\\varepsilon)})) -1 \\right)$, where $W_0$ is the principal branch of Lambert $W$ function.\tFor small $\\varepsilon$, the supremum is $\\varepsilon + 2\\varepsilon^{1.5} + O(\\varepsilon^2)$. This quantifies the approximate symmetry of small KL divergence between Gaussian distributions. We further derive the infimum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\geq M\\ (M>0)$. We give the conditions when the supremum and infimum can be attained. Secondly, for any three $n$-dimensional Gaussian distributions $\\mathcal{N}_1$, $\\mathcal{N}_2$, and $\\mathcal{N}_3$, we theoretically show that an upper bound of $KL(\\mathcal{N}_1||\\mathcal{N}_3)$ is $3\\varepsilon_1+3\\varepsilon_2+2\\sqrt{\\varepsilon_1\\varepsilon_2}+o(\\varepsilon_1)+o(\\varepsilon_2)$ when $KL(\\mathcal{N}_1||\\mathcal{N}_2)\\leq \\varepsilon_1$ and $KL(\\mathcal{N}_2||\\mathcal{N}_3)\\leq \\varepsilon_2$ ($\\varepsilon_1,\\varepsilon_2\\ge 0$). This reveals that KL divergence between Gaussian distributions follows a relaxed triangle inequality. Note that, all these bounds in the theorems presented in this work are independent of the dimension $n$. Finally, we discuss several applications of our theories in deep learning, reinforcement learning, and sample complexity research.",
         "Reviewer_ZfdJ",
         "1687447104686",
         "1702411031943",
         "6",
         "3",
         "3",
         "2",
         "2",
         "Kullback-Leibler (KL) divergence is an important measure of distance between probability distributions with uses in statistics, information theory and many other fields. However, it is not a proper distance measure, since it is not symmetric and does not satisfy the triangle inequality in general. The authors consider the KL divergence between multivariate Gaussian distributions and show that a relaxed notion of symmetry and triangle inequality holds under certain conditions. Specifically, they formulate an upper bound on KL(N2,N1) when KL(N1,N2) < epsilon, and show that it cannot be much greater than epsilon. Similarly, they give a lower bound on KL(N2,N1) when KL(N1,N2)  > M. Finally, they upper bound KL(N1,N3) when KL(N1,N2) < epsilon1 and KL(N2,N3) < epsilon2. They conclude by discussing several applications of the results in deep learning and reinforcement learning. The disadvantages of KL divergence as far as symmetry and triangle inequality go are well known, so finding conditions in which even a relaxed version of these properties hold is interesting and potentially useful. Firstly, due to the continuity of the KL divergence around epsilon=0 (N1=N2), the results are not too surprising. The proofs are technical, lengthy and somewhat repetitive. Lemma G.5 in particular is not so digestible for readers. Secondly, the structure of the paper is unorthodox: usually you would have the Related Work section right after the Introduction instead of before Conclusions; that would also be a better place to start mentioning the applications for which your results might be relevant. The section called Lemmas and Notations has no lemmas. The Applications section should be called Discussion.    - Can you please rearrange the structure of the paper to be more in line with convention?\n- Can Lemma G.5 be made more edible, or could a more informative overview be given?\n\n-- The authors have thoroughly addressed these points in the rebuttal. There is no potential negative societal impact of the work",
         "314",
         "0",
         "0",
         "0.7937000000000001",
         "0.15833333330000002",
         "0.9097418785",
         "216",
         "173",
         "40.2491",
         "11.6595",
         "14.8019",
         "14.0157",
         "12.1639",
         "0.35100000000000003",
         "83",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2725",
         "ouLe91yibj",
         "5834",
         "1683691555299",
         "['~Yufeng_Zhang5', '~Jialu_Pan1', '~Kenli_Li1', '~Wanwei_Liu1', '~Zhenbang_Chen2', '~Xinwang_Liu1', '~J_Wang1']",
         "On the Properties of Kullback-Leibler Divergence Between Multivariate Gaussian Distributions",
         "Kullback-Leibler (KL) divergence is one of the most important measures to calculate the difference between probability distributions. In this paper, we theoretically study several properties of KL divergence between multivariate Gaussian distributions. Firstly, for any two $n$-dimensional Gaussian distributions $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we prove that when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\leq \\varepsilon\\ (\\varepsilon>0)$ the supremum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ is $(1/2)\\left((-W_{0}(-e^{-(1+2\\varepsilon)}))^{-1}+\\log(-W_{0}(-e^{-(1+2\\varepsilon)})) -1 \\right)$, where $W_0$ is the principal branch of Lambert $W$ function.\tFor small $\\varepsilon$, the supremum is $\\varepsilon + 2\\varepsilon^{1.5} + O(\\varepsilon^2)$. This quantifies the approximate symmetry of small KL divergence between Gaussian distributions. We further derive the infimum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\geq M\\ (M>0)$. We give the conditions when the supremum and infimum can be attained. Secondly, for any three $n$-dimensional Gaussian distributions $\\mathcal{N}_1$, $\\mathcal{N}_2$, and $\\mathcal{N}_3$, we theoretically show that an upper bound of $KL(\\mathcal{N}_1||\\mathcal{N}_3)$ is $3\\varepsilon_1+3\\varepsilon_2+2\\sqrt{\\varepsilon_1\\varepsilon_2}+o(\\varepsilon_1)+o(\\varepsilon_2)$ when $KL(\\mathcal{N}_1||\\mathcal{N}_2)\\leq \\varepsilon_1$ and $KL(\\mathcal{N}_2||\\mathcal{N}_3)\\leq \\varepsilon_2$ ($\\varepsilon_1,\\varepsilon_2\\ge 0$). This reveals that KL divergence between Gaussian distributions follows a relaxed triangle inequality. Note that, all these bounds in the theorems presented in this work are independent of the dimension $n$. Finally, we discuss several applications of our theories in deep learning, reinforcement learning, and sample complexity research.",
         "Reviewer_odZe",
         "1688619696785",
         "1702411031865",
         "7",
         "4",
         "3",
         "3",
         "3",
         "This paper investigates the properties of KL divergence between Gaussian distributions. The main theoretical contributions include two main theorems. The first one gives the supremum of reverse KL divergence between Gaussians when the forward KL divergence is bounded. The conditions when the supremum is attained are also identified. The second theorem gives the relaxed triangle inequality of KL divergence between Gaussians. Based on these two main theorems, this paper also derives several corollaries, including the local approximations and a lower bound of reverse KL divergence. It is also notable that the bounds are dimension-free. Finally, this paper discusses several applications of the theoretical results in OOD detection with flow-based generative models and safe/robust reinforcement learning.\n\nOverall, the research questions studied in this paper have not been answered before. The theoretical contributions of this paper are novel and solid. The proofs are carefully written and correct. Notably, the proof of Theorem 4 is rather technical. The theorems presented in this paper can be applied in various contexts involving KL divergence and Gaussian distributions.\n 1.\tThe problems studied in this paper are novel and interesting. This paper answers these research problems for the first time.   \n2.\tThe proofs, which are based on the Lambert W function, are technical.  \n3.\tThe theoretical results can be applied to various problems, including anomaly detection and reinforcement learning. These results also have other potential applications.\n 1.\tIt is possible to make some equations tighter by introducing notations earlier. For example, notations in Equations (G.146)-(G.150) can be introduced earlier to make Equations (G.128)-(G.144) more concise. \n2.\tThe derivations in Equation (E.54) and (J.193) are over-detailed. These two equations can be shortened.\n See Weaknesses. The authors have discussed social impacts and limitations.",
         "284",
         "0",
         "6",
         "0.7394000000000001",
         "0.0908854167",
         "0.8759232759000001",
         "216",
         "159",
         "41.2573",
         "10.1179",
         "13.0806",
         "12.0608",
         "11.4259",
         "0.0999",
         "87",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "2726",
         "ouLe91yibj",
         "5834",
         "1683691555299",
         "['~Yufeng_Zhang5', '~Jialu_Pan1', '~Kenli_Li1', '~Wanwei_Liu1', '~Zhenbang_Chen2', '~Xinwang_Liu1', '~J_Wang1']",
         "On the Properties of Kullback-Leibler Divergence Between Multivariate Gaussian Distributions",
         "Kullback-Leibler (KL) divergence is one of the most important measures to calculate the difference between probability distributions. In this paper, we theoretically study several properties of KL divergence between multivariate Gaussian distributions. Firstly, for any two $n$-dimensional Gaussian distributions $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we prove that when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\leq \\varepsilon\\ (\\varepsilon>0)$ the supremum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ is $(1/2)\\left((-W_{0}(-e^{-(1+2\\varepsilon)}))^{-1}+\\log(-W_{0}(-e^{-(1+2\\varepsilon)})) -1 \\right)$, where $W_0$ is the principal branch of Lambert $W$ function.\tFor small $\\varepsilon$, the supremum is $\\varepsilon + 2\\varepsilon^{1.5} + O(\\varepsilon^2)$. This quantifies the approximate symmetry of small KL divergence between Gaussian distributions. We further derive the infimum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\geq M\\ (M>0)$. We give the conditions when the supremum and infimum can be attained. Secondly, for any three $n$-dimensional Gaussian distributions $\\mathcal{N}_1$, $\\mathcal{N}_2$, and $\\mathcal{N}_3$, we theoretically show that an upper bound of $KL(\\mathcal{N}_1||\\mathcal{N}_3)$ is $3\\varepsilon_1+3\\varepsilon_2+2\\sqrt{\\varepsilon_1\\varepsilon_2}+o(\\varepsilon_1)+o(\\varepsilon_2)$ when $KL(\\mathcal{N}_1||\\mathcal{N}_2)\\leq \\varepsilon_1$ and $KL(\\mathcal{N}_2||\\mathcal{N}_3)\\leq \\varepsilon_2$ ($\\varepsilon_1,\\varepsilon_2\\ge 0$). This reveals that KL divergence between Gaussian distributions follows a relaxed triangle inequality. Note that, all these bounds in the theorems presented in this work are independent of the dimension $n$. Finally, we discuss several applications of our theories in deep learning, reinforcement learning, and sample complexity research.",
         "Reviewer_rMwu",
         "1688620787657",
         "1702411031780",
         "7",
         "3",
         "3",
         "3",
         "3",
         "In this paper, the authors look at the KL divergence between two multivarite Gaussian distributions. The KL divergence is an important distance function between two distributions. However, it lacks certain nice properties that other metric distance functions such as variation distance satisfies: namely, symmetry and triangle inequality. This paper shows that, nevertheless, KL divergence satisfies an approximate version of these two important properties. Specifically, if one of the KL divergences is small then the reverse KL divergence will also be small. Similarly, if two pairs of distributions have small KL divergences between them, then the remaining pair will also have a small KL divergence in between.\n\nThe results are derived by posing this as an optimization problem that minimizes the unknown KL divergences subject to the constraint that the known KL divergences are small. Then certain relevant functions such as  and  are analyzed to derive an upper bound for the above optimization problems.\n\nFinally, the authors argue that such approximate symmetry and approximate triangle inequality appear in several important practical applications. In fact, they mention one such problem involving deep neural networks that led them to study this question.\n\nOne more application of this result is that learning a multivariate Gaussian in either KL gives a similar learning result for the reverse KL. So far algorithms have been derived separately for the two directions, see \\[arXiv:1710.05209\\] and \\[arXiv:2107.10450\\] for more.\n\nI have not carefully checked the mathematical details. The paper works on a fundamental mathematical problem of proving that KL divergence between multivariate Gaussians is almost a metric near 0. and gives a nice solution. This paper is very nicely written and a pleasure to read. This is really a beautiful paper.\n\n None. None. None.",
         "285",
         "0",
         "3",
         "0.7685000000000001",
         "0.0837667888",
         "0.9048542976",
         "216",
         "159",
         "40.8142",
         "11.293",
         "13.5789",
         "13.2809",
         "12.1981",
         "0.043000000000000003",
         "88",
         "0",
         "0",
         "0",
         "3"
        ],
        [
         "2727",
         "ouLe91yibj",
         "5834",
         "1683691555299",
         "['~Yufeng_Zhang5', '~Jialu_Pan1', '~Kenli_Li1', '~Wanwei_Liu1', '~Zhenbang_Chen2', '~Xinwang_Liu1', '~J_Wang1']",
         "On the Properties of Kullback-Leibler Divergence Between Multivariate Gaussian Distributions",
         "Kullback-Leibler (KL) divergence is one of the most important measures to calculate the difference between probability distributions. In this paper, we theoretically study several properties of KL divergence between multivariate Gaussian distributions. Firstly, for any two $n$-dimensional Gaussian distributions $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we prove that when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\leq \\varepsilon\\ (\\varepsilon>0)$ the supremum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ is $(1/2)\\left((-W_{0}(-e^{-(1+2\\varepsilon)}))^{-1}+\\log(-W_{0}(-e^{-(1+2\\varepsilon)})) -1 \\right)$, where $W_0$ is the principal branch of Lambert $W$ function.\tFor small $\\varepsilon$, the supremum is $\\varepsilon + 2\\varepsilon^{1.5} + O(\\varepsilon^2)$. This quantifies the approximate symmetry of small KL divergence between Gaussian distributions. We further derive the infimum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when $KL(\\mathcal{N}_2||\\mathcal{N}_1)\\geq M\\ (M>0)$. We give the conditions when the supremum and infimum can be attained. Secondly, for any three $n$-dimensional Gaussian distributions $\\mathcal{N}_1$, $\\mathcal{N}_2$, and $\\mathcal{N}_3$, we theoretically show that an upper bound of $KL(\\mathcal{N}_1||\\mathcal{N}_3)$ is $3\\varepsilon_1+3\\varepsilon_2+2\\sqrt{\\varepsilon_1\\varepsilon_2}+o(\\varepsilon_1)+o(\\varepsilon_2)$ when $KL(\\mathcal{N}_1||\\mathcal{N}_2)\\leq \\varepsilon_1$ and $KL(\\mathcal{N}_2||\\mathcal{N}_3)\\leq \\varepsilon_2$ ($\\varepsilon_1,\\varepsilon_2\\ge 0$). This reveals that KL divergence between Gaussian distributions follows a relaxed triangle inequality. Note that, all these bounds in the theorems presented in this work are independent of the dimension $n$. Finally, we discuss several applications of our theories in deep learning, reinforcement learning, and sample complexity research.",
         "Reviewer_azx2",
         "1688721651120",
         "1702411031707",
         "7",
         "4",
         "4",
         "4",
         "4",
         "In this paper, the authors prove the following interesting mathematical properties of the Kullback-Leibler (KL) divergence between multivariate Gaussian distributions, while the KL divergence is not a proper distance (in sense that it is not symmetric) and does not satisfy the triangle inequality, but:\n1. if $KL(N_2||N_1) \\leq \\epsilon$ then it can be shown that the supremum of $KL(N_1||N_2) $  can be upper bounded by some explicit function of $\\epsilon$ that is of order $\\epsilon$ for $\\epsilon$ small, so that the KL is approximately symmetric in the Gaussian case when being close; and\n2. an infimum of $KL(N_1||N_2) $ is also derived for $KL(N_2||N_1) \\geq M$; and\n2. for three Gaussian $N_1, N_2, N_3$, one has an upper bound $KL(N_1||N_3) $ that verifies the triangle inequality up to a factor of three, again when the three Gaussians are close.\n\nThe authors discuss the basic proof ideas and some possibly applications in Section 5.\n This paper focuses on the fundamental theoretical properties of Kullback-Leibler divergence between multivariate Gaussian distributions, that, to the best of my knowledge, are novel, and have wide applications in ML.\nI've not checked the detailed proofs, but the proof sketch looks compelling. The proof idea is very interesting and may be of independent interest.\n \n\n The paper is in good shape, I do not have specific concern to raise. 1. The authors mention that they propose an unified OOD detection algorithm KLODS, but no detail about KLODS is given, it would be great if the authors could elaborate more on this. This paper is primarily of theoretical nature, and I do not see any potential negative societal impact of this work.",
         "273",
         "0",
         "1",
         "0.7576",
         "0.17200000000000001",
         "0.9694150686",
         "216",
         "158",
         "41.2347",
         "13.6057",
         "17.2256",
         "15.7865",
         "15.0483",
         "0.1953",
         "70",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2732",
         "os2BdbiGwX",
         "5872",
         "1683693150017",
         "['~Cuong_Pham3', '~Cuong_C._Nguyen1', '~Trung_Le2', '~Dinh_Phung2', '~Gustavo_Carneiro1', '~Thanh-Toan_Do4']",
         "Model and Feature Diversity for Bayesian Neural Networks in Mutual Learning",
         "Bayesian Neural Networks (BNNs) offer probability distributions for model parameters, enabling uncertainty quantification in predictions. However, they often underperform compared to deterministic neural networks. Utilizing mutual learning can effectively enhance the performance of peer BNNs. In this paper, we propose a novel approach to improve BNNs performance through deep mutual learning. The proposed approaches aim to increase diversity in both network parameter distributions and feature distributions, promoting peer networks to acquire distinct features that capture different characteristics of the input, which enhances the effectiveness of mutual learning. Experimental results demonstrate significant improvements in the classification accuracy, negative log-likelihood, and expected calibration error when compared to traditional mutual learning for BNNs.",
         "Reviewer_5v8y",
         "1688250740615",
         "1702411034383",
         "5",
         "2",
         "3",
         "3",
         "2",
         "This paper proposed a mutual learning approach to learn a pair of Bayesian Neural Network(BNN). The posterior of BNN is approximated by Variational Inference using a Gaussian distribution with a diagonal covariance matrix. To make the BNN learn different perspective of the data, the author proposed to increase the diversity in parameter space and intermediate feature space by adding the an estimate of distance between parameter distribution and fused feature distribution of two BNN models into the objective function. Empirically, the proposed method outperform existing mutual learning method and vanilla BNN model in terms of accuracy, negative log likelihood loss and expected calibration error. An ablation study is also provided to investigate the usefulness of each component.  The paper is well written and easy to follow. Increasing the diversity of parameter distribution and intermediate feature distribution of peer BNN models to boost performance is an interesting idea. Experiments and detailed ablation study demonstrate the effectiveness of proposed method. 1. It is mentioned in the abstract and introduction that the BNN model with variational inference may underperform deterministic model or BNN obtained by MCMC, the baseline only involves BNN model trained with(DML) or without(vanilla) mutual learning. Would the proposed method close the gap to some extent? Data augmentation, optimizer may all affect performance, so it is still helpful to include deterministic model results follow with same training setup. I would expect the BNN model to outperform deterministic model at least in NLL and ECE, and with the 50 ensemble, it can outperform the accuracy. \n\n2. Continue with last point, for MCMC method (e.g. in line 81 of the paper), I agree that traditional MCMC method(e.g. Metropolis Hasting) may not be feasible for large model, and memory storage can be an issue for MCMC method. But I don't think the stochastic gradient MCMC cited in line 81 would require prohibitive computational cost, it behaves like adding a noise to at each step of standard SGD training. \n\n3. The code is not provided so it may hurt the reproducibility of the paper. 1. To my knowledge, it is not very clear if variational distribution(e.g. Gaussian with diagonal covariance matrix) can approximate the true posterior very well, can the author comment a bit on this, e.g. how would different choice of variational family affect the model?\n\n2. In line 264 and line 6 of algorithm 1, it is mentioned that one BNN model is initialized with a trained model and this lead to better results empirically. Can the author discuss more on why this happened? It is a bit wired for me as it seems in the implementation detail, the pre-trained model and the model from scratch are trained with same optimizer and learning rate schedule.\n\n3. Seems like $\\alpha$ $\\beta$ are set to 1,2 for CIFAR and 1,1 for Imagenet, these two parameters controls the strength of proposed penalty to the model, can the author comments a bit more on how sensitive are the model to those parameters, It can help to illustrate how diversity helps model performance.\n\n4. As mentioned in line 268, results are average of 3 trials, I think it would be better to include the standard deviation as well to boost the significance of the results.\n\n5. In figure A.3 in supplementary material, looks like a sharp increase of KL divergence between the fused feature distributions at around 30 epochs, but the penalty for feature is only added for last 100 epochs, can the author explain more on this?  The authors addressed the limitations.",
         "585",
         "0",
         "8",
         "0.7803",
         "0.1055805306",
         "0.8540630937",
         "216",
         "163",
         "40.5795",
         "12.7897",
         "15.3999",
         "14.348700000000001",
         "13.2588",
         "0.11",
         "91",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2733",
         "os2BdbiGwX",
         "5872",
         "1683693150017",
         "['~Cuong_Pham3', '~Cuong_C._Nguyen1', '~Trung_Le2', '~Dinh_Phung2', '~Gustavo_Carneiro1', '~Thanh-Toan_Do4']",
         "Model and Feature Diversity for Bayesian Neural Networks in Mutual Learning",
         "Bayesian Neural Networks (BNNs) offer probability distributions for model parameters, enabling uncertainty quantification in predictions. However, they often underperform compared to deterministic neural networks. Utilizing mutual learning can effectively enhance the performance of peer BNNs. In this paper, we propose a novel approach to improve BNNs performance through deep mutual learning. The proposed approaches aim to increase diversity in both network parameter distributions and feature distributions, promoting peer networks to acquire distinct features that capture different characteristics of the input, which enhances the effectiveness of mutual learning. Experimental results demonstrate significant improvements in the classification accuracy, negative log-likelihood, and expected calibration error when compared to traditional mutual learning for BNNs.",
         "Reviewer_fyNb",
         "1688308912228",
         "1702411034296",
         "6",
         "3",
         "3",
         "3",
         "2",
         "The paper proposes a method to combine deep mutual learning with BNN to diversify the weight distributions of each BNN networks in a pair or ensemble, to improve performance. 1. AFAIK this is the first work combining mutual learning with BNN, so the authors can claim this point.\n2. The paper is in general written clearly and easy to follow.\n3. Experiments are adequate with ablation studies on individual features impact on diversity. 1. Some design choices are found to be \"empirically\" working well without too much discussion or hypothesis.\n2. Would be interesting to see how the model performs for o.o.d test data, especially uncertainty performance. Line 178-179: The authors said adding the D(...) term will rapidly increase of this term and impact training. Wouldn't putting a smaller scaling factor for this term fix this issue? None.",
         "138",
         "0",
         "6",
         "0.8457",
         "0.1638888889",
         "0.8492545485",
         "216",
         "163",
         "54.2802",
         "9.1166",
         "11.0272",
         "11.6025",
         "9.600200000000001",
         "0.1041",
         "97",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "2734",
         "os2BdbiGwX",
         "5872",
         "1683693150017",
         "['~Cuong_Pham3', '~Cuong_C._Nguyen1', '~Trung_Le2', '~Dinh_Phung2', '~Gustavo_Carneiro1', '~Thanh-Toan_Do4']",
         "Model and Feature Diversity for Bayesian Neural Networks in Mutual Learning",
         "Bayesian Neural Networks (BNNs) offer probability distributions for model parameters, enabling uncertainty quantification in predictions. However, they often underperform compared to deterministic neural networks. Utilizing mutual learning can effectively enhance the performance of peer BNNs. In this paper, we propose a novel approach to improve BNNs performance through deep mutual learning. The proposed approaches aim to increase diversity in both network parameter distributions and feature distributions, promoting peer networks to acquire distinct features that capture different characteristics of the input, which enhances the effectiveness of mutual learning. Experimental results demonstrate significant improvements in the classification accuracy, negative log-likelihood, and expected calibration error when compared to traditional mutual learning for BNNs.",
         "Reviewer_phoh",
         "1688565002124",
         "1702411034221",
         "5",
         "3",
         "2",
         "3",
         "2",
         "The paper titled addresses the challenge of improving the performance of Bayesian Neural Networks (BNNs) by leveraging the concept of mutual learning. BNNs provide a means for quantifying uncertainty in predictions through probability distributions of model parameters. However, BNNs often fall short in performance compared to their deterministic counterparts. The authors propose a novel approach that employs deep mutual learning to enhance the capabilities of BNNs. 1. Innovative Approach: The paper introduces a novel method that combines deep mutual learning with Bayesian Neural Networks. By promoting diversity in both network parameter distributions and feature distributions, the proposed approach enables peer networks to acquire distinct features, capturing different characteristics of the input data. This innovative technique enhances the effectiveness of mutual learning in BNNs.\n2. Detailed algorithm description: The paper provides a thorough and detailed description of the proposed algorithm for improving the performance of Bayesian Neural Networks (BNNs) through deep mutual learning.\n3. Comprehensive Experiments: The authors conduct extensive experiments to evaluate the proposed approach thoroughly. The experimental results are statistically sound and demonstrate significant improvements in classification accuracy, negative log-likelihood, and expected calibration error compared to traditional mutual learning methods for BNNs. 1. Limited variety in experimental validation: One weakness of the paper is that the proposed approach and its effectiveness are only verified through experiments conducted on Residual Neural Networks (ResNets). It would have been beneficial to include experiments on a diverse set of network architectures to demonstrate the approach's effectiveness across different model types and complexities. \n2. Lack of detailed explanation for temperature, α, and β: One weakness of the paper is the limited explanation provided for the temperature parameter (T), α, and β, which are crucial components of the proposed approach. These parameters play a significant role in controlling the diversity of network parameter distributions and feature distributions, but their specific effects and optimal values are not thoroughly discussed.\n3. Weakness in the conclusion: The current conclusion merely restates the experimental results and does not highlight the broader implications of the proposed approach or its potential impact on the field. The author should supplement more experiments to prove its effectiveness. The author should supplement more experiments to prove its effectiveness and strengthen the conclusion.",
         "368",
         "0",
         "6",
         "0.788",
         "0.12209821430000001",
         "0.9327940345",
         "216",
         "160",
         "14.7437",
         "16.5806",
         "19.8545",
         "17.3942",
         "18.831",
         "0.0999",
         "86",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2735",
         "os2BdbiGwX",
         "5872",
         "1683693150017",
         "['~Cuong_Pham3', '~Cuong_C._Nguyen1', '~Trung_Le2', '~Dinh_Phung2', '~Gustavo_Carneiro1', '~Thanh-Toan_Do4']",
         "Model and Feature Diversity for Bayesian Neural Networks in Mutual Learning",
         "Bayesian Neural Networks (BNNs) offer probability distributions for model parameters, enabling uncertainty quantification in predictions. However, they often underperform compared to deterministic neural networks. Utilizing mutual learning can effectively enhance the performance of peer BNNs. In this paper, we propose a novel approach to improve BNNs performance through deep mutual learning. The proposed approaches aim to increase diversity in both network parameter distributions and feature distributions, promoting peer networks to acquire distinct features that capture different characteristics of the input, which enhances the effectiveness of mutual learning. Experimental results demonstrate significant improvements in the classification accuracy, negative log-likelihood, and expected calibration error when compared to traditional mutual learning for BNNs.",
         "Reviewer_tB5V",
         "1688619721309",
         "1702411034147",
         "4",
         "4",
         "2",
         "3",
         "2",
         "The paper focuses on improving the accuracy of BNNs by promoting diversity in both parameter space and feature space while training two peer BNNs with mutual learning between them. More specifically, they train two variational BNNs with a mean-field Gaussian variational loss for each along with a KL divergence term between the (temperature-scaled) predictive distributions of the two models, a Wasserstein distance term between the corresponding approximate posterior distributions across the two models (added as a softplus(-distance) term), and a KL divergence term between corresponding feature distributions. On the latter term, instead of directly maximizing the distance between corresponding feature distributions, they instead do so on \"fused feature distributions\". To do so, they use learned cross-attention to fuse the features from multiple feature levels in a model (two at a time). Then, they use the KL divergence between the distributions of the fused feature distributions of the two peer networks. To derive the distributions, they use the conditional probability density defined as $p_{i|j} = \\frac{K(F'_i, F'_j)}{sum_{k=1, k \\noteq i}^n K(F'_k, F'_j)}$, where $K(F'_a, F'_b)$ is a kernel function between two fused feature representations. Given those conditional probs, they compute a KL divergence term. Similar to the parameter space diversity term, they add this term to the loss as softplus(-divergence). The paper claims to be the first to propose maximizing the distance between feature distributions to promote diversity. In terms of experiments, the paper includes results for ResNet models on CIFAR-10/100 and ImageNet, measuring accuracy, NLL, and ECE as metrics, and comparing different approaches. The paper does a great job of precisely articulating the modeling approach, and discussing the relevant background info. More specifically, the proposed approach of adding terms to promote diversity in parameter and feature space is clear and would be easy to reimplement. My main concern is with the experiment section. More specifically, a few key details are unclear in the text, and importantly a deterministic baseline is missing that I believe should be present given the framing of the paper and relevant literature. Please see the Questions below. Given updates, I believe the paper would be great and I would gladly update my rating. Main:\n- In the experiments, a few details are currently unclear. The following points are on Table 1, but generalize to all three tables. Please clarify these details here and in the paper.\n  - Consider the ResNet20 section of Table 1. Is my understanding correct that the \"ResNet20\" results are for a pair of BNNs trained from scratch, while the \"ResNet20*\" results are for a pair of BNNs trained with the approximate posterior means set to the values from a deterministic model?\n  - Is it correct that all results (all three metrics across all three approaches) are computed after averaging the predicted probs from the pair of models?\n- For the experiments, a deterministic baseline is missing. Given the intro that discusses how BNNs can lag behind deterministic models in acc (though not always), the experiments lack a comparison. It would be helpful to understand how the proposed approach compares to a deterministic baselines, specifically a single deterministic model and a size-2 deep ensemble. Could you add this as a baseline? I would consider this to be a blocker for the paper given the framing and relevant literature.\n\nOther:\n- The KL divergence term is scaled by the square of the temperature -- why?\n- How did you choose the values for temp, alpha, and beta? They differ between CIFAR-10/100 and ImageNet. Did you ablate values?\n\nMinor comments:\n- updating lines 17 & 22 of Alg 1 could be helpful for readability No limitations are included.",
         "603",
         "0",
         "0",
         "0.716",
         "0.1269510582",
         "0.8272995353",
         "216",
         "159",
         "44.5054",
         "11.6554",
         "14.3602",
         "13.5265",
         "13.0494",
         "0.46430000000000005",
         "87",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2736",
         "os2BdbiGwX",
         "5872",
         "1683693150017",
         "['~Cuong_Pham3', '~Cuong_C._Nguyen1', '~Trung_Le2', '~Dinh_Phung2', '~Gustavo_Carneiro1', '~Thanh-Toan_Do4']",
         "Model and Feature Diversity for Bayesian Neural Networks in Mutual Learning",
         "Bayesian Neural Networks (BNNs) offer probability distributions for model parameters, enabling uncertainty quantification in predictions. However, they often underperform compared to deterministic neural networks. Utilizing mutual learning can effectively enhance the performance of peer BNNs. In this paper, we propose a novel approach to improve BNNs performance through deep mutual learning. The proposed approaches aim to increase diversity in both network parameter distributions and feature distributions, promoting peer networks to acquire distinct features that capture different characteristics of the input, which enhances the effectiveness of mutual learning. Experimental results demonstrate significant improvements in the classification accuracy, negative log-likelihood, and expected calibration error when compared to traditional mutual learning for BNNs.",
         "Reviewer_xPiJ",
         "1688880771624",
         "1702411034066",
         "5",
         "4",
         "3",
         "3",
         "3",
         "This paper presents a novel method for enhancing the performance of Bayesian Neural Networks (BNNs) by employing deep mutual learning. The proposed approach aims to enhance the diversity of both network parameter distributions and feature distributions, encouraging individual networks to capture unique characteristics of the input data. The effectiveness of the proposed method is demonstrated on datasets, including CIFAR10, CIFAR100, and ImageNet. The proposed method improves performance and uncertainty estimation while reducing the expected calibration error (ECE).  The technical approach is novel as the method introduces mutual learning in the context of BNNs and first to propose maximizing the distance between feature distributions and parameter distributions. The paper includes large scale data experiments (ImageNet) and ablation studies to demonstrate the effectiveness of each technical contribution introduced in this paper. The previous studies mentioned in the paper utilize alignments on feature maps \\[4\\] or predictions \\[38\\], rather than diversifying them. In contrast, the proposed method diversifies both feature distributions and parameter distributions which is an opposite approach to the previous works. Interestingly, both alignment-based and diversification methods improves performance over vanilla BNNs, as indicated in Table 1, 2, 3, and 5. However, the paper does not explicitly explain the reasons behind the performance improvements resulting from these contrasting approaches.\n\nGiven the observed contradicting results in the experiments, where the alignment-based method (DML \\[38\\]) also enhances the performance of BNNs, an important question arises: could combining alignment-based methods with parameter diversification further improve BNN performance? Alternatively, is it necessary to diversify both feature and parameter distributions to achieve significant improvements?\n\nIn the experiment section, the proposed method is only compared with \\[38\\] and not with \\[4\\]. \n\nHyperparameters used for CIFAR experiments and ImageNet experiments are different. However, the paper does not describe details regarding the hyperparameter tuning or determination. 3 block resnet is used for CIFAR experiments while 4 block resnet is used for ImageNet experiments. Why different form of resents are used for different datasets? Limitations are shortly addressed in the supplementary.",
         "331",
         "5",
         "0",
         "0.7494000000000001",
         "0.0582251082",
         "0.8471010923000001",
         "216",
         "156",
         "15.9032",
         "15.6095",
         "18.4734",
         "16.4588",
         "17.2909",
         "0.07200000000000001",
         "93",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2881",
         "o7W0Zet6p3",
         "2072",
         "1683270662244",
         "['~Chandra_Sekhar_Mukherjee1', '~Pan_Peng1', '~Jiapeng_Zhang2']",
         "Recovering Unbalanced Communities in the Stochastic Block Model with Application to Clustering with a Faulty Oracle",
         "The stochastic block model (SBM) is a fundamental model for studying graph clustering or community detection in networks. It has received great attention in the last decade and the balanced case, i.e., assuming all clusters have large size, has been well studied. \nHowever, our understanding of SBM with unbalanced communities (arguably, more relevant in practice) is still limited. In this paper, we provide a simple SVD-based algorithm for recovering the communities in the SBM with communities of varying sizes.\nWe improve upon a result of Ailon, Chen and Xu [ICML 2013; JMLR 2015] by removing the assumption that there is a large interval such that the sizes of clusters do not fall in, and also remove the dependency of the size of the recoverable clusters on the number of underlying clusters. We further complement our theoretical improvements with experimental comparisons.\nUnder the planted clique conjecture, the size of the clusters that can be recovered by our algorithm is nearly optimal (up to poly-logarithmic factors) when the probability parameters are constant. \n\nAs a byproduct, we obtain an efficient clustering algorithm with sublinear query complexity in a faulty oracle model, which is capable of detecting all clusters larger than $\\tilde{\\Omega}({\\sqrt{n}})$, even in the presence of $\\Omega(n)$ small clusters in the graph. In contrast, previous efficient algorithms that use a sublinear number of queries are incapable of recovering any large clusters if there are more than $\\tilde{\\Omega}(n^{2/5})$ small clusters.",
         "Reviewer_5GRr",
         "1688035350092",
         "1702410818300",
         "7",
         "3",
         "4",
         "4",
         "3",
         "This paper studies a classic problem of recovering clusters in a random graph. Concretely, the authors consider the stochastic block model. Here there is an underlying graph on n nodes. The n nodes are partitioned into k unknown clusters. There is then an edge independently between any two nodes in the same cluster with probability p and between any two in different clusters with probability q < p.\n\nThis is an extensively studied problem and many algorithms have been designed that allow the recovery of all clusters of a reasonable size (somewhat larger than sqrt(n), which is anyway a requirement for computational efficiency under the planted clique conjecture). The previous state of the art allows recovering clusters under two assumptions (here simplified for clarity and brevity):\n\n1. The clusters to recover have size at least max(sqrt(n), k)/(p-q).\n2. There is a number alpha of about sqrt(n)/(p-q) such that no cluster has size in the interval \\[alpha/C, alpha\\] for a constant C.\n\nThe assumption that the cluster sizes are at least sqrt(n) for those to be recovered is natural as mentioned above. However, the dependency on k is unfortunate when there are many small clusters. These would prevent the recovery of medium sizes clusters when k >> sqrt(n). Secondly, the assumption about the empty interval is quite unnatural.\n\nThe main contribution of this work is to remove the dependency on k in 1. and to remove the assumption 2. all together.\n\nThe authors also present applications of their algorithm in the related problem of clustering with a faulty oracle. Here one can ask whether two nodes v, w are in the same cluster or not. One is then returned a noise answer. Here the paper also improves over the state of the art in terms of the cardinality of clusters that can be recovered. -The problem studied is fundamental in graph clustering.\n-Removing the dependency on k and the requirement of an empty interval of cluster sizes is significant and the algorithm guarantees of the algorithm much more natural than previously\n-The authors have implemented their algorithm and compared experimentally to previous work. The comparison is overall in favour of the new algorithm. -I know this is a theoretical contribution, and also the authors probably did not attempt to optimize constants that much, but a factor 2^13 in the guarantees is quite severe in practice. Hopefully and probably, this constant is smaller in practice. -Could you say a bit about the running time of your algorithm in practice compared to previous work?\n-Can you comment on whether the 2^13 constant can be reduced to a more reasonable constant without too much effort? Yes",
         "442",
         "0",
         "2",
         "0.7448",
         "0.0261784512",
         "0.9240825176",
         "221",
         "166",
         "47.9531",
         "10.775",
         "13.6783",
         "13.1499",
         "10.6455",
         "0.1585",
         "107",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2882",
         "o7W0Zet6p3",
         "2072",
         "1683270662244",
         "['~Chandra_Sekhar_Mukherjee1', '~Pan_Peng1', '~Jiapeng_Zhang2']",
         "Recovering Unbalanced Communities in the Stochastic Block Model with Application to Clustering with a Faulty Oracle",
         "The stochastic block model (SBM) is a fundamental model for studying graph clustering or community detection in networks. It has received great attention in the last decade and the balanced case, i.e., assuming all clusters have large size, has been well studied. \nHowever, our understanding of SBM with unbalanced communities (arguably, more relevant in practice) is still limited. In this paper, we provide a simple SVD-based algorithm for recovering the communities in the SBM with communities of varying sizes.\nWe improve upon a result of Ailon, Chen and Xu [ICML 2013; JMLR 2015] by removing the assumption that there is a large interval such that the sizes of clusters do not fall in, and also remove the dependency of the size of the recoverable clusters on the number of underlying clusters. We further complement our theoretical improvements with experimental comparisons.\nUnder the planted clique conjecture, the size of the clusters that can be recovered by our algorithm is nearly optimal (up to poly-logarithmic factors) when the probability parameters are constant. \n\nAs a byproduct, we obtain an efficient clustering algorithm with sublinear query complexity in a faulty oracle model, which is capable of detecting all clusters larger than $\\tilde{\\Omega}({\\sqrt{n}})$, even in the presence of $\\Omega(n)$ small clusters in the graph. In contrast, previous efficient algorithms that use a sublinear number of queries are incapable of recovering any large clusters if there are more than $\\tilde{\\Omega}(n^{2/5})$ small clusters.",
         "Reviewer_MiyQ",
         "1688635218330",
         "1702410818232",
         "7",
         "3",
         "4",
         "3",
         "4",
         "This work studies stochastic block models where blocks/clusters can have different sizes. It proposed a simple SVD algorithm which recovers communities in this setting. The main technical improvement of this work is that the assumption is removed which requires there to be a ‘size interval’ where no clusters appear. \nA secondary result is a efficient clustering algorithm with sublinear query complexity. \n -\tThis work is a clear improvement over the previous state-of-the-art. As I understand it, a key technical contribution of this work that might influence future work is instead of finding $k$ clusters as is done using the SVD approach, the algorithm first aims to find large clusters one-by-one. Although these are not perfect (they form a so-called plural set), using some non-trivial techniques perfect recovery can be obtained. \n- Experiments on synthetic data indicate that the algorithm not only works well in theory but also in practice.\n- The write-up of this work is excellent. -\tGiven that the aim of the studied setting is to look at more realistic settings, I would have expected to find experimental results on real-world datasets as well. Although this work does provide better bounds for SBMs generated with differently sized clusters, SBMs still have a highly symmetric structure compared to real-world graphs. It would be interesting to see the performance of the proposed algorithm on some real-world graphs.  -\tHow does the algorithm compare with respect to the previous work in terms of running time?\n- In practice the Spectral Clustering algorithm performs well in practice on graphs with clusters of unbalanced size. Even though not many bounds are known of spectral clustering with respect to SBMs, did you try to compare your algorithm experimentally with Spectral Clustering? none",
         "288",
         "0",
         "1",
         "0.795",
         "0.1212698413",
         "0.9042724371",
         "221",
         "159",
         "46.453",
         "11.4505",
         "14.6122",
         "13.8674",
         "12.8447",
         "0.19690000000000002",
         "98",
         "1",
         "1",
         "0",
         "0"
        ],
        [
         "2883",
         "o7W0Zet6p3",
         "2072",
         "1683270662244",
         "['~Chandra_Sekhar_Mukherjee1', '~Pan_Peng1', '~Jiapeng_Zhang2']",
         "Recovering Unbalanced Communities in the Stochastic Block Model with Application to Clustering with a Faulty Oracle",
         "The stochastic block model (SBM) is a fundamental model for studying graph clustering or community detection in networks. It has received great attention in the last decade and the balanced case, i.e., assuming all clusters have large size, has been well studied. \nHowever, our understanding of SBM with unbalanced communities (arguably, more relevant in practice) is still limited. In this paper, we provide a simple SVD-based algorithm for recovering the communities in the SBM with communities of varying sizes.\nWe improve upon a result of Ailon, Chen and Xu [ICML 2013; JMLR 2015] by removing the assumption that there is a large interval such that the sizes of clusters do not fall in, and also remove the dependency of the size of the recoverable clusters on the number of underlying clusters. We further complement our theoretical improvements with experimental comparisons.\nUnder the planted clique conjecture, the size of the clusters that can be recovered by our algorithm is nearly optimal (up to poly-logarithmic factors) when the probability parameters are constant. \n\nAs a byproduct, we obtain an efficient clustering algorithm with sublinear query complexity in a faulty oracle model, which is capable of detecting all clusters larger than $\\tilde{\\Omega}({\\sqrt{n}})$, even in the presence of $\\Omega(n)$ small clusters in the graph. In contrast, previous efficient algorithms that use a sublinear number of queries are incapable of recovering any large clusters if there are more than $\\tilde{\\Omega}(n^{2/5})$ small clusters.",
         "Reviewer_tK15",
         "1688658573598",
         "1702410818163",
         "5",
         "1",
         "3",
         "4",
         "2",
         "The authors consider the problem of perfect recovery in a stochastic block model where the average degree is large and where the groups are not balanced. They provide an algorithm based on singular value decomposition to recover recursively the largest clusters. They provide a few numerical experiments illustrating their claims. The authors apply their results to the problem of clustering with a faulty oracle. I have little knowledge as to this problem of perfect recovery in a dense SBM and I am not able to assess the correctness of the claims and their relevance.\n The same. Maybe the authors could precise the complexity of the algorithm 1. In experiment 6 it seems the authors are able to run this algorithm for n substantially larger than the other experiments. The authors could go to higher n and test how tight are their bounds; in particular taking p and q smaller.\n\nA small section to conclude the article and for future work would be appreciable.\n\nSome references are ill-formatted. Eg ref. 27 \"svd\" –> \"SVD\".\nInconsistency: plural set vs plural-set. The same.",
         "180",
         "0",
         "4",
         "0.7694000000000001",
         "0.1152568922",
         "0.9103051424",
         "221",
         "159",
         "52.27",
         "9.6744",
         "12.4471",
         "12.0099",
         "9.4213",
         "0.2025",
         "105",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "2884",
         "o7W0Zet6p3",
         "2072",
         "1683270662244",
         "['~Chandra_Sekhar_Mukherjee1', '~Pan_Peng1', '~Jiapeng_Zhang2']",
         "Recovering Unbalanced Communities in the Stochastic Block Model with Application to Clustering with a Faulty Oracle",
         "The stochastic block model (SBM) is a fundamental model for studying graph clustering or community detection in networks. It has received great attention in the last decade and the balanced case, i.e., assuming all clusters have large size, has been well studied. \nHowever, our understanding of SBM with unbalanced communities (arguably, more relevant in practice) is still limited. In this paper, we provide a simple SVD-based algorithm for recovering the communities in the SBM with communities of varying sizes.\nWe improve upon a result of Ailon, Chen and Xu [ICML 2013; JMLR 2015] by removing the assumption that there is a large interval such that the sizes of clusters do not fall in, and also remove the dependency of the size of the recoverable clusters on the number of underlying clusters. We further complement our theoretical improvements with experimental comparisons.\nUnder the planted clique conjecture, the size of the clusters that can be recovered by our algorithm is nearly optimal (up to poly-logarithmic factors) when the probability parameters are constant. \n\nAs a byproduct, we obtain an efficient clustering algorithm with sublinear query complexity in a faulty oracle model, which is capable of detecting all clusters larger than $\\tilde{\\Omega}({\\sqrt{n}})$, even in the presence of $\\Omega(n)$ small clusters in the graph. In contrast, previous efficient algorithms that use a sublinear number of queries are incapable of recovering any large clusters if there are more than $\\tilde{\\Omega}(n^{2/5})$ small clusters.",
         "Reviewer_Ajy4",
         "1688723073534",
         "1702410818068",
         "5",
         "4",
         "3",
         "3",
         "2",
         "The paper deals with the problem of community detection for unbalanced community sizes. Specifically, the paper concentrates on the situation where both large (O(\\sqrt{n})) and small communities exist in the network. The paper proposes a stepwise method of recovering the large clusters in the presence of small clusters for planted clique SBM and faulty oracle models. The main strengths of the paper are as follows - \n\n(1) The paper addresses a gap in the literature on the simultaneous recovery of large and small communities in networks.\n\n(2) The paper deals with the problem of community recovery of large communities in the presence of small communities. The paper provides a stepwise method of recovering large communities in planted clique SBM and faulty oracle models.\n\n(3) The paper provides theoretical results supporting the recovery of large communities by overcoming the \"small cluster barrier\" of the size of the remaining small clusters.\n\n(4) The paper is well-written. The main weaknesses of the paper are as follows - \n\n(1) The paper misses some relevant literature. Such as - Li, Tianxi, et.al. \"Hierarchical community detection by recursive partitioning.\" Journal of the American Statistical Association 117, no. 538 (2022): 951-968. It describes an algorithm that is very similar to the algorithm proposed in this work.\n\n(2) Algorithms 2 and 3 assumes the knowledge of p and q, which are very strong assumptions. It is not immediately clear how the algorithm can be extended for general SBM.\n\n(3) The stopping criterion of the proposed algorithm is not clear. \n (1) Does the proposed algorithm assume the knowledge of p and q?\n\n(2) Does the proposed algorithm assume the knowledge of the number of communities, or is there a stopping criteria of the proposed algorithm for recovery of the number of large communities? N/A",
         "295",
         "1",
         "2",
         "0.6443",
         "0.0658666667",
         "0.9451859593",
         "221",
         "158",
         "42.8963",
         "11.0941",
         "14.0926",
         "13.2809",
         "10.7781",
         "0.1041",
         "98",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2885",
         "o7HckkxOZH",
         "11676",
         "1683800438866",
         "['~Xin_Cheng4', '~Yuzhou_Cao1', '~Haobo_Wang1', '~Hongxin_Wei1', '~Bo_An2', '~Lei_Feng1']",
         "Regression with Cost-based Rejection",
         "Learning with rejection is an important framework that can refrain from making predictions to avoid critical mispredictions by balancing between prediction and rejection. Previous studies on cost-based rejection only focused on the classification setting, which cannot handle the continuous and infinite target space in the regression setting. In this paper, we investigate a novel regression problem called regression with cost-based rejection, where the model can reject to make predictions on some examples given certain rejection costs. To solve this problem, we first formulate the expected risk for this problem and then derive the Bayes optimal solution, which shows that the optimal model should reject to make predictions on the examples whose variance is larger than the rejection cost when the mean squared error is used as the evaluation metric. Furthermore, we propose to train the model by a surrogate loss function that considers rejection as binary classification and we provide conditions for the model consistency, which implies that the Bayes optimal solution can be recovered by our proposed surrogate loss. Extensive experiments demonstrate the effectiveness of our proposed method.",
         "Reviewer_mRfi",
         "1688305573631",
         "1702411342722",
         "7",
         "4",
         "3",
         "3",
         "4",
         "Learning with rejection is an important machine learning problem. Most of the existing papers focus on the classification setting, i.e., classification with rejection and selective classification, and seldom works are targeting at the regression setting. This paper aims to investigate regression with cost-based rejection. Although some papers have studied the selective regression problem, I consider that the problem of regression with cost-based rejection is new. \n\nTo solve this new problem, this paper gives a formulation of the expected risk and derives the Bayes optimal solution. To train an ideal model, this paper also proposes a surrogate loss function that regards rejection as binary classification and provides conditions for the consistency. Experiments are conducted to demonstrate the effectiveness of the proposed.\n - The problem of regression with cost-based rejection is interesting and new.\n\n- It is quite important to give the formulation of expected risk for cost-based rejection and the Bayes optimal solution is meaningful and significant, which might serve as a pioneer for follow-up works to check whether the derived model and rejector are consistent when the mean squared error is used as the evaluation metric.\n\n- A reasonable approach to training a good regression model with rejection is proposed and theoretical analyses are provided.\n\n- Experimental results are significant, which supports the importance of considering cost-based rejection in the regression setting.\n In Theorem 4, I notice that the authors did not introduce the concept \"classification calibrated binary classification loss\". For this concept, I also think that some references are required, e.g., \\[1\\] and \\[2\\].\n\n\\[1\\] P. Bartlett et al. Convexity, classification, and risk bounds. JASA 2006.\n\\[2\\] A. Tewari and P. Bartlett. On the consistency of multi-class classification methods. JMLR 2007.\n\n- I also notice that the first two cited references are repeated. I would suggest that the authors should further check the details of the references.\n\n- I also find some typos in this paper, e.g., missing a right parenthesis in Eq. (2).\n\n- It will be interesting to give a general Bayes optimal solution for arbitrary regression losses, instead of limiting to the mean squared error.\n Compared with the selective setting, what is the key challenge of the proposed setting regression with cost-based rejection? The authors are encouraged to further explain this point.\n\n N/A",
         "377",
         "4",
         "5",
         "0.7627",
         "0.1920622481",
         "0.9567770958",
         "215",
         "163",
         "40.7967",
         "11.1043",
         "14.6653",
         "13.639",
         "11.6591",
         "0.2025",
         "102",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2886",
         "o7HckkxOZH",
         "11676",
         "1683800438866",
         "['~Xin_Cheng4', '~Yuzhou_Cao1', '~Haobo_Wang1', '~Hongxin_Wei1', '~Bo_An2', '~Lei_Feng1']",
         "Regression with Cost-based Rejection",
         "Learning with rejection is an important framework that can refrain from making predictions to avoid critical mispredictions by balancing between prediction and rejection. Previous studies on cost-based rejection only focused on the classification setting, which cannot handle the continuous and infinite target space in the regression setting. In this paper, we investigate a novel regression problem called regression with cost-based rejection, where the model can reject to make predictions on some examples given certain rejection costs. To solve this problem, we first formulate the expected risk for this problem and then derive the Bayes optimal solution, which shows that the optimal model should reject to make predictions on the examples whose variance is larger than the rejection cost when the mean squared error is used as the evaluation metric. Furthermore, we propose to train the model by a surrogate loss function that considers rejection as binary classification and we provide conditions for the model consistency, which implies that the Bayes optimal solution can be recovered by our proposed surrogate loss. Extensive experiments demonstrate the effectiveness of our proposed method.",
         "Reviewer_J2H6",
         "1688367278157",
         "1702411342582",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper addresses problem of regression with the reject option. The authors propose the cost-based formulation of an optimal reject-option regression rule and they derive (Bayes) optimal strategy for the case the distribution is known. The authors further propose a surrogate loss to learn the reject-option regression rule from examples. They prove the the consistency and regret bounds for the proposed learning approach. The paper is sound and it is very clearly written.\n\nThe proposed method based on surrogate loss is simple and potentially effective. \n\nThe authors derive theoretical guarantees for the proposed estimator, namely, they show the consistency and the regret bound. The first contribution, i.e. formulation of the cost-based reject option regression and the optimal solution, is a known result. E.g. it is given in \\[41\\], see equation (1) of the paper. Besides \\[41\\], deriving the optimal strategy for a generic reject option predictor (of which the regression with L2-loss is a special case) is straightforward and appears in pattern recognition textbooks, e.g. Schlesinger et al. Ten Lectures on Statistical and Structural Pattern Recognition. Springer 2002.\n\nThe proposed method, based on minimizing the surrogate loss, is not compared against any baseline solution nor any existing methods for learning reject option regression. As a result, when there is no reference, it is difficult to judge about efficiency of the proposed method. The minimal solution would be to use synthetic data with known ground-truth. On real data one could use any regression model which outputs estimate p(y|x), like e.g. Bayesian methods, and plugin Bayes rule.  The author may argue that most existing methods formulate the optimal reject-option regression using the concept of selective risk and coverage \\[41\\]\\[20\\]\\[38\\]. However, all methods (including the proposed approach) can be compared in terms of the selective risk and the coverage which are reported by the authors anyway in the experiments (section 5) although the authors use different terminology. Namely, the selective risk is denoted as the \"accepted loss\" AL and the coverage equals 1 - rejection rate (RR). Note the cost-based formulation and the selective risk vs. coverage formulation (known as the bounded-improvement or bounded-abstention rejection models) are equivalent in the sense that both lead to the same Bayes-optimal solution, i.e. setting the rejection cost (as in the paper under review) has the same effect as setting threshold on the coverage (or the selective risk), see e.g. Franc et al. Optimal strategies for reject option classifiers. JMLR 2023. \n\nMinor problems:\n\n- Regarding the experiments in sec 5, errors observed on AgeDB dataset are excessively large. The mean error ~100, reported for the standard regression model (sup), makes no sense for age prediction regardless whether the authors report MAE or L2-loss which is not clear from the description.\n\n- The observations derived from the experiments (section 5.5) are questionable or trivial: \"(1) Our proposed method significantly outperforms the supervised reression method\" It is not clear in what sense the propsed method is better as it solves a different problem than the non-reject model. \"(2) In most cases, the average loss of our method in the accepted test instances (AL) is always smaller than the average loss of the supervised regression model\"; note that this holds true for any rejection rule regardless how good the rejector $r(x)$ is. Similarly the obsevation (3) is obvious and it hold for any rejection rule.\n\n- Line 273: \"...RcR loss (RcRLoss) decreases\" -> increases Please explain reasons for not using any baseline method in the experimental evaluation?\n\n---\nThe authors satisfactorily addressed my questions in the rebuttal based on which I increased my ratings. yes",
         "595",
         "5",
         "7",
         "0.7653000000000001",
         "0.0944454887",
         "0.9090781212",
         "215",
         "162",
         "43.0329",
         "11.5607",
         "15.2826",
         "14.1701",
         "12.8399",
         "0.2968",
         "102",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "2887",
         "o7HckkxOZH",
         "11676",
         "1683800438866",
         "['~Xin_Cheng4', '~Yuzhou_Cao1', '~Haobo_Wang1', '~Hongxin_Wei1', '~Bo_An2', '~Lei_Feng1']",
         "Regression with Cost-based Rejection",
         "Learning with rejection is an important framework that can refrain from making predictions to avoid critical mispredictions by balancing between prediction and rejection. Previous studies on cost-based rejection only focused on the classification setting, which cannot handle the continuous and infinite target space in the regression setting. In this paper, we investigate a novel regression problem called regression with cost-based rejection, where the model can reject to make predictions on some examples given certain rejection costs. To solve this problem, we first formulate the expected risk for this problem and then derive the Bayes optimal solution, which shows that the optimal model should reject to make predictions on the examples whose variance is larger than the rejection cost when the mean squared error is used as the evaluation metric. Furthermore, we propose to train the model by a surrogate loss function that considers rejection as binary classification and we provide conditions for the model consistency, which implies that the Bayes optimal solution can be recovered by our proposed surrogate loss. Extensive experiments demonstrate the effectiveness of our proposed method.",
         "Reviewer_4Fnw",
         "1688454597714",
         "1702411342426",
         "5",
         "3",
         "3",
         "3",
         "3",
         "This paper focuses on the problem of regression with rejection, specifically the approach of specifing a cost function and learn the pair of regressor and rejector at the same time. The paper prensents a concrete path to solving the problem. It first properly defines the problem and shows the Bayes optimal solution to it. Since the Bayes optimal solution requires knowing the expectation and the variance of the underlying distribution, it then proposes a learnable risk defined using surrogate loss function. Then, the paper theoretically investigate and show the usefullness of the proposed approach, from the perspective of classification calibration and error bound. Finally it empirically evaluates the proposed method on several typical datsets using various metrics.\n Originality:\nThis paper tackles the regression with rejection problem which is of significant importance in the field. The paper solves the problem from a novel perspective and can be seen as a novel combination of several well-known techniques. This paper addresses clearly how it is related and different from related publications.\n\nQuality:\nThe paper is technically sound and self-contained. Its claims are properly supported by theoretical demonstrations.\n\nClarity:\nThe paper is clearly written and easy to follow. The structual is well organized.\n\nSignificance:\nThe proposed method has significance to some extent, as it considers a new approach to an important problem.  - Empricail comparison is no sufficiently conducted.\n  - There is no comparison with existing methods. \n  - There is no investigation on varying cost.\n  - There is no investigation on slow-start. This would show the robustness of the proposed method, since slow-start introduces a hyper-parameter to the method.\n  - There is no investigation on varying training data size. Some theoretical results shows how performance would change on different $n$. It would be pursuative to show it empirically to some extent.\n - For the cost funciton $c(x)$, it is used as a function on $x$ instead of a constant in theoretical demonstrations but considered as a constant in experiments. Does theoretical results has some relationship or limitation on the form of the pointwise cost function? Does some results rely on cost being a non-constant function?\n\n- Are there any detailed discussion on the slow-start mechanism, since is part is not covered by any theory but has crucial practical importance? For example, how the slow-start epochs affect the overall performance? Can we completely stop the learning of $h$ after the slow-start epochs?\n Techinal limitations on loss function are addressed by authors in appendix.\n",
         "408",
         "0",
         "0",
         "0.7296",
         "0.0872130395",
         "0.9402728677000001",
         "215",
         "161",
         "39.212",
         "11.2252",
         "14.3091",
         "13.3042",
         "11.3195",
         "0.0679",
         "100",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2888",
         "o7HckkxOZH",
         "11676",
         "1683800438866",
         "['~Xin_Cheng4', '~Yuzhou_Cao1', '~Haobo_Wang1', '~Hongxin_Wei1', '~Bo_An2', '~Lei_Feng1']",
         "Regression with Cost-based Rejection",
         "Learning with rejection is an important framework that can refrain from making predictions to avoid critical mispredictions by balancing between prediction and rejection. Previous studies on cost-based rejection only focused on the classification setting, which cannot handle the continuous and infinite target space in the regression setting. In this paper, we investigate a novel regression problem called regression with cost-based rejection, where the model can reject to make predictions on some examples given certain rejection costs. To solve this problem, we first formulate the expected risk for this problem and then derive the Bayes optimal solution, which shows that the optimal model should reject to make predictions on the examples whose variance is larger than the rejection cost when the mean squared error is used as the evaluation metric. Furthermore, we propose to train the model by a surrogate loss function that considers rejection as binary classification and we provide conditions for the model consistency, which implies that the Bayes optimal solution can be recovered by our proposed surrogate loss. Extensive experiments demonstrate the effectiveness of our proposed method.",
         "Reviewer_1UF6",
         "1688719535523",
         "1702411342325",
         "5",
         "4",
         "3",
         "3",
         "2",
         "The paper explores the framework of regression with rejection, in which the model can opt to refrain from making predictions on certain instances at specific costs, with the intention of avoiding critical mispredictions. The paper determines the Bayes optimal solution and introduces a theoretically grounded surrogate loss within the framework. 1. The paper is pioneering in studying the regression with rejection setting.\n2. The presentation of the paper is clear and concise. 1. While the regression with rejection setting represents a fresh concept in the literature, the technical approach seems to closely mirror the standard classification with rejection setting. This resemblance potentially limits the novelty of the paper. Could the authors elaborate on the specific technical challenges encountered within this setting?\n\n2. A definition of regressor-consistency that parallels rejector-calibration (Definition 3) is missing. \n\n3. The use of a supervised regression method may not serve as an appropriate and fair baseline for rejection experiments. It would be more convincing to conduct experiments comparing some straightforward rejection methods against the proposed rejection methods.\n\n4. Additional commentary on the experimental results is required. For instance, the setup considers a range of binary classification loss functions; which among these yields the best results based on the experiments conducted?\n\n See Weakness. N/A.",
         "207",
         "0",
         "8",
         "0.7717",
         "0.2232993197",
         "0.9485222101",
         "215",
         "158",
         "25.848",
         "13.9394",
         "18.4942",
         "15.9032",
         "15.3185",
         "0.1041",
         "101",
         "0",
         "2",
         "0",
         "0"
        ],
        [
         "3594",
         "l0zLcLGdcL",
         "11973",
         "1683805710414",
         "['~Yuxiang_Lai1', '~Xinghong_Liu1', '~Tao_Zhou5', '~Yi_Zhou8']",
         "Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation",
         "Universal domain adaptation aims to align the classes and reduce the feature gap between the same category of the source and target domains. The target private category is set as the unknown class during the adaptation process, as it is not included in the source domain. However, most existing methods overlook the intra-class structure within a category, especially in cases where there exists significant concept shift between the samples belonging to the same category. When samples with large concept shift are forced to be pushed together, it may negatively affect the adaptation performance. Moreover, from the interpretability aspect, it is unreasonable to align visual features with significant differences, such as fighter jets and civil aircraft, into the same category. Unfortunately, due to such semantic ambiguity and annotation cost, categories are not always classified in detail, making it difficult for the model to perform precise adaptation. To address these issues, we propose a novel Memory-Assisted Sub-Prototype Mining (MemSPM) method that can learn the differences between samples belonging to the same category and mine sub-classes when there exists significant concept shift between them. By doing so, our model learns a more reasonable feature space that enhances the transferability and reflects the inherent differences among samples annotated as the same category. We evaluate the effectiveness of our MemSPM method over multiple scenarios, including UniDA, OSDA, and PDA. Our method achieves state-of-the-art performance on four benchmarks in most cases.",
         "Reviewer_QTwQ",
         "1686539910493",
         "1702411356953",
         "3",
         "5",
         "1",
         "2",
         "2",
         "This paper aims to improve previous Universal Domain Adptation (UniDA) methods by further exploting the intra-class discrimination. For that, they propose a Memory-Assisted Sub-Prototype Mining (MemSPM) method. MemSPM learns to retrieve new task-oriented features given the input embedding features, and apply existing UniDA methods to the retrieving features. The paper also proposes an additional reconstruction task for the demonstration to the explainability of its proposed method as the authors claimed. Experiments on four datasets are conducted on three DA settings. Considering the effect of learning intra-class discrimination for UniDA is indeed an interesting idea to focus on, and such motivation is new in the UniDA community. By exploiting the intra-class structure, the proposed MenSPM is somehow novel to see. Although the motivation from exploiting intra-class structure is interesting to UniDA, the analysis and the evidences to support the effectiveness of such idea is not enough. This is mainly due to the following concerns.\n\n1. Subclasses learning brings additional learning challenge and increases the learning cost to the problem, and not always the case that some classes have obvious subclasses, thus it is hard to say whether forcing subclasses learning would be beneficial to UniDA. To investivage this, I think it should have a solid analysis to the problem.\n\n2. The proposed method introduces too many hyper-parameters to the leanning process, inlcuding $N$, $S$, $K$, $\\lambda$, $\\lambda_1$, $\\lambda_2$, and $\\lambda_3$, etc., and there have not sufficient studies to investigate those hyper-parameters for different datasets or tasks. Note that this is important in UniDA since there is no validation set for model selection. Therefore, it is hard to say whether the effectiveness of the method may come from hyper-parameters tunning.\n\n3. Abalation studies are also not enough to understanding the effectiveness of different loss terms in Equation (8). Although improvements have shown when comparing to the DCC method, but to my knowledge with the CLIP models,  a simple baseline of standard training on source data only may already outperform the proposed method. However, this is not compared in the experiments.\n\n4. The results reported in the ResNet50 are meaningless since the proposed method do not run on this backbone. This is also a limitation of the proposed method. \n\n5. The experiments to verify the effectiveness of the proposed idea only conduct on the DCC method, which is not enough.\n\nThe authors claim that the proposed method could make interpretability from Figure 3, but I do not know how it works for the explainability since reconstruction does not imply interpretability. A random noise could also reconstruct the input.\n\nThe loss of $\\mathcal{L}_{cdd}$ is not illustrated in the paper. It is a bad way to let readers to understand it from other papers as it is not popular. \n\nSome typos exist in the paper, and please carefully check if some formulas are presented correctly, e.g., Equations (2), (6). All weaknesses listed above should be well addressed to improve the paper. The authors have shown some limitations of the proposd method, but more should consider other that the method itself.",
         "505",
         "0",
         "5",
         "0.7445",
         "-0.0014520202000000001",
         "0.8663344979000001",
         "215",
         "183",
         "41.2356",
         "11.8339",
         "13.619",
         "13.5231",
         "12.8228",
         "0.2383",
         "80",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3595",
         "l0zLcLGdcL",
         "11973",
         "1683805710414",
         "['~Yuxiang_Lai1', '~Xinghong_Liu1', '~Tao_Zhou5', '~Yi_Zhou8']",
         "Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation",
         "Universal domain adaptation aims to align the classes and reduce the feature gap between the same category of the source and target domains. The target private category is set as the unknown class during the adaptation process, as it is not included in the source domain. However, most existing methods overlook the intra-class structure within a category, especially in cases where there exists significant concept shift between the samples belonging to the same category. When samples with large concept shift are forced to be pushed together, it may negatively affect the adaptation performance. Moreover, from the interpretability aspect, it is unreasonable to align visual features with significant differences, such as fighter jets and civil aircraft, into the same category. Unfortunately, due to such semantic ambiguity and annotation cost, categories are not always classified in detail, making it difficult for the model to perform precise adaptation. To address these issues, we propose a novel Memory-Assisted Sub-Prototype Mining (MemSPM) method that can learn the differences between samples belonging to the same category and mine sub-classes when there exists significant concept shift between them. By doing so, our model learns a more reasonable feature space that enhances the transferability and reflects the inherent differences among samples annotated as the same category. We evaluate the effectiveness of our MemSPM method over multiple scenarios, including UniDA, OSDA, and PDA. Our method achieves state-of-the-art performance on four benchmarks in most cases.",
         "Reviewer_pJBT",
         "1687825624088",
         "1702411356853",
         "6",
         "5",
         "3",
         "2",
         "2",
         "This work proposes to exploit the intrinsic structures for each class, where sub-prototypes are devised to associate domain-common knowledge for universal domain adaptation. Specifically, MemSPM employs a memory module to mine sub-class information, and a corresponding reconstruction module to derive task-oriented representations. Experiments on representative benchmarks are conducted to verify the effectiveness of the proposed approach.  1, This paper is generally well-written and easy to follow, and neat figures are presented to enable a more intuitive understanding. \n\n2, The motivation for decoupling with subclass structures seems reasonable.\n\n3, The technical details are well explained.  \n\n4, Surpassing previous methods with noticeable margins, justifying its effectiveness.   I think the main drawback of this paper lies in its presentations:\n\n1, Motivations of some designs are not well explained, i.e., why sub-prototypes benefits the universal scenario？ \n\n2, Some technical details seem missing. \n\nThe details of these concerns are presented in the ‘Questions’ part. \n\nMinors: \nPage 5 Line 179: missing space ''\\[17\\]that''\n 1, Why can sub-prototypes benefit the universal domain adaptation scenario? \nI understand that, even within a domain, samples from the same class can be grouped into sub-classes. But, a critical part is missing why this helps the cross-domain association of common classes. which is the core problem for universal domain adaptation. An explanation or empirical justification is needed here, i.e., what is the pattern of retrieved sub-prototypes for common samples and private ones? \n\n2, Some technical details are not comprehensive enough. \n1) Is the memory learnable parameters? How to initialize them? This can be basic knowledge for people familiar with this, but it is still necessary to briefly detail this. \n2) After reading sec 3.5,  it is still unclear to be how the sub-prototypes help align the embeddings \\hat{Z}. \n\n3, In Fig. 1 (c), does this method assume the sub-class of two domains can be matched? This seems unrealistic under the distribution shift. \n\n Yes. ",
         "311",
         "1",
         "1",
         "0.7933",
         "-0.0048850575000000005",
         "0.9108181",
         "215",
         "168",
         "39.9698",
         "10.7748",
         "13.722",
         "12.6198",
         "11.687",
         "0.0795",
         "91",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "3596",
         "l0zLcLGdcL",
         "11973",
         "1683805710414",
         "['~Yuxiang_Lai1', '~Xinghong_Liu1', '~Tao_Zhou5', '~Yi_Zhou8']",
         "Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation",
         "Universal domain adaptation aims to align the classes and reduce the feature gap between the same category of the source and target domains. The target private category is set as the unknown class during the adaptation process, as it is not included in the source domain. However, most existing methods overlook the intra-class structure within a category, especially in cases where there exists significant concept shift between the samples belonging to the same category. When samples with large concept shift are forced to be pushed together, it may negatively affect the adaptation performance. Moreover, from the interpretability aspect, it is unreasonable to align visual features with significant differences, such as fighter jets and civil aircraft, into the same category. Unfortunately, due to such semantic ambiguity and annotation cost, categories are not always classified in detail, making it difficult for the model to perform precise adaptation. To address these issues, we propose a novel Memory-Assisted Sub-Prototype Mining (MemSPM) method that can learn the differences between samples belonging to the same category and mine sub-classes when there exists significant concept shift between them. By doing so, our model learns a more reasonable feature space that enhances the transferability and reflects the inherent differences among samples annotated as the same category. We evaluate the effectiveness of our MemSPM method over multiple scenarios, including UniDA, OSDA, and PDA. Our method achieves state-of-the-art performance on four benchmarks in most cases.",
         "Reviewer_EAMn",
         "1688470917780",
         "1702411356730",
         "6",
         "5",
         "3",
         "2",
         "3",
         "This paper focuses on Universal Domain Adaptation (UniDA), a practical DA setting that does not make any assumptions on the relation between source and target label sets. The goal is to adapt a classifier from source to target domain such that both source and target domains may have their own private classes apart from shared classes. The paper claims that existing UniDA methods overlook the intrinsic structure in the categories, which leads to suboptimal feature learning and adaptation. Hence, they propose memory-assisted sub-prototype mining (MemSPM) that learns sub-prototypes in a memory mechanism to embody the subclasses from the source data. Then, for target samples, weighted sub-prototype sampling is used before passing the embedding to a classifier, which results in reduced domain shift for the embedding. They also propose an adaptive thresholding technique to select relevant sub-prototypes. Finally, they adopt the cycle consistent matching loss objective from DCC \\[24\\] along with an auxiliary reconstruction loss for training. They show results on UniDA, Partial DA, and Open-Set DA using standard benchmarks like Office-31, Office-Home, VisDA, and DomainNet. * The motivating ideas for the approach are interesting and intuitive. Further, the technical contributions are novel as well as effective.\n\n* It is intriguing that the auxiliary reconstruction task provides interpretability, which is usually not possible in existing DA solutions.\n\n* The paper is fairly easy to follow (with the exception of some equations and many typos and grammatical errors, see Weaknesses).\n\n* With their method and the advantages of a CLIP-pretrained ViT model, they achieve large improvements over existing ResNet-based methods. While they also show small improvements over some existing methods using the CLIP-pretrained model, this can serve as a new strong baseline for future UniDA work. * The paper claims that existing UniDA works overlook the internal intrinsic structure in the categories. \n    * However, \\[W1\\] aims to resolve the same problem. \\[W1\\] proposes to learn lower-level visual primitives that are unaffected by the category shift in the higher-level features. And, in their proposed word-prototype-space, different visual primitives can be shared across domains and classes (including unknown classes).\n    * There is a significant overlap in the motivation given by this paper and that of \\[W1\\]. Consequently, the high-level conceptual novelty of this paper is overclaimed. However, I do believe that these conceptual ideas are interesting as well as important for UniDA.\n    * Please discuss the similarities and differences (both in terms of motivation and the actual approach) of this paper w.r.t. \\[W1\\].\n    * Another paper with similar conceptual ideas is \\[W2\\].\n\n* This paper lacks some mathematical rigor.\n    * Eq. 1, 2: $\\hat{Z}=W\\cdot M$ is shown as matrix multiplication (I assume that it is not element-wise multiplication since dimensions of $W$ and $M$ are different), but the expansion of this matrix multiplication contains an arg-max over the elements of $W$. Then, it does not make sense for the overall computation to be a standard matrix multiplication.\n    * Eq. 1, 2: the text mentions that $s_i$ is the index of sub-prototypes in the $i^\\text{th}$ item but Eq. 2 implies that $s_i$ is a particular dimension found with arg-max. This seems contradictory and is confusing.\n    * Eq. 2: Use $\\mathop{\\arg\\max}_{j}$ instead of using `dim=1` since it is a mathematical equation and not the code implementation.\n    * Eq. 5: It is unclear which dimension is used for top-$k$\n    * Eq. 6: It should be $\\max(... , 0)$ instead of just $\\max(...)$.\n\n* The requirement of a CLIP-pretrained backbone is very restrictive since the method cannot be extended to other settings (like medical imaging) where the CLIP-pretraining may be suboptimal. While the paper shows comparisons where prior methods use the CLIP-pretrained model, it should also show comparisons when starting from a random initialization as well as the more widely used ImageNet initialization.\n    * The paper claims that a CLIP backbone is needed to retrieve sub-prototypes in early iterations. Why not start retrieving sub-prototypes after a few epochs of normal training?\n\n* L135: “eliminates the domain-specific information from the target domain”. This is a very strong claim which does not seem to be backed by evidence. Performing “domain alignment” is not the same as “eliminating” domain-specific information. Further, as we can see from Fig. 3, the sub-prototypes seem to be retaining domain-specific information.\n\n* There are no sensitivity analyses for the several loss-balancing hyperparameters $\\lambda_1, \\lambda_2, \\lambda_3$ (not even in the Supplementary). While the paper claims to have borrowed them from DCC, this approach is vastly different from DCC, and we need to check for sensitivity to these hyperparameters. Further, DCC does not have a reconstruction loss, so it is unclear how that hyperparameter is selected.\n\n* There is no ablation study for the adaptive threshold $\\lambda$. It should be compared to various fixed thresholds and the value of the adaptive threshold should also be plotted over the course of training to obtain more insights into its working.\n\n* Other UniDA works, like OVANet \\[40\\] and \\[W1\\], study the sensitivity of their methods to the degree of openness (i.e. the number of shared/private classes) which changes the difficulty of the UniDA problem. This analysis is missing in this paper. This should be shown for a better understanding of the capabilities of the proposed method.\n\n* Some more related work \\[W3-W4\\] on Open-Set DA and UniDA (apart from \\[W1, W2\\]) that is not discussed in this paper.\n\n* Minor problems (typos):\n    * L53: “adaption” → “adaptation”\n    * L59: “shifts” → “shift”\n    * L92: use `unknown’ i.e. use a backquote in LaTeX for it to properly render the opened and closed quotes like in L102. \n    * L119: use math-mode for K in top-$K$.\n    * L124: “varies” → “vary”\n    * L126, 179: add space between text and \\cite{...}\n    * L134: “differenciates $\\hat{Z}$ with” → “differentiates $\\hat{Z}$ from”\n    * L151: “max” → “maximum”\n    * L166: “only the $K$” → “only the top-$K$”\n    * L181: “$max$” → “$\\max$”\n    * L244: “fellow” → “following”\n\n* Minor problems (grammatical errors):\n    * L32: “aims” → “aiming”\n    * L40: “Since such kind” → “Since this type”\n    * L41: “almost happens in all the” → “occurs in almost all of the”\n    * L59: “embedding give into” → “embedding is passed to” \n    * L125: “sometimes is” → “is sometimes”\n\n### References\n\n\\[W1\\] Kundu et al., “Subsidiary Prototype Alignment for Universal Domain Adaptation”, NeurIPS22\n\n\\[W2\\] Liu et al., “PSDC: A Prototype-Based Shared-Dummy Classifier Model for Open-Set Domain Adaptation”, IEEE Transactions on Cybernetics, Dec. 2022\n\n\\[W3\\] Chen et al., “Evidential Neighborhood Contrastive Learning for Universal Domain Adaptation”, AAAI22\n\n\\[W4\\] Garg et al., “Domain Adaptation under Open Set Label Shift”, NeurIPS22 Please see the weaknesses section. \n\nOverall, the technical contributions seem to be novel and intuitive. However, there are significant concerns regarding missing discussions on highly relevant work \\[W1\\], lack of mathematical rigor, missing sensitivity analyses and ablation studies, and the restrictiveness of requiring a CLIP-pretrained backbone. Hence, my rating is “4: borderline reject” at this time but I am willing to update my rating based on the rebuttal and discussion. I appreciate that the paper provides both limitations and broader societal impact discussions in the Supplementary.",
         "1175",
         "2",
         "6",
         "0.7796000000000001",
         "0.0886058638",
         "0.9329913259",
         "215",
         "161",
         "40.4277",
         "11.8362",
         "14.4307",
         "13.747",
         "12.537",
         "0.8137000000000001",
         "93",
         "0",
         "1",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 34,
        "rows": 221
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>tp2nEZ5zfP</td>\n",
       "      <td>501</td>\n",
       "      <td>1682301203358</td>\n",
       "      <td>[~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...</td>\n",
       "      <td>NetHack is Hard to Hack</td>\n",
       "      <td>Neural policy learning methods have achieved r...</td>\n",
       "      <td>Reviewer_83YB</td>\n",
       "      <td>1688501358606</td>\n",
       "      <td>1702410746791</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3798</td>\n",
       "      <td>17.8189</td>\n",
       "      <td>16.2350</td>\n",
       "      <td>17.1793</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>tp2nEZ5zfP</td>\n",
       "      <td>501</td>\n",
       "      <td>1682301203358</td>\n",
       "      <td>[~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...</td>\n",
       "      <td>NetHack is Hard to Hack</td>\n",
       "      <td>Neural policy learning methods have achieved r...</td>\n",
       "      <td>Reviewer_qyRc</td>\n",
       "      <td>1688628255357</td>\n",
       "      <td>1702410746731</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0868</td>\n",
       "      <td>18.3701</td>\n",
       "      <td>16.5131</td>\n",
       "      <td>16.7018</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>tp2nEZ5zfP</td>\n",
       "      <td>501</td>\n",
       "      <td>1682301203358</td>\n",
       "      <td>[~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...</td>\n",
       "      <td>NetHack is Hard to Hack</td>\n",
       "      <td>Neural policy learning methods have achieved r...</td>\n",
       "      <td>Reviewer_PtAe</td>\n",
       "      <td>1688673902510</td>\n",
       "      <td>1702410746634</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8650</td>\n",
       "      <td>13.3097</td>\n",
       "      <td>12.8228</td>\n",
       "      <td>12.1907</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>tp2nEZ5zfP</td>\n",
       "      <td>501</td>\n",
       "      <td>1682301203358</td>\n",
       "      <td>[~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...</td>\n",
       "      <td>NetHack is Hard to Hack</td>\n",
       "      <td>Neural policy learning methods have achieved r...</td>\n",
       "      <td>Reviewer_Ub8t</td>\n",
       "      <td>1689161570330</td>\n",
       "      <td>1702410746563</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4340</td>\n",
       "      <td>17.3766</td>\n",
       "      <td>15.4700</td>\n",
       "      <td>16.0279</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>tp2nEZ5zfP</td>\n",
       "      <td>501</td>\n",
       "      <td>1682301203358</td>\n",
       "      <td>[~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...</td>\n",
       "      <td>NetHack is Hard to Hack</td>\n",
       "      <td>Neural policy learning methods have achieved r...</td>\n",
       "      <td>Reviewer_eWjQ</td>\n",
       "      <td>1689665510650</td>\n",
       "      <td>1702410746491</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>16.5097</td>\n",
       "      <td>19.6259</td>\n",
       "      <td>17.2589</td>\n",
       "      <td>18.8127</td>\n",
       "      <td>0.3146</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15047</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_iUr9</td>\n",
       "      <td>1687915292924</td>\n",
       "      <td>1702411423879</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9391</td>\n",
       "      <td>14.7570</td>\n",
       "      <td>13.5591</td>\n",
       "      <td>11.6987</td>\n",
       "      <td>0.4482</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15048</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_UWwz</td>\n",
       "      <td>1688653360609</td>\n",
       "      <td>1702411423780</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3066</td>\n",
       "      <td>18.9797</td>\n",
       "      <td>16.9020</td>\n",
       "      <td>17.2150</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15049</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_TyeE</td>\n",
       "      <td>1688683891875</td>\n",
       "      <td>1702411423568</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.2400</td>\n",
       "      <td>17.7186</td>\n",
       "      <td>16.0092</td>\n",
       "      <td>16.2817</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15050</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_5HgB</td>\n",
       "      <td>1688710100227</td>\n",
       "      <td>1702411423474</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>13.6674</td>\n",
       "      <td>17.5411</td>\n",
       "      <td>15.7101</td>\n",
       "      <td>14.5116</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15051</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_yxpU</td>\n",
       "      <td>1689139688998</td>\n",
       "      <td>1702411423376</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>11.5661</td>\n",
       "      <td>14.8672</td>\n",
       "      <td>13.8167</td>\n",
       "      <td>12.1900</td>\n",
       "      <td>0.6631</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submission_id  submission_number  submission_creation_date  \\\n",
       "1522     tp2nEZ5zfP                501             1682301203358   \n",
       "1523     tp2nEZ5zfP                501             1682301203358   \n",
       "1524     tp2nEZ5zfP                501             1682301203358   \n",
       "1525     tp2nEZ5zfP                501             1682301203358   \n",
       "1526     tp2nEZ5zfP                501             1682301203358   \n",
       "...             ...                ...                       ...   \n",
       "15047    0VcvYQ3uPh              13335             1683818526320   \n",
       "15048    0VcvYQ3uPh              13335             1683818526320   \n",
       "15049    0VcvYQ3uPh              13335             1683818526320   \n",
       "15050    0VcvYQ3uPh              13335             1683818526320   \n",
       "15051    0VcvYQ3uPh              13335             1683818526320   \n",
       "\n",
       "                                      submission_authors  \\\n",
       "1522   [~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...   \n",
       "1523   [~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...   \n",
       "1524   [~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...   \n",
       "1525   [~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...   \n",
       "1526   [~Ulyana_Piterbarg1, ~Lerrel_Pinto1, ~Rob_Ferg...   \n",
       "...                                                  ...   \n",
       "15047  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "15048  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "15049  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "15050  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "15051  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "1522                             NetHack is Hard to Hack   \n",
       "1523                             NetHack is Hard to Hack   \n",
       "1524                             NetHack is Hard to Hack   \n",
       "1525                             NetHack is Hard to Hack   \n",
       "1526                             NetHack is Hard to Hack   \n",
       "...                                                  ...   \n",
       "15047  Improved Frequency Estimation Algorithms with ...   \n",
       "15048  Improved Frequency Estimation Algorithms with ...   \n",
       "15049  Improved Frequency Estimation Algorithms with ...   \n",
       "15050  Improved Frequency Estimation Algorithms with ...   \n",
       "15051  Improved Frequency Estimation Algorithms with ...   \n",
       "\n",
       "                                     submission_abstract       reviewer  \\\n",
       "1522   Neural policy learning methods have achieved r...  Reviewer_83YB   \n",
       "1523   Neural policy learning methods have achieved r...  Reviewer_qyRc   \n",
       "1524   Neural policy learning methods have achieved r...  Reviewer_PtAe   \n",
       "1525   Neural policy learning methods have achieved r...  Reviewer_Ub8t   \n",
       "1526   Neural policy learning methods have achieved r...  Reviewer_eWjQ   \n",
       "...                                                  ...            ...   \n",
       "15047  Estimating frequencies of elements appearing i...  Reviewer_iUr9   \n",
       "15048  Estimating frequencies of elements appearing i...  Reviewer_UWwz   \n",
       "15049  Estimating frequencies of elements appearing i...  Reviewer_TyeE   \n",
       "15050  Estimating frequencies of elements appearing i...  Reviewer_5HgB   \n",
       "15051  Estimating frequencies of elements appearing i...  Reviewer_yxpU   \n",
       "\n",
       "       creation_date  last_modification_date  review_rating  ...  \\\n",
       "1522   1688501358606           1702410746791              6  ...   \n",
       "1523   1688628255357           1702410746731              7  ...   \n",
       "1524   1688673902510           1702410746634              7  ...   \n",
       "1525   1689161570330           1702410746563              7  ...   \n",
       "1526   1689665510650           1702410746491              6  ...   \n",
       "...              ...                     ...            ...  ...   \n",
       "15047  1687915292924           1702411423879              6  ...   \n",
       "15048  1688653360609           1702411423780              7  ...   \n",
       "15049  1688683891875           1702411423568              7  ...   \n",
       "15050  1688710100227           1702411423474              7  ...   \n",
       "15051  1689139688998           1702411423376              8  ...   \n",
       "\n",
       "       flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "1522                15.3798      17.8189     16.2350   \n",
       "1523                15.0868      18.3701     16.5131   \n",
       "1524                10.8650      13.3097     12.8228   \n",
       "1525                14.4340      17.3766     15.4700   \n",
       "1526                16.5097      19.6259     17.2589   \n",
       "...                     ...          ...         ...   \n",
       "15047               10.9391      14.7570     13.5591   \n",
       "15048               15.3066      18.9797     16.9020   \n",
       "15049               15.2400      17.7186     16.0092   \n",
       "15050               13.6674      17.5411     15.7101   \n",
       "15051               11.5661      14.8672     13.8167   \n",
       "\n",
       "       automated_readability_index politeness_score  hedge_C  hedge_D  \\\n",
       "1522                       17.1793           0.2552      100        2   \n",
       "1523                       16.7018           0.0751       92        0   \n",
       "1524                       12.1907           0.1278       88        0   \n",
       "1525                       16.0279           0.2410      107        0   \n",
       "1526                       18.8127           0.3146       80        0   \n",
       "...                            ...              ...      ...      ...   \n",
       "15047                      11.6987           0.4482       90        1   \n",
       "15048                      17.2150           0.0999       65        1   \n",
       "15049                      16.2817           0.3011       95        1   \n",
       "15050                      14.5116           0.1041       78        0   \n",
       "15051                      12.1900           0.6631      100        0   \n",
       "\n",
       "       hedge_E  hedge_I  hedge_N  \n",
       "1522         0        1        0  \n",
       "1523         0        0        0  \n",
       "1524         0        0        0  \n",
       "1525         0        0        0  \n",
       "1526         1        0        0  \n",
       "...        ...      ...      ...  \n",
       "15047        0        0        2  \n",
       "15048        0        0        0  \n",
       "15049        0        0        0  \n",
       "15050        0        0        0  \n",
       "15051        1        0        0  \n",
       "\n",
       "[221 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Randomly select 50 unique submission IDs from df_iclr\n",
    "selected_iclr_ids = random.sample(df_iclr['submission_id'].unique().tolist(), 50)\n",
    "df_iclr_50 = df_iclr[df_iclr['submission_id'].isin(selected_iclr_ids)]\n",
    "\n",
    "# Randomly select 50 unique submission IDs from df_neurips\n",
    "selected_neurips_ids = random.sample(df_neurips['submission_id'].unique().tolist(), 50)\n",
    "df_neurips_50 = df_neurips[df_neurips['submission_id'].isin(selected_neurips_ids)]\n",
    "\n",
    "# Display the resulting dataframes\n",
    "display(df_iclr_50)\n",
    "display(df_neurips_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_800042/2815283676.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_iclr_50['venue'] = 'iclr'\n",
      "/tmp/ipykernel_800042/2815283676.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_neurips_50['venue'] = 'neurips'\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "bb678043-d029-47c2-b026-7b858c3e0488",
       "rows": [
        [
         "0",
         "wfzXa8e783",
         "1940",
         "1695136750006",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "Reviewer_EGJf",
         "1698648757307",
         "1701662567826",
         "6",
         "3",
         "3",
         "3",
         "2",
         "**Summary:** \nThis paper presents an open-source toolkit based on LoRa. I believe this work might be more appropriate for the \"benchmarking and datasets\" track. Positioned here, it's challenging for me to evaluate the innovation this paper offers. **Remarks:** \nWhile the improvements and variants on LoRa are relatively straightforward, the theoretical part of the paper seems sound. **Recommendation:** \nI would advise the authors to provide clear insights through experiments and offer some specific suggestions. I cannot evaluate this paper because I believe it is proper for a benchmarking and dataset track, not the main track.",
         "94",
         "0",
         "0",
         "0.7561",
         "0.2401515152",
         "0.7697365284000001",
         "75",
         "34",
         "42.4333",
         "11.2328",
         "14.7773",
         "13.5591",
         "13.3105",
         "0.2025",
         "77",
         "1",
         "2",
         "0",
         "0",
         "iclr"
        ],
        [
         "1",
         "wfzXa8e783",
         "1940",
         "1695136750006",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "Reviewer_DWom",
         "1698746208577",
         "1699636125239",
         "6",
         "3",
         "3",
         "3",
         "3",
         "This paper proposes a comprehensive library for evaluating text-to-image finetuning methods, typically based on LoRA. In addition to different algorithms, it also provides comprehensive evaluation criteria. Finally, some experimental results provide some insight about different finetuning methods. 1. This is a good engineering paper that provides a library for text-to-image finetuning methods evaluation.\n2. It support different matrix factorization techniques such as LoRA, LoHa, LoKr, DyLoRA, GLoRA, GLoKr and so on.\n3. This paper also consider comprehensive evaluation metrics, including fieldity, controllability, diversity, base model preservation and image quality. 1. This paper mainly focus on LoRA-based finetuing strategies, can it be expanded to other parameter-efficient finetuning methods such as \\[1\\] and \\[2\\]? It doesn't provide a clear explanation.\n2. The conclusion about the performance of different finetuning methods is not clearly presented in the experimental section. Maybe some tables can more straightforwardly represent your final conclusions. \n\n\\[1\\] Qiu, Zeju, et al. \"Controlling Text-to-Image Diffusion by Orthogonal Finetuning.\" arXiv preprint arXiv:2306.07280 (2023).\n\\[2\\] Xie, Enze, et al. \"DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning.\" arXiv preprint arXiv:2304.06648 (2023). Please refer to the weakness section.",
         "187",
         "6",
         "9",
         "0.8365",
         "0.053061224500000004",
         "0.9117403030000001",
         "52",
         "10",
         "16.9695",
         "13.6251",
         "15.3091",
         "13.6811",
         "14.7228",
         "0.2131",
         "78",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "2",
         "wfzXa8e783",
         "1940",
         "1695136750006",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "Reviewer_PnHf",
         "1698822869626",
         "1699636125143",
         "6",
         "4",
         "4",
         "4",
         "3",
         "This author introduces LyCORIS, an open source library dedicated to fine-tuning of Stable Diffusion, which integrates a comprehensive range of finetuning methods. For rigorous comparisons between the implemented methods, the author proposes a comprehensive evaluation framework that incorporates a wide range of metrics. Based on the evaluation framework, the author performs extensive experiments to compare different fine-tuning algorithms and to assess the impact of the hyperparameters (i.e, training epochs, learning rate, trained layers, et al). Overall, the experiments, comparisons, analyses, and results of the entire paper are very well-rounded and thorough. 1. Developing an open-source library is of great significance in fostering the advancement of a particular field. After comparing the existing open-source libraries available online, the LyCORIS library offers a relatively more comprehensive set of algorithms.\n\n2. The author has developed a comprehensive benchmark to evaluate various algorithms from multiple perspectives, addressing a significant gap in the text-to-image field. This thorough evaluation and comparison of existing finetuning methods have been lacking in the domain until now.\n\n3. The author conducted comprehensive experiments for different algorithms and parameters; in addition, the author also provided a detailed analysis of the current mainstream fine-tuning algorithms. 1. HuggingFace has also released the PEFT library, which supports a wider range of pre-trained models and includes the methods mentioned in the paper. Therefore, what are the advantages of the LyCORIS library compared to PEFT?\n\n2. The paper conducted a multitude of experiments and comparisons on existing methods and various hyperparameters, leading to certain conclusions. Based on these findings, could there be a more optimal algorithm or design compared to previous ones? For this kind of paper that builds benchmarks based on a certain field, I would recommend the author to submit to a journal.",
         "289",
         "0",
         "5",
         "0.7676",
         "0.17214285710000002",
         "0.8675829172",
         "52",
         "9",
         "20.4212",
         "15.1974",
         "18.2257",
         "16.5672",
         "16.3167",
         "0.1213",
         "86",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "3",
         "wfzXa8e783",
         "1940",
         "1695136750006",
         "['~SHIH-YING_YEH1', '~Yu-Guan_Hsieh1', '~Zhidong_Gao1', '~Bernard_B_W_Yang1', '~Giyeong_Oh1', '~Yanmin_Gong1']",
         "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation",
         "Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts.  Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field.  However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation.  Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion), an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion.  Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.",
         "Reviewer_ekPo",
         "1699260725548",
         "1699636125075",
         "8",
         "4",
         "3",
         "3",
         "4",
         "The authors propose LyCORIS, an open-source library that contains multiple fine-tuning techniques for Stable Diffusion. The authors also explore many improved fine-tuning techniques such as LoCon, LoHa and LoKr. This paper also presents evaluations for different fine-tuning techniques using multiple metrics and prompt types. (1) The theory and experiments are both solid. The paper has over 57 pages devoted to analyzing the fine-tuning techniques.\n(2) The details for experiments are very clear.\n(3) In addition to the framework, the authors also explore other fine-tuning techniques. (1) The results of this framework combined with ControlNet can be presented in this paper.\n(2) Efficiency (time and GPU memory cost) of different approaches are not provided and analyzed. (1) Please refer to the main questions in the weakness section.\n(2) A minor question: It will be better if the authors provide the results on other versions of stable diffusion, such as SD2.0 and SDXL.",
         "151",
         "0",
         "0",
         "0.7539",
         "0.0711904762",
         "0.7818619609",
         "52",
         "4",
         "48.9543",
         "9.5572",
         "10.8611",
         "11.3747",
         "10.6575",
         "0.1844",
         "84",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "4",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_HFRa",
         "1697955924532",
         "1699636992453",
         "3",
         "4",
         "2",
         "2",
         "1",
         "This paper introduces ν-ensembles, a novel deep ensemble algorithm that achieves both efficiency and conceptual simplicity. When presented with an unlabeled dataset, ν-ensembles generate distinct labelings for each ensemble member and subsequently fit both the training data and the randomly labeled data. The strength of ν-ensembles lies in their ability to enhance deep ensemble diversity and calibration without significantly increasing computational demands. Key strengths include improved calibration in both in-distribution and out-of-distribution settings, achieved without complex implementation or extensive hyperparameter tuning. This method maintains the efficiency of standard deep ensembles, ensuring diversity through a straightforward process of assigning random labels to unlabeled data points. The theoretical grounding via PAC-Bayesian analysis provides a guarantee of diversity, accuracy, and calibration on test data, making ν-ensembles a promising and efficient technique for enhancing deep neural network ensembles. 1. The paper lacks the related works of other calibration method such as train time calibration loss, and post hoc calibration which is very important in this domain.\n2. From my experience, the ECE measurement could be very unstable when classification accuracy is low. For experiments in table 1 for CIFAR100, the accuracy is very low, and the results may not reliable.\n3. The experiments lack the comparison with SOTA methods such as Focal Loss Calibration and Adaptive Label Smoothing. In table 1, how many times does the author run the experiments? Since the ECE measurement can be very stable among low prediction accuracy models, the ECE reported in Table can have very large variance. Please report the variance of multiple runs to verify the effectiveness of your method.\n\nThe experiment is limited to CIFAR10 datasets. Since the authors mention that the small dataset regime often happens in medical area. It is better to verify your algorithm on the small medical datasets.",
         "296",
         "0",
         "3",
         "0.7848",
         "0.052918367300000005",
         "0.9382253885",
         "47",
         "19",
         "22.8589",
         "14.6669",
         "18.2108",
         "15.9828",
         "15.2685",
         "0.2519",
         "90",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "5",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_bec4",
         "1698206643703",
         "1699636992323",
         "3",
         "3",
         "2",
         "2",
         "1",
         "This paper introduces an ensembling technique for making use of unlabeled data in $k$-class classification. Namely, the authors suggest training $k$ models, each of which see a different (randomly selected without replacement) label for each unlabeled data point. In this way, at least one model is guaranteed to have trained on a correct data point (since we exhaust all labels). The authors show that this approach can have benefits with respect to calibration metrics such as ECE when compared to other ensembling approaches on small-scale datasets. - **Originality:** Although the proposed method is quite simple, to the best of my knowledge I have not seen a similar approach analyzed empirically or theoretically in the literature on ensembling. \n- **Quality:** The paper motivates the proposed method with a simple example and attempts to provide theoretical justification with a PAC-Bayes bound and related analysis. The algorithm and associated experiments in the paper are described well, but I have reservations about the quality of experiments as detailed in weaknesses below.\n- **Clarity:** The experiments in the paper are easy to follow, but the theoretical aspect of the work is not as clear.\n- **Significance:** Improving ensembles is an important problem, and the idea of diversifying ensembles has received much attention over the past few years. As such, the paper considers a significant problem, but I question the progress made on this problem by the proposed method. ## Main Weaknesses\n1. **Insufficient experimental setup for proposed method.** \n    The authors claim that for small-scale datasets their method preserves the performance boost of standard ensembling but results in better calibration, while maintaining the same level of efficiency (as opposed to joint training methods that are compared to). However, this comparison seems incomplete - firstly, my understanding is that the compared-to ensembling approaches do not make use of the additional unlabeled data (at least standard ensembling does not). In Table 1 (the main table in the paper) the results are with respect to a training size of 1000 data points, but the unlabeled data size and validation size are 5000 points each. As a result, this comparison seems unfair - one should at least consider some other pseudo-labeling scheme for the unlabeled data, since it makes up the majority of the data being considered.\n\n    Additionally, even this part aside, the authors should compare the method to training ensembles with some kind of data augmentation (label smoothing \\[1\\], Mixup \\[2\\], etc.) since these methods are not only known to improve feature learning diversity but also regularize predicted confidences. Furthermore, training with these methods is going to be even more efficient than the proposed approach, and I expect would perform better. My reasons for expecting this are two-fold: firstly, the proposed approach intuitively regularizes confidence by having the ensemble uncertainty be high on the unlabeled data (essentially these points should be predicted uniformly randomly based on how the ensembles are trained), but Mixup and label smoothing are approaches that can do this as well. Additionally, and more importantly, the authors themselves note that their approach does not work (and can even hurt) for larger dataset sizes, but the aforementioned data augmentations are known to improve calibration even in that regime.\n\n2. **Theoretical approach needs greater clarity.** The theory here needs significantly more clarification in my view. For example, the authors define $\\hat{\\rho}$ to be a uniform combination of point masses on different weights (and even here the notation should be made more precise, $\\delta$ is not defined a priori) and then claim that $\\hat{V}$ is the empirical variance of $\\hat{\\rho}$, but that is not what it represents from Equation (2), which is the variance of the predictive distribution of the ensemble when evaluated with respect to the true labels of data points in $U$. Furthermore, for the predictive distribution the authors use $p(y \\mid x, f)$ in Equation (2) and it should be clarified at this point that $y$ corresponds to the true label of $x$ (which the authors mention later). More importantly, the proof of Proposition 1 is very hard to make sense of. What is the indicator variable of $y$ not being in the random labels? Aren't the random labels supposed to be exhaustive? Even ignoring this, how does the second term become zero when passing from the first line to the second line? \n\n## Recommendation\nOverall I do not think the merits of the proposed approach are significant enough to merit acceptance, so my recommendation is **reject**. It is possible I misunderstood some aspects of the theory and I am happy to correct some of my statements here upon author clarification, but I feel even with that the authors would need more comprehensive experimental comparisons to emphasize the usefulness of the approach. My main questions are stated above as part of weaknesses.",
         "796",
         "2",
         "3",
         "0.7691",
         "0.11389269410000001",
         "0.9224106073",
         "47",
         "16",
         "35.7231",
         "14.3942",
         "17.0581",
         "15.4976",
         "15.9236",
         "0.1932",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "6",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_i38b",
         "1698692174281",
         "1699636992166",
         "6",
         "4",
         "4",
         "4",
         "4",
         "The paper proposes a very neat method for improving the diversity of deep ensembles: It assigns random labels to a set of unlabelled data and lets each ensemble component fit different random labels such that these ensemble components can be diverse. The paper further provides theoretical guarantees for the resulting ensembles' behavior on test samples. The empirical results further show that the method acquires significantly better calibration on small training dataset regime, without sacrificing accuracy. Importantly, the method only introduces little extra training overhead while outperforming baseline approaches that are way more complicated. Overall, I think the proposed idea is novel, interesting, easy-to-use, and could be of great impact. - The proposed method is easy! It is much easier and efficient to implement than other methods for enhancing ensemble diversity, such as Stein-based methods.\n\n- The proposed method comes with theoretical guarantees: Although the method sounds like some heuristic, the author provides PAC-Bayes bounds for its performance on test data.\n\n- The empirical performance improvement is significant: The results show that the proposed method improves the calibration error to a great extent for both in-distribution test data and out-of-distribution data (i.e. corrupted data), without hurting the accuracy. - The method \"Sample y randomly without replacement\", however, when the number of ensemble is larger than the number of classes, it is unclear to me how the method should be applied.\n\n- Since the method assumes having access to a validation dataset, a baseline worth considering would be temperature scaling.\n\n- The presentation of the results can be improved: There is no legend for the lines in Figure. 2; The usage of bold font is not consistent and confusing in Table. 1 Why the method becomes less effective when we have access to more data?\n\nIf I understand correctly, the method assigns random labels to **in-distribution** data, this sounds weird to me, as it implies that the ensemble would have high uncertainty on these in-distribution samples. I think one can also consider introducing OOD samples into training and assigning random labels to them for each ensemble member.",
         "345",
         "0",
         "0",
         "0.7883",
         "0.061763565900000005",
         "0.9469445348000001",
         "47",
         "10",
         "33.8655",
         "13.4897",
         "15.7641",
         "14.8858",
         "14.3705",
         "0.1932",
         "99",
         "1",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "7",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_My8L",
         "1698833708470",
         "1699636992048",
         "5",
         "4",
         "3",
         "4",
         "2",
         "The authors present a method for improving the calibration of deep neural network ensembles in the small data regime when access to an unlabelled data set is assumed. In particular, they propose the counterintuitive idea of randomly labelling the unlabelled dataset (distinctly for each ensemble member) and training the deep ensemble on the joint supervised and randomly labelled data. The randomly labelled data promotes ensemble diversity. A PAC bound which relates generalisation performance to ensemble diversity is derived while the diversity of the ensemble is demonstrated to be related to the ensemble size. Experiments on various slices of CIFAR-10 and CIFAR-100 show that while the method does not improve accuracy relative to standard ensembles, there are substantial gains on calibration. Calibration does not improve consistently over more complicated/expensive diversity promoting ensemble methods. - The paper is very well written and clear.\n- The idea for the method, of using randomly labelled unsupervised data to promote ensemble diversity is simple, cheap and easy to implement and in so far as promoting diversity makes sense.\n- Some theoretical results are presented in which the ensemble diversity is related via a PAC bound to the generalization performance (I have some other comments on these results below).\n- The experimental results are convincing that at least in the small data regime with relatively little unsupervised data the calibration relative to standard ensembles is significantly improved. Please see my questions in the section below for potential weaknesses that can be addressed through further experiments.\n\n- The method is targeted solely at the small data regime, gains in calibration go to zero as the amount of labelled data increases.\n- The method introduces a new $\\beta$ hyperparameter which must be tuned.\n- The experiments are presented without error bars and it is unclear if they come from a single run or are averaged over multiple seeds, standard practice, especially when considering the relative small datasets considered in this paper is to run experiments with multiple random seeds and present averages and standard deviations of the metrics of interest (or better yet other forms of statistical test of the significance of the results).\n- Experiments are conducted on small slices of CIFAR-10 and CIFAR-100, while performance in the large data regime is alluded to in the paper, an experimental evaluation of this setting (for example ImageNet is fairly standard in the ensemble literature) would be much appreciated.\n- From equation 3, it seems to be the case that as the number of classes (c) increases the gains in ensemble diversity go to zero, so the method is both likely to give no gains in the large data and large number of classes regime.\n- The primary theoretical motivation for the method is equation 1, which is a PAC bound on the generalization performance, it is difficult to get a sense of how tight this bound is and to what extent there is a competition between the various terms in the bound.\n\nSmall things (didn't effect rating):\n- Typo: \"coincides we standard weight decay\" -> \"coincides with standard weight decay\"\n- It took me a while when reading the paper printed out to realise that there are two colours plotted in the left hand side of Figure 2 - as the orange is almost fully hidden by the red, making this clear in the figure or caption would be helpful to readers. - While the experimental results do not show big drops in accuracy, I am quite concerned that given vastly more unlabelled data the method would lead to overfitting the random labels and thereby harm test set accuracy (as is a well known phenomenon in the noisy label literature). More formally one could imagine that vast amounts of unlabelled data would promote the diversity term in the RHS of equation 1, but I given results in the noisy labels literature, I would find it hard to believe that this would not come at a corresponding cost in the first term on the RHS of equation 1. Could the authors please comment on this concern? Experimentally, I would be interested in seeing an experiment on ImageNet, for example, where the labelled set is of size 50k and the unlabelled set is 950k examples, a standard resnet50 or similar capacity model is used with 4 ensemble members (as per other papers in the literature) and a comparison to standard ensembles in terms of accuracy and calibration is given. This is a significant concern for me, as usually with methods that make use of an unsupervised dataset, the expectation is that as the unlabelled dataset grows, the gains from using it grow to. I fear this will not be the case for this method, which would limit the method to the small dataset, small number of classes and small unlabelled dataset regime. I recognise that the $\\beta$ hyperparameter can to a certain extent control this trade-off, so if further experiments are conducted to address this concern, please report the results over the $\\beta$ hyperparameter range.",
         "835",
         "0",
         "0",
         "0.7756",
         "0.0024741462",
         "0.9451873302",
         "47",
         "9",
         "28.0723",
         "17.4922",
         "20.681",
         "17.4907",
         "18.7118",
         "0.5162",
         "99",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "8",
         "wHgu98u8Sc",
         "8035",
         "1695494318474",
         "['~Konstantinos_Pitas1', '~Julyan_Arbel1']",
         "$\\nu$-ensembles: Improving deep ensemble calibration in the small data regime",
         "We present a method to improve the calibration of deep ensembles in the small data regime in the presence of unlabeled data. Our approach, which we name $\\nu$-ensembles, is extremely easy to implement: given an unlabeled set, for each unlabeled data point, we simply fit a different randomly selected label with each ensemble member. We provide a theoretical analysis based on a PAC-Bayes bound which guarantees that for such a labeling we obtain low negative log-likelihood and high ensemble diversity on testing samples. Empirically, through detailed experiments, we find that for low to moderately-sized training sets, $\\nu$-ensembles are more diverse and provide better calibration than standard ensembles, sometimes significantly.",
         "Reviewer_3iBP",
         "1698897134942",
         "1699636991904",
         "5",
         "4",
         "3",
         "3",
         "2",
         "The paper introduces a method to enhance the calibration of deep ensembles, particularly in situations where there is a small amount of labeled data and some unlabeled data. For each point in the unlabeled dataset, the ensemble members are trained with different randomly selected labels. The authors provide a theoretical justification for this approach, drawing on PAC-Bayes bounds to argue that it leads to lower negative log-likelihood and higher ensemble diversity on test samples. Empirically, they demonstrate that ν-ensembles outperform standard ensembles in terms of diversity and calibration, especially when the training dataset is small or moderate in size. - The paper gives a method to improve calibration error for deep ensembles using unlabeled data. The use of unlabeled data to improve calibration error of deep ensembles has not been explored much before as most of the works have focused on joint training approaches which can be memory and computationally expensive.\n- The paper is overall well written and easy to understand. \n- The paper presents supports their method with both theoretical and experiments. - One major weakness of the paper is that their method only improves calibration error not accuracy but they have not compared to any other calibration technique like temperature sampling. \n- The other issue is that the method appears very similar to the Agree to disagree work mentioned in the paper where they also use unlabeled data to maximize diversity and the idea seem incremental. Can the authors please explain in detail how exactly Agree to disagree maximizes diversity on the unlabeled set?\n- Another limitation is that this method only improves calibration in the small data regime. \n- Another limitation is that there are only two datasets used in the paper - CIFAR-10 and CIFAR-100. It would be nice to have additional datasets. - The paper says that the labels for unlabeled data points are chosen without replacement. What happens if we sample with replacement? One should expect the same empirical results to hold but maybe the theoretical argument will not hold?\n- I understand the text written at bottom of the Figure 1 but I don’t understand the figure. What are the 3 columns in the figure?\n- One part that is not clear to me is when we are forcing the models to make random predictions on unlabeled data which is from the same distribution, why we are not hurting the accuracy or the cross entropy loss of the model? When training data is small and unlabeled data set is bigger, can the authors share their regularization parameters and if they had to give small weights on the regularization term?\n- The colors used in figure 2 and 3 are very similar and it is hard to distinguish different lines. \n- There are other works which also use this idea of diversifying using unlabeled datapoint for other problems. For example, DIVERSIFY AND DISAMBIGUATE: OUT-OF-DISTRIBUTION ROBUSTNESS VIA DISAGREEMENT. Can the authors please compare to this work also?\n- Did the authors try using the unlabeled data from different distributions like random Gaussian noise. One benefit would be that fitting random labels on this dataset will not interfere with the learning on the original distribution.",
         "530",
         "0",
         "0",
         "0.7822",
         "-0.026552287600000002",
         "0.9537856579",
         "47",
         "8",
         "40.043",
         "12.4219",
         "14.9313",
         "14.341",
         "12.1643",
         "0.12560000000000002",
         "92",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "9",
         "vRyp2dhEQp",
         "1283",
         "1695036218168",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "Reviewer_tXy3",
         "1698113315631",
         "1699636055179",
         "6",
         "4",
         "3",
         "2",
         "2",
         "The submission focuses on the backdoor attacks in data-constrained scenarios. By leveraging CLIP-based technologies, the proposed CLIP-CFE (CLIP for Clean Feature Erasing) suppresses clean features while amplifying poisoning features to achieve more efficient attack with limited poisoning samples. + The submission presents a novel method, which introduces the optimized feature erasing noise to effectively suppress benign features. Besides, it enhances the poisoning features through contrastive learning and amplifies the existing backdoor attacks efficiently in data-constrained scenarios.\n\n+ The experimental results demonstrate the effectiveness of the CLIP-based attacks in data-constrained scenarios. Across various real-world constraints such as *number-constrained, class-constrained*, and *domain-constrained* conditions, the proposed backdoor attack consistently achieves a high attack success rate while maintaining the benign accuracy. + **Insufficient experimental results**\n\nThe submission should take more recent backdoor attack and defense mechanisms into consideration while discussing the adaptive defenses more thoroughly, e.g., the noise used for erasing benign features might be unlearned \\[1, 2\\]. Besides, it is necessary to compare the effectiveness of utilizing different proxy extractors other than CLIP.\n\n\n+ **Ambiguous expressions**\n\nSeveral points in the submission need further explanation, e.g., the reason and effect of choosing the overall attack process relying on the style of CLIP within the feature space, and the analysis of erasing benign features compared to the semantic-agnostic out-of-domain samples.\n\nReferences:\n\n\\[1\\]: Li Y, Li Y, Wu B, et al. Invisible backdoor attack with sample-specific triggers. Proceedings of the IEEE/CVF international conference on computer vision. 2021: 16463-16472.\n\n\\[2\\]: Akhtar N, Liu J, Mian A. Defense against universal adversarial perturbations. Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 3389-3398. Given that the submission's motivation is related to data-constrained scenarios, the author may provide more empirical evidence regarding to the occurrence of these backdoor attacks in real-world scenarios.",
         "295",
         "3",
         "2",
         "0.8060",
         "0.15949633700000002",
         "0.8649680018",
         "53",
         "17",
         "17.1557",
         "14.8827",
         "18.7003",
         "15.9032",
         "17.3402",
         "0.0999",
         "79",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "10",
         "vRyp2dhEQp",
         "1283",
         "1695036218168",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "Reviewer_kSYS",
         "1698236409147",
         "1699636055090",
         "8",
         "2",
         "3",
         "3",
         "3",
         "This paper proposes a new backdoor attack that performs well in data-constraint conditions that are more akin to real-world scenarios. The attack uses the CLIP model as a feature extractor to diminish the entanglement between benign and poison features. The experiment results show significant improvement compared to previous methods in these more realistic conductions. - A novel approach to backdoor attack\n- Comprehensive evaluations - CLIP limits the application domain\n- Defense discussion missing\n- Runtime information missing The authors present a novel backdoor attack that utilizes the pre-trained CLIP model as a feature extractor to suppress benign features and accentuate poison features. The attack also relaxes previous assumptions that having knowledge of the training datasets and the target models trained on datasets from one distribution. The authors show previous methods do not perform well in these more realistic scenarios but their new method is consistently effective and the trigger is hard to detect visually. Overall, the paper is well-written and the evaluation is comprehensive. However, there are a few points I would like to see the authors to further address.\n\n- The usage of the CLIP model for backdoor attacks is indeed novel. However, this also limits the domains of possible application of the attack. While the method seems to perform well on datasets with natural sceneries, such as CIFAR-100, CIFAR-10, and ImageNet-50, the performance cannot be guaranteed on datasets where the domain drastically differs from CLIP’s training set, such as medical scans, satellite imageries, etc. Additionally, even for similar domains, it would be interesting to see if the feature extraction capabilities transfer onto fine-grained datasets, such as CUB-200-2011, Stanford-Cars, Oxford-Flowers, etc. The authors should consider including results on more diverse datasets.\n\n- The target models used in this paper are all relatively simple/small (experimental settings focused). They also differ drastically from the CLIP model both in terms of architecture and performance. The authors have already pointed out the effect of model architecture in Section 5.1. Evaluating the attack on more advanced and larger architectures, such as ViT, can further prove the author’s claim for applicability in real-world scenarios.\n\n- Discussion regarding potential defenses is also missing. It would be interesting to see how this new attack performs against backdoor detection or defense methods. Since the optimization suppresses the clean features and augments the poison features, defense/detection methods that rely on optimization, such as Neural Cleanse\\[1\\] could potentially be more effective (compared to defending against traditional backdoor attacks). Furthermore, a recent work\\[2\\] on backdoor defense seems to use similar intuition (detangling benign and poison features). It would be interesting to see how this defense performs against an attack that is intuitively similar.  \n\\[1\\]Wang et al. Neural cleanse: Identifying and mitigating backdoor attacks in neural networks. 2019. In IEEE Symposium on Security and Privacy (S&P).  \n\\[2\\]Min et al. Towards Stable Backdoor Purification through Feature Shift Tuning. 2023. arXiv preprint arXiv:2310.01875.\n\n- Considering the optimization process needed to conduct this attack, the authors should consider including relevant runtime information. Since the focus of this paper is on presenting a backdoor attack that is applicable in real-world scenarios, the computing resource required can be another limiting factor. \n\nMinors:\n\n- Fonts in figures are too small to be legible\n- Page 8, VGG-16 datasets? (should be models)",
         "544",
         "4",
         "5",
         "0.8294",
         "0.1282828283",
         "0.8720514774",
         "53",
         "16",
         "30.8873",
         "13.0891",
         "15.2929",
         "14.3292",
         "14.0499",
         "0.1262",
         "93",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "11",
         "vRyp2dhEQp",
         "1283",
         "1695036218168",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "Reviewer_nLdg",
         "1698654858453",
         "1699636055014",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper assumed a threat model for backdoor attacks, so-called as ‘data-constrained backdoor attacks’, where the attacker doesn’t have access to the entire training dataset. Then, the authors claimed that the exiting backdoor attacks are inefficient in this new threat model. The authors considered an interesting topic on AI security, specifically, how to improve the backdoor efficiency in a data-constrained scenario. First, the authors only provided the empirical results to support the performance decline when the exiting backdoor attack in the new threat model, as shown in Fig.2. I highly recommend that the authors give a possible theoretical analysis to this phenomenon.\n\nSecondly, the new proposed 'clip-guided backdoor attack' method includes two components: clean feature suppression and poisoning feature augmentation. Specifically, the main idea is to exploit adversarial example to generate the noise to suppress the clean feature or amplify the poison feature. Unfortunately, as far as I know this idea has been exploited by many published papers, for instance, as shown as follows. The main difference of this paper is that it is based on a novel pre-trained model CLIP.\n\n\\[1\\] Zhao, Shihao, et al. \"Clean-label backdoor attacks on video recognition models.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\\[2\\] Turner, D. Tsipras, and A. Madry, “Label-consistent backdoor attacks,” arXiv preprint arXiv:1912.02771, 2019.\n\nIn summary, the main idea has been exploited already, which will significantly reduce the contribution of this paper. What is the main difference between the 'clip-guided backdoor attack' with the existing references which have been mentioned in the 'weaknesses'",
         "258",
         "2",
         "2",
         "0.7959",
         "0.1806709957",
         "0.8726058006",
         "53",
         "11",
         "38.9541",
         "11.5963",
         "13.3574",
         "13.4046",
         "13.2499",
         "0.0795",
         "86",
         "2",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "12",
         "vRyp2dhEQp",
         "1283",
         "1695036218168",
         "['~Ziqiang_Li4', '~Hong_Sun5', '~Pengfei_Xia1', '~Heng_Li10', '~Beihao_Xia1', '~Yi_Wu11', '~Bin_Li8']",
         "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios",
         "Recent deep neural networks (DNNs) have came to rely on vast amounts of training data, providing an opportunity for malicious attackers to exploit and contaminate the data to carry out backdoor attacks. However, existing backdoor attack methods make unrealistic assumptions, assuming that all training data comes from a single source and that attackers have full access to the training data. In this paper, we introduce a more realistic attack scenario where victims collect data from multiple sources, and attackers cannot access the complete training data. We refer to this scenario as $\\textbf{data-constrained backdoor attacks}$. In such cases, previous attack methods suffer from severe efficiency degradation due to the $\\textbf{entanglement}$ between benign and poisoning features during the backdoor injection process. To tackle this problem, we introduce three CLIP-based technologies from two distinct streams: $\\textit{Clean Feature Suppression}$ and $\\textit{Poisoning Feature Augmentation}$. The results demonstrate remarkable improvements, with some settings achieving over $\\textbf{100}$% improvement compared to existing attacks in data-constrained scenarios.",
         "Reviewer_rJBe",
         "1698840789932",
         "1699636054933",
         "6",
         "4",
         "3",
         "2",
         "2",
         "This paper addresses an important and practical backdoor attack scenario called data-constrained backdoor attacks. The key insight is that in real-world settings, attackers often do not have full access to a victim's entire training dataset, which spans multiple sources. The paper clearly defines three variants of data-constrained attacks based on restrictions on the number of poisoning samples, classes, or domains.\nA thorough set of experiments on CIFAR and ImageNet datasets demonstrates that existing backdoor methods like BadNets and Blended attacks fail under data constraints, due to entanglement between benign and poisoning features. The analysis of this entanglement issue is a nice contribution. To address this limitation, the authors cleverly utilize CLIP in two ways: 1. Clean feature suppression via CLIP-CFE to erase benign features.\n2. Poisoning feature augmentation via CLIP-UAP and CLIP-CFA to amplify poisoning features.\nThe introduction of CLIP for backdoor attacks is novel. Results show CLIP-UAP and CLIP-CFA consistently outperform baseline triggers across constraints, architectures, and datasets. CLIP-CFE provides further improvements in attack success rate. The attacks remain stealthy and do not impact benign accuracy. 1.\tAddresses a highly practical attack scenario of data-constrained backdoor attacks that reflects real-world training environments where attackers have limited data control.\n2.\tProvides a clear taxonomy of data-constrained attacks based on restrictions to number of samples, classes, and domains.\n3.\tIdentifies through analysis and experiments that existing attacks fail under data constraints due to entanglement of benign and poisoning features. This is an important insight. 1.\tWhile the data-constrained scenario is practical, the specific sub-variants of number, class, and domain constraints may not fully capture all real-world limitations an attacker could face. More complex constraints could be studied.\n2.\tThe computational overhead and time required for the CLIP optimization process is not extensively analyzed. This could be a limitation for realistic attacks.\n3.\tThe stealthiness metrics mainly rely on signal processing based measures like PSNR and SSIM. More rigorous stealthiness analysis like visualizations and defense evaluations may be beneficial. see in weakness",
         "330",
         "0",
         "8",
         "0.8079",
         "0.10107993200000001",
         "0.9159598351",
         "53",
         "9",
         "30.2501",
         "12.6044",
         "15.1937",
         "13.8498",
         "14.4178",
         "0.0999",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "13",
         "vQiD6v1w41",
         "3932",
         "1695328069592",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "Reviewer_XYg3",
         "1698710426902",
         "1699636353905",
         "3",
         "4",
         "3",
         "1",
         "2",
         "The paper presents a new framework for semi-supervised domain adaptation (SSDA) that establishes an upper bound on target error. This framework introduces a method called Joint Error-based Triplet Alignment (JTA), which performs alignments not only between the labeled source domain and the unlabeled target domain but also between the labeled source domain and the labeled target domain. As a result, their empirical studies demonstrate that JTA can reduce domain gaps and enhance feature learning by explicitly considering the alignment for the labeled target data. The paper also introduces a dissimilarity metric known as Maximum Cross Margin Discrepancy (MCMD) to bridge the gap between theory and algorithm, ensuring the consistency of the target error bound. The main problem of this paper is the lack of sufficient details to understand and follow their motivation and derivation. Given the promising empirical results presented in the paper, I strongly recommend that the authors consider a complete rewrite of the paper, focusing on delivering a clear and well-motivated presentation. This should involve providing comprehensive derivations with sufficient details or citations, ensuring that each step of each equation is transparently explained for the benefit of the reader's understanding. The performance of the proposed work is promising. 1. I find the paper's motivation unclear. To be specific, the upper bound of the hypothesis regarding the unlabeled target domain should be the most crucial starting point for readers to comprehend what the proposed method aims to address. However, the lack of an explanation for the proof of Equation (1) makes it extremely difficult for me to grasp and follow. Concerning D.1, I am unsure how the first equation of the unlabeled target error bound was derived. If it stems from Ben David's theorem (assuming my recollection is accurate, Ben David did not derive any error bound under semi-supervised settings) or the work of others, it would be beneficial to provide citations so that readers can fully contextualize and understand the subject matter.\n\n2. What is the source of the intractability, particularly for f_{S} and f_{V}? Given that both S and V are fully labeled, it seems reasonable to assume that a straightforward optimization approach like empirical risk minimization (ERM) could yield a reasonable approximation for f_{S} and f_{V). The mention of intractability is often made within the framework of variational inference, where certain integrations cannot be feasibly solved. Providing a clear explanation of this intractability would significantly enhance the paper's motivation.\n\n3. How is the reduction of the error term achieved between two fixed true labeling functions? I want to emphasize that \"true\" here means unchanging or fixed. The paper is proving a complex upper bound derivation, and its clarity is hindered by inconsistent definitions throughout, making it difficult to follow.\n\n4. The t-SNE visualization, without any indications of the class labels for each data sample, fails to convey meaningful information. In fact, I find the t-SNE visualization rather perplexing. I recommend that the authors consider sharing the code for their implementation with the reviewers. This would serve not only to confirm the reproducibility of their work but also to enhance the reviewers' understanding of the proposed methodology.\n\n5. The experimental setup lacks clarity, particularly in the context of semi-supervised domain adaptation, where the number of labeled target samples and the way to select the labeled target sample are crucial. It is important to provide sufficient details regarding the sample selection process. \n\n6. The authors assert that \\[1\\] violates the triangle inequality without providing a thorough explanation or derivation. This is a strong claim, as it implies \\[1\\] is a departure from well-established theoretical foundations, especially considering that \\[1\\] is published on a top tire. To support their claim, the authors should conduct in-depth elaboration and studies.\n\n### Reference\n\n\\[1\\] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for domain adaptation. In Proceedings of the 36th International Conference on Machine Learning, volume 97, pp. 7404–7413. PMLR, 2019. 1. Could you please clarify what is meant by the conditional distribution referred to in Section 3.1? To be specific, which random variables are conditioned on which other random variables? Based on the authors’ preliminary at the beginning of the section that both f_{S} and f_{V} are true labeling functions (true means fixed and deterministic). Meanwhile, I am confused by the idea of describing a mapping function (mapping function is normally deterministic) as a distribution (sampling from a distribution is stochastic). How come a stochastic term can be used to describe a deterministic notation? Can you elaborate on this?\n\n2. To me, the loss introduced in this work appears to be an extension of the one (MDD) presented in \\[1\\] to the semi-supervised setting. I would appreciate it if the authors could offer a comprehensive discussion outlining the primary distinctions between \\[1\\] and their proposed approach, excluding the consideration of the semi-supervised setting and the violation of the triangle inequality. \n\n### Reference\n\n\\[1\\] Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for domain adaptation. In Proceedings of the 36th International Conference on Machine Learning, volume 97, pp. 7404–7413. PMLR, 2019.",
         "849",
         "7",
         "12",
         "0.7813",
         "0.0869150691",
         "0.9562900662",
         "49",
         "10",
         "35.4208",
         "13.2123",
         "16.0491",
         "14.7848",
         "14.7039",
         "0.9511000000000001",
         "96",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "14",
         "vQiD6v1w41",
         "3932",
         "1695328069592",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "Reviewer_tePx",
         "1698782026911",
         "1699636353828",
         "3",
         "3",
         "2",
         "2",
         "1",
         "The paper at hand proposes a method for domain adaptation by including some labeled data from the target domain. A \"triplet alignment\" is introduce which aims for aligning feature distributions as well as minimizing classification error. + relevant problem - The paper is quite hard to read and understand. Figures are rather small. Honesty speaking Fig. 1 even confused me more than it helped me to understand the approach.\n- Experimental results are hard to interpret and judge. If I read it correctly, the effect of data augmentation seems significant. When comparing without data augmentation  (ours* in Tab. 1) the advantages over previously proposes approaches seems marginal (if at all). I also miss confidence intervals. - What are clear advantages of the approach -- e.g., the claim that \"data augmentation is not nessaccary for our approach\" (besides still having a significant impact) is not well motivated.\n- What are limitation of the approach?",
         "153",
         "0",
         "1",
         "0.8190",
         "0.0409090909",
         "0.9198144674000001",
         "49",
         "9",
         "44.2428",
         "9.6968",
         "12.6354",
         "11.8999",
         "8.5706",
         "0.1932",
         "97",
         "0",
         "1",
         "0",
         "1",
         "iclr"
        ],
        [
         "15",
         "vQiD6v1w41",
         "3932",
         "1695328069592",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "Reviewer_hsiV",
         "1698808420540",
         "1699636353732",
         "1",
         "5",
         "3",
         "3",
         "1",
         "This paper proposed a joint error based triplet alignment approach to solve the semi-supervised domain adaptation problem. They evaluated on several cross-domain benchmarks by comparing with several methods. Generally, the paper is easy to follow. However, the novelty is not enough. This paper proposed a joint error based triplet alignment approach to solve the semi-supervised domain adaptation problem. They evaluated on several cross-domain benchmarks by comparing with several methods. Generally, the paper is easy to follow. They show various results to examine their methods. The novelty is not enough. The joint error based triplet alignment is not new, which is an extension of maximum cross margin discrepancy to three subsets, source, labeled target and unlabeled target. Eventual model is also very complicated. \n\nThe model performance is not good enough. Especially compared with DECOTA in Table 1 & 2, it is very comparable. Also for semi-supervised setting, the selected target samples are very essential. There is no standard variance. Also t-test is needed to examine the significance. The clarification of model novelty.\nThe performance improvement.",
         "174",
         "0",
         "0",
         "0.7846",
         "0.0049242424",
         "0.9568377137",
         "49",
         "9",
         "38.6381",
         "10.2578",
         "12.8618",
         "11.645199999999999",
         "10.255",
         "0.0999",
         "100",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "16",
         "vQiD6v1w41",
         "3932",
         "1695328069592",
         "['~Dexuan_Zhang1', '~Thomas_Westfechtel1', '~Tatsuya_Harada1']",
         "Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment",
         "Existing domain adaptation methods are very effective in aligning feature distributions. However, these techniques usually do not improve the performance that much when a few annotated examples are available in the target domain. To address this semi-supervised domain adaptation scenario, we propose a novel joint error based triplet alignment approach that simultaneously optimizes the classification loss as well as the joint error among the source, labeled and unlabeled target domains. Besides, we propose a novel dissimilarity measurement between two classifiers, namely maximum cross margin discrepancy, which can asymptotically bridge the gap between the theory and algorithm. We empirically demonstrate the superiority of our method over several baselines.",
         "Reviewer_TnGf",
         "1698960672685",
         "1699636353588",
         "3",
         "3",
         "3",
         "3",
         "2",
         "This work introduces a Triplet Alignment approach for semi-supervised domain adaptation. It simultaneously minimizes the joint error among different domains and the error rate on labeled data. 1.\tThe motivation for this work is clear. It aims to address the challenge of semi-supervised domain adaptation, particularly when only a limited number of annotated examples are available in the target domain. The proposed method optimizes both the classification loss and the joint error across source, labeled, and unlabeled target domains simultaneously.\n2.\tThe proposed models are presented in a clear and comprehensible manner. 1.\tThe proposed model, to the best of my knowledge, lacks significant novelty as it closely resembles the approach in \\[2\\]. It would be helpful to explicitly identify the main difference.\n2.\tThe choice of baseline methods in this work appears to be less competitive. Given the recent progress in semi-supervised domain adaptation (SSDA), including \\[1\\]\\[2\\], it is advisable to compare the proposed method with these contemporary approaches. Furthermore, while the use of t-SNE for feature space visualization is commendable, the comparisons are made with older methods like ENT (Grandvalet & Bengio, 2005), MJE (Zhang & Harada, 2019), and MME (Saito et al., 2019). It is imperative to include comparisons with more recent methods to provide a comprehensive evaluation.\n\\[1\\]  Yu, Yu-Chu, and Hsuan-Tien Lin. \"Semi-Supervised Domain Adaptation with Source Label Adaptation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\\[2\\] Rahman, Md Mahmudur, Rameswar Panda, and Mohammad Arif Ul Alam. \"Semi-Supervised Domain Adaptation with Auto-Encoder via Simultaneous Learning.\" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2023. Please see \"Weaknesses\"",
         "270",
         "6",
         "7",
         "0.7760",
         "0.1943277311",
         "0.9432914257",
         "49",
         "7",
         "34.3667",
         "11.97",
         "14.4481",
         "13.3652",
         "13.0976",
         "0.1719",
         "94",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "17",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_pc5v",
         "1698547649041",
         "1699636458715",
         "5",
         "5",
         "2",
         "3",
         "2",
         "This paper presents the Ranking-Constrained Actor-Critic algorithm, an offline reinforcement learning approach for optimizing Mixed Integer Linear Programs (MILPs). Traditional MILP solvers depend on hand-crafted heuristics for branching, limiting their efficiency and generalizability. Recent deep learning methods rely on high-quality training data, which can be scarce, particularly for large problems. The key contributions of the paper are the development of the new RL algorithm and its ability to efficiently learn branching strategies even from sub-optimal training data. The algorithm outperforms previous methods in terms of prediction accuracy and computational efficiency across various MILP problems, addressing the limitations of traditional solvers. This paper claims to be innovative by being the first to apply offline reinforcement learning algorithms in branch-and-bound methods. Furthermore, the essence of the proposed method lies in further refining the dataset, specifically selecting the top-k actions in the set Gω for Bellman operator operations. This can effectively enhance the performance of the branching strategy. I believe this perspective can also be inspiring for similar problems in other domains. This paper proposes training branch-and-bound strategies using offline reinforcement learning. However, in practice, interacting with solvers is relatively straightforward, and under these circumstances, using online reinforcement learning may yield better performance. The authors need to clarify the necessity of utilizing offline reinforcement learning. •\tConsidering that interacting with solvers online is convenient, is there a necessity to use offline reinforcement learning to train branch-and-bound strategies?\n•\tIn Equation 7, when k is small, the distribution of Q-values over the dataset will be centered around -δ, which is unfavorable for training. How do the authors ensure training effectiveness in this scenario?\n•\tI believe that the essence of the method proposed by the authors lies in further refining the dataset, specifically selecting the top-k actions in Gω for Bellman operator operations. I am curious to know if, after obtaining the top-k actions in Gω, simple imitation learning on these state-action pairs would yield similar results as the current approach. In other words, my question is whether the key to the effectiveness of this algorithm lies in the dataset refinement rather than offline reinforcement learning. I suggest that the authors conduct further ablation experiments to validate this idea.",
         "365",
         "0",
         "0",
         "0.8040",
         "0.07807720060000001",
         "0.9679618478",
         "49",
         "12",
         "20.8673",
         "15.082",
         "18.2288",
         "16.1033",
         "16.537",
         "0.1507",
         "84",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "18",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_s5Ux",
         "1698571655333",
         "1699636458619",
         "3",
         "4",
         "3",
         "2",
         "2",
         "This work proposes the usage of offline reinforcement learning for variable selection in the branch-and-bound algorithm. To do so, they introduce a novel offline algorithm that uses a classifier to determine whether a state-action pair is in the offline dataset. Their offline Q-values are now restricted towards picking only the top-k most likely actions for each state. The usage of offline reinforcement learning seems more fitting than current imitation learning algorithms due to its lack of reliance on high quality demonstrations. - The paper is a little unclear at some points. For instance, in the last paragraph of Section 2.2: Which variables are the selected ones? Just from the node chosen by the node selection policy, or all variables across the entire tree? In general, the distinction between node selection and variable selection doesn’t become clear: Does the method also do node selection (by picking variables from the entire tree), or just variable selection?\n- Further, it is not exactly clear whether there is a single model trained and evaluated on all instances, or multiple independent models trained on and evaluated on individual datasets.\n- One missing benchmark is the utilization of an off-the-shelf offline RL algorithm, such as conservative Q-learning as a baseline for the specific utility of RCAC over more established offline-RL algorithms (I.e. is the improvement in performance due to offline-RL or RCAC specifically?).\n- The testing set is also rather small: 10k training instances, 2k validation instances and, 20 test instances is a strange ratio.\n- The reward function is also a little bit strange: Why consider the dual bound, but ignore the primal one completely? Further, these bounds are not scale-invariant, meaning that the same problem, modulo a constant scalar, could have different dual bound improvements. Even if one takes care to normalize the objective vector c beforehand, most solvers like SCIP rescale this vector for increased numerical stability. Depending on which problems are chosen, the range of rewards across different instances might also be massive depending on the duality gap. However, we agree with the authors that this metric is still better than tree-size or number of nodes.\n\nSome minor points:\n- Abstract: hand-craft\\[ed\\]\n- Intro: The sentence “All of these models are trained…” needs a re-write\n- Intro: “To our knowledge, … to apply offline RL to MILP solving” (re-write)\n- Sec. 2: typo pseudocsot\n- Sec. 2.2. A\\[n\\] MDP\n- Equation 4: one closing brace is too much (after $Q_\\theta$)\n- Sec. 3.1: when a\\[n\\] MILP instance\n- Sec 3.1: discounted factor $\\rightarrow$ discount factor\n- Sec 3.3: citation of Gasse et al.: use cite instead of citep; same again happened in Sec. 4.1\n- Sec. 4.1: please use cite and citep depending on how you add these citations into the text\n- Sec. 5.2 does not add any benefit to the paper and can be omitted in its current state - Which set of variables if being selected from?\n- What is the performance of other offline-RL algorithms?\n- Can you evaluate on a larger testset?\n- Why only look at the dual bound improvement (alternative: optimality gap between primal and dual)?\n- In Sec 3.2. “In fact, a good action does no harm to policy optimization even if it is an OOD action” – can you please elaborate on this a bit more?",
         "553",
         "0",
         "4",
         "0.8156",
         "0.0484206349",
         "0.8696163893000001",
         "49",
         "12",
         "48.758",
         "10.5731",
         "13.5684",
         "13.0239",
         "10.5035",
         "0.25670000000000004",
         "96",
         "0",
         "2",
         "2",
         "0",
         "iclr"
        ],
        [
         "19",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_3oNR",
         "1698766364331",
         "1699636458528",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper studies the problem of learning variable selection policies for mixed-integer linear programming (MILP). The authors propose an offline reinforcement learning (RL) approach to learn branching strategies from sub-optimal or inadequate training signals. Experiments demonstrate the proposed method outperforms baselines on various benchmarks. 1.\tThe paper is easy to follow.\n2.\tExperiments demonstrate the proposed method outperforms baselines on various benchmarks. 1.\tThe novelty of the proposed method is incremental, as the proposed method is a simple application of offline reinforcement learning methods to branching strategies learning.\n2.\tThe authors claim that the proposed method is the first attempt to apply the offline RL algorithms to MILP solving. However, I found one previous work \\[1\\] applies offline RL methods to branching strategies learning as well. \n3.\tThe authors may want to explain the novelty of their method over the work \\[1\\] in detail.  \n4.\tThe experiments are insufficient. First, the authors may want to evaluate their method on the load balancing dataset from the ML4CO competition as well. Second, the baselines are insufficient. The authors may want to compare their method to the work \\[1\\]. Third, the authors may want to evaluate the generalization ability of the learned models.\n\n\\[1\\] Huang, Zeren, et al. \"Branch Ranking for Efficient Mixed-Integer Programming via Offline Ranking-Based Policy Learning.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Cham: Springer Nature Switzerland, 2022. Please refer to Weaknesses for my questions.",
         "239",
         "4",
         "8",
         "0.6839",
         "0.0766666667",
         "0.89818573",
         "49",
         "10",
         "40.7962",
         "10.694",
         "13.0651",
         "12.3033",
         "11.9765",
         "0.1719",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "20",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_nNZN",
         "1699130159488",
         "1699636458444",
         "8",
         "3",
         "3",
         "3",
         "2",
         "The paper considers the problem of learning to select branching strategies while solving mixed integer programs via branch and bound algorithm. The key idea is to collect offline training dataset using full strong branching as behavior policy and learn an offline RL algorithm to generate the learned branching policy. Improvement of the dual bound is chosen as the reward function. Experiments are performed on four synthetic and two real world problems. - Using offline RL for branching policies seems like a natural idea that should do better than pure imitation learning. I am surprised that this wasn't tried earlier and commend the paper for making this simple but natural idea work well. \n\n- The description of the problem and solution is written clearly and easy to understand.\n\n- The proposed approach performs well on multiple benchmarks. - A large part of the paper talks about sub-optimality of the FSB policy. For example, this statement \"Although FSB generally achieves high-quality branching, it could still become sub-optimal when the linear programming relaxation is uninformative or there exists dual degeneracy\" Is there more justified argument for this backed by some evidence?\n\n- why choose the proposed algorithm over any existing offline RL algorithm like CQL\\[1\\], IQL etc.?\n\n\\[1\\] Kumar, A., Zhou, A., Tucker, G., & Levine, S. (2020). Conservative q-learning for offline reinforcement learning. Advances in Neural Information Processing Systems, 33, 1179-1191. - What are connections of equation 6 to reward weighed regression?",
         "240",
         "3",
         "2",
         "0.8317",
         "0.1780952381",
         "0.9082451463000001",
         "49",
         "5",
         "39.297",
         "11.6371",
         "14.282",
         "13.6629",
         "11.9277",
         "0.12",
         "109",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "21",
         "uHVIxJGwr4",
         "4761",
         "1695361157305",
         "['~Shengyu_Feng1', '~Yiming_Yang1']",
         "Learning to Branch with Offline Reinforcement Learning",
         "Mixed Integer Linear Program (MILP) solvers are mostly built upon a branch-and-bound (B\\&B) algorithm, where the efficiency of traditional solvers heavily depends on hand-craft heuristics for branching.  Such a dependency significantly limits the success of those solvers because such heuristics are often difficult to obtain, and not easy to generalize across domains/problems.  \nRecent deep learning approaches aim to automatically learn the branching strategies in a data-driven manner, which removes the dependency on hand-crafted heuristics but introduces a dependency on the availability of high-quality training data. Obtaining the training data that demonstrates near-optimal branching strategies can be a difficult task itself, especially for large problems where accurate solvers have a hard time scaling and producing near-optimal demonstrations.  This paper overcomes this obstacle by proposing a new offline reinforcement learning (RL) approach, namely the \\textit{Ranking-Constrained Actor-Critic} algorithm, which can efficiently learn good branching strategies from sub-optimal or inadequate training signals. Our experiments show its advanced performance in both prediction accuracy and computational efficiency over previous methods for different types of MILP problems on multiple evaluation benchmarks.",
         "Reviewer_9gri",
         "1699190885255",
         "1699636458378",
         "5",
         "4",
         "3",
         "3",
         "3",
         "The authors propose an offline Reinforcement Learning (RL) framework for learning to branch (L2B) which reportedly exhibits superior performance with a sub-optimal dataset compared to existing methods that require extensive, high-quality datasets. This advantage is particularly notable in reducing the time to collect datasets for training the models. The reported performance on the MIP instances also indicates the effectiveness of the framework. 1. **Innovative Formulation:** The novel formulation of L2B as an Offline RL approach using a sub-optimal dataset is a significant departure from traditional methods.\n2. **Efficiency in Data Collection:** The framework requires significantly less time to collect its dataset, enhancing its practicality.\n3. **Performance:** The proposed framework improved performance compared to the GGCN framework on smaller dataset sizes, which is commendable. Despite the novelty of the work, I have reservations about the robustness of its results. These concerns are expanded upon in this section and further detailed in the questions that follow. \n\n1. **Lack of Scaling-Generalization Results:** A key aim of collecting datasets on smaller instances is to develop policies that excel on larger, more complex instances. It would be beneficial to see how various models perform on scaled-up versions of instances in various problem categories like SC, MIS, CA, or CFL. How do these policies perform on Medium or Hard instances (scaled-up versions) in SC, MIS, CA, or CFL? Does RCAC retain its performance advantage on scaling up to larger instances?\n\n2. **Insufficient Comparison with Existing Methods:** \n- The paper lacks a thorough comparison with recent advancements in the GGCN framework, particularly the augmented loss function introduced in \"Lookback for Learning to Branch\" (Gupta et al. 2022, https://arxiv.org/abs/2206.14987). It would be insightful to see how RCAC compares to this improved GGCN variant. \n - If I understand correctly, RCAC (S) and GGCN (S) primarily differ in their approach to training despite similarities in other aspects, such as dataset collection. Specifically, GGCN (S) employs a Cross-Entropy loss function, while RCAC (S) is focused on learning a Q-function (and a corresponding policy). The distinctiveness of the RCAC framework lies in its utilization of rewards instead of directly using FSB selections, as is the case with GGCN. However, an alternative comparison could involve integrating rewards into the GGCN framework as an additional signal. This could be achieved, for instance, by employing rewards to modulate the Cross-Entropy loss at each node, similar to how node depth might be used. Demonstrating RCAC's superior performance in this modified context would further reinforce the effectiveness of its RL-based approach as formulated in the study. \n    - It would be valuable to have the values of \\( k \\) specified for each model. I am particularly curious to know whether \\( k > 1 \\) for RCAC(S).\n- Comparisons with other RL methods, especially in terms of dataset size and time efficiency, would also be valuable. Clarifications:\n\n1. **Section 3.3:** Should \"representation of the B&B tree\" be replaced with \"representation of the B&B node\" for accuracy? \n2. **Training Dataset for GGCN (H) and RCAC (H):** Are these models trained on the same dataset? Is GGCN (H) trained on a separate dataset collected as specified in the Appendix?\n3. **VHB Dataset Transitions:** Could the authors clarify what constitutes a 'transition' in this context? Does the transition include (s,a,s’) even when FSB is not employed in VHB, which is 0.05 times? Do you discard any transition? How is it ensured that you explore a wide array of instances before 100K transitions are collected?\n4. **S Method Training:** Is the S method trained with only 5K transitions? \n5. **Reward Distribution:** Could the authors provide details on the distribution of reward values in the dataset, perhaps in the Appendix? Information on how this varies with tree depth and how normalization is handled would be valuable.\n6. **Figure 3 Clarity:** What is the specific problem family represented in Figure 3?\n7. **Practicality of H dataset collection:** Given that VHB takes longer than FSB (as indicated in column 2), is it still a practical choice since the performance is worse than S?\n8. **GGCN Expansion:** Could the authors clarify the abbreviation GGCN? It seems to be a variation of GCNN (Graph Convolutional Neural Networks) as used in Gasse et al. 2019.\n9. **Inference Procedure in RCAC:** Are there two forward passes $G_\\omega\\$ and $\\pi_\\phi$ during inference in RCAC? How does this differ from the inference process in GGCN?\n10. **Hyperparameter \\(k\\):** Figure 3 suggests that \\(k\\) has a significant impact on RCAC's performance. Could the authors provide the \\(k\\) values used for each model and dataset?\n\n11. **Aggregation in Table 4:** How are scores aggregated across 20 instances in Table 4? Assuming this is a cumulative sum, RCAC appears to outperform in WA but not against RPB in AP. Can the authors speculate on which problem types might be more amenable to improvement by RCAC?\n\n12. **Reward Ablation:** Could the authors discuss the rationale behind choosing dual bound improvement over primal-dual gap improvement? Understanding the preference for one metric over the other would be enlightening.\n\n\nSuggestions:\n1. **Dataset Comparison:** I think it will be pretty helpful to have a section or a figure demonstrating the difference (transition vs. individual nodes) between the dataset collected using the standard IL methods and the one proposed in this work. \n2. **Statistical Significance:** Please include p-values to indicate the statistical significance of differences in Tables 2 and 3.\n3. **Evaluation Methodology:** Given that 20 seems a relatively small sample size for testing, it's common practice to evaluate each instance with multiple seeds, as demonstrated in Gasse et al. 2019. Could the authors clarify whether a similar approach can be employed in their study?",
         "936",
         "1",
         "23",
         "0.7754",
         "0.0670068027",
         "0.8958138227",
         "49",
         "5",
         "40.0849",
         "12.1838",
         "15.6848",
         "14.5266",
         "13.367",
         "0.30210000000000004",
         "86",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "22",
         "tQ8gcygV4p",
         "1080",
         "1695005759142",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "Reviewer_MDsd",
         "1698325660933",
         "1699636034553",
         "3",
         "5",
         "2",
         "3",
         "1",
         "Offline reinforcement learning (RL) suffers from the extrapolation error. There are numerous model-free and model-based offline RL algorithms that aim to tackle this challenge. Among them, model-based offline RL algorithms often learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, such quantifications are often inaccurate. This paper addresses this issue by training bidirectional dynamics models and rollout policies, and design a conservative rollout method that selects those synthetic transitions with the smallest reconstruction loss. The authors provide some theoretical analysis of their method and build their method upon some off-the-shelf model-free offline RL algorithms. # Strengths\n\nThe strengths can be summarized below:\n\n- this paper is well-motivated, and the whole paper structure is clear\n\n- the logic flow of this paper is clear, and it is easy to follow and understand\n\n- the authors provide theoretical analysis to support their method # Weaknesses\n\nDespite the aforementioned strengths, this paper has some flaws in novelty, empirical evaluation, and theoretical analysis. Based on these considerations, I can confirm that this paper is clearly under the acceptance bar of this venue. Please see the detailed comments below.\n\n- (major) The core idea presented in this paper is NOT new. A highly relevant paper is published previously \\[x\\]. In \\[x\\], the authors also train bidirectional dynamics models and bidirectional rollout policies for offline data augmentation. Thus, the technical parts of this paper have a huge overlap with \\[x\\], making the contribution and significance of this paper quite weak. The differences are, that this paper selects the transitions with reconstruction loss while \\[x\\] selects reliable transitions via the proposed double check mechanism. It is doubtable whether the data selection approach adopted in this paper is better than the double check method, as intuitively, the reconstruction loss may not be reliable for forward/backward horizon larger than 1 (where no true next/previous states are available)\n\n\\[x\\] Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination. NeurIPS 2022.\n\n- (major) The empirical evaluations are limited and somewhat weak. The baseline algorithms this paper adopts are very old. It is somewhat confusing why the authors only choose to compare against these very weak algorithms. More advanced and recent offline RL algorithms ought to be included as the baselines (e.g., TD3BC, IQL, Decision Transformer, LAPO, etc.). The authors build their method upon CQL, BCQ, and BEAR. Can your method benefit more advanced offline RL algorithms?\n\n- (major) This paper does not consider statistical significance. Written statements and the presentation of the results as tables (often without standard deviations) obscure this flaw. In fact, ALL tables in this paper does not include any signal of statistical significance, e.g., std, IQM. We have reached a point of maturity in the field where claims need to be made in reference to actual statistical evidence, which seems to be lacking in the current presentation.\n\n- (major) The theoretical analysis is also not new. Similar techniques are adopted in the MBPO paper. Specifically, one online model-based RL algorithm BMPO \\[y\\] theoretically shows that the error of the bidirectional models is smaller than unidirectional models, making the theoretical insights of this paper less appealing and unsurprising.\n\n\\[y\\] Bidirectional model-based policy optimization. ICML 2020.\n\n- (minor) The authors ought to specify the version of the D4RL datasets they use in the paper. In Table 1, your evaluated scores in halfcheetah-medium-expert are questionably low, why is that?\n\n- (minor) This paper does not do a good job in the related work part, the authors include too few recent offline model-based/model-free offline RL papers Please refer to the the weaknesses part.",
         "603",
         "0",
         "3",
         "0.7867",
         "0.0567165212",
         "0.9565235972",
         "53",
         "15",
         "32.288",
         "13.2124",
         "15.5541",
         "14.3361",
         "14.0344",
         "0.3178",
         "87",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "23",
         "tQ8gcygV4p",
         "1080",
         "1695005759142",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "Reviewer_qiBS",
         "1698549177482",
         "1699636034488",
         "5",
         "4",
         "3",
         "3",
         "2",
         "This paper presents a new model-based method for offline reinforcement learning. The key technical contributions of the proposed model include: 1) It learns the bidirectional rollouts of the state transitions and the reward functions; 2) It learns forward and backward offline policies, following the BCQ method. With the learned bidirectional dynamics model and the corresponding policies, given a pivotal data point drawn from the offline dataset, the replay buffer can be augmented with the generated data trajectories. \n\nAdditionally, the paper provides a theoretical analysis, establishing a tighter bound on the rollout error for the conservative bidirectional rollouts compared to unidirectional approaches. \n\nFinally, the empirical findings on the D4RL benchmark demonstrate the effectiveness of the proposed method. 1. The proposed method is simple, reasonable, and effective on the existing D4RL benchmark, showing great potential for practical offline RL applications. \n2. The paper is well-written and easy to follow. The overall design of the proposed method is presented in a clear and thoroughly motivated manner. \n3. The method seems to be a highly versatile framework. As shown in the paper, it can be easily integrated with existing model-free offline RL approaches. 1. My primary concern with this paper is about the novelty of the proposed bidirectional rollout technique. At NeurIPS 2022, a paper titled \"Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination\" by Lyu et al. introduces a conceptually similar idea. In both papers, forward and backward models are trained to augment the offline dataset. It is crucial for the authors to address this similarity and provide a comprehensive comparison between COBiMO and the method presented by Lyu et al., considering aspects such as model design and empirical results.\n2. In the experiment section, the authors present averaged results of 6 random seeds. To enhance the statistical robustness of their findings, it would be better to include the standard deviations over multiple runs in Tables 1-3. \n3. The paper primarily compares COBiMO with approaches that were proposed 2-3 years ago. It would be beneficial for the authors to extend their comparisons to include more recent advances in offline RL to provide a comprehensive evaluation of COBiMO's performance in the context of the most current state of the field.\n4. In Section 5.3, there is an absence of an explanation regarding the factors that lead to performance degradation in certain tasks when COBiMO is applied (which can be reasonable but needs more analysis). Besides, as claimed in Section 5.3, the proposed method outperforms the original algorithms significantly in 10/12 tasks. However, it's essential to ensure that all relevant results supporting this claim are presented, as only a partial subset of the results is currently shown in Table 3.\n5. Typos:\n- In the first paragraph of Section 5.1, \"...from three domain\" should be corrected to \"...from three domains\".\n- In the third paragraph of page 4, \"...represents a gaussian distribution...\" should be \"...represents a Gaussian distribution...\". In summary, my primary concerns include the technical novelty in comparison to the missing reference (major), and some finer details of the provided experimental results (minor).",
         "513",
         "0",
         "8",
         "0.7682",
         "0.1505058522",
         "0.9512968659000001",
         "53",
         "12",
         "35.9958",
         "12.2057",
         "14.9981",
         "13.9117",
         "12.7486",
         "0.30110000000000003",
         "96",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "24",
         "tQ8gcygV4p",
         "1080",
         "1695005759142",
         "['~Zixian_Zhou1', '~Xiang_Ao2', '~Yang_Liu73', '~Qing_He2']",
         "Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts",
         "Offline reinforcement learning (offline RL) learns from an offline dataset without further interactions with the environment. Although such offline training patterns can avoid cost and damage in the real environment, one main challenge is the distributional shift between the state-action pairs visited by the learned policy and those in the offline dataset. Prevailed existing model-based offline RL approaches learn a dynamics model from the dataset and perform pessimistic policy optimization based on uncertainty estimation. However, the inaccurate quantification of model uncertainty may incur the poor generalization and performance of model-based approaches, especially in the datasets lacking of sample diversity. To tackle this limitation, we instead design a novel framework for model-based offline RL, named Conservative Offline Bidirectional Model-based Policy Optimization (abbr. as COBiMO). First, we learn an ensemble bidirectional model from the offline dataset and construct long bidirectional rollouts by joining two unidirectional ones, thereby increasing the diversity of the model rollouts. Second, we devise a conservative rollout method that minimizes the reconstruction loss, further improving the sample accuracy. We theoretically prove that the bound of rollout error of COBiMO is tighter than the ones using the unidirectional models. Empirical results also show that COBiMO outperforms previous offline RL algorithms on the widely used benchmark D4RL.",
         "Reviewer_7BFv",
         "1698807801456",
         "1699636034401",
         "3",
         "4",
         "2",
         "3",
         "1",
         "This paper studies the model-based offline reinforcement learning problem. The authors propose to learn bidirectional model and bidirectional behavioral policies and use them to generate rollout trajectories. The output policy is obtained by a model-free offline reinforcement learning on the augmented dataset. The paper provides theory and empirical study to justify the proposed algorithm. 1. The paper is clearly written and easy to follow. 1. The Related Work misses important paper. For instance, this paper is not the first to use bidirectional model in offline learning. Confidence-aware Bidirectional Offline Model-based Imagination is the first to apply this idea to the best of my knowledge.\n2. I cannot recognize the algorithmic novelty of the algorithm. Forward imagination is widely used in model-based offline learning and Reverse Imagination was first proposed in ROMI. This paper seems to just combine these two ideas directly without justifying why it can substantially improve the performance\n3. The theory seems to be trivial.\n4. The experiment misses important baselines, such as ROMI and Confidence-aware Bidirectional Offline Model-based Imagination which share similar ideas. Besides, the performance does not seem compelling if one also look at the performance in ROMI and Confidence-aware Bidirectional Offline Model-based Imagination paper. 1. What is the main intuition behind using bidirectional imagination? Why should we expect it provide substantial improvement?\n2. What does the theory part tell us, is there any interesting insight?\n3. How does the algorithm perform compared to other later model-based algorithms? How does the algorithm perform on other tasks in D4RL?",
         "252",
         "0",
         "7",
         "0.7828",
         "0.1666666667",
         "0.9260005355",
         "53",
         "9",
         "30.2158",
         "12.3398",
         "14.5116",
         "13.4487",
         "12.3402",
         "0.1199",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "25",
         "sKPzAXoylB",
         "8965",
         "1695531697040",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "Reviewer_KmBd",
         "1698096053419",
         "1699637128872",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper introduces a novel approach called Utility-based Perturbed Gradient Descent (UPGD) to address catastrophic forgetting and loss of plasticity in neural networks. UPGD combines gradient updates with a mask to protect useful weights from being forgotten and reuse less useful weights. The paper also proposes metrics to evaluate loss of plasticity and catastrophic forgetting. Empirically, the method outperforms existing methods in streaming learning problems in terms of retaining plasticity and avoiding catastrophic forgetting. **Originality**\nConceptually, the problem addressed by the authors of avoiding forgetting while retaining plasticity in streaming learning settings remains underexplored. The specific method proposed by the authors is relatively straightforward and conceptually similar to prior approaches; however, it empirically outperforms prior methods as the experimental results demonstrate.\n\n**Quality**\nThe convergence guarantee results are valuable. The experiments are generally comprehensive and well-conducted. Assessing the quality of the approximated utilities in section 4.1 is \nof critical importance, and the results are convincing. Conducting miniImagenet scale experiments is a solid addition to the experimental section. The ablation study in Figure 8 is also insightful.\n\n**Clarity**\nThe writing is generally clear and the figures are well-illustrated.\n\n**Significance**\nOverall, the paper addresses a major issue in the field of streaming learning. Given that the paper doesn't investigate the theoretical properties of UPGD, the significance of the paper hinges on the strength of the empirical results. Since the proposed method lacks theoretical performance guarantees, its empirical performance is critical. The authors have generally done a good job demonstrating that UPGD avoids forgetting and maintains plasticity; however, a few concerns remain:\n\n- It appears that S-EWC does not have too much of a gap with UPGD judging from figure 7: it entirely avoids catastrophic forgetting, and the only setting where it loses plasticity where UPGD does not is on MNIST\n- S-MAS outperforms UPGD on miniImagenet at the end of training, and does not have a large gap overall\n- The ablation of figure 8 checks the contribution of each component of UPGD sequentially as they are added to regular SGD. Ideally, the ablation would study how each component affects UPGD when they are *individually* removed (e.g. UPGD without WP).\n\n**Minor comments**\nFigure 7 is referred to before Figure 6; ideally, their order would be swapped.\nI see in Section 4 that the results are averaged over 20 trials, but the meaning of the error margins in some of the figures is not made clear (e.g. figure 2). I would also suggest increasing the number of trials to smooth out the curves if possible. Is it possible to show theoretical performance guarantees for UPGD? For instance, can the approximation error of equation 2 be bounded? Alternatively, if the true utilities are used in equation 3, is it possible to derive some guarantees against forgetting or loss of plasticity?\n\nHow much more significantly does UPGD improve upon baselines S-EWC and S-MAS?\n\nHow does UPGD-W perform with WP and WD removed individually?",
         "487",
         "0",
         "1",
         "0.7320",
         "0.1304191468",
         "0.9185432792",
         "47",
         "17",
         "29.0538",
         "13.6602",
         "16.2613",
         "15.0211",
         "14.0811",
         "0.1695",
         "88",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "26",
         "sKPzAXoylB",
         "8965",
         "1695531697040",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "Reviewer_3zCE",
         "1698692987251",
         "1699637128739",
         "3",
         "4",
         "4",
         "3",
         "1",
         "This work proposes to modify stochastic gradient descent (SGD) to overcome forgetting and promote plasticity in continual learning. These goals are achieved by masking out the parameters with high utility and perturbing gradient direction by Gaussian noise. For utility computation, the authors propose an approximate but efficient scheme based on second-order Taylor expansion of the loss. Experiments demonstrate that (i) the proposed utility approximation is more accurate than simple baselines such as weight magnitude, (ii) it maintains plasticity, (iii) plasticity and accuracy are in general correlated, (iv) the method tends to forget less than baselines, and (v) it simultaneously promote plasticity and prevents forgetting. This paper is written well. The notation is okay and the mathematical derivations seem correct. The baseline methods are clearly outperformed and the experiments verify the central claim of the paper. Although continual learning is an important machine learning challenge, I feel the paper suffers from significant weaknesses:\n\n  - First and foremost, I do not think this paper makes a significant contribution. The methodology is incremental in that it combines two well-known ideas (perturbed gradient descent + keeping active neurons unchanged). \n  - Second, it is tested on very toy setups. The experiments are not convincing enough to show the applicability of the method to interesting real-world setups. For instance, I am not sure the networks achieve similar plasticity if tested on, e.g., webcam data instead of MNIST, where the feature space is a lot richer and hence plasticity is much more difficult.\n  - Third, theoretical properties/implications of the method should be carefully examined. \n    - For instance, the Taylor expansion would only hold if $W_{l,i,j}$ are infinitesimally small. We do not know in general if this holds or not. I suggest the paper should include a (preferably rigorous) discussion on this.\n    - Likewise, gradient descent is no longer steepest descent but some approximation to it. Investigating why it works is important. As shown by the results, no collapse occurs but again, I wonder how this translates into more challenging settings where utilities of most parameters are high. Here I list my questions as well as suggestions:\n\n- It would be better if Label-Permuted EMNIST was described before the results are discussed in paragraph 5.\n- _Although a few methods address both issues simultaneously, such methods expect known task boundaries, maintain a replay buffer, or require pretraining, which does not fit streaming learning._ <--- reference needed for this claim.\n- What does \"a Hessian diagonal approximation in linear complexity\" mean? Linear in the number of parameters?\n- It would be better if the main text included details on the \"utility propagation theorem\".\n- It would be better if the descriptions of the tasks/datasets (e.g. Input-Permuted MNIST in section 4.2) were given before the details.\n- Does \"each learner is trained for 1M samples, one sample each time step\" mean gradient descent using one sample only? Is this realistic?",
         "480",
         "0",
         "0",
         "0.8331",
         "0.09343537410000001",
         "0.9183989763",
         "47",
         "10",
         "39.3732",
         "11.51",
         "13.8202",
         "13.2344",
         "11.9386",
         "0.1932",
         "87",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "27",
         "sKPzAXoylB",
         "8965",
         "1695531697040",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "Reviewer_y5kB",
         "1698706759624",
         "1699642867494",
         "6",
         "3",
         "3",
         "3",
         "3",
         "The paper proposes a measure of weight utility of weights in neural networks for given loss and using it to modify a gradient-based weight update in networks to alleviate the problem of catastrophic forgetting.  The authors identify two fundamental aspect of catastrophic forgetting - the forgetting aspect (not losing what the network already know) and plasticity aspect (ability to learn new concepts).  The proposed method is meant to address two problems at the same time, preseving high utility weights with no modifications (to prevent forgetting) while randomly perturbing low utility weights to \"encourage\" them to participate in the computations related to new tasks (plasticity).  Empirical evaluations show solid performance of the proposed method according to the forgetting and plasticity metrics newly defined by the authors. The proposed rule is straight forward.  \n\nComputational complexity of the evaluation of true utility is well addressed making the method practical.\n\nEmpirical evidence provided shows the proposed rule is effective for alleviation of catastrophic forgetting.\n\nDecomposing the catastrophic forgetting problem into two aspects: forgetting and plasticity, seems very sensible.\n\nProposed measures of plasticity and forgetting seem sensible.\n\nThe paper is well written. Though empirical evidence provided in the paper suggest it does (in that it works), I am not sure that the proposed definition of weight utility make sense.  The power of neural networks (and the problem of the interpretation of its computation) is its distributed computation.  Utility of an individual weight is almost always nothing - in fact, quite often any particular weight, sometimes even large number of weights, can be taken out of the network, with little impact on performance.  So, it's more about combinations of weights working together...and the proposed utility doesn't measure that.  I understand that evaluating utility of combinations of weights is intractable, but I worry that this simplification, of judging utility of each weight in isolation, is encouraging less distributed representation, which might come with a penalty in performance.\n\nFundamentally, on the forgetting front, the proposed method is just another weight consolidation method, and it's a bit hard to believe it beats Elastic Weight Consolidation.  It am not 100% sure that the proposed method doesn't favour plasticity over forgetting nor that the forgetting evaluation isn't biased towards methods that favour plasticity (see questions below). Though I understand (and like) in principle what the utility-based update is supposed to do, I can't quite understand why it actually works.  The proposed measure of the utility of parameters is a measure with respect to the loss on the new input/output pair.  If this pair comes from a new task, how does measuring utility of the model parameters with respect to the loss of this new task have bearing on the utility of the parameters for the old tasks?  Just because utility of a given weight is, say, low for the current sample, it doesn't mean it's low for previous samples.  It seems to me that the proposed method would score high on plasticity (it finds available weights for new task)...but I don't see how it protects against forgetting, in principle, though if we are to talk about empirical evidence...  I don't understand how 4.3 measures catastrophic forgetting.  Permuting labels of CIFAR10 with the new tasks suggests to me that it's all about plasticity again.  Shouldn't it be an experiment, where labels are kept intact, but new tasks are added...and previous tasks examples are not used?  Am I missing something about how experiments reported in 4.3 are done?\n\nWhy are the accuracy results of training on CIFAR-10 and EMNIST so poor in Figure 6?  State of the art CIFAR-10 is close (or above) 90%.  Something close to 80% would be probably still acceptable...but 60% is quite poor.  I am not exactly sure what EMNIST variant entails, but is 70% accuracy a good accuracy for this dataset?  It is often easy to shown improvements of something at the low end of the models' performance, but that doesn't always translate to same effect at the high (or close to) end of the models' performance...and in the end, the latter is what we really care about.  So, does the proposed method prevent forgetting at the high end, when model is performing at or reasonably close to state of the art?\n\nThis is not a massive issue, but does the per batch normalisation of utility make the performance of the method variable with different  mini-batch size settings?",
         "730",
         "0",
         "0",
         "0.7435",
         "0.0644808927",
         "0.8415006399",
         "47",
         "10",
         "41.9389",
         "11.9311",
         "14.8075",
         "13.9683",
         "12.4911",
         "0.050100000000000006",
         "104",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "28",
         "sKPzAXoylB",
         "8965",
         "1695531697040",
         "['~Mohamed_Elsayed2', '~A._Rupam_Mahmood1']",
         "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning",
         "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues.",
         "Reviewer_XNx6",
         "1699165868969",
         "1700672717423",
         "6",
         "4",
         "2",
         "2",
         "3",
         "This paper proposes Utility-based Perturbed Gradient Descent(UPGD). A modification to the vanilla gradient descent update rule that helps the model to operate in a more challenging scenario of streaming learning. The authors introduced their utility function as an importance weight for each parameter of a neural network. The authors show the effectiveness of their contribution compared to common importance assignment methods in the continual learning literature. **Clear Structure and Writing:** The paper benefits from a clear structure and concise writing style.\n\n**Addressing a Complex Issue:** The authors tackle an underexplored yet challenging problem, and I appreciate their efforts to address online continual learning.\n\n**Mathematical Foundation:** The definition of utility introduced in the paper is based on simple and sound mathematical derivations. \n\n**New metric:** The introduction of a new plasticity metric is a nice contribution to the relatively uncharted territory of streaming learning. **Unscaled perturbations:** My main point of issue is the reasoning behind the perturbations in the update rule. The authors claim that by adding the perturbation we are making the unimportant weights more plastic however I am not really convinced by this explanation I believe it requires elaboration both in the rebuttal and in the paper. \n\nAnother related issue with the proposed perturbation is the fact that all of them are getting drawn from the same standard normal distribution. This design choice is strange to me since the parameters of a neural network usually differ in magnitude from layer to layer. By adding an unscaled random perturbation to all of the weights we are ignoring this scale difference which I believe is sub-optimal. I know that in the unprotected version, they are getting weighted by different values but this particular scaling is more correlating with changes in the loss value rather than the parameter magnitudes.\n\nHighly relevant to the above issue, I believe it is also necessary to have an additional ablation study, investigating the role of having and not having the perturbations in the update rule. I also want to disentangle the effect of weight decay. The only time that UG is added in the ablation is in the presence of WD. More specifically I am curious about the following scenarios in Figure 8: \n\n* Added ablations:\n    + SGD + UG + WP + WD (present in the paper)\n    + SGD + UG + WP \n    + SGD + UG + WD\n    + SGD + UG\n\n    \n**Including more diverse experiments:** Moreover, in the experiments section I believe the authors need to include more diverse experiments. All of the streaming tasks are permutations of the same task. Whether in the label or in the input space. It is not as obvious as the authors' claim that after the permutation of the input space the previously learned representations are not relevant anymore (end of page 6). In the input-permuted scenario, only the first layer needs to have significant change. This is especially true for the label-permuted tasks as the network does a good job of clustering the data up to the final FC layer. I encourage the authors to use the Cifar100 superclass dataset (or any similar sequence of tasks that does not simply rely on the permutation).\n\n**Visualization:** Finally, I believe the visualization needs several improvements: the legends on the plot are very hard to read (Fig 2, 3, 4, 5). Some colors are similar to each other and the width of the lines in the legends is too thin. (Especially in figure 4). In Figure 7, some numbers in dark blue cells are almost impossible to read. **Q1:** Have the authors tried to use an scaled version of the perturbation that takes the magnitude of the parameters into account? (Other than the unprotected version). Also I would appreciate the if you could elaborate on the effect of perturbations.\n\n**Q2:** Could you also explain about the average online accuracy? it is stated that \"The average online accuracy is the percentage of correct predictions within each task.\" I cannot see the average part here. Is it calculating the accuracy on each task separately then averaging over the number of tasks?",
         "679",
         "0",
         "0",
         "0.7295",
         "0.0576258913",
         "0.9159082770000001",
         "59",
         "17",
         "42.2021",
         "12.1002",
         "14.7586",
         "13.9683",
         "12.0852",
         "0.929",
         "90",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "29",
         "sK2A7Ve2co",
         "5473",
         "1695387922229",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "Reviewer_XKu5",
         "1698340335396",
         "1699672907827",
         "1",
         "3",
         "1",
         "1",
         "1",
         "The paper proposes a method to obtain Gaussian approximations of posterior distributions in Bayesian deep learning. The experiments compare the proposed method against several related approaches on toy experiments as well as classification on CIFAR-10/100 and ImageNet. The authors report that their method tends to produce samples quicker than competitor methods. The paper is definitely still a work in progress and not ready for publication at a conference like ICLR.\nThus, I vote for rejection and encourage the authors to completely revise their manuscript and submit to another venue.\n\nThe writing style and organization of the paper is very bad, which makes it extremely hard to follow. In particular, the theoretical exposition is lacking:\n- The theory is mixed with the related work (Eqs. (1)-(3), last Sec. of 1.1)\n- Central notions and symbols are not introduced, the exposition remains very handwavy. To name only a few examples:\n  - what do the authors mean by \"transforming a pretrained into a Bayesian model\"?\n  - background on MCMC, Metropolis-Hastings corrections\n  - definition of a \"perfect sampler\"\n  - how do the authors define a \"mode-specific MH\"\n  - it remains unclear in which sense the proposed method better deals with multi-modal posteriors than related work\n  - definition of notion of time step $t$ and $\\theta_t$ in Eq. (4)\n  - definition of $D_x$, $D_y$ in Eq. (15, 16)\n  - definition of $\\mathrm{Conf}$ in Eq. (20)\n  - ...\n- The experimental evaluation is not convincing.\n  - While the authors report fast sampling, their approach is outperformed by competitor methods most of the time.\n  - On the simplest toy example (unimodal Gaussian posterior), the authors report good results in terms of effective sample size (which is not very surprising because they use the correct approximation). However, they do not report ESS on the mixture model (Figure 2 RHS). \n  - The authors argue that their method deals well with multi-modal posteriors. Thus, they should compare\n against other methods that capture multiple modes, i.p., Deep Ensembles \\[1\\] and Multi-SWAG \\[2\\].\n  - As the authors employ a Gaussian posterior approximations, they should compare against variational Gaussian approximations, e.g., BayesByBackprop \\[3\\].\n\n\\[1\\] Lakshminarayanan et al., \"Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles\", NeurIPS 2017\n\n\\[2\\] Wilson & Izmailov, \"Bayesian Deep Learning and a Probabilistic Perspective of Generalization\", NeurIPS 2020\n\n\\[3\\] Blundell et al., \"Weight Uncertainty in Neural Networks\", ICML 2015 Please elaborate on the concerns raised below \"Weaknesses\".",
         "399",
         "6",
         "1",
         "0.8017",
         "0.055785256400000004",
         "0.9074112773",
         "49",
         "15",
         "40.3959",
         "11.5687",
         "14.224",
         "13.3617",
         "12.3358",
         "0.2383",
         "104",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "30",
         "sK2A7Ve2co",
         "5473",
         "1695387922229",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "Reviewer_xaq1",
         "1698616789279",
         "1699636558195",
         "3",
         "5",
         "2",
         "2",
         "2",
         "This paper proposes an adaptive proposal sampling (APS), a mode seeking sampler that adapts the proposal to match a posterior mode. The proposed ``adaptive proposal sampler'' appears to be new in the literature. 1. Extension of the proposed sampler to high-dimensional problems is questionable. As mentioned in the paper, the parameters are regarded as independent of each other, making the proposed sampler less accurate and thus less attractive. \n\n2. When the modes of the target distribution are well separated, it is difficult to believe that the proposed sampler can efficiently traverse the entire energy landscape because, similar to the Metropolis-Hastings algorithm, the proposed sampler lacks a mode-escaping mechanism. \n\n3. For the exact Gaussian proposal sampler, the acceptance rate can be low when the dimension of \\theta is high. 1. If the exact GPS is applied to the numerical examples of the paper, will the reported results be improved? How much?   \n\n2. The proposed method needs to compare with more baseline methods, such as SGHMC \\[1\\]  and adaptively weighted SGLD \\[2\\], on multi-modal and high-dimensional problems.\n\nReferences: \n\n\\[1\\] Chen et al. (2014) Stochastic Gradient Hamiltonian Monte Carlo. ICML 2014. \n\n\\[2\\]  Deng et al. (2022) An adaptively weighted stochastic gradient MCMC algorithm\nfor Monte Carlo simulation and global optimization. Statistics and Computing, 32:58.",
         "211",
         "6",
         "9",
         "0.7536",
         "0.06515948960000001",
         "0.9111343622",
         "49",
         "11",
         "38.8025",
         "11.8793",
         "15.971",
         "14.332699999999999",
         "12.8694",
         "0.0751",
         "96",
         "2",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "31",
         "sK2A7Ve2co",
         "5473",
         "1695387922229",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "Reviewer_zCTz",
         "1698618917865",
         "1699636558088",
         "3",
         "4",
         "1",
         "2",
         "2",
         "The paper proposes a new sampling algorithm for multi-modal distributions, especially deep neural network posteriors. Specifically, the authors learn an adaptive Gaussian proposal along with sampling. Several experiments, including synthetic distributions and deep learning tasks, are conducted to test the proposed method. 1.\tThe studied topic of sampling on multi-modal distributions is important.\n2.\tThe proposed algorithm is simple to implement in practice. 1.\tThe proposed method does not achieve what it claims to “having both exactness and effectiveness”. Apparently, the method is not exact without the MH correction step. The method is only exact when the target distribution is a Gaussian with a diagonal covariance, which is a trivial case. I’m not sure what “perfect sampler” means in the paper. Overall, I think many claims need to be modified in order to be accurate and rigorous. \n2.\tThe methodology of the proposed method is confusing. The algorithm does not have a component to encourage exploring multiple modes. It is unclear to me how the method manages to find diverse modes. \n3.\tAlgorithm 1 seems to find a Gaussian distribution to approximate the target distribution. How is it different from variational inference? What are the advantages?\n4.\tWhy does the proposed method require a pretrained solution, theta_MAP? Will it work if training from scratch? \n8.\tI do not follow the reason for introducing the variance limit lambda. Why does the method need it?\n9.\tThe experimental setups and results are confusing. It is unclear if the authors also use a pre-trained solution for the baseline NUTS in S3.1. If not, then it is unfair to claim faster convergence of the proposed method than NUTS. Besides, given that the method uses a pre-trained solution, it is unsurprising that “We found that a-GPS converges so fast that a burn-in period was unnecessary”. For the time comparison, it is unclear if the authors include pre-training time.\n10.\tFor deep learning experiments, it will be better to include MCMC baselines, e.g. Zhang et al, as the proposed method belongs to MCMC methods. To show the samples are from diverse modes, the authors can visualize weight space and function space, similar to those in Zhang et al.\n\n\nZhang et al, Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning, ICLR 2020 1.\tWhy is LA’s inference time even less than MAP? Why is the proposed method’s inference time less than SWAG? Does the proposed method use Bayesian model averaging during inference?",
         "405",
         "0",
         "9",
         "0.7441",
         "0.0309343434",
         "0.9304510951",
         "49",
         "11",
         "53.1978",
         "8.9835",
         "12.1736",
         "11.8164",
         "9.3087",
         "0.1932",
         "96",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "32",
         "sK2A7Ve2co",
         "5473",
         "1695387922229",
         "['~Fabian_Meyer_Bull1', '~Geir_Storvik1', '~Arnt_B._Salberg1', '~Anne_Schistad_Solberg1']",
         "Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler",
         "To trust the predictions provided by deep neural networks we need to quantify the uncertainty. This can be done with Bayesian neural networks. However, they require a trade-off between exactness and effectiveness. This paper introduces a new sampling framework: Adaptive Proposal Sampling (APS). APS is a mode seeking sampler that adapts the proposal to match a posterior mode. When modes overlap, APS will adapt to a new mode if it draws a sample that belongs to a new mode. A variant of APS is the approximate Gaussian Proposal Sampler (a-GPS). We show that it becomes a perfect sampler if it has the same score function as the posterior. With a warm-start of a pretrained model, combined with stochastic gradients it scales up to deep learning. Results show that a-GPS 1) proposes samples that are proportional to a mode, 2) explores multi-modal landscapes, 3) has fast computations, 4) scales to big data. Immediate results suggest that this framework may be a step towards having both exactness and effectiveness.",
         "Reviewer_RZPX",
         "1698652042813",
         "1699636557963",
         "3",
         "4",
         "3",
         "2",
         "2",
         "The paper proposes a sampler that samples weights via traversing the loss landscape of a pre-trained deep neural network via a series of normal distributions. The approach is evaluated on a series of classification and out-of-distribution detection tasks. The paper proposes a sampler that samples weights via traversing the loss landscape of a pre-trained deep neural network via a series of normal distributions. The approach is evaluated on a series of classification and out-of-distribution detection tasks. - The main weakness of the paper is in the experimental evaluation. The experiments show convincingly that the proposal works with several architectures and several classification data sets (no regression tasks were evaluated). What it does not show is that it works better than its baselines, i.e., why should it be used instead of SWAG, or SGD-MC? E.g., SGD-MC almost always outperforms it (it is missing from Table 4, but the results in Table 13, show that it clearly performs better), except for the strange behavior in Table 6.   \n\n\n- The presentation of the paper is rather sub-optimal. E.g.,\n    - parameters such as $c$ and $\\lambda$ appear in the text long before they are even introduced, if at all. The important $\\lambda$, e.g., only is further detailed in Algorithm 1.\n    - The writing contains a lot of typos, e.g., for the first paragraph on the second page\n        - \"full-gradient MCMC similar **to** SG-MCMC\"\n        - \"SGLD **has** fast computations but **suffers** form inefficient explorations\"\n        - \"Previous **works** on state dependent\"\n    - Dropout's absence in most of the results is not explained in the main text but only appears in the one table where it is present rather than absent\n    - The writing is somewhat repetitive\n    - The reference list is full of arxiv preprints instead of the actual publications \n    - Table 4 contains wrong highlights in two columns (ECE and NLL), the same is true for several tables in the appendix.\n    - On the positive side, however, other details, like definitions of performance metrics are highlighted prominently\n\n### Minor\n- SGD-MC is mentioned in the text for Table 4 but not in the actual results\n- LA is missing in Table 3 without an explanation\n- Sec 2.1: \"the loss function, ..., typically cross-entropy is interpreted as the negative log-likelihood\". Cross-entropy is typical for classification tasks, but not for any other tasks. And in this case, it is not just interpreted as a negative log-likelihood, _it is_ the negative of a categorical distribution. \n- For the posterior in  (15). A Gaussian prior is $\\exp(-||\\theta||)$, similarly for the loss factor. This directly provides you with (17) instead of having to redefine anything.\n- Sec 3.2.2 \"separated by high loss area\". As Draxler et al. (2018) and Garipos et al. (2018) show there are a lot of paths of similar loss between a lot of maxima instead of a clear separation. (These motivated the SWA baseline of the present work)\n\n\n\n_____\nDraxler et al., _Essentially no Barriers in Neural Network Energy Landscape_, ICML 2018  \nGaripov et al., _Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs_, NeurIPS 2018 - The conclusion only discusses a-GPS' performance with respect to SWAG and Laplace. Can the authors additionally provide a deeper discussion on their relation to SGD-MC and in general summarize why their approach should be picked instead of these established baselines?\n- SGLD is mentioned in the related work, but never used in the experiments. Can the authors comment on this lack of comparison? Especially since they cite Izmailov et al. (2021) who showed good results for this approach.\n- A lot of approaches and networks diverged or failed otherwise throughout the experiments. Can the authors give further details? E.g., it seems rather strange that a simple model such as VGG should diverge on a straight-forward classification task such as CIFAR100.\n- The method was only tested on classification tasks. What about regression problems? Do the authors expect a similar performance? \n- How is the split in CIFAR10 and CIFAR 100 in 5/50 classes decided? _(Apologies if I missed it somewhere in the appendix)_",
         "675",
         "3",
         "1",
         "0.7542",
         "0.0275083022",
         "0.8832126856",
         "49",
         "11",
         "51.8979",
         "9.7817",
         "12.2617",
         "12.0985",
         "10.234",
         "0.077",
         "101",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "33",
         "nxPTSDp9xK",
         "6136",
         "1695409971904",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "Reviewer_Uwik",
         "1698715047173",
         "1699636664998",
         "5",
         "5",
         "3",
         "3",
         "2",
         "The paper introduces the Cross-Guided Ensemble of Tokens (CrossGET), which is designed to enhance the efficiency of vision-language Transformers. It tackles the significant challenge of mitigating the computational costs and latency associated with vision-language models. Within this framework, two essential components come into play: Cross-Guided Matching and Ensemble, orchestrating the fusion of tokens guided by cross-modal cues, and Complete-Graph Soft Matching, contributing to the refinement of token matching outcomes. 1.Comprehensive Experimentation and Solid Theoretical Foundation: The paper's strength lies in its extensive and well-documented experiments, combined with a rigorous theoretical underpinning for the proposed method. This makes the work sound and reliable, both in terms of its theoretical framework and practical applicability.\n2. Relevance of the Addressed Problem: The choice of the problem addressed in the paper holds significant value, especially in the context of the substantial computational overhead associated with many state-of-the-art multimodal models. This highlights the practical importance of the research. However, it is recommended that the authors extend their analysis and experimentation to encompass a broader range of models, moving beyond the initial exploration with BLIP-2. This would further enhance the paper's contribution and generalizability. 1. Cross-Modal Guidance Utilization: In the paper, the emphasis is placed on the ability of CrossGET to be applied to modality-dependent models like BLIP and BLIP2. The approach involves learning a cross-token to serve as guidance for another modality. However, there are concerns about this approach. Taking BLIP as an example, it appears that it may not fully harness textual guidance. In scenarios like visual grounding, where different textual descriptions highlight various aspects of the same image, it raises questions about how CrossGET selects tokens from different texts to focus on.\n2. Unfair Experimental Comparisons: The paper contains instances of unfair comparisons in the experiments. For example, in section 4.1, the authors directly compare retrieval results of models such as TRIPS and UPOP. Yet, these models vary significantly in terms of training data and model parameter sizes, making the comparison less meaningful. To provide a clearer perspective, the paper should emphasize how much TRIPS, or similar acceleration methods, improve over the baseline, and how much the proposed method accelerates and enhances performance compared to the baseline.\n3. Limited Model Performance Improvement: The paper reports only marginal improvements in model performance while introducing a relatively complex method. Moreover, the acceleration achieved by the proposed method appears similar to that of ToMe. Given the relative complexity of the proposed approach, the effectiveness of this work may be questioned, especially if the gains in performance and acceleration are not substantial. 1. Implementation of Token Reduction in BLIP-2: It would be beneficial for the authors to provide more detailed information on how they specifically implemented token reduction in BLIP-2 within the context of their method. A more elaborate explanation of the process and its impact on BLIP-2's performance would enhance the clarity and completeness of the paper.\n2. Impact of CrossGET on OPT in BLIP-2: A notable aspect of this work is the introduction of CrossGET into the frozen OPT component of BLIP-2 for token reduction. However, it's important to consider that OPT is a decoder-only model. The paper should address how this approach might affect the inference capabilities of OPT and whether any experiments were conducted to analyze and verify why image captioning performance appears to be minimally impacted. Further insight into this aspect of the methodology would enhance the paper's robustness and contribute to a better understanding of the results.Im glad to improve my score if my   concerns be addressed.",
         "586",
         "0",
         "6",
         "0.7977",
         "0.1171066253",
         "0.94465065",
         "48",
         "10",
         "25.0653",
         "14.7832",
         "17.2295",
         "15.7704",
         "16.3387",
         "0.1262",
         "77",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "34",
         "nxPTSDp9xK",
         "6136",
         "1695409971904",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "Reviewer_4d9L",
         "1698744941721",
         "1702028039451",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper introduces CrossGET, a token reduction-based strategy, to accelerate vision-language transformers. The key contributions of CrossGET can be summarized as follows: 1) CrossGET incorporates cross-modal guided information through cross-modal tokens. 2) CrossGET employs the Complete-Graph Soft Matching (CGSM) strategy, which offers more reliable token-matching results compared to existing bipartite soft matching strategies. Experimental evaluations conducted across multiple models, datasets, and tasks demonstrate the superior performance of the proposed method. The acceleration of VL models is highly relevant for their practical deployment. While this paper presents promising results and extensive evaluations, there are important concerns that should be addressed before publication.\n1. Some experimental results are perplexing. Table 1 suggests that ToMe performs worse when equipped with Adapter or ExtraToken. However, Adapter and VPT are parameter-efficient tuning methods that enhance performance with minimal additional parameters. It is unclear how they could instead degrade performance. I suspect there may be errors in the implementations. It is recommended to double-check the results or provide convincing explanations. Additionally, the upper-right subfigure in Figure 4 is also confusing. In my understanding, CrossGET and ToMe have close GFLOPs under the same configuration (as evident from the left subfigure). Therefore, the significant differences in GFLOPs for each data point pair in the upper-right subfigure indicate that they are compared under different configurations. A reasonable explanation should be provided here. Moreover, the down-right subfigure seems to be unusual as well. How is it possible for the model to achieve even better performance (nearly 86) with only 1/10 GFLOPs? Are the settings the same as in other figures?\n\n2. The contribution of the Complete-Graph Soft Matching (CGSM) appears to be minor. For instance, Table 1 suggests that ToMe and CrossGET $\\Delta$ perform similarly in different metrics, indicating that the proposed CGSM may have little impact. ToMe employs the bipartite soft matching strategy for its efficiency and simplicity, and the ToMe paper demonstrates that this strategy can approximate optimal matching through extensive combination experiments. This paper should provide more evidence (visualizations, analytical experiments) to justify the effectiveness of the proposed CGSM.\n\n3. Most experiments in this paper focus on Image-Text retrieval tasks. Is the proposed method equally effective in other VL tasks, such as the CoOP benchmark or open vocabulary segmentation?\n\n4. This paper lacks an important comparison. \\[1\\] proposes reducing the number of tokens through clustering and demonstrates better performance than ToMe in accelerating transformers. However, this paper only briefly mentions it in the introduction without further discussion or comparisons. It is recommended to include more comparisons (\\[1\\] vs. CrossGET $\\Delta$, \\[1\\] + CGM&CGE vs. CrossGET $\\star$, etc., better in dense prediction tasks) with \\[1\\].\n\nI am glad to increase my rating if my concerns are addressed.\n\n\\[1\\]. Weicong Liang, Yuhui Yuan, Henghui Ding, Xiao Luo, Weihong Lin, Ding Jia, Zheng Zhang, Chao Zhang, and Han Hu. \"Expediting large-scale vision transformer for dense prediction without fine-tuning.\" Advances in Neural Information Processing Systems, 35:35462–35477, 2022a. No other questions.",
         "489",
         "5",
         "6",
         "0.8278",
         "0.1423076923",
         "0.9290834665000001",
         "76",
         "37",
         "31.5291",
         "12.1382",
         "15.0298",
         "13.6713",
         "13.8195",
         "0.1507",
         "76",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "35",
         "nxPTSDp9xK",
         "6136",
         "1695409971904",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "Reviewer_oYGw",
         "1698817237524",
         "1699636664735",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes cross guided matching and cross guided ensemble as cross-modal importance indicator. Besides, a Complete-Graph Soft Matching algorithm is proposed as an improved version of ToME's bipartite soft matching. 1. Both Cross Guided Matching (CGM) and Complete-Graph Soft Matching (CGSM) is well motivated and proved to be effective.\n2. Extensive experiments are conducted on several vision language tasks for both modal indenpendent VL model (CLIP) and modal dependent VL model (BLIP2). I do recognize the amount of work that went into this submission. 1. The proposed approach is named as Cross-Guided Ensemble of Tokens, however, I find that the proposed Cross-Guided Ensemble (CGE) is not that useful as illustrated in Table 1. So, I think the paper should re-organize the structure and highlight the really useful designs.\n2. The proposed Complete-Graph Soft Matching is not specialized for cross-modal tasks, so does it outperform the ToMe algorithm in general visual recognition tasks? The proposed method can improve the model efficiency after training with little performance loss, and I am curious if the proposed method can also accelerate the training of multi-modal tasks.",
         "183",
         "0",
         "4",
         "0.7942",
         "0.08515625",
         "0.9441901445",
         "48",
         "9",
         "40.5737",
         "12.6515",
         "15.565",
         "14.5546",
         "14.8862",
         "0.0529",
         "73",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "36",
         "nxPTSDp9xK",
         "6136",
         "1695409971904",
         "['~Dachuan_Shi2', '~Chaofan_Tao1', '~Anyi_Rao2', '~Zhendong_Yang2', '~Chun_Yuan1', '~Jiaqi_Wang1']",
         "CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers",
         "Recent vision-language models have achieved tremendous progress far beyond what we ever expected. However, their computational costs are also dramatically growing with rapid development, especially for the large models. It makes model acceleration exceedingly critical in a scenario of limited resources. Although extensively studied for unimodal models, the acceleration for multimodal models, especially the vision-language Transformers, is relatively under-explored.  To pursue more efficient and accessible vision-language Transformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal acceleration framework for vision-language Transformers. This framework adaptively combines tokens through real-time, cross-modal guidance, thereby achieving substantial acceleration while keeping high performance. \\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and Ensemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and ensemble to exploit cross-modal information effectively, only introducing cross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In contrast to the existing bipartite soft matching approach, \\textit{CrossGET} introduces a complete-graph soft matching policy to achieve more reliable token-matching results while maintaining parallelizability and high efficiency. Extensive experiments are conducted on various vision-language tasks, including image-text retrieval, visual reasoning, image captioning, and visual question answering. Performance on both classic multimodal architectures and emerging multimodal LLMs demonstrate the effectiveness and versatility of the proposed \\textit{CrossGET} framework. The code and models will be made public.",
         "Reviewer_Yt1v",
         "1698832481643",
         "1701806853489",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper proposes CrossGET to accelerate VLM by token merging. Specifically, this work introduces complete-graph matching to partition tokens and merge/reduce tokens based on similarities. The experimental results on common vision-language tasks demonstrate some effectiveness of the proposed method. The paper is well-organized and the presentation is good. The motivation of accelerating VLMs is clear. 1. The major issue is novelty. CrossGET is incremental over ToMe by replacing ToMe's matching algorithm, adding learnable tokens and adapt unimodal ToMe to the multimodal setting.\n2. As shown in Table 1, the newly proposed matching algorithm has marginal improvements.\n3. CrossGET is proposed to accelerate heavy VLMs. However, majority of experiments are carried out on relatively light-weighted BLIP. There's only a small section for the truly heavy BLIP2, which is a stronger VLM that really needs acceleration.\n4. CrossGET requires fine-tuning of VLMs. (1) In most cases, when models need fine-tuning, they are relatively small (acceleration is not demanding). (2) Huge VLMs that are really heavy can be used as zero-shot in different tasks or different datasets of a same task. In this sense, CrossGET which does not apply to pre-training stage is a bottleneck.\n5. The paper fails to compare or adapt relevant works \\[1\\]\\[2\\].\n\n\\[1\\] DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification, NeurIPS 2021\n\n\\[2\\] Not all patches are what you need: Expediting vision transformers via token reorganizations. ICLR 2022\n\n**Final recommendation**: I agree the paper is improved by additional experiments and extensive analysis, and thus I raise my rating to 5. When CrossGET is applying to Flamingo or BLIP2 which uses frozen LLMs, it reduces to accelerating only vision encoders? Then, there will be a bunch of alternative approaches in accelerating ViTs?",
         "283",
         "4",
         "5",
         "0.8172",
         "0.0279545455",
         "0.9102016687000001",
         "74",
         "34",
         "38.8176",
         "11.3603",
         "13.9992",
         "13.1874",
         "12.0743",
         "0.049",
         "81",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "37",
         "m3xVPaZp6Z",
         "8871",
         "1695527592497",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Reviewer_AWzJ",
         "1697814581368",
         "1700464672733",
         "6",
         "4",
         "3",
         "2",
         "3",
         "This work considers training an agent without online interaction or abundant offline data but only with the reward function of the target environment. Borrowing the idea of rehearsal from the cognitive mechanism, this work proposes policy rehearsal. In detail, this work hopes to train an array of models to imitate the target model. Theoretical analyses indicate that the target environment performance gap between the policy trained in these imitated models and the optimal policy can be bounded by three terms, which are further summarized as diversity and eligibility. Based on these two criteria, this work proposes two corresponding reward functions for training imitated models and then uses these models to train the policy. Also, the proposed ReDM can easily combined with offline datasets. Extensive results show the effectiveness of ReDM. - The ideas about the setting are novel and important, minimizing interaction with the environment as much as possible is an important problem in the RL community. Also, introducing rehearsal into RL is novel and enlightening.\n\n- The writing of Sec 3.2 is clear and solid, I have roughly read all the proofs, which are written quite clearly.\n\n- The proposed ReDM utilizes two novel terms for learning an imitated model, which is interesting and helpful.\n\nCurrently, my evaluation of this paper is really Boardline. If authors can address my concerns in Weaknesses and Questions, or point out what I have misunderstood, I'd like to update my scores accordingly. Also, I will keep active in the following discussion stage. - The connection between diversity and controlling $\\epsilon_e, \\epsilon_a$ is unclear. For example, if all environments are the same, i.e., there is no diversity, it is obvious that $\\epsilon_a=0$ is minimal. There also needs more explanation about why $\\epsilon_e$ can be controlled via diversity.\n\n- Based on the previous points, one of my major concerns is why the proposed methods can help optimize the gap calculated in Thm 3.3. The authors have summarized the three errors in Thm 3.3 as diversity and eligibility, which indeed provides insights for analyzing this problem. But I think a more direct connection, like whether the objective in Sec 3.3 can be proven to directly control the three errors in Thm 3.3, will make the analyses more solid.\n\n- In experiments, providing the results directly trained in the target environments as the reference will better show the results.\n\n- Lack of some related works, like utilizing model-based methods for improving generalization \\[1-3\\], and finding diverse skills for unsupervised RL \\[4-6\\] as this work hopes to find diverse models.\n\n\\[1\\] Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning\n\n\\[2\\] Task Aware Dreamer for Task Generalization in Reinforcement Learning\n\n\\[3\\] The Benefits of Model-Based Generalization in Reinforcement Learning\n\n\\[4\\] Diversity is All You Need: Learning Skills without a Reward Function\n\n\\[5\\] Effective diversity in population based reinforcement learning - In my opinion, the considered setting is that the agent can only get the reward function of the target task but has no knowledge about the dynamic of the target task. Is it right? Given the offline data, it is understandable that the agent can learn the dynamic to some degree. But without an offline dataset, it seems that there is no idea for the agent to learn the dynamic of the target task. \n\n- Based on the previous question, I'm confused about the setting of Experiment 4.1 \" ReDM With no Interaction Data\". As there are no data about the environment and the agent can not interact with the environment, how does the agent to learn about the environment?\n\n- As Unsupervised RL considers training an agent in the environment without reward, in my opinion, the setting in this work is like training an agent and models in the environment with reward but without dynamic. As the dynamic of the target environment will vary a lot, whether finetuning the agent (as well as the model) in the target environment with few steps will be more reasonable?\n\n- About $r_e$ for Eligibility. The proposed method is to randomly sample N trajectories and estimate the biggest return. Is this inefficient as the state space and action space are continuous in experiments? Also, what is the choice of N in experiments?\n\n- I'm curious about the performance of ReDM in the D4RL setting (Sec. 4.3) but without any Interaction Data.",
         "720",
         "5",
         "0",
         "0.7541",
         "0.0956459436",
         "0.9084495306",
         "57",
         "30",
         "42.3274",
         "11.5374",
         "14.2015",
         "13.5218",
         "11.3151",
         "0.0512",
         "109",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ],
        [
         "38",
         "m3xVPaZp6Z",
         "8871",
         "1695527592497",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Reviewer_GFGi",
         "1698672856727",
         "1699637116619",
         "8",
         "3",
         "4",
         "2",
         "4",
         "This paper presents a pretty interesting idea called rehearsal, which is able to **initialize or warm up a generalizable policy with zero interaction data or limited mismatched offline data**. Concretely, the proposed method, *ReDM*, takes as input a reward function and a termination function and generates a set of transition functions or models. Imaginary trajectories can thus be generated by rolling out these transition models and used to warm up the policy. As some of the models may produce data close to the target environment dynamics, the policy warmed up with these data can have a good initialization when deployed to the target environment, which is helpful for subsequent fine-tuning. Additionally, the method can be modified for offline-RL settings, allowing it to learn a robust and generalizable policy even with a small amount of offline data mismatched with target environment dynamics. \n\nThe method is motivated theoretically and contains lots of analysis like performance bound, laying foundations for future study in this new direction. Besides, the experiments on the standard gym and D4RL environment empirically prove the effectiveness of the method for both online and offline policy learning. 1. The idea is novel unlike traditional model-based RL, this new idea suggests learning a bunch of transition models from reward function and termination functions, exempting the need for interaction data. \n2. In terms of soundness, it proves empirically and theoretically that the transition models learned in this way can help warm up the policy and improve its performance when deployed in environments with diverse transition dynamics. 1. The paper writing is not attractive. In my perspective, the main paper contains too much tedious content regarding the theoretical analysis and lacks an explanation for the rehearsal framework. My suggestion would be to move some theoretical content to the appendix and include at least one figure to explain the procedures of this new rehearsal framework and what it can achieve or why we need it. People don't care about the theoretical stuff until they are attracted by the idea and want to dive into it. Thus I suggest making some figures to explain the idea or the method.\n2. No standard deviation is included for experiments in Table 1. Also, there is no error bar in Figure 7. \n3. What is the $D_{TV}$ should be explained in the main paper. It is strongly related to your main theorem but without definition.\n4. What is relative performance? Is it calculated through minus the baseline performance?\n5. The axis *Number of models* in Figure 3 should be \\[0, 10, 20, 30, 40\\], right? 1. How about replacing the random model for calculating the eligible reward with a human-crafted planner? It is supposed to be helpful for improving the performance as well. I guess this can be a good direction for exploration and to make this method more practical. A simple rule-based planner is also as easily accessible as a reward function in most practical settings like robotics. \n2. In the zero interaction data setting, the method indeed works well in three simple gym environments. I wonder if the method still works well in the more complex Mujoco environment without any pre-collected interaction data. I am curious about its performance on high-dimensional control tasks.",
         "537",
         "1",
         "9",
         "0.7805",
         "0.12279079620000001",
         "0.9027240276",
         "47",
         "11",
         "39.5944",
         "12.5012",
         "14.9712",
         "14.2443",
         "12.6653",
         "0.2889",
         "94",
         "0",
         "2",
         "0",
         "0",
         "iclr"
        ],
        [
         "39",
         "m3xVPaZp6Z",
         "8871",
         "1695527592497",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Reviewer_anZu",
         "1698734618441",
         "1700596735397",
         "8",
         "3",
         "3",
         "2",
         "3",
         "The paper proposes a method for offline model-based reinforcement learning. The idea is to generate a set of candidate dynamics models and learn an adaptive policy that optimizes the original reward on this candidate set. If the true dynamics are in the distribution of the candidate set, the adaptive policy should perform well on the true task. The central problem lies in generating a candidate set of dynamics models. The authors propose optimizing over dynamics models with RL using a reward that incentivizes (1) diversity among the set and (2) the tendency for random trajectories to achieve high reward. The method alternates between optimizing for a new dynamics model to add to the set and optimizing for a new adaptive policy given the current set. When interaction data from the true task is available, it is used to regularize the optimization over dynamics models. Experiments show the method can work with no interaction data on low-dimensional continuous control tasks (inverted pendulum, mountain car, acrobot). On two D4RL tasks (hopper, half-cheetah) with a small amount of random interaction data, the method outperforms prior offline model-free and model-based RL methods. The method is similar to MAPLE but replaces the dynamics model generation process with a more directed procedure (RL on a custom reward vs learning an ensemble of models). The reward used in the dynamics model generation process is well motivated by formal analysis of error bounds. The different components of the method are analyzed/ablated. My main concern is the limited applicability of this method beyond low-dimensional benchmark tasks due to some significant assumptions. The method assumes access to a query-able reward/termination function and the initial state distribution. Though more importantly, the method assumes that the dynamics can be easily parameterized and optimized over with RL. Additionally, the method assumes that random plans through the candidate dynamics models will achieve some non-zero reward (to optimize the dynamics models for the eligibility reward). These assumptions makes the method difficult to apply (if not impossible) in sparse-reward or high-dimensional (e.g image-based) environments. In principle these issues could be solved by providing the method with enough interaction data to learn a good dynamics model initialization. However, then prior offline model-based or model-free methods might also work well. Additionally, this still wouldn't make the method applicable to sparse reward problems. \n\nAnother concern is the limited scope of the experiments relative to prior work. The evaluations on InvertedPendulum, MountainCar, and Acrobot are good for analyzing the method, however for the comparison to prior work, experiments are only shown for HalfCheetah and Hopper. It would be good to additionally include at least Walker2d. Additionally, the experiments with interaction data only test random interaction data and relatively small amounts of data (200 and 5000 transitions). While it is understandable that this is the setting where the proposed method would excel, it would be good to also show comparison to prior work with interaction data of varying optimality and amounts (including the full D4RL datsets). \n\nThere is no discussion of MAPLE in the related work section. MAPLE is very related (just a different model generation process) so the similarities and differences should be addressed here. It would also be good to include a brief mention of meta-learning in the related work as the proposed method uses similar concepts when optimizing for the adaptive policy.\n\nSmaller comments:\n- Algorithm 1 does not say a lot about the method. It could be replaced by algorithms 5/6 from the appendix. \n- Figure 1 should use a more descriptive x-axis label like \"Tasks\".\n- Figure 3 needs a more descriptive caption that explains what \"model loss\" means here.\n- The locations of Figure 2 and 3 should be switched. - The explanation of the optimal policy gap is confusing. Specifically this sentence: \"This discrepancy highlights the candidate model set’s capability to derive a proficient policy in the model itself.\" Does \"model\" here mean the true dynamics?\n- \"we conjecture that a diversified dynamics model set will correspond to a smaller ϵa since recognizing the dynamics is much easier\" It's not clear to me why a more diverse candidate model would lower the adaptation cost. Could you explain this?\n- In Figure 6, what is the shown performance relative to? Is this the performance of the policy at each iteration in the model at that iteration minus the performance of the policy at that iteration in the ground truth model?\n- Figure 7: Are these results averaged over Hopper and HalfCheetah and averaged over each gravity level?",
         "752",
         "0",
         "0",
         "0.7605",
         "0.1021203666",
         "0.8813570142",
         "58",
         "21",
         "35.9155",
         "12.6506",
         "15.7954",
         "14.5885",
         "12.6808",
         "0.5623",
         "98",
         "0",
         "0",
         "0",
         "2",
         "iclr"
        ],
        [
         "40",
         "m3xVPaZp6Z",
         "8871",
         "1695527592497",
         "['~Chengxing_Jia1', '~Chenxiao_Gao1', '~Hao_Yin3', '~Fuxiang_Zhang1', '~Xiong-Hui_Chen1', '~Tian_Xu2', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Zhi-Hua_Zhou2', '~Yang_Yu5']",
         "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines.",
         "Reviewer_YzNF",
         "1698848293497",
         "1700708716647",
         "8",
         "3",
         "2",
         "3",
         "3",
         "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, the authors introduce the idea of *rehearsal* into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, they propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to natually generalize to previously unseen environments. Their experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with zero interaction data. Besides, they further extend ReDM to scenarios where limited or mismatched interaction data is available. The provided empirical results reveal that ReDM produces high-performing policies compared with other offline RL baselines. 1. The problem of policy rehearsing in offline reinforcement learning is interesting and challenging as an academic topic.\n2. The description to the problem modeling and the methods is clear and generally easy-understanding.\n3. The proposed method is well motivated by comprehensive preliminary theoretical analysis.\n4. The experiment analysis is in-depth and insightful, which helps the readers bettere understand the effectiveness and underlying mechanism of the propose methods. 1. The environments used in the experiments are still limited. I encourage to supplement more environments to demonstrate the applicability of your proposed method is possible. Otherwise, we may argue if the solution can only be effective on some specific kinds of tasks.\n2. Considering the proposed method needs to train the new dynamics models and meta-policy simultaneously, the complexity of this method and the training stability/convegence are encouraged to be clarified and analyzed.\n3. The assumed accessibility to the task reward function and initial state distribution is often unrealistic in the real applications. 1. I am curious if totally no interaction data, how can the generated dynamics model approximates the real dynamics in the target environment. It seems there lacks enough grounding points to support this potential. Does there exist the probability that the generated dynamics models are far from the dynamics in the target environment? I hope to see more analysis on this during the rebuttal.\n2. The D4RL benchmark in your experiments is all Mujoco tasks with low input dimensions. Could you please consider incorporating some more high-dimensional task, in which the hypothesis space is too large to narrow down?\n3. In the paper, you claim that the interaction data is only used to narrow down the hypothesis space. But could you please consider how to utilize these interaction data in a more direct way to better facilitate the policy learning as the complement to the purely dynamics model learning, like finetuning the learned meta policy? Besides, I cannot agree the statement that the biasedness in the interaction data will somehow hinder the policy optimization in traditional offline RL methods. If such pre-collected trajectories are expert ones or near-optimal ones, such *biasedness* can actually help avoid some low-value and dangerous states.\n4. Considering your method encourages the diversity in the model learning part, some learned dynamics models may be unreasonable though the meta policy can still achieve high returns via planning in such models, like violating the physics laws or economics laws. And I can hardly expect the *eligibility* part in your method can help alleviate this 'short-path' issue. More explanations and discussions are encouaged during the rebuttal phase.",
         "614",
         "0",
         "11",
         "0.7928",
         "0.0638390498",
         "0.9844013453",
         "59",
         "21",
         "22.4917",
         "15.0427",
         "18.6066",
         "16.5463",
         "15.3218",
         "0.4435",
         "102",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "41",
         "lr806pdNZa",
         "8208",
         "1695500772032",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "Reviewer_BZEx",
         "1698149520614",
         "1699637019167",
         "5",
         "4",
         "2",
         "4",
         "2",
         "The paper focuses on the problem of \"censorship\" in large language models (LLM). Specifically, the paper argues that it is unfeasible to address this issue by relying on ancillary \"machine learning\" (ML) techniques, and that it should rather be tackled via mechanisms belonging to the security domain. To support such a position, the paper presents detailed theoretical arguments demonstrating that LLM censorship is an \"undecidable problem\", thereby revealing that using ML-based techniques, such as, e.g., another language model (LM), will never provide a foolproof solution. ## High-level\n\n+ Outstanding writing\n+ Relevant Problem (for both research and practice)\n+ The theoretical arguments are well-founded\n\n## Comment\n\nI deeply thank the authors for writing this piece and submitting it to ICLR'24. I've loved reading it, and I was genuinely pleased by the outstanding writing quality: out of the papers I reviewed for ICLR'24, this one is by far the best written one. Moreover, the paper tackles a very open issue and the \"conclusion\" can be leveraged by researchers and practitioners alike: the latter can benefit by integrating additional security mechanisms in their products, whereas the former would be provided with \"clear evidence\" that tackling censorship by means of traditional ML methods will never provide a foolproof solution. Indeed, the theoretical arguments made in this paper are well-rooted, and I particularly appreciated connecting LLM to Turing Machines and the application of the Rice Theorem as a scaffold to support the paper's main claims. \n\nHowever, despite all such strengths, the paper also presents (imho) various weaknesses, which are discussed below. ## High-level\n- It suffers from an \"identity crisis\" (it feels more like a \"position\" paper)\n- Lack of a concrete experiment \n- Some statements require further evidence to be supported\n- The paper is built on a strong assumption that does not seem to have been accounted for\n- The \"mosaic prompts\" are not really novel\n- Some pieces of the text are unclear\n\n\n## Comment \n\nDespite my appreciation, I do have concerns about the suitability of this paper to ICLR'24. Before I discuss such concerns, however, I want to emphasize that my remarks are _my opinions_. I couldn't spot any technical or methodological flaw in the paper (which is also well-written): hence, my critiques are mostly directed at the \"significance\" aspect of the paper, and I endorse the authors to reflect on the following remarks. Ultimately, my goal is to help them make this paper as a noteworthy contribution to the state-of-the-art (be it for ICLR'24, or for any other venue).\n\n### **Identity Crisis (Lack of a concrete experiment)**\n\nThe most prominent weakness is that, IMHO, the paper suffers from an \"identity crisis\" -- which is rooted on the fact that the paper touches both the \"security\" and \"ML\" domains.\n\nOn the \"security\" hand, all the considerations made in the paper are \"obvious\". The fact that, e.g., an attacker can bypass censorship mechanisms by inducing a LLM to output a \"malicious set of actions\" through individual prompts is \"not new\", and the fact that a similar strategy can fool essentially any precaution is \"not surprising\". Indeed, this is a well-known problem in reality, and the only way to solve this problem is by reading the attacker's minds. Plus, ultimately, LLM are just \"tools\": whether they are used in good- or bad-will is a different manner (and this had been known since the development of cryptographic protocols, since they also aid attackers in preventing their messages from being interpreted). So, to summarise, as a \"security\" researcher, the conclusion of this paper was already known, and the supporting theoretical arguments were hence somewhat redundant.\n\nOn the \"ML\" hand, the paper lacks a clear experiment that demonstrates at least one of the scenarios described in the ```practical implications```. Indeed, after introducing some definitions and demonstrating a given theorem, the paper merely limits to provide \"thought experiments\" discussing how an hypothetical attacker can achieve their goal. Yet, all such discussions are textual: there is an excessive usage of the words \"can\" \"could\" \"may\" \"it is possible that\". The paper does provide some references (e.g., \"The authors of... showed that this can be done\") but the lack of a concrete experiment is still hard to overlook. Such a lack is further aggravated by the additional what-ifs which project LLM into the future (e.g., ```these risks could become even more problematic```). I acknowledge that \"anything can happen\", but this is a weak argument. \n\nHence, I feel that the lack of a \"hard\" experiment is a significant weakness of this paper, which affects both its appeal to the security domain, as well as the one to the ML domain. For instance, I would have appreciated a clear demonstration of Figure 2 (I've spent ~30 minutes trying to have ChatGPT to process similar instructions, but I've never been successful).\n\nPut differently, the paper currently reads as a \"visionary paper\" or a \"position paper\" rather than a true research paper. **However** do note that I am not saying that the paper is devoid of merit: providing \"theoretical evidence\" that it is not possible to craft \"perfect\" ML-based censorship mechanisms is a strong message.\n\n\n### **Lack of evidence for some statements**\n\nOne of the major points in support of the \"value\" of this paper is that the current way to address censorship in LLM is by means of \"ML-based mechanisms\", and --after demonstrating that doing so will never guarantee 100% protection-- the suggestion that censorship should be treated as a security problem.\n\nIndeed, to quote the abstract:\n\n> Commonly employed censorship approaches treat the issue as a machine learning\nproblem and rely on another LM to detect undesirable content in LLM outputs.\n\nThe following was also stated in the Introduction:\n\n> Such methods range from fine-tuning LLMs (OpenAI, 2023) to make them more aligned, to employing external censorship mechanisms to detect and filter impermissible inputs or outputs (Markov et al., 2023; Chockalingam and Varshney, 2023; Greshake et al., 2023).\n\nHowever, I only see 4 works listed here. Hence, I wonder: is it really true that ML-based methods are the \"way-to\" address censorship problems? For instance, even Greshake et al. state ```Unfortunately, it is currently hard to imagine a foolproof solution for the adversarial prompting vulnerability```; moreover, the authors of NeMo Guardrails (used by NVIDIA (Chockalingam and Varshney, 2023)) state the following in their \\[GitHub repo\\](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/security/guidelines.md):\n\n> Integrating external resources into LLMs can dramatically improve their capabilities and make them significantly more valuable to end users. However, any increase in expressive power comes with an increase in potential risk. To avoid potentially catastrophic risks, including unauthorized information disclosure all the way up to remote code execution, the interfaces that allow LLMs to access these external resources must be carefully and thoughtfully designed from a security-first perspective.\n\nTo me, the impression is that these mechanisms are proposed as a \"partial\" solution, since even the respective authors advocate for security principles to be followed. In light of this, the underlying \"message\" of the paper partially loses its value (at least imho). It would be enticing to carry out of more profound analysis of current works on approaches for LLM censorship, and pinpointing how many of such works truly claim to address censorship in an ML-only way, without making any security consideration: doing so would dramatically improve the contribution of this paper.\n\n\n### **A strong assumption**\n\nBy looking at the definition of \"censorship mechanism\", the impression I have is that the paper assumes that censorship is always applied \"a-posteriori\". That is: the LLM receives an input, elaborates a response, and then --right before providing the response to the user-- it checks whether the response is permissible or not by means of some censorship. I wonder: is this really true?\n\nBecause, if this is not the case (i.e., there is some censorship applied to some \"intermediate process\" of the response), then the censorship would work, since it would be applied before the application of the transformation which makes the text encrypted. \n\nIn light of this, I invite the authors to provide evidence that this assumption holds _in reality_ (plus, I conjecture that such an observation CAN be used to develop some more effective defenses!). Otherwise, the authors should acknowledge that their analysis only applies to a specific use-case of censorship (do note that, however, this would decrease the impact of the paper). Alternatively, the authors can provide evidence (theoretical and, possibly, practical) that the envisioned analysis/findings hold even in these intermediate cases.\n\n### **Naming of Mosaic prompts**\n\nWhile I appreciate the name \"Mosaic Prompts\", I feel the way it is presented to be \"excessive\". Indeed, the described procedure is exactly the same as the \"divide et impera\" (or \"divide and conquer\") which is the de-facto praxis in computer science (and already associated to LLM, see \\[here\\](https://medium.com/@finomeno/exploring-large-language-models-insights-for-architects-393600dae131) and \\[here\\](https://medium.com/@digitalmiike/chatgpt-guide-10-effective-prompt-strategies-for-enhanced-output-979c8032eaaa)).\n\nHence, I endorse the authors to tone down this name, or at least acknowledge that it is just a renaming of a popular technique in computer science. (I am stating this also in light of the \"acknowledgment\" made in Footnote-1 -- which I greatly appreciated!)\n\n### **Some pieces of text are unclear**\n\nAlthough the paper is excellently written, I had issues in understanding some parts of the text. In what follows, I will directly quote each of these \"problematic\" parts, and explain the problems I encountered---starting from the Introduction.\n\n> Such constraints can be semantic, e.g. does not provide instructions on how to perform illegal activities, or syntactic, e.g. does not contain any ethnic slurs from a provided set.\n\nI did not understand the provided examples -- or rather, it is hard to determine the subject of the examples. I recommend rephrasing to, e.g., \"the output must not provide...\"\n\n> methods against malicious attackers.\n\nAre there attackers who are not malicious? (this redundancy occurs many times in the paper)\n\n> restricting the string x to the set of permissible strings P\n\nI recommend being more specific: \"the string x to the set of permissible strings P that can be constructed by the LLM model\" (otherwise, it may be confused with a string written by an user)\n\n> demonstrated in Fig. 1\n\nThe caption states \"Figure\" (and not Fig.)\n\n> typically defined by the language recognised it recognises\n\nThis is unclear \n\n> descriptions of Turing machines can be viewed as a programming language, capable of being interpreted by a universal Turing machine capable of emulating them.\n\nPlease revise this statement as it is very confusing.\n\n> As the semantic censorship impossibility result that we established by connecting the problem of semantic censorship to Rice’s Theorem doesn’t fully capture real world censorship settings where inputs and outputs are bounded we seek to provide another result on the impossibility of censorship that does.\n\nMake this shorter, especially since the same message was written two lines before.\n\n> we assert that given an invertible string transformation g\n\nIs this \"g\" supposed to be the \"bijective transformation\"? Still, I am slightly confused about this \"g\" here; perhaps an example would be useful.\n\n> it is capable of applying g to its output x to instead output g(x).\n\nThis is very unclear. Do you mean g(g(x))?\n\n> either nothing is be permissible\n\nTypo\n\n> While existing LLMs are good at \\[...\\] Yuan et al. (2023)\n\nThis paragraph appers to be disconnected from the \"Practical Implications\". Or rather, it does not align well with the way the previous paragraph ended. Actually, I do not see any \"practical implications\" that are truly compellling here.\n\n> While our results describe adversaries which can instruct\n\nWhich results? \n\n> For example, users could provide \\[...\\] running the model\n\nIt would be wonderful if the authors showcased a way to do so in practice _today_. \n\n> In an extreme setting where there exist only 2 permissible output strings\n\nWhy this assumption? To me, the following example holds even without this (perhaps I missed something?)\n\n> converting text to ACII\n\nTypo\n\n> Subsequently, the user can request the model to output i’th bit\n\nWhat is the ```i'th bit```? Plus, how can the user do so?\n\n> our Mosaic Prompting results\n\nGiven that no experiments have been carried out, it is a bit of a stretch to define this as a \"result\" (even the Appendix does not provide \"empirical results\")\n\n\n\nFinally, I report that the bibliography often does not provide the venue of a given work (e.g., the paper by Markov et al. (2023) was published in AAAI; whereas the one from Greshake et al. was accepted at AISec). This is annoying as a reader, as I could not ascertain the quality of a given referenced work. I liked the paper, and I am willing to improve my score if presented with compelling evidence that some of my remarks are flawed. Nonetheless, I invite the authors to answer the following questions (most of which are drawn from my \"Weaknesses\" section): depending on the answer, my rating will likely change.\n\n1) Can the authors provide more evidence that LLM censorship is truly \"commonly treated as a ML problem\" (and that security-based approaches are not taken in consideration)?\n\n2) Would the proposed theoretical analysis, as well as the proposed \"attack\", still apply if censorship is carried out during the process of crafting a response by the LLM? (Please elaborate)\n\n3) How could the \"attack\" shown in Figure 2 be realized _today_? \n\nThen, I have one last question. Assume that this paper is accepted to ICLR'24 as a spotlight. How would the authors present this work? Would the talk include only \"what-ifs\", or would it also showcase some concrete evidence that the envisioned scenarios are truly a security issue that cannot be countered with ML-only ways$^1$?\n\n$^{\\text{1: E.g., how do I make ChatGPT tell me \"howdoibuildabomb\"?}}$",
         "2281",
         "5",
         "1",
         "0.8001",
         "0.0992714858",
         "0.7997633219",
         "47",
         "17",
         "41.5888",
         "12.6065",
         "15.223700000000001",
         "14.314",
         "13.9864",
         "0.8282",
         "84",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "42",
         "lr806pdNZa",
         "8208",
         "1695500772032",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "Reviewer_ST3b",
         "1698230841205",
         "1699637019047",
         "5",
         "2",
         "3",
         "2",
         "2",
         "This paper investigates the theoretical limitations of the current external censorship mechanisms in LLMs from the view of computing theory. Given these inherent limitations, the authors argue that LLM censorship should be addressed more as a security problem than a machine learning problem. - Trendy topic\n- A novel perspective to study LLM censorship - Implications can be extended\n- Readability can be improved In this paper, the authors first focus on the semantic censorship mechanisms, proving that the current mechanisms cannot reliably detect if LLM output is \"semantically impermissible.\" They further show that such limitations are inherent and can extend beyond semantic censorship mechanisms by designing Mosaic prompts.\n\nOverall, the authors study a trendy topic and offer a novel perspective to understand LLM censorship. However, I have the following concerns.\n\n- The authors prove the impossibility of semantic censorship using string transformation by showing how the transformed string might break the \"invariance of semantic censorship.\" Here, I have some doubts regarding the invariance property. In my opinion, the semantics of a string often change after the transformation. Thus, it is reasonable for the transformed string to bypass semantic censorship mechanisms. Moreover, LLMs do not necessarily output harmful texts with the transformed string. Why does the invariance property hold? Is this property an important goal considered by LLM censorship developers when designing their mechanisms?\n\n- Implications can be extended. It appears to me that the current implication discussion stops at showing LLM censorship is more of a security problem than a machine learning problem. What are the direct implications for model developers when building censorship? Are there any defensive measures against the Mosaic prompts? The authors only briefly mention that there are standard approaches, such as access controls and user monitoring, to build censorship from the security view. However, there is no further analysis showing that these approaches can indeed overcome the theoretical limitations of current external censorship mechanisms and surpass them in censorship performances.\n\n- Readability can be improved. Many sentences are too long and difficult to read. For example, \"Thus, we can understand censorship as a method of determining permissibility of a string and censorship mechanisms can be described as a function, f(x), restricting the string x to the set of permissible strings P by transforming it to another string x' ∈ P if necessary, e.g. x' ='I am unable to answer.'\"",
         "394",
         "0",
         "0",
         "0.7870",
         "0.08387096770000001",
         "0.8256777525000001",
         "47",
         "16",
         "29.8058",
         "13.2713",
         "16.9721",
         "15.3932",
         "13.4282",
         "0.1199",
         "100",
         "0",
         "0",
         "2",
         "0",
         "iclr"
        ],
        [
         "43",
         "lr806pdNZa",
         "8208",
         "1695500772032",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "Reviewer_3fNc",
         "1698538750067",
         "1699637018926",
         "3",
         "3",
         "2",
         "2",
         "1",
         "The paper's topic studying censorship and its effectiveness is interesting, ie. what kinds of knowledge can be extracted from LLMs and whether protection mechanisms can be circumvented. But the paper contributes little of practical value. It also lacks a proper evaluation to claims and conceptual illustrations. The theoretical treatment would be interesting, but the paper claims are mostly direct implications of existing theorems or require minor enhancements. Overall, the contribution appears marginal.\n\nDetails:\n* abstract:  LM -> LLM or define it.\n*  The example, Figure 1 is not of any practical value and might be conceptually it is flawed - the three steps are the least challenge in making successful ransomware attack (deploying it is much more of an issue, avoiding being detected too). The Mosaic prompt is also not very convincing. Both should be shown to be actually working.\n* The idea to use encryption (Appendix A) is interesting, but is this a practical concern? Does it add to the discussion of how protection mechanisms can be circumvented? It might, if it was shown to work. But as is, it seems incomplete.\n* On a high level, the paper argues that censorship cannot work because a malicious person might not directly asked for censored actions, but for steps needed for these actions, which might not be censored. But this holds for almost anything in our world and is nothing new. Any technological knowledge can be abused.  A knife can be used to kill or to save a life (doctor during surgery).  A motor can power an ambulance saving life or a truck performing a terrorist act. This is general knowledge. The paper seems to sell this as a novel aspect. The fundamental question is: Should knowledge and technology be made available that can be abused?  This is also not really a security question as the paper argues. Obviously any abuse relates to security, but I don't see, why the paper's claim to say \"LLM censorship (ie. avoiding censorship through attacks) is a security concern\" should be a new insight. see above see above see above",
         "346",
         "0",
         "1",
         "0.7665",
         "0.09049690690000001",
         "0.7391343713",
         "47",
         "12",
         "52.9766",
         "9.1188",
         "11.819",
         "11.950800000000001",
         "8.4543",
         "0.0291",
         "95",
         "0",
         "1",
         "1",
         "1",
         "iclr"
        ],
        [
         "44",
         "lr806pdNZa",
         "8208",
         "1695500772032",
         "['~David_Glukhov1', '~Ilia_Shumailov1', '~Yarin_Gal1', '~Nicolas_Papernot1', '~Vardan_Papyan1']",
         "LLM Censorship: The Problem and its Limitations",
         "Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, and LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated, and viewed as a security problem with adaptation of security-based defenses to mitigate potential risks.",
         "Reviewer_xHLz",
         "1698608286944",
         "1699637018817",
         "5",
         "3",
         "2",
         "4",
         "3",
         "This paper explores some of the theoretical limitations of LLM censorship, the problem of identifying permissible inputs and outputs to language models. In particular, the paper focuses on the limitations of semantic censorship, or filtering of strings based on their meaning. First, the paper shows that determining whether a “program” output by an LLM is permissible is an undecidable problem. Then, the paper discusses the impossibility of semantic censorship by showing that strings can undergo transformations which preserve their semantic meaning but are otherwise unintelligible except to a user who knows how to invert the transformation. Finally, the paper introduces Mosaic Prompts, a way of breaking up an impermissible prompt into permissible pieces. This paper’s primary strength is that it identifies an important issue to focus on that has been unexplored in the literature - what are the theoretical limits on the ability to filter LLM inputs or outputs based on their semantic meaning? The paper is a good exposition of this problem and the theoretical settings it considers highlight some important limitations for the task. The figures and tables also do a good job of clarifying some of the concepts in the text. Overall, the authors’ assertion that syntactic censorship is likely to be more successful than semantic censorship is well-taken from this work. This paper’s primary weakness is the number of assumptions and limitations that come into the different theoretical treatments that the paper covers. First, the paper itself admits that the treatment of Rice’s theorem for programs on Turing Machines is not generally applicable to the bounded inputs and outputs case of LLMs. Second, in the section 2.2 on the invertible transform, I believe there may be a flaw in the reasoning of the proof. Under assumption 1, the authors assume that the model is capable of following instructions such that it can produce the transformation $g$. This assumption is explicitly stated. It seems that the proof also requires that the LLM (or corresponding companion LLM that is doing censorship) is unable to compute the inverse transformation $g^{-1}$. If it were, then it could check the semantics of the un-transformed string for permissibility. This assumption weakens the power of the impossibility result in my opinion. Finally, while I think that the Mosaic Prompt approach is interesting, I do think the paper underestimates the LLM’s ability to attend to previous prompts. While in the mosaic approach the model is likely to answer early prompts, it is conceivable that once enough of the pieces of the impermissible prompt are present, one would be able to detect the impermissibility of the conversation overall. Does the impossibility result in Section 2.2 require an assumption that $g^-1$ is not computable by the permissibility model?\n\nIs the problem space simplified at all by considering the compositionality of strings? For example, if there is an impermissible substring within a larger string, does that make the larger string automatically impermissible as well?\n\nDoes something like “fuzzy” permissibility fit into this framework at all? For example, many prompts and outputs would be considered “borderline” or have some level of “toxicity” if sent to a human rater, rather than a bright-line permissible vs. not rule. Does that make the problem any easier or harder?",
         "537",
         "0",
         "0",
         "0.7747",
         "0.1567073171",
         "0.8508368134000001",
         "47",
         "11",
         "36.7413",
         "13.0664",
         "15.4781",
         "14.6074",
         "13.6159",
         "0.06570000000000001",
         "99",
         "0",
         "0",
         "1",
         "0",
         "iclr"
        ],
        [
         "45",
         "lmShn57DRD",
         "1208",
         "1695022608110",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "Reviewer_qMLP",
         "1697955080810",
         "1699636047386",
         "6",
         "2",
         "3",
         "3",
         "3",
         "This paper delves into the challenges presented by multivariate long-term time series forecasting (MLTSF), specifically the difficulty of capturing cross-channel dependencies and temporal order information using current Transformer-based models. Despite the achievements of Transformer models in various fields, their application in MLTSF reveals certain inadequacies. Models like Informer, Autoformer, and FEDformer, while advanced, still face challenges in understanding intricate channel relationships in multivariate time series. \n\nTo address these issues, the authors propose the GRformer model. This innovative solution combines the strengths of Graph Neural Networks (GNN) and position encoding derived from Recurrent Neural Networks (RNN). The inclusion of a mix-hop propagation layer within a feedforward neural network promotes efficient interaction between different time series data points. Additionally, by leveraging a multi-layer RNN, the model recursively generates positional embeddings, emphasizing the importance of sequence order. \n\nThe paper's empirical tests, conducted on eight real-world datasets, demonstrate the GRformer's superior predictive accuracy in MLTSF tasks, underlining its potential as a novel solution in the field of time series forecasting. **Strengths**:\n\n1. **Originality**: \n   - The GRformer presents a unique fusion of GNN and RNN-based position encoding within a Transformer framework, addressing gaps in MLTSF.\n   - The incorporation of the Pearson correlation coefficient for graph structure is a notable innovation.\n\n2. **Quality**: \n   - Rigorous empirical validation is conducted on eight real-world datasets, ensuring robustness.\n   - The model's design is comprehensive, with the mix-hop propagation layer and RNN-based position encoding as highlights.\n\n3. **Clarity**: \n   - The paper delineates complex concepts coherently, facilitating reader understanding.\n   - Distinctive features and advantages of GRformer over existing models are clearly articulated.\n\n4. **Significance**: \n   - The GRformer's advancements in capturing cross-channel dependencies have potential broad impacts in time series forecasting.\n   - The paper paves the way for future research by highlighting existing challenges and areas of improvement.\n\nIn essence, the paper excels in its innovative methodology, thorough validation, lucid presentation, and relevance in the field. 1. **Mathematical Notation Consistency**:\n   - The authors' use of mathematical notation appears inconsistent. For instance, function names should ideally be presented in regular typeface rather than italic. Proper notation ensures clarity and avoids potential confusion.\n\n2. **Graph Construction Using Pearson Coefficient**:\n   - While the authors opted for the Pearson correlation coefficient for graph construction, which subsequently serves as the foundational structure for the GNN, one might question the exclusion of making GNN parameters learnable. This adaptability could potentially offer more flexibility to the model.\n\n3. **Assumption of Homoscedasticity**:\n   - The Pearson coefficient assumes homoscedasticity in the data. It's unclear if the authors verified this assumption across their datasets. Such checks are crucial to ensure the validity of the chosen coefficient.\n\n4. **Alternative Correlation Metrics**:\n   - The paper doesn't seem to explore or discuss other potentially beneficial correlation coefficients like Time-Lagged Cross-Correlation (TLCC) or Dynamic Time Warping (DTW). An exploration or justification of the chosen metric over others could have added depth to their methodology. **Hyperparameter Selection in Graph Construction**:\n   - The methodology introduced by the authors involves several hyperparameters, which seemingly have a significant impact on the model's outcomes. Specifically, when constructing the graph structure:\n     - How was the threshold value of 0.8 determined?\n     - Regarding the 'topk' selection, how was the value of \\( k \\) chosen, and does it correlate with the number of variables?\n\n **Mix-hop Propagation Parameter**:\n   - How was the value for the EMA parameter \\( \\alpha \\) in the mix-hop propagation process determined?",
         "562",
         "0",
         "9",
         "0.8096",
         "0.1543367347",
         "0.9348136187",
         "53",
         "19",
         "12.8649",
         "15.8084",
         "19.5397",
         "16.5463",
         "17.2062",
         "0.1041",
         "83",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "46",
         "lmShn57DRD",
         "1208",
         "1695022608110",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "Reviewer_Evwp",
         "1698032964680",
         "1699636047317",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper enhances Transformer with GNN and position embedding generated by RNN for multivariate time series forecasting. The proposed GRformer constructs graph by pearson correlation and uses a mix-hop propagation GNN layer to capture cross-channel dependency. For temporal dependency, it uses an RNN to recursively generate positional embeddings. Experiments on eight real-world datasets show that the proposed GRformer is on compare with SOTA model, PatchTST. - This paper is well-written and easy to follow.\n- Using pearson correlation for graph constructing is reasonable and efficient. My main concern is that the novelty is limited:\n\n- For RNN-based position embedding: \n  1. The idea of enhance Transformer with RNN is not new\\[1\\].\n  2. RNN operates recursively and cannot be parallelized, which offsets the efficiency advantages of Transformers that can be highly parallelized.\n  3. Ablation study in Table 3 shows that the improvement of RNN against previous learnable position embedding is not significant.\n- For Mix-hop propagation: \n    1. The mix-hop propagation layer is **exactly the same** as that in \\[2\\] and there is no explicit reference to it in Section 3.2.3.\n    2. Besides the graph construction via Pearson correlation, this is a direct combination of PatchTST and \"Connecting the dots\".\n\n\\[1\\] Qin, Yao, et al. \"A dual-stage attention-based recurrent neural network for time series prediction.\" arXiv preprint arXiv:1704.02971 (2017).\n\n\\[2\\] Wu, Zonghan, et al. \"Connecting the dots: Multivariate time series forecasting with graph neural networks.\" Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining. 2020. - What is the authors' primary objective in visualizing the weights of the MLP in Figure 1(b), given that it only reflects the correlation among hidden states? \n- Could you provide a comparison of the computational efficiency between your RNN-based position embedding and a learnable position embedding, particularly in relation to varying sequence lengths?\n- How were the hyperparameters (0.8 and $k$) in Equations (2) and (3) chosen, and what impact do these specific values have on the model's performance and behavior?",
         "329",
         "5",
         "7",
         "0.7978",
         "0.0755532213",
         "0.936165452",
         "53",
         "18",
         "36.6467",
         "11.615",
         "15.9253",
         "14.0465",
         "12.0187",
         "0.38480000000000003",
         "74",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "47",
         "lmShn57DRD",
         "1208",
         "1695022608110",
         "['~Aobo_Liang1', '~Xiaolin_Chai1', '~Yan_Sun10']",
         "Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network",
         "Many Transformer-based models have achieved great performance on multivariate long-term time series forecasting (MLTSF) tasks in the past few years, but they are ineffective in capturing cross-channel dependencies and temporal order information. In multivariate time series analysis, the cross-channel dependencies can help the model understand the correlations between multivariate time series, and the consistency of time series is also essential for more accurate predictions. Therefore, we propose GRformer, adopting the Graph neural network (GNN) and position encoding based on recurrent neural network (RNN) to better process multivariate time series data. We design a mix-hop propagation layer and embed it in the feedforward neural network to encourage proper interaction between different time series. To introduce temporal order information, we use a multi-layer RNN to recursively generate positional embeddings for sequence elements. Experiments on eight real-world datasets show that our model can achieve more accurate predictions on MLTSF tasks.",
         "Reviewer_rJkP",
         "1698711813614",
         "1699636047246",
         "3",
         "4",
         "1",
         "2",
         "1",
         "This paper proposes GRformer, a new neural architecture for multivariate long-term time series forecasting (MLTSF). The authors propose a hybrid architecture that consists of a Transformer-based graph neural network to model cross-channel dependencies and a recurrent neural network to model temporal dependencies. The proposed model shows promising performance on eight benchmarks. However, the motivation and reasoning behind the criticism of the Transformer-based approach are difficult to understand. Some of the claims are made without proper evidence, or by simply citing previous work, without providing any further detailed study or analysis. Additionally, the performance improvements on the benchmarks seem to outperform the baselines. However, I believe the claim of achieving a performance improvement with a 5.7% decrease in MSE and 6.1% decrease in MAE is misleading. These numbers are calculated by averaging MSE and MAE without considering the scales between different benchmarks and metrics. ILI has much higher mean squared errors (MSEs) and mean absolute errors (MAEs) than other benchmarks. This means that if you compute the average score in this way, the average score can be dominated by the relative improvement in this specific dataset. The tone reporting the improvement suggests that the model showed around a 6% decrease in errors on all benchmarks, but the average relative improvement for each benchmark at different metrics is actually 2.55% for MSE and 4.96% for MAE. The model achieves improvements over 7 different benchmarks using 4 metrics for each benchmark dataset. The experiments are done extensively with ablation on different positional encoding strategies. This however raises a question on why the RNN is needed (Table 3. R: the first column vs L: the second column show a very minor difference). I am not sure what I am seeing in Figure 1(b), and I don’t understand how to interpret the authors' claim that cross-channel interaction is chaotic based on simply visualizing the weight matrices of the Transformer's dense layer (internal MLP).\n\nI am not sure I understand the authors' point about positional encoding not being able to represent temporal orders well. RNNs have their own problems, such as vanishing gradients when modeling long-term temporal dependencies. Are you suggesting that RNNs outperform Transformers in multivariate long-term time series forecasting (MLTSF)?\n-> Are the ablation results in Table 3 the experiments to back this claim? If that's the case, the performance difference between an RNN-based positional encoding (?) vs a learned positional embedding is almost 0.\n\nWhat exactly is the RNN-based position encoding method? In the caption for Figure 2, it says \"The multi-layer RNN injects temporal order information.\" However, RNNs are not just injecting temporal order information as some sort of advanced positional encoding method; they can actually learn temporal dependencies. I am not sure if you are distinguishing between positional encoding and learning temporal representation.\n\nFigure 2 (b) is hard to understand, at least explain the operator signs in the caption, arrows are not clear. What is the main evidence that Transformer-based models are ineffective at capturing cross-channel dependencies and temporal orders? If Transformers were bad at capturing temporal orders, they would not have become as popular as they are today. I am curious why the authors make such claims, as I do not see any plausible supporting evidence in the manuscript.\n\nThe authors mentioned that they used multi-layered RNNs, however in the appendix, it's said 1-layer RNN was used. Can you clarify the details of the RNN architecture?\n\n“To properly capture temporal dependencies, we consider using a multilayer RNN to encode the positions in the time series.” Why deep RNNs can properly capture temporal dependencies while Transformers can’t?",
         "596",
         "0",
         "0",
         "0.7782",
         "0.0033277217000000003",
         "0.9233770967",
         "53",
         "10",
         "40.7114",
         "11.4642",
         "15.2089",
         "14.4033",
         "12.5358",
         "0.1958",
         "93",
         "0",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "48",
         "lOwkOIUJtx",
         "8429",
         "1695510038947",
         "['~Jiayang_Liu2', '~Yiming_Bu1', '~Daniel_Tso1', '~Qinru_Qiu1']",
         "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling",
         "High accuracy, low latency and high energy efficiency represent a set of contradictory goals when searching for  system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduce camera refresh rates, and increase the volume of data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, saccade mechanism observed in the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from foveal and peripheral vision, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90\\% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our study demonstrates a 5\\% higher image recognition accuracy compared to state-of-the-art foveal-peripheral vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches.",
         "Reviewer_7Zf9",
         "1698696716802",
         "1699637050853",
         "8",
         "3",
         "3",
         "3",
         "3",
         "This paper presents a new algorithm for sequential foveated visual sampling of an image.\n\nThe main claims of the paper are that \n\n- the required input pixels per frame are reduced by 90% without losing image recognition performance\n- 5% higher recognition accuracy compared to existing foveal sampling models with matching pixel number input\n- higher data efficiency in training\n\nI find the algorithm to be interesting and novel, and that the second and third claims above are supported.\nI am confused where to find evidence for the first claim.\n\nOverall I think this paper is a borderline accept. I find the method simple and useful, with interesting potential application. \nIt is appealing that the method seems to be suitable for existing classification models (no retraining). ## Major\n\nI am confused how the image information from the sequential glimpses is passed and integrated in the predictive reconstruction model. Much more space is spent on the background to the hybrid loss function than actually making explicit how the sequential image information is used to improve reconstruction.\n\nIn addition, the abstract states \"our model reduces the required input pixels by over 90% per frame while maintaining the same level of performance in image recognition as with the original images.\" I don't understand where to find support for this claim in the results. For example, in Figure 3, all subsampled models perform worse than the original. The data in Figure 4 are coming closest to the original; is this what is meant?\n\nAlso, please clarify whether the experiments in Figure 3 are conducted with the trained saccade control model (which one?). \n\n\n## Minor\n\n- Instead of \"continuous saccades\" a better terminology would be \"sequential saccades\" or \"scanpaths\". See e.g. \\[2, 3, 4\\]\n- There are now known to be three types of photosensitive cells: rods, cones and intrinsically-photosensitive ganglion cells \\[1, 8\\]\n- You use SSIM but the relevant paper(s) are not cited (e.g. \\[7\\]).\n- Heading 3.1 \"Periphrl\"\n\n## Literature\n\n1. Do, M. T. H., & Yau, K.-W. (2010). Intrinsically Photosensitive Retinal Ganglion Cells. Physiol Rev, 90.\n\n1. Hoppe, D., & Rothkopf, C. A. (2019). Multi-step planning of eye movements in visual search. Scientific Reports, 9(1), 144. https://doi.org/10.1038/s41598-018-37536-0\n\n1. Kümmerer, M., & Bethge, M. (2021). State-of-the-Art in Human Scanpath Prediction (arXiv:2102.12239). arXiv. http://arxiv.org/abs/2102.12239\n\n1. Kümmerer, M., Bethge, M., & Wallis, T. S. A. (2022). DeepGaze III: Modeling free-viewing human scanpaths with deep learning. Journal of Vision, 22(5), 7. https://doi.org/10.1167/jov.22.5.7\n\n1. Rosenholtz, R. (2016). Capabilities and Limitations of Peripheral Vision. Annual Review of Vision Science, 2(1), 437–457. https://doi.org/10.1146/annurev-vision-082114-035733\n\n1. Watson, A. B. (2014). A formula for human retinal ganglion cell receptive field density as a function of visual field location. Journal of Vision, 14(7), 15. https://doi.org/10.1167/14.7.15\n\n1. Wang, Z., Simoncelli, E. P., & Bovik, A. C. (2003). Multiscale structural similarity for image quality assessment. The Thirty-Seventh Asilomar Conference on Signals, Systems & Computers, 2003, 1398–1402. https://doi.org/10.1109/ACSSC.2003.1292216\n\n1. Zele, A. J., Feigl, B., Adhikari, P., Maynard, M. L., & Cao, D. (2018). Melanopsin photoreception contributes to human visual detection, temporal and colour processing. Scientific Reports, 8(1), 3842. https://doi.org/10.1038/s41598-018-22197-w - I would like to see how the hybrid reconstruction loss changes over timestep, and not just classification accuracy.\n- The sampling of the periphery of individual pixels with small probability is not very like human vision. Effectively this is providing low pass information. Have the authors considered how the sampling density could be approximated more plausibly (e.g. \\[6\\])?\n- Have the authors considered comparing scanpath strategies learned in this model to human scanpaths (e.g. \\[3, 4\\])?",
         "591",
         "20",
         "22",
         "0.8122",
         "0.1227193813",
         "0.9176356196000001",
         "47",
         "10",
         "42.1304",
         "11.3233",
         "14.4005",
         "13.4718",
         "13.597",
         "0.3629",
         "108",
         "1",
         "0",
         "0",
         "0",
         "iclr"
        ],
        [
         "49",
         "lOwkOIUJtx",
         "8429",
         "1695510038947",
         "['~Jiayang_Liu2', '~Yiming_Bu1', '~Daniel_Tso1', '~Qinru_Qiu1']",
         "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling",
         "High accuracy, low latency and high energy efficiency represent a set of contradictory goals when searching for  system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduce camera refresh rates, and increase the volume of data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, saccade mechanism observed in the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from foveal and peripheral vision, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90\\% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our study demonstrates a 5\\% higher image recognition accuracy compared to state-of-the-art foveal-peripheral vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches.",
         "Reviewer_rEUv",
         "1698697040175",
         "1700663753570",
         "6",
         "4",
         "2",
         "3",
         "3",
         "This paper aims to reconstruct the original image from multiple subsampled views, using reinforcement learning and neural network models for scan control and image reconstruction, respectively. The paper conducts numerous experiments to demonstrate that the proposed algorithm can maintain detection task accuracy, reasonable saccade control, and high reconstruction quality under high data efficiency. However, the motivation for the work is not well-founded, and there are possible improvements in the experiments. 1. The task addressed in the paper is novel, as it is the first in the industry to reconstruct an image from continuous central foveal subsampled images. Other methods focus on single-sample images and proceed directly to downstream tasks without reconstructing the original image, making this work unique.\n2. The methods used are innovative, employing an actor-critic model for saccade control, which can achieve near-original image classification accuracy in just five scans.\n3. The writing style of the paper is easy to understand, especially in describing the proposed methods. 1. While the task is novel, it lacks a convincing real-world application, as it simulates the process of multiple eye samplings without addressing practical problems.\n2. The experimental comparisons are not entirely fair. The uniform control group uses an 8% sampling probability, while the 1/16+2% group differs by 0.25%, indicating an unequal amount of information that might affect performance.\n3. Using classification model metrics to assess the quality of reconstruction is questionable, as classification tasks do not focus on texture details. If this method was to downsample the original image with the same number of sampled pixels, how much better is the method in terms of performance compared to this? see weaknesses",
         "271",
         "0",
         "7",
         "0.7977",
         "0.1371333333",
         "0.8944661021",
         "59",
         "22",
         "26.1536",
         "14.7902",
         "17.6374",
         "16.0982",
         "16.0539",
         "0.0999",
         "95",
         "0",
         "1",
         "0",
         "0",
         "iclr"
        ]
       ],
       "shape": {
        "columns": 35,
        "rows": 420
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>politeness_score</th>\n",
       "      <th>hedge_C</th>\n",
       "      <th>hedge_D</th>\n",
       "      <th>hedge_E</th>\n",
       "      <th>hedge_I</th>\n",
       "      <th>hedge_N</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wfzXa8e783</td>\n",
       "      <td>1940</td>\n",
       "      <td>1695136750006</td>\n",
       "      <td>[~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>Reviewer_EGJf</td>\n",
       "      <td>1698648757307</td>\n",
       "      <td>1701662567826</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7773</td>\n",
       "      <td>13.5591</td>\n",
       "      <td>13.3105</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wfzXa8e783</td>\n",
       "      <td>1940</td>\n",
       "      <td>1695136750006</td>\n",
       "      <td>[~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>Reviewer_DWom</td>\n",
       "      <td>1698746208577</td>\n",
       "      <td>1699636125239</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3091</td>\n",
       "      <td>13.6811</td>\n",
       "      <td>14.7228</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wfzXa8e783</td>\n",
       "      <td>1940</td>\n",
       "      <td>1695136750006</td>\n",
       "      <td>[~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>Reviewer_PnHf</td>\n",
       "      <td>1698822869626</td>\n",
       "      <td>1699636125143</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2257</td>\n",
       "      <td>16.5672</td>\n",
       "      <td>16.3167</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wfzXa8e783</td>\n",
       "      <td>1940</td>\n",
       "      <td>1695136750006</td>\n",
       "      <td>[~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...</td>\n",
       "      <td>Navigating Text-To-Image Customization: From L...</td>\n",
       "      <td>Text-to-image generative models have garnered ...</td>\n",
       "      <td>Reviewer_ekPo</td>\n",
       "      <td>1699260725548</td>\n",
       "      <td>1699636125075</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8611</td>\n",
       "      <td>11.3747</td>\n",
       "      <td>10.6575</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wHgu98u8Sc</td>\n",
       "      <td>8035</td>\n",
       "      <td>1695494318474</td>\n",
       "      <td>[~Konstantinos_Pitas1, ~Julyan_Arbel1]</td>\n",
       "      <td>$\\nu$-ensembles: Improving deep ensemble calib...</td>\n",
       "      <td>We present a method to improve the calibration...</td>\n",
       "      <td>Reviewer_HFRa</td>\n",
       "      <td>1697955924532</td>\n",
       "      <td>1699636992453</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>18.2108</td>\n",
       "      <td>15.9828</td>\n",
       "      <td>15.2685</td>\n",
       "      <td>0.2519</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iclr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_iUr9</td>\n",
       "      <td>1687915292924</td>\n",
       "      <td>1702411423879</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7570</td>\n",
       "      <td>13.5591</td>\n",
       "      <td>11.6987</td>\n",
       "      <td>0.4482</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_UWwz</td>\n",
       "      <td>1688653360609</td>\n",
       "      <td>1702411423780</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>18.9797</td>\n",
       "      <td>16.9020</td>\n",
       "      <td>17.2150</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_TyeE</td>\n",
       "      <td>1688683891875</td>\n",
       "      <td>1702411423568</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>17.7186</td>\n",
       "      <td>16.0092</td>\n",
       "      <td>16.2817</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_5HgB</td>\n",
       "      <td>1688710100227</td>\n",
       "      <td>1702411423474</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5411</td>\n",
       "      <td>15.7101</td>\n",
       "      <td>14.5116</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0VcvYQ3uPh</td>\n",
       "      <td>13335</td>\n",
       "      <td>1683818526320</td>\n",
       "      <td>[~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...</td>\n",
       "      <td>Improved Frequency Estimation Algorithms with ...</td>\n",
       "      <td>Estimating frequencies of elements appearing i...</td>\n",
       "      <td>Reviewer_yxpU</td>\n",
       "      <td>1689139688998</td>\n",
       "      <td>1702411423376</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.8672</td>\n",
       "      <td>13.8167</td>\n",
       "      <td>12.1900</td>\n",
       "      <td>0.6631</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neurips</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    submission_id  submission_number  submission_creation_date  \\\n",
       "0      wfzXa8e783               1940             1695136750006   \n",
       "1      wfzXa8e783               1940             1695136750006   \n",
       "2      wfzXa8e783               1940             1695136750006   \n",
       "3      wfzXa8e783               1940             1695136750006   \n",
       "4      wHgu98u8Sc               8035             1695494318474   \n",
       "..            ...                ...                       ...   \n",
       "415    0VcvYQ3uPh              13335             1683818526320   \n",
       "416    0VcvYQ3uPh              13335             1683818526320   \n",
       "417    0VcvYQ3uPh              13335             1683818526320   \n",
       "418    0VcvYQ3uPh              13335             1683818526320   \n",
       "419    0VcvYQ3uPh              13335             1683818526320   \n",
       "\n",
       "                                    submission_authors  \\\n",
       "0    [~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...   \n",
       "1    [~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...   \n",
       "2    [~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...   \n",
       "3    [~SHIH-YING_YEH1, ~Yu-Guan_Hsieh1, ~Zhidong_Ga...   \n",
       "4               [~Konstantinos_Pitas1, ~Julyan_Arbel1]   \n",
       "..                                                 ...   \n",
       "415  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "416  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "417  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "418  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "419  [~Anders_Aamand1, ~Justin_Y._Chen1, ~Huy_Nguye...   \n",
       "\n",
       "                                      submission_title  \\\n",
       "0    Navigating Text-To-Image Customization: From L...   \n",
       "1    Navigating Text-To-Image Customization: From L...   \n",
       "2    Navigating Text-To-Image Customization: From L...   \n",
       "3    Navigating Text-To-Image Customization: From L...   \n",
       "4    $\\nu$-ensembles: Improving deep ensemble calib...   \n",
       "..                                                 ...   \n",
       "415  Improved Frequency Estimation Algorithms with ...   \n",
       "416  Improved Frequency Estimation Algorithms with ...   \n",
       "417  Improved Frequency Estimation Algorithms with ...   \n",
       "418  Improved Frequency Estimation Algorithms with ...   \n",
       "419  Improved Frequency Estimation Algorithms with ...   \n",
       "\n",
       "                                   submission_abstract       reviewer  \\\n",
       "0    Text-to-image generative models have garnered ...  Reviewer_EGJf   \n",
       "1    Text-to-image generative models have garnered ...  Reviewer_DWom   \n",
       "2    Text-to-image generative models have garnered ...  Reviewer_PnHf   \n",
       "3    Text-to-image generative models have garnered ...  Reviewer_ekPo   \n",
       "4    We present a method to improve the calibration...  Reviewer_HFRa   \n",
       "..                                                 ...            ...   \n",
       "415  Estimating frequencies of elements appearing i...  Reviewer_iUr9   \n",
       "416  Estimating frequencies of elements appearing i...  Reviewer_UWwz   \n",
       "417  Estimating frequencies of elements appearing i...  Reviewer_TyeE   \n",
       "418  Estimating frequencies of elements appearing i...  Reviewer_5HgB   \n",
       "419  Estimating frequencies of elements appearing i...  Reviewer_yxpU   \n",
       "\n",
       "     creation_date  last_modification_date  review_rating  ...  gunning_fog  \\\n",
       "0    1698648757307           1701662567826              6  ...      14.7773   \n",
       "1    1698746208577           1699636125239              6  ...      15.3091   \n",
       "2    1698822869626           1699636125143              6  ...      18.2257   \n",
       "3    1699260725548           1699636125075              8  ...      10.8611   \n",
       "4    1697955924532           1699636992453              3  ...      18.2108   \n",
       "..             ...                     ...            ...  ...          ...   \n",
       "415  1687915292924           1702411423879              6  ...      14.7570   \n",
       "416  1688653360609           1702411423780              7  ...      18.9797   \n",
       "417  1688683891875           1702411423568              7  ...      17.7186   \n",
       "418  1688710100227           1702411423474              7  ...      17.5411   \n",
       "419  1689139688998           1702411423376              8  ...      14.8672   \n",
       "\n",
       "     smog_index  automated_readability_index  politeness_score hedge_C  \\\n",
       "0       13.5591                      13.3105            0.2025      77   \n",
       "1       13.6811                      14.7228            0.2131      78   \n",
       "2       16.5672                      16.3167            0.1213      86   \n",
       "3       11.3747                      10.6575            0.1844      84   \n",
       "4       15.9828                      15.2685            0.2519      90   \n",
       "..          ...                          ...               ...     ...   \n",
       "415     13.5591                      11.6987            0.4482      90   \n",
       "416     16.9020                      17.2150            0.0999      65   \n",
       "417     16.0092                      16.2817            0.3011      95   \n",
       "418     15.7101                      14.5116            0.1041      78   \n",
       "419     13.8167                      12.1900            0.6631     100   \n",
       "\n",
       "     hedge_D  hedge_E  hedge_I hedge_N    venue  \n",
       "0          1        2        0       0     iclr  \n",
       "1          0        0        0       0     iclr  \n",
       "2          0        0        0       0     iclr  \n",
       "3          0        0        0       0     iclr  \n",
       "4          0        0        0       0     iclr  \n",
       "..       ...      ...      ...     ...      ...  \n",
       "415        1        0        0       2  neurips  \n",
       "416        1        0        0       0  neurips  \n",
       "417        1        0        0       0  neurips  \n",
       "418        0        0        0       0  neurips  \n",
       "419        0        1        0       0  neurips  \n",
       "\n",
       "[420 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a new column 'venue' to each dataframe\n",
    "df_iclr_50['venue'] = 'iclr'\n",
    "df_neurips_50['venue'] = 'neurips'\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "df_merged = pd.concat([df_iclr_50, df_neurips_50], ignore_index=True)\n",
    "\n",
    "# Display the merged dataframe\n",
    "display(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged dataframe to a CSV file\n",
    "df_merged.to_csv('iclr_neurips_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
