{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_json('final_data/HA_ALL_nonllm.json', orient='records', lines=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rows with null value in their review_suggestion, put the value as follows: review_rating < 4: reject, review_rating >= 4 and < 6: revision, review_rating >= 6: accept\n",
    "def fill_review_suggestion(row):\n",
    "    if row['review_suggestion'] is None:\n",
    "        if row['review_rating'] < 4:\n",
    "            return 'Reject'\n",
    "        elif 4 <= row['review_rating'] < 6:\n",
    "            return 'Revision'\n",
    "        elif row['review_rating'] >= 6:\n",
    "            return 'Accept'\n",
    "    else:\n",
    "        return row['review_suggestion']\n",
    "df['review_suggestion'] = df.apply(fill_review_suggestion, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in review_suggestion, replace Approved With Reservations with Revision, Approved with Accept, Not Approved with Reject\n",
    "def replace_review_suggestion(row):\n",
    "    if row['review_suggestion'] == 'Approved With Reservations':\n",
    "        return 'Revision'\n",
    "    elif row['review_suggestion'] == 'Approved':\n",
    "        return 'Accept'\n",
    "    elif row['review_suggestion'] == 'Not Approved':\n",
    "        return 'Reject'\n",
    "    else:\n",
    "        return row['review_suggestion']\n",
    "df['review_suggestion'] = df.apply(replace_review_suggestion, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in review_suggestion, replace Major Revision and Minor Revision with Revision\n",
    "def replace_review_suggestion(row):\n",
    "    if row['review_suggestion'] == 'Major Revision':\n",
    "        return 'Revision'\n",
    "    elif row['review_suggestion'] == 'Minor Revision':\n",
    "        return 'Revision'\n",
    "    else:\n",
    "        return row['review_suggestion']\n",
    "df['review_suggestion'] = df.apply(replace_review_suggestion, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in review_suggestion, replace any value that has accept term in it with Accept and any value that has reject term in it with Reject\n",
    "def replace_review_suggestion(row):\n",
    "    if 'accept' in row['review_suggestion'].lower():\n",
    "        return 'Accept'\n",
    "    elif 'reject' in row['review_suggestion'].lower():\n",
    "        return 'Reject'\n",
    "    else:\n",
    "        return row['review_suggestion']\n",
    "df['review_suggestion'] = df.apply(replace_review_suggestion, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns except for review_suggestion, paper_id, reviewer, venue\n",
    "df_decision = df[['paper_id', 'review_suggestion', 'reviewer', 'venue']]\n",
    "df_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in df_decision['reviewer], replace all ' ' and '_' with '-'\n",
    "def replace_reviewer(row):\n",
    "    return row['reviewer'].replace(' ', '-').replace('_', '-')\n",
    "df_decision['reviewer'] = df_decision.apply(replace_reviewer, axis=1)\n",
    "df_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_reviews(folder_path):\n",
    "    rows = []\n",
    "    # find all JSON files in the folder\n",
    "    for file_path in glob.glob(os.path.join(folder_path, '*.json')):\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        paper_id = data.get('paper_id')\n",
    "        assessor = data.get('assessor')\n",
    "        metrics = data.get('metrics', {})\n",
    "        \n",
    "        # group metrics by reviewer name\n",
    "        reviewer_metrics = {}\n",
    "        for key, value in metrics.items():\n",
    "            # only process keys that start with \"review_\"\n",
    "            if not key.startswith('review_'):\n",
    "                continue\n",
    "            parts = key.split('_')\n",
    "            reviewer = parts[1]                          # e.g. \"Palwinder-Singh\"\n",
    "            metric_name = '_'.join(parts[2:])            # e.g. \"Comprehensiveness\"\n",
    "            \n",
    "            reviewer_metrics.setdefault(reviewer, {})\n",
    "            reviewer_metrics[reviewer][metric_name] = value\n",
    "        \n",
    "        # turn each reviewerâ€™s metrics into a row\n",
    "        for reviewer, mdict in reviewer_metrics.items():\n",
    "            row = {\n",
    "                'paper_id': paper_id,\n",
    "                'assessor': assessor,\n",
    "                'reviewer': reviewer\n",
    "            }\n",
    "            row.update(mdict)\n",
    "            rows.append(row)\n",
    "    \n",
    "    # build the final DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "folder = 'Human_Annotation_Data'\n",
    "df_human = load_reviews(folder)\n",
    "\n",
    "# show the first few rows\n",
    "df_human = df_human[df_human['Overall_Quality'] > 10]\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human = df_human[['paper_id', 'reviewer', 'assessor', 'Overall_Quality']]\n",
    "df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_human and df_decision on paper_id and reviewer\n",
    "df_human['paper_id'] = df_human['paper_id'].astype(int)\n",
    "df_decision['paper_id'] = df_decision['paper_id'].astype(int)\n",
    "df_human['reviewer'] = df_human['reviewer'].astype(str)\n",
    "df_decision['reviewer'] = df_decision['reviewer'].astype(str)\n",
    "\n",
    "df_merge = pd.merge(df_human, df_decision, on=['paper_id', 'reviewer'], how='inner')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iclr = df_merge[df_merge['venue'] == 'iclr']\n",
    "df_neurips = df_merge[df_merge['venue'] == 'neurips']\n",
    "df_sw = df_merge[df_merge['venue'] == 'semanticweb']\n",
    "df_f1000 = df_merge[df_merge['venue'] == 'f1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# color map for suggestions/decisions\n",
    "color_map = {\n",
    "    'Accept': 'green',\n",
    "    'Reject': 'red',\n",
    "    'Revision': 'blue'\n",
    "}\n",
    "\n",
    "# Define a function to plot politeness_score per decision distribution\n",
    "def plot_distribution(df, title):\n",
    "    # Add a decision column based on review_rating [1, 4) reject, [4, 6) revision, [6, 10] accept\n",
    "    # df['decision'] = pd.cut(df['Overall_Quality'], bins=[0, 4, 6, 10], labels=['Reject', 'Revision', 'Accept'], right=False)\n",
    "    \n",
    "    # Plot politeness_score distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for decision in df['review_suggestion'].unique():\n",
    "        sns.kdeplot(\n",
    "            data=df[df['review_suggestion'] == decision],\n",
    "            x='Overall_Quality',\n",
    "            label=decision,\n",
    "            color=color_map.get(decision, 'black'),\n",
    "            fill=False,\n",
    "            alpha=0.9,\n",
    "            linewidth=3,\n",
    "            cut=0\n",
    "        )\n",
    "    plt.title(f\"Overall Quality Score Distribution - {title}\", fontsize=16)\n",
    "    plt.xlabel(\"Overall Quality Score\", fontsize=12)\n",
    "    plt.ylabel(\"Density\", fontsize=12)\n",
    "    plt.legend(title=\"\", fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot\n",
    "\n",
    "plot_distribution(df_merge, 'Human Annotation')\n",
    "\n",
    "# for df in [df_iclr, df_neurips, df_sw, df_f1000]:\n",
    "#     plot_distribution(df, 'Human Annotation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
