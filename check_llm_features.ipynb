{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_authors",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "submission_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "creation_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "last_modification_date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_confidence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_soundness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_presentation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_contribution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_review",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paper_submission_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_creation_to_review_submission_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "llm_Comprehensiveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_Vagueness",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_Objectivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_Fairness",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_Actionability",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_Constructiveness",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_Relevance Alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_Clarity and Readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_Usage of Technical Terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_Factuality",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_Overall Quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_overall_score_100",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_Sentiment Polarity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_Politeness",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "9b2fd618-0c6e-4071-bebd-a8dd7786510d",
       "rows": [
        [
         "0",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_BcRN",
         "1698598642014",
         "1699636398632",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper proposes a training method to improve the CLIP’s visual representation based on task-specific vision models. It utilizes the vision models from model zoo to construct pseudo labels for noisy image-text models, serving as extra supervision besides the contrastive loss. This simple method is effective, improving  up to 16.3% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. 1. The proposed method is simple yet effective, leveraging existing vision models to serve as teacher for extra supervision. The improvements is obvious even compared to fine-tuned CLIP model on CC3M dataset.\n2. The effectiveness is demonstrated on a bunch of downstream tasks, including segmentation, detection, depth estimation, and surface normal estimation across multiple datasets. Limitations of novelty.  The paper claims proposed method uses publicly accessible experts trained on diverse tasks with different data distributions and objectives, which is different from previous works that use vision foundation models to generate labels. However, from the Fig.1 and model design, data samples are labeled by various foundation models and losses are computed respectively to optimize task heads, which is similar to previous pseudo labeling strategy. The training process involves multiple vision foundation model forwarding process, which would slowen the training process. How much impact will this have on the training process? And is it fair to compare the training strategy with CLIP-FT model in paper?",
         "226",
         "0",
         "2",
         "0.8079000000000001",
         "0.1061594203",
         "0.8954392672",
         "49",
         "12",
         "30.6084",
         "13.0004",
         "15.6607",
         "14.5546",
         "14.526299999999999",
         "0.0364",
         "94",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "low",
         "4.0",
         "4",
         "3",
         "4",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "85.0",
         "85.0",
         "positive",
         "polite"
        ],
        [
         "1",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_hJxN",
         "1698648844616",
         "1699636398538",
         "3",
         "5",
         "2",
         "3",
         "2",
         "This paper aims to augment CLIP training with task-specific data and task heads. In particular, the authors use open-source task-specific vision models to generate the pseudo-labels and train the task-specific heads using these labels. The experiment results show the effectiveness of training such CLIP model while keeping zero-shot classification ability. - Well written and easy to follow. \n\n- The motivation is clear and idea is simple to understand.\n\n- The experiment results show the effectiveness of pseudo-label training in different tasks, including segmentation, detection, and depth estimation. - The experiment results are not convincing. The baselines are not strong. The authors should present more strong baselines, including Mask2Former. Moreover, this work dose not compare with recent state-of-the-art approach whether on semantic segmentation or depth prediction. \n\n- Missing the frozen trained CLIP model baselines with heavier head \\[1\\], \\[2\\], \\[3\\]. What are the Frozen CLIP results of strong baselines?\n\n- The ablation studies are not good. For example, the effects of various task heads are not explored. The effects of different task-specific experts are not explored.  \nThe experiment details can be put into appendix.\n- In abstract, “it lacks object localization capabilities” Personally, CLIP models have the localization ability. Several works \\[1\\]\\[2\\] have adopted CLIP as feature extractor, which also achieve good results.\n\n- Figure-1 (c) needs to add the baseline results for better comparison. \n\n\n\\[1\\], Frozen clip models are efficient video learners, ECCV-2022\n\n\\[2\\], Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP, NeurIPS-2023\n\\[3\\]. F-VLM: Open-Vocabulary Object Detection upon Frozen Vision and Language Models, ICLR-2023 See the weakness part.",
         "261",
         "8",
         "0",
         "0.7694000000000001",
         "0.0820393375",
         "0.8567712307",
         "49",
         "11",
         "39.7853",
         "10.703",
         "12.5661",
         "12.2047",
         "12.4388",
         "0.07200000000000001",
         "94",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "moderate",
         "4.0",
         "3",
         "4",
         "4",
         "5.0",
         "4.0",
         "4.0",
         "partially factual",
         "65.0",
         "65.0",
         "neutral",
         "neutral"
        ],
        [
         "2",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_8Cdu",
         "1698863097320",
         "1699636398427",
         "3",
         "5",
         "2",
         "3",
         "1",
         "This paper proposes CLIPTeX, which enhances CLIP's capabilities utilizing specialized vision models. \nBy generating pseudo-labels from these models and subsequently training CLIP on these labels combined with image-text pairs, the approach has shown notable improvements in various vision tasks. \n\nCLIPTeX not only bolsters CLIP's visual understanding but also preserves its foundational strengths, ensuring its applicability across several computer vision tasks. This paper conducts experiments across multiple datasets to demonstrate the potential of CLIPTeX. 1. This paper is well-written and easy to follow.\n2. The rigorous experimentation across diverse tasks such as segmentation, detection, depth estimation, and surface normal estimation lends credibility to the paper's claims.\n3. This work emphasizes the potential of using pseudo-labels, setting a precedent for future research to consider such augmentation strategies. 1. The pre-processing to get the pseudo label is somehow time-consuming.\n2. Considering CLIP is a vision-language pre-training model, evaluation results on the cross-modal downstream tasks are necessary, which helps demonstrate the cross-modal dense understanding capability of proposed CLIPTeX, such as 2D visual grounding, 2D question-answering, etc.\n3. The reviewer holds that the novelty of this paper is limited. Instead of introducing a fundamentally new approach or technique, the paper's main contribution is in integrating specialized task-specific vision models with CLIP. While this integration does lead to performance improvements, the core idea revolves around a simple application of pseudo-labels. Essentially, the work can be viewed as a refinement of CLIP without enough novelty. \n4. Besides quantitative results, qualitative results on downstream tasks are required to further prove the 2D representation capability of CLIPTeX. Please check the Weaknesses mentioned above.",
         "264",
         "0",
         "7",
         "0.8374",
         "0.0525974026",
         "0.9221839309000001",
         "49",
         "8",
         "20.0915",
         "14.8293",
         "18.2521",
         "15.9032",
         "16.8967",
         "0.19390000000000002",
         "80",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "3.0",
         "4",
         "4",
         "4",
         "5.0",
         "5.0",
         "5.0",
         "partially factual",
         "88.0",
         "88.0",
         "neutral",
         "polite"
        ],
        [
         "3",
         "zxPDdw8koz",
         "4303",
         "1695343783421",
         "['~Mohammadreza_Salehi3', '~Mehrdad_Farajtabar1', '~Maxwell_Horton1', '~Fartash_Faghri1', '~Hadi_Pouransari1', '~Raviteja_Vemulapalli1', '~Oncel_Tuzel2', '~Ali_Farhadi3', '~Mohammad_Rastegari2', '~Sachin_Mehta1']",
         "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
         "Contrastive language image pretraining (CLIP) is a standard method for training vision-language models. While CLIP is scalable, promptable, and robust to distribution shifts on image classification tasks, it lacks object localization capabilities.  This paper studies the following question: Can we augment CLIP training with task-specific vision models from model zoos to improve its visual representations? Towards this end, we leverage open-source task-specific vision models to generate pseudo-labels for an uncurated and noisy image-text dataset. Subsequently, we train CLIP models on these pseudo-labels in addition to the contrastive training on image and text pairs. This simple setup shows substantial improvements of up to 16.3\\% across different vision tasks, including segmentation, detection, depth estimation, and surface normal estimation. Importantly, these enhancements are achieved without compromising CLIP's existing capabilities, including its proficiency in promptable zero-shot classification.",
         "Reviewer_Q843",
         "1699416352034",
         "1699636398331",
         "8",
         "3",
         "3",
         "3",
         "3",
         "In this work, the authors augment the capabilities of CLIP with task-specific experts that help to improve its representation for the downstream tasks. Those experts are well-known models from model zoos used to create hard pseudo-labels on web-scale noisy image-text datasets. - Easy to read. Good experiments and ablation. \n- It is great to see that by using experts and doing contrastive task-specific loss, the performance on downstream task improve, and CLIP maintains its versatility and obtain comparable performance on zero-shot classification\n- The method is simple and efficient. - It is interesting to see that the complementary task help between each others. Table 5, I believe lot of insights can be done and I was expecting to see more analysis in this part of the paper. \n- It would be great to guess what set of tasks should be pick, for the downstream task. So, we can get a set of different CLIPTeX trained with the combinatories of task/experts so people can use the one that is more likely to work for the downstream task.\nFor example, for segmentation seems to be that the most valuable experts are the segmentation and depth for linear and PSPNet. Similar to SSD in detection. etc... - What is the proof that CLIP is more robust to dataset distribution shifts? Reference, experiments?\n- Why Mask R-CNN needs LR milestones and gamma?",
         "228",
         "0",
         "0",
         "0.7506",
         "0.3529761905",
         "0.8587207794",
         "49",
         "2",
         "56.3637",
         "9.621",
         "12.2299",
         "12.231",
         "10.3101",
         "0.4364",
         "93",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "85.0",
         "85.0",
         "positive",
         "polite"
        ],
        [
         "4",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_6Reb",
         "1698589805767",
         "1699636362362",
         "6",
         "5",
         "3",
         "3",
         "3",
         "This paper studies an online dynamic pricing problem by considering a novel model with feature-based price elasticity.  The authors provide a novel algorithm, ``Pricing with Perturbation (PwP),\" that efficiently solves this pricing problem and obtains near-optimal regret, which matches the lower bound of regret up to log terms. 1. The presentation is clear. Beginning with the introduction part, the paper clearly lists its comparisons and generalizations from previous work. Later in the main text, the intuition of the algorithm is also well described. The assumptions made in the paper are also clearly listed and justified.\n\n2. The novelty of the algorithm and its technical contributions are sound. The proposed Pricing with Perturbation (PwP) algorithm is smart and can efficiently solve the problem of a lack of fisher information.\n\n3. Discussions on potential extensions of the work are discussed in detail in the appendix. 1. The motivation for this contextual price elasticity seems unclear.\n\n2. Certain assumptions, such as $x^\\top \\eta$ having a positive lower bound, lack a real-world explanation.\n\n3. Lack of applying this framework to real-data studies 1. Can the authors present certain real-world motivations for this contextual price elasticity? e.g., why is it reasonable to rely on the context $x_t$, and is it reasonable to assume that for all $x_t$, $x_t^\\top \\eta$ is positive all the time? \n\n2. About the linear assumption on $x_t^\\top \\eta$, can this be generalized to some non-linear function of $x_t$? Also, when $x_t$ is stochastic, can the assumption of $x_t^\\top \\eta>0$ be relaxed to $E\\[x_t^\\top \\eta\\]>0$, where $E\\[\\cdot\\]$ is the expectation over $x$?\n\n3. Can the authors provide a real-world (or semi-real) data study? on evaluating the performance of algorithms in real-life situations.\n\n4. In terms of the presentation of simulation results, could the authors present log-log plots and compare them with the $1/2 log T$ curve? Since it would be hard to see the regret order if they are not presented in this way,",
         "322",
         "0",
         "9",
         "0.7199",
         "0.1048061787",
         "0.9118013978",
         "49",
         "12",
         "45.2022",
         "10.9542",
         "14.0176",
         "13.1874",
         "11.7498",
         "0.1041",
         "94",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "5",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_vsAQ",
         "1698794304737",
         "1699636362256",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The paper investigates a context-based dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. The authors adopt a novel approach to formulating customers’ expected demand by incorporating feature-based price elasticity. The paper provides a matched regret bound for the problem. Generally speaking, from my point of view, the paper is well written. I really enjoy reading the discussions the authors make, including the relationship between two different formulations and Section 4.1.1. The technical part is solid. The idea of perturbation, though not completely novel, is quite interesting. 1.\tIn my opinion, Ban and Keskin (2021) should be given more credits. As far as I know, Ban and Keskin (2021) is the first to consider the heterogenous price elasticities which are formulated to be linear with context. At least when introducing the formulation, I think the paper should be cited and discussed more.\n2.\tI understand that a known link function is a good starting point and a common practice. One direction that I think might further improve the paper is to consider (or at least discuss about) an unknown link function. The reason why I mention this point is that Fan et al. (2021) studies a problem with unknown noise distribution. According to equivalence of the two formulation, it seems that it is not undoable to consider a version without knowing the link function. \n3.\tAbout the Perturbation, similar ideas can be found in the dynamic pricing literature (see, e.g., Nambiar et al. 2019). From my perspective, the only reason why the time horizon $T$ should be known in advance is because we need it to calculate $\\Delta$. Nambiar et al. (2019) dynamically change the magnitude of the perturbation, which may potentially help the current algorithm to get rid of the known time horizon $T$. Please correct me if I am wrong.\n\nReference:\nGah-Yi Ban and N Bora Keskin. Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity. Management Science, 67(9):5549–5568, 2021.\n\nJianqing Fan, Yongyi Guo, and Mengxin Yu. Policy optimization using semiparametric models for dynamic pricing. arXiv preprint arXiv:2109.06368, 2021.\n\nMila Nambiar, David Simchi-Levi, and He Wang. Dynamic learning and pricing with model misspecification. Management Science, 65(11):4980-5000, 2019. See above.",
         "371",
         "4",
         "9",
         "0.8034",
         "0.040322580600000005",
         "0.9313320518",
         "49",
         "9",
         "50.8505",
         "9.2389",
         "11.4157",
         "11.538",
         "10.4235",
         "0.1822",
         "96",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "none",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "95.0",
         "95.0",
         "positive",
         "polite"
        ],
        [
         "6",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_g3du",
         "1698930603674",
         "1700722619651",
         "6",
         "3",
         "3",
         "3",
         "2",
         "This paper unifies the ``linear demand'' and the ``linear valuation'' by proposing a new demand model where each item has a feature-dependent price elasticity. The authors devise an effective online optimization algorithm that can achieve a nearly optimal regret bound. Some numerical simulations are conducted to empirically show the effectiveness of the proposed approach. S1. A new demand model for the contextual pricing problem.\n\nS2. The proposed algorithm has a regret bound close to the theoretical lower bound.\n\nS3. Numerical simulations are conducted. W1. Although the proposed demand model extends existing models by considering the feature-dependent price elasticity, the proposed model and online algorithm still rely on linear forms of elasticity and valuation. Remember ICLR is a deep learning conference. A potentially more suitable treatment may be substituting the linear functions with a neural tangent kernel and then devising online algorithms correspondingly.\n\nW2. What is the major technical challenge if we replace the uniform \\alpha with a feature-dependent price elasticity? The authors may want to discuss more the impact of introducing feature-dependent price elasticity terms on algorithm design as well as regret analysis. \n\nW3. As the authors mention in Ethic issues, personalized pricing may have fairness issues. Therefore, it is essential to discuss how to deal with the cases when we add some fairness regularization terms or fairness constraints to the optimization problem. \n\nW4. Still about personalized pricing. As the objective is purely the interest of the platform, I would like to see discussions or experimental results on how the personalized pricing algorithm affects customer well-being metrics such as consumer surplus. W2",
         "262",
         "0",
         "8",
         "0.7992",
         "0.1764419404",
         "0.8751015663",
         "62",
         "20",
         "25.3956",
         "14.0564",
         "15.689",
         "14.5546",
         "14.287",
         "0.11520000000000001",
         "91",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "7",
         "zt8bb6vC4m",
         "4003",
         "1695329721281",
         "['~Jianyu_Xu1', '~Yu-Xiang_Wang1']",
         "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
         "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
         "Reviewer_DP3X",
         "1699005113456",
         "1699636362126",
         "3",
         "3",
         "2",
         "3",
         "2",
         "In this work, the authors face the problem of contextual dynamic pricing in a heteroscedastic environment. The authors face this applicative problem by proposing a new theoretical framework. They provide a lower bound on the expected regret for the setting. Then, the authors provide an algorithm, for which they discuss the upper bound, which matches the lower bound up to log factors. The authors also provide a numerical validation of the solution. The work faces a problem of interest from the applicative point of view. \n\nThe relevant literature is properly discussed. The presentation can be improved, in particular from the introductory part.\n\nThe main concern is about the theoretical analysis of this paper. Indeed, an important focus of this work is related to heteroscedasticity, which is its differential part w.r.t. existing literature. However, this phenomenon is not highlighted in the analysis. For example, in Thr 4.5, the authors retrieve a bound in which such a phenomenon is not highlighted, and the result presented is already present in the literature. Furthermore, the result presented is known for a setting that is simpler than the one presented in this paper, so it holds in this scenario. See weaknesses.",
         "196",
         "0",
         "2",
         "0.6975",
         "0.12310606060000001",
         "0.9069638848",
         "49",
         "7",
         "44.575",
         "10.52",
         "13.763300000000001",
         "13.141",
         "10.3936",
         "0.0483",
         "102",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "moderate",
         "4.0",
         "4",
         "3",
         "4",
         "5.0",
         "3.0",
         "4.0",
         "partially factual",
         "65.0",
         "65.0",
         "neutral",
         "neutral"
        ],
        [
         "8",
         "zmV50sislh",
         "6748",
         "1695437867951",
         "['~Qian_Chen10', '~Tianjian_Zhang1', '~Linxin_Yang1', '~Qingyu_Han2', '~Akang_Wang1', '~Ruoyu_Sun1', '~Xiaodong_Luo2', '~Tsung-Hui_Chang1']",
         "A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs",
         "Recently, machine learning techniques have been widely utilized for solving mixed-integer linear programs (MILPs). Notably, learning-based approaches that encode MILPs as bipartite graphs and then leverage graph neural networks (GNNs) to identify high-quality solutions have shown remarkable potential. Symmetry as an intrinsic property of many MILPs leads to multiple equivalent solutions, which incurs noticeable computational challenges and hence is treated with care in classic optimization algorithms. However, to the best of our knowledge, none of the learning-based methods take special care of symmetry within MILPs such that their computational performance might be jeopardized. To mitigate this issue, we propose a symmetry-aware learning approach that includes (i) position embeddings as node features to differentiate interchangeable variable nodes, and (ii) a novel loss function to alleviate ambiguity caused by equivalent solutions. We conduct extensive experiments on public datasets and the computational results demonstrate that our proposed approach significantly outperforms existing ones in both computational efficiency and solution quality.",
         "Reviewer_9XGv",
         "1698659346752",
         "1699636777123",
         "5",
         "4",
         "2",
         "3",
         "2",
         "This paper focuses on two issues---indistinguishable variable nodes and label ambiguity---in using GNNs to solve MILPs with symmetries.\nIt proposes to use position embeddings and designs a symmetry-aware loss to alleviate the aforementioned two issues, respectively.\nExperiments on four datasets demonstrate the effectiveness of the proposed method in terms of computational efficiency and solution quality. 1.\tThis paper is easy to follow. It’s worth mentioning that it formulates the issues in using GNNs to solve MILPs with symmetries clearly.\n2.\tThe proposed methods are simple yet effective. They can be combined with a series of GNN based approaches to improve their performance.\n3.\tExperiments on four benchmark datasets, as well as the extensive ablation studies, demonstrate the effectiveness of position embeddings and the symmetry-aware loss. 1.\tThe authors may want to provide more discussions on some related works.\n\n\ta) The authors mention that \\[1\\] and \\[2\\] “try to tackle the label ambiguity drawback by learning conditional distribution” (Section 2). Then, they claim that it “is not symmetry-aware” (Paragraph Baselines, Section 5.1). However, more explanations are necessary.\n\n\tb) The authors claim that “the random features used in \\[2\\] may cause severe generalization issue” (Section 2). They may want to conduct experiments to support this claim and to demonstrate the superiority of position embeddings over random features.\n\n\tc) The authors claim that “none of the existing learning-based approaches take special care of symmetry handling” (Section 2). However, these approaches identified the symmetry issues and proposed some tricks to deal with these issues. The authors may want to further explain what they mean by “take special care of symmetry handling”.\n\n\td) Since “works from mathematical perspectives suggest symmetry-handling algorithms” (Section 2), the authors may want to provide more details about the relationship between this work and those works from mathematical perspectives.\n\n2.\tThe position embedding technique, which is one of the core contributions of this paper, has been implemented in the code of \\[3\\] to tackle the strong symmetry.\nhttps://github.com/sribdcn/Predict-and-Search_MILP_method/blob/main/PredictAndSearch_GRB.py#L47.\nTherefore, the technical contribution is minor.\n3.\tThe symmetry-aware loss involves using Hungarian Algorithm to solve Problem (9), whose time complexity is $O(n^3)$. This may lead to a high training cost. Therefore, the authors may want to report the running time.\n4.\tThe authors may want to report the standard deviation of the results in Table 1.\n5.\tSome of the references, such as \\[2\\] and \\[3\\], are in the wrong form.\n\n\\[1\\] Vinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid Von Glehn, Pawel Lichocki, Ivan Lobov, Brendan O’Donoghue, Nicolas Sonnerat, Christian Tjandraatmadja, Pengming Wang, et al. Solving mixed-integer programs using neural networks. arXiv preprint arXiv:2012.13349, 2020.\n\n\\[2\\] Ziang Chen, Jialin Liu, Xinshang Wang, and Wotao Yin. On representing mixed-integer linear programs by graph neural networks. In The Eleventh International Conference on Learning Representations, 2023.\n\n\\[3\\] Qingyu Han, Linxin Yang, Qian Chen, Xiang Zhou, Dong Zhang, Akang Wang, Ruoyu Sun, and Xiaodong Luo. A gnn-guided predict-and-search framework for mixed-integer linear programming. In The Eleventh International Conference on Learning Representations, 2023. 1.\tWhy are the results of BKS, Gurobi and PS on the datasets WA and IP different from those reported in \\[3\\]?\n2.\tIt seems that with the position embedding, the permutation invariance does not hold any more. For example, if we exchange the positions of two different columns, we will obtain different graph embeddings as they will have invariant node features while variant position embeddings. Is that the case?\n3.\tHow to calculate $\\Phi$ for a given dataset?\n4.\tSince $\\Phi$ indicates the number of possible equivalent solutions, it measures the extend of the issue of label ambiguity. Is there any metric to measure the extend of the issue of indistinguishable variable nodes?",
         "610",
         "11",
         "16",
         "0.7926000000000001",
         "0.0799570106",
         "0.8030416369000001",
         "48",
         "11",
         "42.0889",
         "11.0849",
         "13.9512",
         "13.223",
         "13.0027",
         "0.0709",
         "78",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "5",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "3",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "9",
         "zmV50sislh",
         "6748",
         "1695437867951",
         "['~Qian_Chen10', '~Tianjian_Zhang1', '~Linxin_Yang1', '~Qingyu_Han2', '~Akang_Wang1', '~Ruoyu_Sun1', '~Xiaodong_Luo2', '~Tsung-Hui_Chang1']",
         "A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs",
         "Recently, machine learning techniques have been widely utilized for solving mixed-integer linear programs (MILPs). Notably, learning-based approaches that encode MILPs as bipartite graphs and then leverage graph neural networks (GNNs) to identify high-quality solutions have shown remarkable potential. Symmetry as an intrinsic property of many MILPs leads to multiple equivalent solutions, which incurs noticeable computational challenges and hence is treated with care in classic optimization algorithms. However, to the best of our knowledge, none of the learning-based methods take special care of symmetry within MILPs such that their computational performance might be jeopardized. To mitigate this issue, we propose a symmetry-aware learning approach that includes (i) position embeddings as node features to differentiate interchangeable variable nodes, and (ii) a novel loss function to alleviate ambiguity caused by equivalent solutions. We conduct extensive experiments on public datasets and the computational results demonstrate that our proposed approach significantly outperforms existing ones in both computational efficiency and solution quality.",
         "Reviewer_MwS2",
         "1698687887527",
         "1699636777000",
         "3",
         "3",
         "2",
         "2",
         "2",
         "The paper “ A symmetry -aware Learning Approach for solving Mixed-Integer Linear programs'' discusses  how to solve mixed-integer linear programs (MILPs), while taking into account the symmetry that may exist between variables leading to multiple optimal solutions.  It highlights the issue that MILPs often have symmetry, resulting in multiple equivalent solutions and causing challenges for traditional optimization methods. While machine learning-based approaches using graph neural networks (GNNs) have shown promise in solving MILPs, they haven't addressed the issue of symmetry. To tackle this problem, the paper proposes a \"symmetry-aware\" learning approach that incorporates position embeddings to distinguish interchangeable variables and introduces a novel loss function to handle the ambiguity caused by equivalent solutions. The authors conducted experiments on public datasets and found that their approach outperforms existing methods in terms of computational efficiency and solution quality. MILP has been used in various capacities in optimization aspects of ML and  recently, with the development of GNN, MILP can be solved as GNNs and this enables use of MILPs as a plug in module in many different deep learning models. In this respect, the paper studies a relevant problem. The premise of the paper is based on the weak assumption that symmetry incurs noticeable computational costs. This is not clearly demonstrated in the paper.\nThe improvements proposed by the paper, are not justified as sound theoretical choices. The position embedding seems to add  additional features(why necessarily this way) whereas the symmetry aware loss minimizes distortion to another permutation of the input. What it means in terms of optimization is not clear maybe a simple example of how this helps will illustrate the point better.\nExperimental results are ok, but does not backup the main premise of the the paper that symmetry is significant cost on computational resources. NA",
         "296",
         "0",
         "1",
         "0.8198000000000001",
         "0.1106666667",
         "0.957783103",
         "48",
         "10",
         "24.3528",
         "15.5",
         "19.1108",
         "16.9418",
         "16.7759",
         "0.0354",
         "88",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "3",
         "4",
         "5.0",
         "3.0",
         "5.0",
         "partially factual",
         "65.0",
         "65.0",
         "neutral",
         "polite"
        ],
        [
         "10",
         "zmV50sislh",
         "6748",
         "1695437867951",
         "['~Qian_Chen10', '~Tianjian_Zhang1', '~Linxin_Yang1', '~Qingyu_Han2', '~Akang_Wang1', '~Ruoyu_Sun1', '~Xiaodong_Luo2', '~Tsung-Hui_Chang1']",
         "A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs",
         "Recently, machine learning techniques have been widely utilized for solving mixed-integer linear programs (MILPs). Notably, learning-based approaches that encode MILPs as bipartite graphs and then leverage graph neural networks (GNNs) to identify high-quality solutions have shown remarkable potential. Symmetry as an intrinsic property of many MILPs leads to multiple equivalent solutions, which incurs noticeable computational challenges and hence is treated with care in classic optimization algorithms. However, to the best of our knowledge, none of the learning-based methods take special care of symmetry within MILPs such that their computational performance might be jeopardized. To mitigate this issue, we propose a symmetry-aware learning approach that includes (i) position embeddings as node features to differentiate interchangeable variable nodes, and (ii) a novel loss function to alleviate ambiguity caused by equivalent solutions. We conduct extensive experiments on public datasets and the computational results demonstrate that our proposed approach significantly outperforms existing ones in both computational efficiency and solution quality.",
         "Reviewer_7CFb",
         "1698695520566",
         "1699636776805",
         "3",
         "3",
         "3",
         "2",
         "1",
         "The paper introduces a neural network MIP solver that is designed to handle symmetry in binary linear programming. The solver predicts initial solutions for MILP using neural networks. The authors highlight the significance of handling variable symmetry and suggest addressing this challenge through positional embedding and a custom-designed loss function. Experimental results show that this approach is superior to other neural solvers and the default Gurobi configuration. * The paper is written in a clear and easy to understand manner.\n* While the traditional optimization community has widely recognized the symmetry of variables, it has not been studied as much with neural networks. The authors provide valuable insights into the field of neural MILP solving, and their efforts should be greatly appreciated. - My primary concern is that this paper represents incremental work compared to a paper published in ICLR 2023 by Han et al., titled \"A GNN-Guided Predict-and-Search Framework for Mixed-Integer Linear Programming.\"\n  - The paper by Han et al. is cited and compared as a significant baseline in this paper. Both papers follow a similar process: a neural network predicts an initial solution, certain digits with higher confidence are fixed and treated as new constraints, and finally, Gurobi is used to solve the modified problem with additional constraints. The only technical addition in this paper appears to be the inclusion of positional embeddings in nodes.\n  - What makes this paper seem more incremental is my observation that positional embeddings are already implemented in the code accompanying Han et al. (ICLR 2023): \\[github link\\](https://github.com/sribdcn/Predict-and-Search_MILP_method/blob/b45ded73d261ef912ebb56934607d6424a88b387/PredictAndSearch_GRB.py#L48). My point is that publishing a new paper at a top ML conference by employing a technique that has already proven effective in a previous paper, without providing valuable insights, is questionable.\n  - The experimental improvement compared to Han et al. (ICLR 2023) also seems incremental in Table 1.\n- The authors might argue for the importance of symmetry in solving MIP, which I agree with. However, as an ICLR paper, it requires stronger motivation. \n  - An excellent example can be found in another paper published at ICLR 2023, where the breaking of symmetry is explored: Chen et al.'s \"On Representing Mixed-Integer Linear Programs by Graph Neural Networks.\" Chen et al. offer theoretical insights into solving symmetric MIPs using graph neural networks. They discovered that symmetry is a theoretical bottleneck of GNNs when solving MIPs, and then proposed to break symmetry by introducing random noise. \n  - It's worth noting that when breaking the symmetry of MIPs, positional embeddings and random noise are two sides of the same coin. The underlying technical motivation is to assign the symmetric nodes different features. Also, positional embeddings are random features concatenated to nodes, because positional embeddings are not permutation-invariant. If we randomly permute the nodes, the positional embeddings also change randomly. * Seeing that Han et al. (ICLR 2023) have already implemented positional embedding, can the authors explain where the performance improvement comes from?\n* Can the authors distinguish this paper, technically, from Han et al. (ICLR 2023)?",
         "499",
         "1",
         "3",
         "0.8001",
         "0.0524685632",
         "0.876499176",
         "48",
         "10",
         "34.4649",
         "12.2407",
         "14.5426",
         "13.8643",
         "13.294",
         "0.1932",
         "105",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "none",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "11",
         "zmV50sislh",
         "6748",
         "1695437867951",
         "['~Qian_Chen10', '~Tianjian_Zhang1', '~Linxin_Yang1', '~Qingyu_Han2', '~Akang_Wang1', '~Ruoyu_Sun1', '~Xiaodong_Luo2', '~Tsung-Hui_Chang1']",
         "A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs",
         "Recently, machine learning techniques have been widely utilized for solving mixed-integer linear programs (MILPs). Notably, learning-based approaches that encode MILPs as bipartite graphs and then leverage graph neural networks (GNNs) to identify high-quality solutions have shown remarkable potential. Symmetry as an intrinsic property of many MILPs leads to multiple equivalent solutions, which incurs noticeable computational challenges and hence is treated with care in classic optimization algorithms. However, to the best of our knowledge, none of the learning-based methods take special care of symmetry within MILPs such that their computational performance might be jeopardized. To mitigate this issue, we propose a symmetry-aware learning approach that includes (i) position embeddings as node features to differentiate interchangeable variable nodes, and (ii) a novel loss function to alleviate ambiguity caused by equivalent solutions. We conduct extensive experiments on public datasets and the computational results demonstrate that our proposed approach significantly outperforms existing ones in both computational efficiency and solution quality.",
         "Reviewer_Vpp5",
         "1699044161972",
         "1699636776523",
         "3",
         "4",
         "3",
         "3",
         "2",
         "This paper studies GNNs for solving MILPs and considers the symmetric properties of MILPs (i.e., switching some variables does not essentially change the problem). The proposed methods include: 1) adding additional features (positional embedding) to differentiate variables that are symmetric; 2) defining the loss function for an orbit of the symmetry group, not just a point. The approach is tested on two datasets and compared with other methods. Some numerical advantages are reported by the authors. Symmetry is an important property in MILPs but is rarely considered in GNN-based methods for solving MILPs. It is good to introduce this topic to the community. The writing is clear. The ideas of adding differentiable features and using orbit loss (or symmetry-aware loss) make sense (they are standard in handling symmetry and have been used in other problems). The numerical results show that the approach is promising. 1. This paper only considers one very special type of symmetry group (a binary matrix and the symmetry group is the the permutation group on the columns). In general, the exact symmetry group of a MILP problem, and hence the symmetry-aware loss, may be very expensive to compute, which makes the proposed method in some sense impractical. I would suggest investigating algorithms based on only partial information about the symmetry group (e.g. the output of the Weisfeiler-Lehman test/color refinement).\n2. Line 6 in Algorithm 1 is expensive to implement, especially when the symmetric group is large. I think the authors should discuss how to solve this subproblem (probably approximately) fast, instead of just saying \"can be solved in parallel\". \n3. Positional embedding (or the related random feature technique) has frequently appeared in the previous literature, which makes the contribution of this paper in some sense incremental. None.",
         "291",
         "0",
         "4",
         "0.7831",
         "0.0324761905",
         "0.872069478",
         "48",
         "6",
         "43.2276",
         "11.4824",
         "15.2319",
         "14.1265",
         "12.702",
         "0.1695",
         "90",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "12",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_wKPf",
         "1697902750791",
         "1699637014797",
         "5",
         "3",
         "4",
         "1",
         "2",
         "The authors proposed a novel embedding method to represent data points that have partial order relation. The author's idea is to map those data points to bit sequences, where the inequality of the values of two sequences corresponding to the original partial order relation. 1. The original idea of using bit sequences is novel as far as I know, simple, easy to understand, and intuitive to some extent.\n1. The authors successfully associate the proposed method with the existing order embedding, which helps the authors' understanding.\n1. The algorithm's explanation also maintains some intuition.\n1. The algorithm has strong advantage on the space computational complexity.\n1. Overall, the technical parts of the paper are well-written. Overall, the presentation of the paper needs essential refinement. The current version's presentation degrades the paper's quality although the research idea itself is nice and impressing to me.\n\n1. From the introduction, the ultimate motivation of the work is not very clear. For continuous space embedding case, we could use them for visualization or we could input the representations to another machine learning architecture, such as neural network. However, we have no clear idea how we can use the obtained binary embedding in applications. If we just want to do link prediction or reconstruction, we do not need to stick to embedding-based methods.\n\n1. As a starting motivation of the research, the paper criticizes hyperbolic embedding, pointing out that \"learning in hyperbolic space is challenging because optimization algorithms, like gradient descent and its variants, are not well studied for hyperbolic space.\" Indeed, the gradient descent methods on hyperbolic space have been well-studied theoretically, e.g., \\[A-E\\]. Although the convergence to the global optimum cannot be guaranteed, as not in Euclidean space, but they are not by far worse than the author's theoretical guarantee on the proposed algorithm. The author mentioned that the problem is a NP-complete problem as a decision problem, but it is not a practically positive result unless P=NP. In this sense, the current draft gives readers impression that the author has not solved the original motivation. If it is difficult to provide a theoretical guarantee of the proposed algorithm, the author should criticize the hyperbolic embedding in another way. \n\n1. This item is about another important motivation of the paper, \"logical operation.\" The explanation regarding the logical operation on the binary representations does not seem correct. The logical \"not\" operator does not seem to work like the semantic \"not.\" Assume that \"living thing\" is \\[0, 0\\], \"cat\" is \\[0, 1\\], and \"dog\" is \\[1, 0\\]. This does not self-contradict since a cat is a living thing and a dog is a living thing, too. Let's apply the logical \"not\" to the living thing. According to your explanation, \"not living thing\" is \\[1, 1\\]. Now, according to the rule, we conclude that \"a not living thing is a cat\", and \"a not living thing is a dog.\" This is obviously wrong. Hence, the proposed boolean representations are not intuitive as the authors claim.\n\n1. Citation does not include which year it is published, which makes it extremely difficult to see the flow of the existing methods.\n\n1. The page limitation is violated.\n\n1. As I discuss in the Questions section, the advantages of the proposed methods do not seem completely stated in the current draft.\n\n\\[A\\] Zhang, Hongyi, and Suvrit Sra. \"First-order methods for geodesically convex optimization.\" In Conference on Learning Theory, pp. 1617-1638. PMLR, 2016.\n\n\\[B\\] Zhang, Hongyi, Sashank J Reddi, and Suvrit Sra. \"Riemannian SVRG: Fast stochastic optimization on Riemannian manifolds.\" Advances in Neural Information Processing Systems 29 (2016).\n\n\\[C\\] Liu, Yuanyuan, Fanhua Shang, James Cheng, Hong Cheng, and Licheng Jiao. \"Accelerated first-order methods for geodesically convex optimization on Riemannian manifolds.\" Advances in Neural Information Processing Systems 30 (2017).\n\n\\[D\\] Zhou, Pan, Xiao-Tong Yuan, and Jiashi Feng. \"Faster first-order methods for stochastic non-convex optimization on Riemannian manifolds.\" In The 22nd International Conference on Artificial Intelligence and Statistics, pp. 138-147. PMLR, 2019.\n\n\\[E\\] Bécigneul, Gary, and Octavian-Eugen Ganea. \"Riemannian adaptive optimization methods.\" ICLR 2019. - Why did you not show the memory (RAM) to store the representation in the numerical experiments? I thought you could emphasize the advantage of the proposed method clearer this way, since the proposed method's type is boolean, and existing method's types are float or double.\n- Why did you not show the order of time complexity of the proposed algorithm? If I understand it correctly, each step's time and space complexity is linear to the dimension, which seems to be an advantage of the proposed algorithm.",
         "758",
         "6",
         "18",
         "0.7241000000000001",
         "0.09107399690000001",
         "0.8398560286000001",
         "47",
         "20",
         "43.4382",
         "10.9568",
         "14.5665",
         "13.7247",
         "11.6684",
         "0.2889",
         "99",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "75.0",
         "75.0",
         "neutral",
         "polite"
        ],
        [
         "13",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_EAos",
         "1698496730611",
         "1699637014689",
         "6",
         "4",
         "3",
         "4",
         "3",
         "The paper introduces a novel approach, BINDER, for order embedding using binary vectors. BINDER aims to represent concepts with hypernym-hyponym relationships in a binary vector space, allowing for embeddings of both seen and unseen concepts. Experimental results demonstrate BINDER's superiority over existing order embedding methodologies. 1) Conceptual Simplicity: BINDER offers a novel and conceptually simple approach to hierarchical representation learning by using binary vectors. This simplicity is an advantage because it makes the method more interpretable and easier to understand compared to complex, black-box models.\n\n2) Strong Performance in Reconstruction Task: BINDER consistently demonstrates excellent performance in the reconstruction task. This indicates its robust ability to learn embeddings that satisfy order constraints, which is a critical aspect of hierarchical representation learning.\n\n3) Transitive Closure: BINDER's ability to predict hypernymy relations without relying heavily on transitive closure in the training data is a significant strength. This property suggests that the model can generalize effectively to unseen concepts and is not overly dependent on the availability of transitive edges.\n\n4) Originality of Approach: BINDER introduces a unique approach to order embedding using binary vectors. This originality stems from its different perspective on hierarchical representation learning and adds to the diversity of methods in this field.\n\n5) Potential for Extensions: The paper hints at possible extensions, such as incorporating node similarity expressions and considering sibling similarity. These extensions have the potential to enhance BINDER's capabilities and could pave the way for future research. 1) Generalization to Unseen Concepts: While BINDER claims to generate embeddings for unseen concepts by using logical functions over existing concepts, it would be beneficial to provide more detailed explanations and examples of how this generalization is achieved. A concrete illustration of how BINDER generates embeddings for unseen concepts could strengthen the paper.\n\n2) Experimental Rigor: The paper mentions that BINDER is a randomized algorithm but provides results from the best run out of five. It would be helpful to include more detailed information on the variability observed in these runs, such as mean and standard deviation. A discussion of the algorithm's sensitivity to random initialization would also be insightful.\n\n3) Hyperparameter Sensitivity: The paper discusses hyperparameters like the learning rate and bias but does not delve into their sensitivity analysis. A study on how these hyperparameters affect BINDER's performance and convergence would provide a better understanding of its behavior.\n\n4) Comparative Discussion: While BINDER's strengths are well-discussed, it would be beneficial to have a comparative discussion with competing methods, highlighting where BINDER outperforms them in more depth. This would provide additional context for readers.\n\n5) The complexity. It seems that the model requires very high dimensionalty but there is no such discussion. The worst case is that the concepts are fully disjoint, then you need N dimension, which makes the model not scalable. 1) Why does the accuracy (acc) decrease when the number of transitive edges increases? How can this phenomenon be explained?\n\n2) In equation (1), you specify that a $\\neq$ b, meaning when a = b, it should be considered a negative example. However, in Section 2.3, the negative pairs (n) involving reflexivity constraints, where a is-a a, are excluded. Does this mean that reflexivity constraints are neither treated as positive nor negative examples? I understand that in the experiments and method, you've avoided dealing with the self-relation, but in practice, it might occur. How do you plan to handle cases where the reflexivity constraint is present?\n\n3) In Section 2.3 (Training Algorithm), it might enhance clarity and conciseness by describing the sampling process as selecting $r$ from $W \\setminus \\{a, b\\}$. This would align well with the earlier statement that the number of negative examples is $n^2 - n - |P|$.\n\n4) In Table 3 (Reconstruction Results Acc(\\%) (dim)) and similar cases, what is the purpose of including \"(dim)\" in the table header?\n\n5) One notable advantage of BINDER is its ability to generate embeddings for unseen concepts using logical functions over existing concepts, a feature not present in its competitors.\n\n6) Could the finite permutation space of binary vectors result in a loss of expressivity, limiting the model's ability to capture complex relationships?",
         "688",
         "0",
         "1",
         "0.8389000000000001",
         "0.1037961973",
         "0.9189862013000001",
         "47",
         "13",
         "26.4766",
         "13.9298",
         "17.1862",
         "15.3679",
         "14.5235",
         "0.195",
         "78",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "moderate",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "95.0",
         "95.0",
         "neutral",
         "polite"
        ],
        [
         "14",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_JqKj",
         "1698792625602",
         "1699637014554",
         "3",
         "4",
         "2",
         "2",
         "3",
         "This work proposes BINDER, an approach for order-based representation. BINDER uses binary bits as representation vectors, via a scalable optimization procedure. Authors evaluate experiments on both prediction and reconstruction tasks. Overall, the paper is well-organized, and the authors provide a detailed description of their contributions. 1. The Introduction section is also missing an important recent work on two-view knowledge graph embeddings, which jointly embed both the ontological and instance view spaces: \n\\[KDD 2022\\] Dual-Geometric Space Embedding Model for Two-View Knowledge Graphs. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22). Association for Computing Machinery, New York, NY, USA, 676–686. https://doi.org/10.1145/3534678.3539350\n\n2. It would be helpful if the authors could create an illustration of an example knowledge graph following their problem formulation. \n\n3. Further, the model fails to include important baseline models such as standard knowledge graph embedding model in the hyperbolic space e.g., RefH/RotH/AttH, hyperbolic GCN (HGCN), and the product space (M2GNN). \n\n4. Moreover, the size of the datasets also seem to be relatively small-scale with number of nodes and edges on the scale of thousands as opposed to million node/billion edge graphs indicative of real world KGs e.g., DBPedia & YAGO. Why is only the hyperbolic space being considered? Entities can form cyclic relations as well, which is better modeled in the spherical space.  Perhaps the authors need to more clearly denote the distinction between entities and concepts.",
         "236",
         "1",
         "4",
         "0.8234",
         "0.062440191400000004",
         "0.8767731190000001",
         "47",
         "9",
         "37.8775",
         "12.1462",
         "14.7143",
         "14.0326",
         "14.6042",
         "0.07200000000000001",
         "80",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "none",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "95.0",
         "95.0",
         "neutral",
         "polite"
        ],
        [
         "15",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_VtjX",
         "1699042810956",
         "1699637014430",
         "1",
         "5",
         "3",
         "3",
         "1",
         "In this work the authors develop a method for creating bit-vector representations of entities such that an order relation on bit-vectors captures some hierarchical structure. More specifically, the authors focus on representing hypernym ($\\texttt{is-a}$) relationships between entities. For a given set of entities $W$ and some set of $\\texttt{is-a}$ relationships expressed as pairs $P \\subseteq W \\times W$, the authors propose to represent each entity $a \\in W$ by a bit-vector $\\mathbf a \\in \\\\{0,1\\\\}^d$ for some $d$, such that\n\n$$\\mathbf b_j = 1 \\implies \\mathbf a_j = 1 \\quad \\iff \\quad (a,b) \\in P \\setminus \\Delta_W,$$\n\nwhere $\\Delta_W = \\\\{(a,a) \\mid a \\in W\\\\}$ is the identity relation on $W$.\n\nThe authors formulate a loss function for a bit-vector representation of entities which is a linear combination of a \"positive loss\", which counts the number of times $(a,b) \\in P$ and $a\\ne b$, but there is some $j$ for which $\\mathbf b_j = 1$ and $\\mathbf a_j = 0$, and a \"negative loss\", which counts the number of times $(a,b) \\in N \\subseteq W \\times W \\setminus (P \\cup \\Delta_W)$ are such that $\\mathbf b_j = 1 \\implies \\mathbf a_j = 1$. Since the representation is discrete we cannot take gradients of this loss function, so the authors propose an algorithm which randomly flips bits with a probability which is correlated with the amount of improvement in the loss function as a consequence of flipping that bit.\n\nThey evaluate their model on 5 hypernym datasets. They evaluate in both a reconstruction setting as well as a setting where edges from the transitive closure are removed during training and expected to be recovered during evaluation. They claim their model generally outperforms  baselines including order embeddings, Poincare embeddings, and hyperbolic entailment cones. The authors do an admirable job presenting the background and motivation for this work. Their proposed model is explained clearly, and the randomized algorithm they propose is somewhat novel. Unfortunately, there a many fundamental problems with this work.\n\nFirst, it is unclear to me what problem or task the proposed model is actually solving. What do we gain by representing entities with bit vectors capturing their hypernym relationships? In general, the motivation to embed entities in this setting is one of the following:\n1. Space Efficiency: The new representation requires fewer bits to store than some naive approach (eg. adjacency list of the transitive reduction)\n2. Computational Efficiency: There is some operation which can be performed on the embedded representation more efficiently than on some other representation\n3. Generalization: The embedding allows one to infer missing edges between existing nodes or make predictions of graph edges from unseen nodes (based on input node features)\n4. Transference to Other Tasks: The embedding captures the graph relationships which can then be plugged into other architectures for use in tasks which benefit from the knowledge of the graph structure (eg. MLP for classification)\n\nThe authors discuss space efficiency in Appendix F.3, however comparisons here are only made to other baselines, and the numbers quoted are far and above what would be required (eg. the authors claim that baselines with more than 100 dimensions take more than 10 hours to run, but this is far longer than the numbers reported in \\[0\\] and my personal experience suggests, where it is possible to train a model to represent WordNet reasonably well in 10-20 minutes). Comparing bit vectors to floating point models which were not quantized is disingenuous at best. The authors do claim their embedding is useful for is generalization, however the evaluation performed only assesses generalization to the transitive closure, which is trivial to perform symbolically on the set $P$ which would result in perfect accuracy on this evaluation. There are also issues with this evaluation separately, which are addressed below, but fundamentally this task is not truly a test of generalization in any useful sense.\n\nThe authors do claim that Binder embeddings have some unique capabilities unavailable to other models. Specifically, they claim that Binder embeddings have a well-defined complement, union, or intersection, however this is not true, or at least not any more true here than in any other embedding method. The authors even state that if \"we have a concept 'living-thing' for which we have a binary vector representation, \\[...\\] if we want to obtain a representation for 'not living things' we can obtain that simply by reversing the bits of the 'living thing' vector', however this is not true. To see this, consider a \"living thing\" vector as $\\[0,1,1\\]$, then based on the authors' embedding definition the set of living things is $\\{\\[0,1,1\\],\\[1,1,1\\]\\}$. By their claim, the representation of \"not living thing\" should therefore be $\\[1,0,0\\]$. This would mean that the set of living things includes the bit vectors $\\\\{\\[0,1,1\\],\\[1,1,1\\]\\\\}$ and the set of not living things is $\\\\{\\[1,0,0\\],\\[1,1,0\\],\\[1,0,1\\],\\[1,1,1\\]\\\\}$. Note that this means that the bit vector $\\[1,1,1\\]$ is both living and not living. Moreover, it also means the space is not decomposed into just \"living thing\" and \"not living thing\" - for example, the vector $\\[0,1,0\\]$ is neither living or not living. Therefore this definition of complement is not correct. Not only that, there is *no* bit vector which captures the full complement of being a living thing, because to not be a living thing, according to their definition, we simply need to have a zero in the first or second position, and there is no way to express this \"or\" condition with a single vector. A similar argument shows Binder embeddings are not closed under union.\n\nSecondly, even if there is some benefit to representing entities by bit-vectors, it is straightforward to provide a deterministic algorithm which takes a set $P$ and produces a bit-vector embedding which perfectly satisfies the constraint above using a topological sort. With some additional care in the construction process, it even seems possible to create a bit-vector with minimal size which perfectly satisfies the constraint. Therefore, the use of a randomized algorithm here does not seem to have any benefit.\n\nThirdly, there are a number of problems with the experiments. For some reason, the authors chose to report a reweighted accuracy statistic as opposed to the more conventional F1 metric when dealing with data imbalances. In addition, the authors evaluate on a test set with negatives which were created by random perturbation, however this approach can lead to a very coarse evaluation, and has issues with test set bias. For the test set accompanying Order Embeddings paper, for example, you can get almost 0.90 F1 by simply treating any node in the training data which has a child as though it is a parent to every other node in the training set. It was for this reason that more comprehensive evaluations advocate for using the full adjacency matrix \\[0\\]. In addition, the other models present in that paper all serve as reasonable baselines, and the \\[associated code\\](https://github.com/iesl/geometric-graph-embedding) has implementations readily available.\n\nFinally, a number of the characterizations or claims made in the introduction are incorrect. The authors claim optimization algorithms are not well studied for hyperbolic space, however this is not the case - Riemannian gradient descent is well understood (\\[1\\], \\[2\\], \\[3\\]). Moreover, there are approaches to parameterizing and training on hyperbolic space which have been shown empirically to work well with standard gradient descent techniques such as SGD or Adam \\[4\\]. The authors claim box embeddings have more degrees of freedom than point embeddings, but this is not true - a box embedding in $d$-dimensional space does have $2d$ parameters per box, but it is for this reason that experiments using box embeddings compare $d$-dimensional boxes to $2d$-dimensional vectors, so they have exactly the same number of free parameters. The claim that bit vectors are more interpretable is not supported by any experiments, and there is no clear reason to expect that the randomized algorithm leads to interpretable properties in each dimension. The interpretability hinted at for the bit vectors is equivalent to the level of interpretability that order, probabilistic order, or box embeddings provide.\n\n\\[0\\] Boratko, Michael, et al. \"Capacity and bias of learned geometric embeddings for directed graphs.\" Advances in Neural Information Processing Systems 34 (2021): 16423-16436.\n\\[1\\] Bonnabel, Silvere. \"Stochastic gradient descent on Riemannian manifolds.\" IEEE Transactions on Automatic Control 58.9 (2013): 2217-2229.\n\\[2\\] Bécigneul, Gary, and Octavian-Eugen Ganea. \"Riemannian adaptive optimization methods.\" arXiv preprint arXiv:1810.00760 (2018).\n\\[3\\] Hu, Jiang, et al. \"A brief introduction to manifold optimization.\" Journal of the Operations Research Society of China 8 (2020): 199-248.\n\\[4\\] Law, Marc, et al. \"Lorentzian distance learning for hyperbolic representations.\" International Conference on Machine Learning. PMLR, 2019. The section on the weaknesses highlights my concerns with this work. \n\n1. Can you clarify the specific problem or task that your proposed model is designed to solve? How does the use of bit vectors capturing hypernym relationships contribute to solving this problem?\n\n2. Regarding space efficiency, how does the bit vector representation compare to a sparse adjacency list? If it is not more compact, does it offer any benefits beyond the sparse adjacency list?\n\n3. In terms of generalization, the current evaluation focus on the transitive closure. When training on this data in the 0% case, does your negative set include edges from the transitive closure? Regardless, if we know the relation is transitive, what benefit do we gain by training on the transitive reduction and being able to \"generalize\" to the transitive closure which is not also achievable by simply taking the transitive closure of the training data?\n\n4. You mention unique capabilities of Binder embeddings, such as well-defined complement, union, or intersection operations. Given the issues highlighted with these operations, how do you respond to the concerns about the correctness of these claims?\n\n5. Could you elaborate on why a randomized algorithm is used for generating bit-vector embeddings when a deterministic algorithm could suffice?\n\n6. Why was a reweighted accuracy statistic chosen over the conventional F1 metric in your experiments, especially in the context of data imbalances?\n\n7. Please correct or respond to my assertions above regarding the inaccuracies in characterizing other baselines. (For example, the assertion that optimization algorithms in hyperbolic space are not well-studied,  or that box embeddings have more degrees of freedom than point embeddings.) After correcting these claims, please address what specific benefits this embedding provides beyond those provided by the baselines.\n\n8. The interpretability of bit vectors is claimed to be superior in your paper. Can you provide empirical evidence or a theoretical framework that supports this claim, in a setting where equivalent effort is also given to order, probabilistic order, or box embeddings?\n\n9. Would you consider evaluating the representational capacity of your model on the full adjacency matrix? This may be computationally prohibitive; if so, it is reasonable to select a subgraph (eg. Animal subgraph from WordNet) and evaluate the full adjacency matrix on that subgraph.\n\n---\n\nI apologize if my review seems harsh. I would like to commend the authors for the clear and structured presentation of their approach. The manuscript is well-written, and the methodology is articulated with a level of detail that reflects a thorough understanding of the subject matter. It is evident that considerable effort has gone into developing and describing the proposed model.\n\nOne of the main challenges in this area of research seems to be a legacy of ambiguity in motivations and intentions from previous works, like a bad game of \"telephone\". Previous evaluations designed to highlight specific aspects of a model may be misconstrued to be a task in and of themselves, and this problem can compound on itself in subsequent work. It is also possible that I misunderstood the author's motivations and approach, and if so then I humbly apologize and ask the authors to clarify things for me.",
         "1957",
         "28",
         "16",
         "0.7801",
         "0.0865779046",
         "0.8620133996",
         "47",
         "6",
         "39.3787",
         "12.7481",
         "15.7533",
         "14.598700000000001",
         "13.9316",
         "0.8969",
         "74",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "none",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "100.0",
         "100.0",
         "neutral",
         "polite"
        ],
        [
         "16",
         "zkE2js9qRe",
         "8183",
         "1695499900639",
         "['~Croix_Gyurek1', '~Niloy_Talukder1', '~Mohammad_Hasan1']",
         "Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors",
         "For natural language understanding and generation, embedding concepts using an \norder-based representation is an essential task. Unlike traditional point vector based\nrepresentation, an order-based representation imposes geometric constraints on the\nrepresentation vectors for explicitly capturing various semantic relationships that may exist\nbetween a pair of concepts. In existing literature, several approaches on order-based \nembedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include, Order embedding, Poincar\\'e embedding on hyperbolic space, and Box embedding. \nEach of the above approaches suffers from some significant weaknesses. Order embedding\nfails to capture full spectrum of logical operations (such as, inverse, union)\non their embedding vectors, which are essential for deducing complementary or aggregated concepts. Box embedding overcomes this limitation by making the representation richer,\nbut along the process it sacrifices simplicity requiring custom-made optimization scheme \nfor learning the representation. Poincar\\'e embedding improves embedding quality by \nexploiting the ever-expanding property of hyperbolic space, but it also suffers from the\nsame fate as box embedding as gradient descent like optimization is not easy in the\nhyperbolic space. In this work, we propose BINDER, a novel approach for order-based \nrepresentation. BINDER uses binary bits as representation vectors.\nBINDER uses a simple, yet efficient algorithm for learning representation\nvectors in a fraction of time in comparison to existing order-based representation learning\nmethods. Our experimental results show that BINDER is very accurate, yielding better\nresults than the existing state-of-the-art methods for both prediction and reconstruction tasks.",
         "Reviewer_psGs",
         "1699176535017",
         "1699637014327",
         "3",
         "4",
         "2",
         "3",
         "2",
         "This paper proposes a method called Binder, which is a hierarchical concept representation method through order embedding of binary vectors. The paper explores the importance of order-based representation in natural language understanding and generation, and discusses the strengths and weaknesses of existing approaches. It also describes the geometric constraints imposed by order-based representation and how they capture semantic relationships between concepts. The paper concludes by discussing potential applications of Binder's approach to hierarchical concept representation in practical natural language processing tasks. 1. The paper proposes BINDER, a novel order embedding approach which embeds the entities at the vertex of a d-dimensional hypercube, which is simple, elegant, compact and explainable.\n\n2. The paper proposes an optimization algorithm for BINDER, which is simple, efficient, and effective, and can be seen as a proxy of gradient descent for the combinatorial space.\n\n3. The experimental results show that BINDER achieves great performance on link prediction and reconstruction tasks. 1. For reconstruction task, OE achieves better performance than BINDER with fewer dimension. Thus, BINDER does not show superiority over OE.\n2. BINDER may still suffer from the limitation of optimization, leading to inferior performance.\n3. It is better to report the mean results, rather than the best results. 1. You claim that “In BINDER’s embedding, an ‘1’ in some representation dimension denotes “having a latent property”. How to verify it through experiments?\n\n2. What are the differences between the proposed optimization method and randomized local search algorithm? What is the novelty of the proposed optimization method?\n\n3. How to ensure the convergence of the proposed optimization algorithms?\n\n4. Why BINDER is better than OE in WordNet Nouns dataset?\n\n5. How is the dimension (in parenthesis) in Table 3 set? Why is the dimension of OE smaller than that of BINDER?\n\n6. Can you provide the experimental results of box embedding?",
         "305",
         "0",
         "12",
         "0.7586",
         "0.2639705882",
         "0.9477813244000001",
         "47",
         "5",
         "31.3097",
         "12.6808",
         "15.9361",
         "14.1918",
         "13.1578",
         "0.1544",
         "95",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "unfactual",
         "75.0",
         "75.0",
         "neutral",
         "polite"
        ],
        [
         "17",
         "zdboax4dlK",
         "1381",
         "1695049614035",
         "['~Amirhossein_Farzam1', '~Allen_Tannenbaum2', '~Guillermo_Sapiro1']",
         "Ricci Curvature, Robustness, and Causal Inference on Networked Data",
         "In the complex landscape of networked data, understanding the causal effects of interventions is a critical challenge with implications across various domains. Graph Neural Networks (GNNs) have emerged as a powerful tool for capturing complex dependencies, yet the potential of geometric deep learning for GNN-based network causal inference remains underexplored. This work makes three key contributions to bridge this gap. First, we establish a theoretical connection between graph curvature and causal inference, revealing that negative curvatures pose challenges in identifying causal effects. Second, based on this theoretical insight, we present computational results using Ricci curvature to predict the reliability of causal effect estimations, empirically demonstrating that positive curvature regions yield more accurate estimations. Lastly, we propose a method using Ricci flow to improve treatment effect estimation on networked data, showing superior performance by reducing error through flattening the edges in the network. Our findings open new avenues for leveraging geometry in causal effect estimation, offering insights and tools that enhance the performance of GNNs in causal inference tasks.",
         "Reviewer_fMiq",
         "1698709496083",
         "1699636065930",
         "5",
         "4",
         "2",
         "2",
         "3",
         "The authors explore networked data via graph-neutral networks. Using graph Ricci curvature, they predicted the reliability of causal effect estimations on networked data. Their empirical findings confirmed that positive curvature regions yield more accurate results. The main review will take place in this section owing to the flow in which the review was conducted.\n\n### Abstract\n\n- The first sentence is interesting and whilst I know this is the abstract, it would be helpful to know _why_ the author(s) think it is critical challenge to understand the causal effect in networked data - who cares and why?\n\n\n### Introduction\n\n- What do you mean by \"the endogeneity\"  - this is a fairly non-standard way to use that way (at least to this reviewer, hence please do tell your usage of the term)\n- \"identifying causal effects is particularly challenging on a network of units with non-trivial dependencies\" - why is this? What gives rise to the difficulty?\n- A graphic may be helpful at the end of page one to illustrate the concepts that you discuss (e.g. graph curvature) for readers less familiar with this topic.\n\n\n### CAUSALITY, INVARIANCE, AND ROBUSTNESS\n\n- What is meant by \"unit\" in the first sentence of this paragraph?\n- Do you assume the presence of unobserved confounders? If so, please spell that out.\n- Why is your outcome denoted $\\mathbf{Y}$? That gives the impression that you are dealing with a multi-objective (more than one outcome) setting - are you? Perhaps best to spell out the domain of the features and the outcome(s) either way to avoid any confusion.\n- I find definition 2 and the paragraph following, very vague and ambiguous. It is not clear what you are describing. What is $\\mathbf{C}$? The way the bottom part of page 3 is phrased, make it difficult for a reader to extract meaning from a language that is rather too formal (without providing all the background, since that, I assume, lives in (Buhlmann, 2020)).\n- Whilst I appreciate that (Rothenhausler et al., 2021) uses the term \"anchor\" for a very common graph concept, it may be better to stick with the common tongue when it comes to graph formalism, where $A$ in figure 1 is either a leaf node or a root node depending on the perspective of the modeller. These terms predate the former's by a few decades and so may make this part of the section of the paper a bit more accessible by using the more common nomenclature. \n- You should adopt the standard graphical norms when it comes to causal inference. If H is a hidden confounder then it is standard to dash the edges (H,X) and (H,Y). The way you have drawn figure 1 makes it appear as if H is observed.\n- H is hidden (latent or unobserved) yet you are including it in equation 2? Please explain how that works.\n- You use 'source' and 'anchor' to refer to variable $A$ but never the standard 'root/leaf'? Consider picking one of these four terms.\n\n### CURVATURE, ROBUSTNESS, AND ENTROPY\n\n- The start of section 3 could do with an illustration of the concepts involved with Ricci curvature (e.g. figure four from the top: https://www.researchgate.net/publication/334371953_Community_Detection_on_Networks_with_Ricci_Flow/figures?lo=1)\n- Use $S(\\cdot)$ and not $S(.)$ for the Boltzmann entropy.\n\n### Entropic causal inference\n\n- Move the review of entropic causal inference to the preliminaries - the introduction of it the way you have done it now, breaks the flow of the paper.\n- This does make any sense: $Y = f(X,E)$ - what is $f$? What is $X$ the same as before? What is $E$ noise terms? What is the causal modelling framework you are using? Is $f$ an SEM? You seem to suggest that $E$ are exogenous variables which d-separeted (?) I assume that's what your symbol means since you haven't defined it, from the outcome variable $Y$ but then you introduce something you call 'alternative exogenous variables' - what's that?\n- Equation 9 presently does not point toward anything since it is not clear how the connection is made between it and what you say it is pointing to, which is not clear since section four is lacking a lot of detail for this to be a convincing argument.\n- What I find curious further about this section if that if equation 9 is a powerful result you build on, it would be helpful if you placed it in a lemme/theorem/proposition to indicate its importance to the paper.\n\n### Curvature and causal inference\n\n- Paragraph 2 in this section could use a figure for your stated causal relationship.\n- This may be a very silly question but you say: \"we expect a higher entropy of the exogenous variables when the curvature is larger\" - how can you expect anything at all about the exogenous variables since you cannot measure them? They are latent and so unknown to the modeller. Hence, what use is theorem 2 (being the devil's advocate here)\n- Suggestion: place this within a remark: \"This ultimately suggests that more positive Ricci curvatures are expected to correspond to lower errors in estimating the causal effect\"\n\n### RELATED WORK\n\n- What are you evaluation metrics actually measuring w.r.t. your contribution in this paper? What is the relation to Ricci curvature w.r.t. these metrics?\n- To confirm, none of your networks have unobserved confounders? See the Strengths section for relevant comments. See the Strengths section for relevant comments.",
         "905",
         "2",
         "0",
         "0.7875000000000001",
         "0.10808124350000001",
         "0.8884601593",
         "53",
         "10",
         "57.6228",
         "9.3546",
         "11.8793",
         "11.7711",
         "9.7607",
         "0.8362",
         "94",
         "1",
         "0",
         "0",
         "1",
         "5.0",
         "low",
         "5.0",
         "4",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "partially factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "18",
         "zdboax4dlK",
         "1381",
         "1695049614035",
         "['~Amirhossein_Farzam1', '~Allen_Tannenbaum2', '~Guillermo_Sapiro1']",
         "Ricci Curvature, Robustness, and Causal Inference on Networked Data",
         "In the complex landscape of networked data, understanding the causal effects of interventions is a critical challenge with implications across various domains. Graph Neural Networks (GNNs) have emerged as a powerful tool for capturing complex dependencies, yet the potential of geometric deep learning for GNN-based network causal inference remains underexplored. This work makes three key contributions to bridge this gap. First, we establish a theoretical connection between graph curvature and causal inference, revealing that negative curvatures pose challenges in identifying causal effects. Second, based on this theoretical insight, we present computational results using Ricci curvature to predict the reliability of causal effect estimations, empirically demonstrating that positive curvature regions yield more accurate estimations. Lastly, we propose a method using Ricci flow to improve treatment effect estimation on networked data, showing superior performance by reducing error through flattening the edges in the network. Our findings open new avenues for leveraging geometry in causal effect estimation, offering insights and tools that enhance the performance of GNNs in causal inference tasks.",
         "Reviewer_poe6",
         "1698777490509",
         "1699636065859",
         "3",
         "5",
         "2",
         "1",
         "1",
         "This paper claims to address the challenge of understanding causal effects in networked data using Graph Neural Networks (GNNs). They claim to utilize the link between graph curvature and causal inference, finding that negative curvatures complicate identifying causal effects to predict the reliability of causal effect estimations, showing that positive curvature regions lead to more accurate results. The exploration of curvature is intriguing.\nCausal inference on network data is an interesting problem to investigate. - The contribution of this paper is relatively moderate, as it amalgamates ideas from other sources, resulting in a contribution that is at best modest.\n- The paper is poorly written. \n- This paper seems to essentially be using causal discovery to improve causal inference. This is not properly explained. \n- Sounds like this paper violates the SUTVA assumption in casual inference on networks. - This paper seems to essentially be using causal discovery to improve causal inference.  Could the author please elaborate on that? \n- How do you justify violating the SUTVA assumption in casual inference on networks?\n- Implementing Ricci flow adjustments involves complex computations, especially on large-scale networks, which can be computationally intensive and time-consuming. This complexity may limit its applicability to real-time or resource-constrained scenarios. How do the authors justify the complexity and computational costs?\n- How interpretable are the results? What is behind the improved estimations (beyond statistical metrics)? \n- Ricci flow adjustments' effectiveness varies based on the unique structure of real-world networks, which are diverse and dynamic. Generalizing this method across different scenarios is challenging due to the complex nature of network connections. Moreover, the method's reliance on parameters like edge weights and curvature values makes it highly sensitive to even minor fluctuations. Selecting appropriate parameter values demands careful tuning and a deep understanding of the network, posing significant challenges in achieving optimal performance. Could the authors elaborate on these issues?",
         "311",
         "0",
         "0",
         "0.7886000000000001",
         "0.0841597796",
         "0.9391565323000001",
         "53",
         "9",
         "23.982",
         "13.3246",
         "16.6167",
         "14.424",
         "13.4968",
         "0.2298",
         "86",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "moderate",
         "3.0",
         "3",
         "4",
         "3",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "70.0",
         "70.0",
         "negative",
         "neutral"
        ],
        [
         "19",
         "zdboax4dlK",
         "1381",
         "1695049614035",
         "['~Amirhossein_Farzam1', '~Allen_Tannenbaum2', '~Guillermo_Sapiro1']",
         "Ricci Curvature, Robustness, and Causal Inference on Networked Data",
         "In the complex landscape of networked data, understanding the causal effects of interventions is a critical challenge with implications across various domains. Graph Neural Networks (GNNs) have emerged as a powerful tool for capturing complex dependencies, yet the potential of geometric deep learning for GNN-based network causal inference remains underexplored. This work makes three key contributions to bridge this gap. First, we establish a theoretical connection between graph curvature and causal inference, revealing that negative curvatures pose challenges in identifying causal effects. Second, based on this theoretical insight, we present computational results using Ricci curvature to predict the reliability of causal effect estimations, empirically demonstrating that positive curvature regions yield more accurate estimations. Lastly, we propose a method using Ricci flow to improve treatment effect estimation on networked data, showing superior performance by reducing error through flattening the edges in the network. Our findings open new avenues for leveraging geometry in causal effect estimation, offering insights and tools that enhance the performance of GNNs in causal inference tasks.",
         "Reviewer_UoX4",
         "1699241264461",
         "1699636065800",
         "3",
         "3",
         "2",
         "2",
         "3",
         "This manuscript bridges the Ollivier Ricci curvature with causal inference and shows that positive curvatures 'help' with the causal inference while negative ones do not. The connection is built on a causal model that regards the problem as a worst-case risk minimization. The main spot of the theoretical analysis is to show that if the ricci curvature is negative, then higher entropy is needed to fit the causal model. Numerical results align with the theoretical analysis. Further experiments show that integrating ricci flow with GNNs can improve the performance. 1. The paper discusses the background and related work quite carefully, and is in general well-written.\n2. I like this discovery. Building connections between geometry of the network and the causal inference should shed light on more future work, in addition to more understanding of this topic, especially given the fast development.\n3. I acknowledge the theoretical analysis as the main contribution, it is good that the experimental results corroborate with the theoretical analysis. 1. It seems that the background is discussed too much (until page 5) and the main entree is too short (only one page), which possibly indicates that this work relies a lot on previous work. Further, the large body of discussion triggers confusion, I would expect a clear logical argument, for example, the causal model has some property, leads to robustness, further goes to entropy, and lands in Ricci curvature. The above may be wrong, but readers need the correct version instead of a stack of notions.\n\n2. As for the proposed method integrating ricci flow and GNN, I could not find anything else except one paragraph in section 5.1. So if I am not misunderstanding, the proposed algorithm is: First run Ricci flow and attain the edge weights, then use existing frameworks of GNN-based causal inference. This is OK but the contribution is quite limited. Have the authors think about how to further take advantage of this property and design new GNN frameworks? Such as \\[1\\] and many others. Further, it would be good to at least present the pseudo code/descriptions by steps of the proposed method.\n\n\\[1\\] Curvature Graph Networks. 1. I unfortunately do not understand the formalization part very well. Could you explain what are the roles of system robustness and distributional robustness in the causal model? (Especially the risk minimization). In section 3.2 you said \"we utilize the correlation between Boltzmann entropy and Ricci curvature to formally establish this anticipated connection\" but later in section 4, Shannon entropy is discussed and Theorem 2 also uses Shannon entropy. This is confusing, could you please make it clear?\n\n2. I am fine with the most proof of Theorem 3.2 but not the second assumption. If I understand correctly, $X$ is the feature and $Y$ is the label, then the difference of two datasets may not just lie on the features. I wonder if the assumption that $H(Y|X;E)$ remains similar is OK in a causality task, but nothing more.\n\n3. What does it mean by a \"wrong causal model\"?\n\n4. This is not a major issue, but have you experienced computational issues when the networks are large? The computation of ricci flow takes $\\tilde{O}(mn^3)$ if I remember correctly, which can be larger than the time for GNN. Then if we think about applications, this is a hurdle.",
         "551",
         "2",
         "10",
         "0.8052",
         "0.1119542957",
         "0.8874665499000001",
         "53",
         "4",
         "50.9348",
         "10.3029",
         "13.5027",
         "13.0737",
         "10.819",
         "0.5519000000000001",
         "87",
         "0",
         "0",
         "0",
         "1",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "75.0",
         "75.0",
         "neutral",
         "polite"
        ],
        [
         "20",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_irmp",
         "1697978211527",
         "1699636429994",
         "6",
         "4",
         "4",
         "2",
         "3",
         "The author proposed physically-intuitive embedding method for partial order hierarchy. The method uses shadow cones, which generalize existing hyperbolic entailment cones. The author also constructed the algorithm to optimize the shadow cones. 1. The paper provides novel multiple variants of the existing hyperbolic entailment cone method. The techniques provided for handling shadow cones are significant technical contributions in the area.\n1. The physics-inspired explanation, with plenty of intuitive figures, of the proposed method helps readers understand the proposed method's concept and algorithm. The explanation also provides another explanation of why existing hyperbolic entailment cones cannot be defined for a point around the center of the Poincare ball.\n1. Table 1 summarizes the proposed 4 methods well. Overall, the paper is well-written as a technical report but has room for improvement in terms of scientific discussion or presentation.\n1. Although the light-source-shadow-based explanation is quite helpful in understanding WHAT the proposed methods are doing, but does not explain at all WHY they do so. Specifically, we do not see what the shape and size of the light source and the size of embedding in the umbral cases imply in the context of partial order or semantics. Also, readers do not see how we select one of the 4 proposed methods depending on the situation.\n1. Overall, the paper is written as a technical extension of the hyperbolic entailment cone method, but the current draft does not position the proposed method well in the context of the whole partial order embedding area. It is not an unacceptable way, but limits the readers. The authors might want to compare it with other methods such as Order embedding, Gaussian embedding, Box embedding, etc.\n1. The title of the paper lacks essential keywords and confuses readers. It should include the word \"shadow cone.\" Also, if possible, the words \"hierarchy\" or \"partial order\" could be included. Readers might think the phrase \"dark side\" indicates the surface of a hemisphere, rather than a shadow cone. Also, from the word \"moon,\" readers feel the impression that the embedding has a volume. However, this is not the case for the penumbral cone embedding. I am aware that we have many styles on which we title a paper, but, at least, we need to avoid confusing readers. 1. Why the experimental results by Entailment Cone and Penumbral-Poincaré-ball are different while they are equivalent according to Theorem 3.2?\n1. What do the shape and size of the light source and the size of embedding in the umbral cases imply in the context of partial order or semantics?\n1. How do we select one of the 4 proposed methods depending on the situation?",
         "441",
         "0",
         "9",
         "0.7558",
         "0.026785714300000003",
         "0.9128438830000001",
         "49",
         "19",
         "45.6284",
         "11.2774",
         "14.1308",
         "13.5382",
         "11.9012",
         "0.1615",
         "92",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "5",
         "80.0",
         "80.0",
         "neutral",
         "polite"
        ],
        [
         "21",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_JBVb",
         "1698155132625",
         "1699636429907",
         "8",
         "3",
         "3",
         "3",
         "3",
         "This paper considers the problem of learning representations to model hierarchical relationships using hyperbolic space. The authors introduce several formulations of *shadow cones*, a novel and unifying framework of physics inspired representations. Entailment relations are defined by the containment of shadows of the object representations given a fixed light source and boundary if hyperbolic space. The authors present two different shadow formulations each in two different hyperbolic spaces. A smooth loss function is introduced to train shadow cones in a stable manner, avoiding some of the training issues presented in prior work. The effectiveness of the presented method is shown on standard open source datasets. * The proposed approach is novel and well-motivated, avoiding many of the issues in prior work\n* The proposed representation formulation encapsulates previous approaches\n* The paper is well written and includes many intuitive figures and diagrams to illustrate the proposed approach\n* The empirical results demonstrate the efficacy of the proposed methodology on standard datasets for this task * The paper uses quite a bit of space introducing all four formulations of shadow cones, leaving less space for additional empirical results\n* At the end of Section 4, the authors make claims about ease of training, but do not justify claims beyond just a statement by fiat. \n* The proposed approaches are only compared against a single baseline -- even though this is the supposed state of the art in hyperbolic representations it would be beneficial to see comparisons with other methods.\n* The empirical results are all demonstrated on the same singular type of task. It would benefit the paper to see experiments on different types of tasks such as collaborative filtering. * What advantages might this method have over a different representation learning paradigm such as box embeddings (e.g. \\[1\\])?\n* Why is there such a big discrepancy in the results between Penumbral-Poincaré-ball and Entailment cones in Table 2? These formulations are mathematically equivalent, but perform quite differently in some cases. Is this attributable to the loss function or training procedure in some way?\n* What is the relationship between convexity and performance? The non-convex method seems to perform better. Why is this the case?\n* What are the potential challenges to learning representations in the half-space formulation?\n\n\\[1\\] Dasgupta S, Boratko M, Zhang D, Vilnis L, Li X, McCallum A. Improving local identifiability in probabilistic box embeddings. Advances in Neural Information Processing Systems, 2020",
         "403",
         "2",
         "1",
         "0.7695000000000001",
         "0.0638305322",
         "0.875056684",
         "49",
         "17",
         "30.9327",
         "13.5585",
         "16.2491",
         "14.9556",
         "13.825",
         "0.0751",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "4",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "5",
         "85.0",
         "85.0",
         "neutral",
         "5"
        ],
        [
         "22",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_s6e6",
         "1698490763984",
         "1699636429797",
         "6",
         "3",
         "2",
         "3",
         "2",
         "Hyperbolic space have been shown to be particularly well suited to encode the latent structure of complex objects such as trees or graphs. In particular, using random graphs with an hyperbolic latent space are known to exhibit properties often found in real world networks such a the small world phenomenon or the scale free property. \n\nIn this paper, the authors introduce the so-called shadow cones framework: a methodology that allows to define a partial order embedding of hierarchical data. The authors show that such framework can be particularly efficient to learn a latent embeddings of nodes for trees or more generally for DAGs. Their method extends to the concept of entailment cones previously introduced by Ganea. On three different datasets, the authors show that using their method to learn the hierarchical structure of partially observed DAGs can allow to infer unseen edges better than previous approaches. - Hyperbolic spaces have been shown to be very promising latent space to model graph data. This paper is focused on DAGs and proposes a new framework to learn embedding for hierarchical data. \n\n- The authors did an excellent job in ensuring the comprehensibility of their method, notably by incorporating highly insightful illustrations.\n\n- As a by product, the paper provides a comprehensive overview of various approaches to incorporate 'shadows' for embedding points in hyperbolic space, employing the concepts of umbral and penumbral cones. This lucid exposition elucidates the source of the limitations observed in prior methods, particularly with regard to the $\\epsilon$ hole problem. - I think the authors should better stress the concrete applications of their method. For example, are there applications related to structure learning?  \n\n- In my opinion, the authors should include in their comparison methods that do not rely on hyperbolic spaces (but rather on Euclidean ones for example or with manifold with positive curvature). I thank the authors for their nice submission.\n\nApart for my questions presented in the previous section (i.e. use of the method for applications and comparison with methods not using hyperbolic spaces), I would be interested to know if the method could be used in more general settings. In particular:\n\n- How the method could be used for real world graphs that are not (exactly) DAGs?\n\n- How the method could be used for multiclass hierarchical problems?\n\nHere are some typos and additional comments: \n\n- In the loss function (cf. Eq(1)), if think N and P are not properly defined in the text.\n\n- At the end of the first paragraph of the introduction of Section 3, I think there is an error. Should the last sentence rather be \"Specifically, $v$ is in the shadow cone of $u$ iff $v \\subset$ the shadow of $u$.\" ?\n\n- After Theorem 4.2, I think the first \"their\" should be removed from the sentence \"which is\ndesigned to draw child nodes v closer to their the cones of their patent nodes\".",
         "484",
         "0",
         "0",
         "0.7727",
         "0.1312085976",
         "0.8662823439",
         "49",
         "13",
         "48.6583",
         "11.1727",
         "13.9105",
         "13.2198",
         "11.9401",
         "0.8146",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "low",
         "5.0",
         "4",
         "5",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "23",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_SzVy",
         "1698609725308",
         "1699636429703",
         "6",
         "3",
         "2",
         "3",
         "2",
         "This paper proposes the use of (light) cones to learn embeddings of posets in hyperbolic space. Specifically, the paper looks at two models depending whether the data or the light source has mass. The paper proves a variety of consistency results such the fact that inclusion of the cones form a poset. The idea of using cones is quite interesting to me. The paper shows that it results in a loss at least at the optimal point that does preserve the partial order structure. Further, it does so in a way that gives coordinates from which we can extract the partial order. Hence I think this is quite interesting and quite novel. I think of these are strong strengths. \n\nThe paper is mostly easy to follow however there are a few details I would like added. Please see weaknesses and questions 1) The first weakness for me is the context for the work. I think some more discussion to related concepts such as DAG learning, which is learning DAGs from data \\[1,2,3\\], other hyperbolic hierarchical learning like hyperbolic tree learning, which is about learning trees to represent hyperbolic data or embed in hyperbolic apace \\[4,5\\], graph embeddings in hyperbolic space \\[6,7,8\\], and hyperbolic link prediction \\[9\\] would be great. \n\n2) I think the experimental setup could be further expanded upon. First, I think it should be clarified that we can do the link prediction without the embedding step (this would have a 100% accuracy) and then mention that you do the embedding step to understand the how well the embedding performs. As part of the experiment, it would be good to have a baseline for Euclidean poset embedding. However, I admit I do not know of one. Maybe on of the DAG learning papers has a baseline that could be used. \n\n3) Building on the above it would be good to show that such embeddings can be used other non-trivial down stream tasks and that such embeddings provide an advantage. \n\n\\[1\\] X. Zheng, B. Aragam, P.K. Ravikumar, and E.P. Xing. Dags with no tears: Continuous optimization for structure learning. In Advances in Neural Information Processing Systems 31, 2018.\\\n\\[2\\] Yu, Y., Gao, T., Yin, N., & Ji, Q. (2021, July). DAGs with no curl: An efficient DAG structure learning approach. In International Conference on Machine Learning (pp. 12156-12166). PMLR.\\\n\\[3\\] Lachapelle, S., Brouillard, P., Deleu, T., & Lacoste-Julien, S. (2019). Gradient-based neural dag learning. arXiv preprint arXiv:1906.02226.\n\n\\[4\\] Ittai Abraham, Mahesh Balakrishnan, Fabian Kuhn, Dahlia Malkhi, Venugopalan Ramasub- ramanian, and Kunal Talwar. Reconstructing Approximate Tree Metrics. In Proceedings of the Twenty-sixth Annual ACM Symposium on Principles of Distributed Computing, PODC ’07, pages 43–52, New York, NY, USA, 2007. ACM.\\\n\\[5\\] Sonthalia, R., & Gilbert, A. (2020). Tree! i am no tree! i am a low dimensional hyperbolic embedding. Advances in Neural Information Processing Systems, 33, 845-856.\n\n\\[6\\] Chamberlain, B. P., Clough, J., & Deisenroth, M. P. (2017). Neural embeddings of graphs in hyperbolic space. arXiv preprint arXiv:1705.10359.\\\n\\[7\\] T. Blasius, T. Friedrich, A. Krohmer, and S. Laue. Efficient Embedding of Scale-Free Graphs in the Hyperbolic Plane. IEEE/ACM Transactions on Networking, 26(2):920–933, April 2018.\\\n\\[8\\] Kevin Verbeek and Subhash Suri. Metric Embedding, Hyperbolic Space, and Social Networks. Computational Geometry, 59:1 – 12, 2016.\n\n\\[9\\] Zhe Pan and Peng Wang. 2021. Hyperbolic Hierarchy-Aware Knowledge Graph Embedding for Link Prediction. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 2941–2948, Punta Cana, Dominican Republic. Association for Computational Linguistics. I have a few questions. \n\n1) In the loss function $P$ and $N$ haven't been defined. \n\n2) For the cones I do not understand the boundary computation. Could the authors please expand on that? I did not see anything in the appendix either. \n\n3) Why do we need the ball around $y$ to be in the shadow for $y$ to be in the umbral cone, but only need the point $y$ to be in the shadows for the penumbral cone? I see that the umbral method seems to perform the best. I imagine based on how the loss in formulated this pushes the point to the interior of the cone rather than leaving it on the boundary where we might have numerical issues. \n\n4) Could the authors provide intuition for why umbral cones are not geodetically convex? I believe in this regard calling them cones might be a bit confusing, because cones in Euclidean space are not only convex, but contains these geodesic rays. I would have thought the same is true for the hyperbolic ones. Hence was surprised when I saw this result.",
         "761",
         "16",
         "15",
         "0.7842",
         "0.14448892330000002",
         "0.809056282",
         "49",
         "11",
         "60.774",
         "8.0207",
         "10.9281",
         "11.2081",
         "8.9529",
         "0.364",
         "107",
         "1",
         "0",
         "1",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "partially factual",
         "92.0",
         "92.0",
         "positive",
         "polite"
        ],
        [
         "24",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_Arvf",
         "1698749524713",
         "1701125357640",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This paper proposes a physically intuitive partial order embedding framework \"shadow cones\" that generalizes the well-known \"hyperbolic entailment cones\". Also, this framework generalizes to two different hyperbolic models, the Poincaré disk and Poincaré half-space. The experiments shows that the generalized \"shadow cones\" outperform the \"hyperbolic entailment cones\" baseline. 1. The paper is well-motivated and has a good connection to existing research.\n2. It considers two hyperbolic models, the Poincaré disk and the Poincaré half-space.\n3. The theoretical analysis provides nice properties of the proposed models. 1. Compared with the novel and interesting motivation, the description, especially the figures, lacks explanation, almost all the symbols in the figures are not mentioned in the captions or corresponding text.\n2. The experiment is not very supportive of the claim. For example, In the experiment, Poincaré ball based cones performed worse than Poincaré half-space based cones. While in the important baseline \"hyperbolic entailment cones\", the Poincaré ball is used, if the proposed cone generalizes \"hyperbolic entailment cone\", it should be as good as the \"hyperbolic entailment cone\".\n3. The use of different definitions for light source in the Penumbral cone and the Umbral cone is somewhat inconsistent. Please see the weaknesses.",
         "197",
         "0",
         "6",
         "0.7006",
         "0.1862637363",
         "0.9387722611",
         "66",
         "27",
         "40.7264",
         "11.6572",
         "14.8915",
         "14.1918",
         "14.5363",
         "0.1376",
         "73",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "3",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "75.0",
         "75.0",
         "neutral",
         "polite"
        ],
        [
         "25",
         "zbKcFZ6Dbp",
         "4527",
         "1695351643486",
         "['~Tao_Yu1', '~Toni_J.B._Liu1', '~Albert_Tseng1', '~Christopher_De_Sa2']",
         "Shadow Cones: A Generalized Framework for Partial Order Embeddings",
         "Hyperbolic space has proven to be well-suited for capturing hierarchical relations in data, such as trees and directed acyclic graphs. Prior work introduced the concept of entailment cones, which uses partial orders defined by nested cones in the Poincar\\'e ball to model hierarchies. Here, we introduce the ``shadow cones\" framework, a physics-inspired entailment cone construction. Specifically, we model partial orders as subset relations between shadows formed by a light source and opaque objects in hyperbolic space. The shadow cones framework generalizes entailment cones to a broad class of formulations and hyperbolic space models beyond the Poincar\\'e ball. This results in clear advantages over existing constructions: for example, shadow cones possess better optimization properties over constructions limited to the Poincar\\'e ball. Our experiments on datasets of various sizes and hierarchical structures show that shadow cones consistently and significantly outperform existing entailment cone constructions. These results indicate that shadow cones are an effective way to model partial orders in hyperbolic space, offering physically intuitive and novel insights about the nature of such structures.",
         "Reviewer_6mLv",
         "1698994582440",
         "1700643652951",
         "6",
         "3",
         "3",
         "2",
         "3",
         "The authors introduce the \"shadow cones\" framework for constructing entailment cones in hyperbolic space. Unlike prior work that utilized nested cones in the Poincaré ball, shadow cones model partial orders based on subset relations between shadows created by a light source and opaque objects.  This framework extends beyond the Poincaré ball, allowing for more diverse formulations and hyperbolic space models. Shadow cones offer advantages over existing constructions, particularly in terms of optimization properties. Experimental results demonstrate the consistent and significant outperformance of shadow cones compared to existing entailment cone constructions across datasets of varying sizes and hierarchical structures. 1. The introduction of shadow cones presents an innovative approach to defining entailment relations in hyperbolic space. Drawing inspiration from physical phenomena adds an intuitive and captivating aspect to the concept.\n\n2.  The authors provide a comprehensive mathematical formulation for shadow cones, enhancing the rigor of their work and enabling further exploration and development by other researchers in the field.\n\n3.  The experimental results across four datasets demonstrate the superior performance of the proposal compared to the current state-of-the-art methods. 1. While the authors tested their framework on four datasets, it would be beneficial to see how the framework performs on a wider variety of datasets, including those from different domains or those with different characteristics (like KG, recommender system datasets and so on). This would provide a more comprehensive evaluation of the framework's performance and versatility.\n\n2.The work builds on the entailment cone but a few partial order methods have been proposed and a thorough comparison or discussion is needed.\n\n3. Captions for the figures are brief and ambiguous, hindering their readability. \n\n\n\\[1\\]Capacity and Bias of Learned Geometric Embeddings for Directed Graphs.\n\\[2\\]Modeling Transitivity and Cyclicity in Directed Graphs via Binary Code Box Embeddings see weakness",
         "295",
         "2",
         "5",
         "0.8035",
         "0.1550724638",
         "0.9411929846",
         "61",
         "19",
         "21.6882",
         "15.12",
         "18.8497",
         "16.5672",
         "16.9667",
         "0.0945",
         "96",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "4",
         "4",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "positive",
         "polite"
        ],
        [
         "26",
         "zUHgYRRAWl",
         "4337",
         "1695345226979",
         "['~Chenghui_Zhou1', '~Barnabas_Poczos1']",
         "Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage VAE",
         "Variational autoencoder (VAE) is a popular method for drug discovery and various architectures and pipelines have been proposed to improve its performance. However, VAE approaches are known to suffer from poor manifold recovery when the data lie on a low-dimensional manifold embedded in a higher dimensional ambient space [Dai and Wipf, 2019]. The consequences of it in drug discovery are somewhat under-explored. In this paper, we explore applying a multi-stage VAE approach, that can improve manifold recovery on a synthetic dataset, to the field of drug discovery. We experimentally evaluate our multi-stage VAE approach using the ChEMBL dataset and demonstrate its ability to improve the property statistics of generated molecules substantially from pre-existing methods without incorporating property predictors into the training pipeline. We further fine-tune our models on two curated and much smaller molecule datasets that target different proteins. Our experiments show an increase in the number of active molecules generated by the multi-stage VAE in comparison to their one-stage equivalent. For each of the two tasks, our baselines include methods that use learned property predictors to incorporate target metrics directly into the training objective and we discuss complications that arise with this methodology.",
         "Reviewer_DTvh",
         "1698432721685",
         "1699636403897",
         "1",
         "5",
         "1",
         "1",
         "1",
         "The authors propose a new method for training VAEs for drug discovery tasks. Unfortunately, I must vote to reject without further review as the authors blatantly violated the ICLR submission template. Violations include:\n\n* Obviously significantly reducing the margin size to fit within the page limit.\n* Removing the \"Under review as a conference paper at ICLR 2024\" header.\n* Not including a references section in their submission. Rejecting without further review. Rejecting without further review. Rejecting without further review.",
         "80",
         "0",
         "0",
         "0.7838",
         "-0.0098484848",
         "0.8092228174",
         "49",
         "13",
         "34.4578",
         "10.8443",
         "12.6812",
         "11.4568",
         "10.1706",
         "0.07390000000000001",
         "80",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "low",
         "4.0",
         "2",
         "1",
         "1",
         "2.0",
         "5.0",
         "3.0",
         "factual",
         "25.0",
         "25.0",
         "negative",
         "impolite"
        ],
        [
         "27",
         "zUHgYRRAWl",
         "4337",
         "1695345226979",
         "['~Chenghui_Zhou1', '~Barnabas_Poczos1']",
         "Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage VAE",
         "Variational autoencoder (VAE) is a popular method for drug discovery and various architectures and pipelines have been proposed to improve its performance. However, VAE approaches are known to suffer from poor manifold recovery when the data lie on a low-dimensional manifold embedded in a higher dimensional ambient space [Dai and Wipf, 2019]. The consequences of it in drug discovery are somewhat under-explored. In this paper, we explore applying a multi-stage VAE approach, that can improve manifold recovery on a synthetic dataset, to the field of drug discovery. We experimentally evaluate our multi-stage VAE approach using the ChEMBL dataset and demonstrate its ability to improve the property statistics of generated molecules substantially from pre-existing methods without incorporating property predictors into the training pipeline. We further fine-tune our models on two curated and much smaller molecule datasets that target different proteins. Our experiments show an increase in the number of active molecules generated by the multi-stage VAE in comparison to their one-stage equivalent. For each of the two tasks, our baselines include methods that use learned property predictors to incorporate target metrics directly into the training objective and we discuss complications that arise with this methodology.",
         "Reviewer_uwWu",
         "1698666834458",
         "1699636403824",
         "3",
         "4",
         "1",
         "2",
         "1",
         "The article \"Objective-agnostic enhancement...\" describes the use of multi-layer VAE models for the prediction and generation of small molecules for drug discovery problems. The use of multi-layer VAE models is proposed in view of their better generative statistics, approximation of the true, for a given dataset, immersion in high-dimensional space.\n\nThe article is very simple, offering basically nothing new. The level of workmanship is low, additionally parts of the paper are clearly missing.\n\nI believe that the proposed article is not ready, does not contain any novelties, and as such should not be accepted. 1. Correct posing of a problem, with correct references to related work.\n2. The authors undertake the issue of finding better low-dimension space immersion in high-dimensional space. On the other hand, it is not proved that their solution is the right one. 1. The authors note that typically, high-dimensional data can be projected onto a low-dimensional space immersed in a high-dimensional space. To demonstrate this, they conduct a very simple experiment on synthetic data. This experiment does not show much, only the authors claim that for one of the later layers a space with the correct dimensionality for the data is obtained. This experiment is clearly spurious and can be removed.\n2. The authors propose to build a VAE model with many hidden layers iteratively. In each step, developing the projection of the most recently obtained hidden layer into a new VAE model. The obtained model would get the variances on the diagonal reach the values {0, 1}, which would show the selection/reduction of individual dimensions projection. \nIt seems that the analogy with synthetic experiment is insufficient for a direct application of this approach.\n3. Several models with randomly selected numbers of hidden layers are used in the experiments.\n4. In the comparisons, each model has a different dimensionality of hidden layers for the same data.\n5. There is no bibliography in the work. I suspect that this is a simple editorial error (references in the work are marked as links), but such an error in a work for a major conference is unacceptable. Similarly, there is no appendix to which there is a reference in the main text. 1. Is the synthetic experiment really needed? I would remove it if I were you. In place of it, I would give some better mathematical discussion.\n2. Is the analogy between the scheme presented in the synthetic data experiment to the problem of molecule generation really valid? Could you, please, better justify the analogy?\n3. Why just that number of layers are used in the models? Why are there 3 layers for HGNN and MoLeR? The \"MoLeR + prop\" model is completely unclear? Why does the RNN model only have two layers? The LatentGAN model seems to have only one hidden layer, right? Or maybe some of the nodels are for comparison? This is not clear from the text of the work.\n4. If one of the goals was to show that multi-layer models, along with variance optimization, allow for better matching of the implicit dimensions, does using different dimensions allow this to be shown for different models? There is no description of the individual statistics used in the work.\n5. Was variance optimization used for all models? This is not clear from the text.\n6. The standard in the editorial composition of scientific works is to place descriptions of tables above them, not below.",
         "568",
         "0",
         "13",
         "0.7239",
         "0.0615771877",
         "0.8907097578000001",
         "49",
         "11",
         "48.9896",
         "10.038",
         "12.8701",
         "12.413",
         "9.5053",
         "0.2922",
         "88",
         "1",
         "0",
         "0",
         "0",
         "3.0",
         "moderate",
         "2.0",
         "1",
         "4",
         "2",
         "5.0",
         "3.0",
         "5.0",
         "unfactual",
         "45.0",
         "45.0",
         "negative",
         "impolite"
        ],
        [
         "28",
         "zUHgYRRAWl",
         "4337",
         "1695345226979",
         "['~Chenghui_Zhou1', '~Barnabas_Poczos1']",
         "Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage VAE",
         "Variational autoencoder (VAE) is a popular method for drug discovery and various architectures and pipelines have been proposed to improve its performance. However, VAE approaches are known to suffer from poor manifold recovery when the data lie on a low-dimensional manifold embedded in a higher dimensional ambient space [Dai and Wipf, 2019]. The consequences of it in drug discovery are somewhat under-explored. In this paper, we explore applying a multi-stage VAE approach, that can improve manifold recovery on a synthetic dataset, to the field of drug discovery. We experimentally evaluate our multi-stage VAE approach using the ChEMBL dataset and demonstrate its ability to improve the property statistics of generated molecules substantially from pre-existing methods without incorporating property predictors into the training pipeline. We further fine-tune our models on two curated and much smaller molecule datasets that target different proteins. Our experiments show an increase in the number of active molecules generated by the multi-stage VAE in comparison to their one-stage equivalent. For each of the two tasks, our baselines include methods that use learned property predictors to incorporate target metrics directly into the training objective and we discuss complications that arise with this methodology.",
         "Reviewer_un1d",
         "1698911651980",
         "1699636403750",
         "1",
         "4",
         "2",
         "2",
         "2",
         "A multi-stage VAE model that help generate molecules with conditional properties. Proposed a novel multi-stage model. No reference section. \nNo under review header.\nI believe this paper is not ready to be reviewed. N/A",
         "34",
         "0",
         "3",
         "0.8889",
         "-0.1",
         "0.80578053",
         "49",
         "8",
         "48.1506",
         "8.2326",
         "10.9553",
         "9.8885",
         "7.4594000000000005",
         "0.2086",
         "33",
         "1",
         "0",
         "0",
         "0",
         "1.0",
         "extreme",
         "1.0",
         "1",
         "1",
         "1",
         "2.0",
         "2.0",
         "1.0",
         "partially factual",
         "10.0",
         "10.0",
         "negative",
         "impolite"
        ],
        [
         "29",
         "zQXX3ZV2HE",
         "2189",
         "1695178042065",
         "['~Liang_Muxue1', '~Chuan_Wang1', '~Siyuan_Liang1', '~Aishan_Liu1', '~Zeming_Liu1', '~Liang_Yang2', '~Xiaochun_Cao3']",
         "Adversarial Instance Attacks for Interactions between Human and Object",
         "Adversarial attacks can easily deceive deep neural networks (DNNs); however, they are also valuable for evaluating the robustness of DNNs. Existing attacks on object detection primarily focus on attacking the recognition of objects, while whether the attacks remain effective on more complex scene understanding tasks (e.g., extracting the interaction between objects) remains largely unexplored. In this paper, we, for the first time, propose Adversarial Instance Attacks, a novel black-box attacking framework for scene interactions without interfering with object detections. To achieve the goal, we first introduce an Interaction Area Sampling module that identifies vulnerable anchors (area) for adversarial instances positioning. Secondly, we design an Object Category Search module and build an interaction co-occurrence knowledge graph to explore categories with higher obfuscation scores toward specific object-interaction pairs. Finally, our framework generates perturbations that serve as adversarial instances with high co-occurrence obfuscation towards specific interactions in vulnerable areas and deceive HOI models. Extensive experiments conducted against multiple models demonstrate effectiveness in attacking interactions of HOI. Our approach surpasses existing methods by significant margins, achieving an improvement of at least +10.36%}.",
         "Reviewer_FvgA",
         "1698417808331",
         "1699636152756",
         "3",
         "4",
         "3",
         "2",
         "2",
         "The paper proposes a approach called Adversarial Instance Attacks (AIA) to attack the interaction predictions between humans and objects in the context of Human Object Interaction (HOI) tasks. The authors argue that existing adversarial attacks on object detection do not effectively extend to interactions, as interactions are more complex and require considering spatial and semantic relationships. AIA is designed to generate adversarial instances that distract the model's attention away from the original interaction, without disrupting the detection of human and object bounding boxes or their categories. The proposed AIA framework comprises three main modules: Interaction Area Sampling (IAS), Object Category Search (OCS), and Adversarial Instance Generation (AIG). The authors claim that AIA outperforms other attack methods in attacking interactions. Innovative Approach: The paper introduces a novel approach to attacking interactions in HOI tasks, addressing a gap in the existing literature.\n\nExperimental Results: The paper presents a thorough evaluation of the proposed AIA framework and compares it with other attack methods on various target and surrogate models. The results indicate that AIA is effective in attacking interactions.\n\nDiscussion on Perturbation Bounds: The paper provides an insightful analysis of the impact of different perturbation bounds on the success of attacks, shedding light on how noise affects interaction recognition. Lack of Clarity: The paper is challenging to follow due to its complex technical language and insufficient contextual explanations. It assumes a high level of familiarity with the subject matter, making it less accessible to a broad audience.\n\nAmbiguity in Terminology: Some terms and acronyms are not adequately defined or clarified, such as \"Adversarial Instance Attacks,\" \"Adversarial Interaction Attack,\" and \"HOTR.\"\n\nMissing Visual Aids: Given the complexity of the proposed framework, the paper would benefit from visual aids, diagrams, or flowcharts to help readers understand the different modules and their interactions.\n\nEvaluation Metrics: The paper could benefit from a more detailed discussion of the evaluation metrics used and how they relate to the effectiveness of the attacks. 1. Could you provide more clarity on the specific datasets used in the experiments and how they were collected or prepared?\n\n2. Can you elaborate on the definition of \"L\" in the context of perturbation bounds? What does it represent, and how is it determined?\n\n3. How does the AIA framework perform against state-of-the-art HOI models, and are there specific models it is more effective against?\n\n4. What kind of perturbations or attacks are used in the experiments? Is there a specific method for generating these adversarial instances?",
         "411",
         "0",
         "4",
         "0.7982",
         "0.13815040650000002",
         "0.8926494718",
         "51",
         "14",
         "23.7753",
         "15.0483",
         "18.0497",
         "16.2186",
         "16.108",
         "0.3442",
         "94",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "low",
         "5.0",
         "5",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "30",
         "zQXX3ZV2HE",
         "2189",
         "1695178042065",
         "['~Liang_Muxue1', '~Chuan_Wang1', '~Siyuan_Liang1', '~Aishan_Liu1', '~Zeming_Liu1', '~Liang_Yang2', '~Xiaochun_Cao3']",
         "Adversarial Instance Attacks for Interactions between Human and Object",
         "Adversarial attacks can easily deceive deep neural networks (DNNs); however, they are also valuable for evaluating the robustness of DNNs. Existing attacks on object detection primarily focus on attacking the recognition of objects, while whether the attacks remain effective on more complex scene understanding tasks (e.g., extracting the interaction between objects) remains largely unexplored. In this paper, we, for the first time, propose Adversarial Instance Attacks, a novel black-box attacking framework for scene interactions without interfering with object detections. To achieve the goal, we first introduce an Interaction Area Sampling module that identifies vulnerable anchors (area) for adversarial instances positioning. Secondly, we design an Object Category Search module and build an interaction co-occurrence knowledge graph to explore categories with higher obfuscation scores toward specific object-interaction pairs. Finally, our framework generates perturbations that serve as adversarial instances with high co-occurrence obfuscation towards specific interactions in vulnerable areas and deceive HOI models. Extensive experiments conducted against multiple models demonstrate effectiveness in attacking interactions of HOI. Our approach surpasses existing methods by significant margins, achieving an improvement of at least +10.36%}.",
         "Reviewer_fSia",
         "1698647640926",
         "1699636152669",
         "1",
         "2",
         "2",
         "1",
         "2",
         "The authors have introduced an adversarial attack problem that targets interactions between humans and objects. They evaluate this problem within the context of the Human Object Interaction (HOI) task, as proposed by Gkioxari et al. in 2018. Furthermore, the authors have successfully demonstrated an attacking framework for this novel problem The paper proposes to tackle a new problem for adversarial attack for interactions between human and objects, based on the Human Object Interaction (HOI) task (Gkioxari et al., 2018), which is a new contribution to the field and might be interested to the adversarial attack community. However, the motivation is not clear when it is a difficult problem compared to existing attack problems. And the evaluation and writing quality are poor. Deficient Writing Quality: The paper exhibits evident signs of hasty preparation, accompanied by numerous errors. To illustrate a few examples, some of which are highlighted in bold text:\n\n* The reviewer could not understand “on the interaction between scene contents and **realize**’ based on” \n\n* The math notations of {$ h_i^b, o_i^b, o_i^l, a_i $} are incorrect and confusing. It does not make sense to use a set { } for both coordinates and categories. And defining $a_i$ as the categories of the object is wrong.\n\n* directly adding noise to the union area not only **drop the precise** of interaction perception but also **bring** .... \n\nThe motivation is unclear. The arguments within the sentences lack proper support. For instance, the sentence \"a direct strategy to disturb the interaction is adding noises on the union area of human and object, following the feature extraction procedure in HOI. However, directly adding noise to the union area not only drop the precise of interaction perception but also bring interference in locating and classifying human and objects\" lacks clarity and substantiation.\n\nUnderstanding the paper's concept is challenging, primarily due to its poor writing quality. For example, the exact process for generating \"N^q candidate interaction areas\" is not explained and appears disconnected from the subsequent content. Upon reviewing Section 3.3, the reviewer found it to be incomplete, offering only a feature extraction process without any content related to sampling. The method for obtaining the extracted candidate predicate areas $A$ is also unclear.\n\nThe rationale behind distance calculation remains unclear, as does the definition of the midpoint function $f_{mid}()$.\n\n\"To address this issue, we employ random assignment to connect perplexing object categories to candidate predicate areas in order to generate the attack instances.\" However, the explanation for this random assignment is unclear.\n\nIn summary, while the paper may address an important problem of black-box adversarial attacks in scene interactions, its writing quality falls significantly below the standards of ICLR. Significant revisions are required. Therefore, the reviewer recommends clear rejection.\"\n\n\nThe equation (6) seems to contradict to the original claim of the paper  \"our goal is to bring confusion on the\ninteraction of a pair of human and an object, without contaminating their detection results including\nthe human bounding box, object bounding box, and object category\", as the object bounding boxes seem to be changed. Please provide more clarifications to it. Please refer to the above comments.",
         "522",
         "1",
         "1",
         "0.7922",
         "0.033107672500000004",
         "0.8696472049",
         "51",
         "11",
         "33.1415",
         "13.0399",
         "16.2725",
         "14.9895",
         "13.4814",
         "0.0988",
         "90",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "none",
         "5.0",
         "5",
         "5",
         "3",
         "5.0",
         "4.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "negative",
         "impolite"
        ],
        [
         "31",
         "zQXX3ZV2HE",
         "2189",
         "1695178042065",
         "['~Liang_Muxue1', '~Chuan_Wang1', '~Siyuan_Liang1', '~Aishan_Liu1', '~Zeming_Liu1', '~Liang_Yang2', '~Xiaochun_Cao3']",
         "Adversarial Instance Attacks for Interactions between Human and Object",
         "Adversarial attacks can easily deceive deep neural networks (DNNs); however, they are also valuable for evaluating the robustness of DNNs. Existing attacks on object detection primarily focus on attacking the recognition of objects, while whether the attacks remain effective on more complex scene understanding tasks (e.g., extracting the interaction between objects) remains largely unexplored. In this paper, we, for the first time, propose Adversarial Instance Attacks, a novel black-box attacking framework for scene interactions without interfering with object detections. To achieve the goal, we first introduce an Interaction Area Sampling module that identifies vulnerable anchors (area) for adversarial instances positioning. Secondly, we design an Object Category Search module and build an interaction co-occurrence knowledge graph to explore categories with higher obfuscation scores toward specific object-interaction pairs. Finally, our framework generates perturbations that serve as adversarial instances with high co-occurrence obfuscation towards specific interactions in vulnerable areas and deceive HOI models. Extensive experiments conducted against multiple models demonstrate effectiveness in attacking interactions of HOI. Our approach surpasses existing methods by significant margins, achieving an improvement of at least +10.36%}.",
         "Reviewer_62sG",
         "1698744806152",
         "1699636152594",
         "3",
         "4",
         "3",
         "2",
         "2",
         "In this paper, the authors propose a black-box attack method against Human Object Interaction (HOI). The proposed method of Adversarial Instance Attacks (AIA) consists of an Interaction Area Sampling (IAS) module for finding the vulnerable areas, an Object Category Search (OCS) module for assigning the confusing category, and an Adversarial Instance Generation (AIG) module for attacking effects. The experiment validations on the V-COCO datasets are given to demonstrate its effectiveness on various models. 1. The proposed attack method is conducted in a new area, Human Object Interaction.\n2. Choosing the fragility of one image to attack is an interesting and reasonable idea for Human Object Interaction. 1. For the experiments, the comparisons between I-FGSM and PGD on detectors and the proposed method are unfair. The authors use the transfer results by I-FGSM and PGD to attack HOI, where the adversarial examples based on the architecture of detectors (e.g., Faster RCNN and YOLO ) are generated. Thus, these methods have a weak transferability across the different tasks. However, the proposed method has more knowledge about the attacked task instead of only detectors.\n2. The tasks of HOI highly rely on the results of detections. The existing attacks for detection can be directly employed in this task, leading to awful results. From the proposed method, the attacks aim to fool the interactions between the human and object, instead of the human and the object itself. If so, wrong detection results and boxes easily lead to wrong interactions. Thus, those attacks against object detection, especially for fooling the detection boxes should be involved in comparisons. Besides, why only attacking the interaction in HOI is worthy of investigating?\n3. Expect for the illustration in Figure 1, more visualizations with various methods (e.g., PGD and I-FGSM) should be involved to demonstrate its imperceptibility and effectiveness.\n4. There are some minor problems.\n- In the caption of Figure 1, ‘remaining0’ seems a typo.\n- Some formats of references are wrong and inconsistent. 1. The comparison between I-FGSM and PGD on detectors and the proposed method for HOI is unfair as the prior knowledge is different. \n2. Discuss the motivation for only attacking the interaction in HOI, and give some attack results on only attacking the detectors.\n3. Give more visual comparisons between various methods.",
         "378",
         "0",
         "9",
         "0.7396",
         "-0.036809991800000004",
         "0.9304254651",
         "51",
         "10",
         "38.47",
         "11.7752",
         "13.61",
         "13.1604",
         "11.7891",
         "0.1213",
         "81",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "75.0",
         "75.0",
         "neutral",
         "neutral"
        ],
        [
         "32",
         "zQXX3ZV2HE",
         "2189",
         "1695178042065",
         "['~Liang_Muxue1', '~Chuan_Wang1', '~Siyuan_Liang1', '~Aishan_Liu1', '~Zeming_Liu1', '~Liang_Yang2', '~Xiaochun_Cao3']",
         "Adversarial Instance Attacks for Interactions between Human and Object",
         "Adversarial attacks can easily deceive deep neural networks (DNNs); however, they are also valuable for evaluating the robustness of DNNs. Existing attacks on object detection primarily focus on attacking the recognition of objects, while whether the attacks remain effective on more complex scene understanding tasks (e.g., extracting the interaction between objects) remains largely unexplored. In this paper, we, for the first time, propose Adversarial Instance Attacks, a novel black-box attacking framework for scene interactions without interfering with object detections. To achieve the goal, we first introduce an Interaction Area Sampling module that identifies vulnerable anchors (area) for adversarial instances positioning. Secondly, we design an Object Category Search module and build an interaction co-occurrence knowledge graph to explore categories with higher obfuscation scores toward specific object-interaction pairs. Finally, our framework generates perturbations that serve as adversarial instances with high co-occurrence obfuscation towards specific interactions in vulnerable areas and deceive HOI models. Extensive experiments conducted against multiple models demonstrate effectiveness in attacking interactions of HOI. Our approach surpasses existing methods by significant margins, achieving an improvement of at least +10.36%}.",
         "Reviewer_L4HX",
         "1698933201485",
         "1699636152505",
         "5",
         "3",
         "3",
         "3",
         "2",
         "This paper proposed a new concept for adversarial attack on Human Object Interaction (HOI). Different from adversarial attack on object classification or detection, there was less work focused on HOI attack. In this paper, the main idea is to find a proper region in an image, where an invisible object is inserted and which will mislead the HOI classifier. To this end, three modules are proposed, i.e., Interaction Area Sampling module, Object Category Search module, and Adversarial Instance Generation module. + A novel adversarial attack is defined for human object interaction recognition task. HOI recognition task is a high-level task with respect to object classification or detection tasks. It motivation of this paper makes sense which is to insert an inviable object to mislead the HOI classifier. - My main concern is that the proposed attack is somewhat an untargeted attack for an HOI recognition system, where we cannot choose the target HOI category, instead, the target HOI category is determined by the method via finding the most confusing interaction. I am not sure the whether such attack will happen in real applications or not.\n- The proposed method is straightforward, which is combination of existing techniques such as Targeted adversarial Objectness Gradient attacks (TOG) in Adversarial Instance Generation module. Can we conduct a targeted adversarial attack for HOI recognition, which is that we can explicitly choose the target HOI category we want the attack achieves.",
         "236",
         "0",
         "0",
         "0.7818",
         "0.0552020202",
         "0.8878258467000001",
         "51",
         "8",
         "31.3614",
         "13.7087",
         "15.492",
         "14.435",
         "13.5447",
         "0.2084",
         "84",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "3",
         "3",
         "5.0",
         "4.0",
         "4.0",
         "partially factual",
         "65.0",
         "65.0",
         "neutral",
         "polite"
        ],
        [
         "33",
         "zLwCT9srfo",
         "7961",
         "1695491975818",
         "['~Julia_Gusak1', '~Xunyi_Zhao1', '~Théotime_Le_Hellard1', '~Zhe_LI20', '~Lionel_Eyraud-Dubois1', '~Olivier_Beaumont1']",
         "H-Rockmate: Hierarchical Approach for Efficient Re-materialization of Large Neural Networks",
         "Training modern neural networks poses a significant memory challenge, as storing intermediate results during the forward and backward passes demands substantial memory resources. To address this issue while maintaining model accuracy, re-materialization techniques have been introduced to recompute selected intermediate results rather than storing them, thereby adhering to peak memory constraints. The main algorithmic problem is to compute a re-materialization schedule that minimizes the computational overhead within a given memory budget. Our H-Rockmate framework builds upon an existing Rockmate solution and overcomes its limitation to work with sequential block structures by proposing a hierarchical approach. The framework performs an automatic decomposition of the data-flow graph into a hierarchy of small-scale subgraphs, and finds a re-materialization schedule for the whole graph by recursively solving optimization problems for each subgraph. H-Rockmate allows users to transform their PyTorch models into nn.Modules that execute forward and backward passes efficiently within the specified memory budget. This framework can handle neural networks with diverse data-flow graph structures, including U-Nets and encoder-decoder Transformers. H-Rockmate outperforms existing re-materialization approaches in terms of average training iteration time and peak memory trade-offs, demonstrating superior memory efficiency in training modern neural networks.",
         "Reviewer_u563",
         "1697419993497",
         "1701667998218",
         "6",
         "4",
         "3",
         "2",
         "3",
         "The authors proposed a hierachical (or devide and conquer) approach to make re-compute/materialize decision by:\n  1. partition the graph into subgraphs hierachically\n  2. apply a modified ILP solver (H-ILP) on solved subraphs recursively\n  3. additionally, the base solver for the leaf subgraphs of the (hierachical) tree is modularized to swap between different algos\n\nto address the issue of existing approaches which (are either ILP based thus) don't scale to large graph or fail to optimize more general graph with long skip connections like Unet. + The hierachical + ILP solution proposed by the authors is intuitive and practical in the sense that:\n  1. the search space of ILP based approach is too large to scale to graph with thousands of computational ops/nodes, a good graph partition can trim down the search space efficiently\n  2. non-ILP based approach has a hard time dealing with networks with long skip connections like UNET or ENCODER/DECODER architecutre.\n\n+ the base solver for the bottom/leaf subgraph is modularized, thus can swap to different algos as a graph/solver runtime tradeoff\n\n+ solid explanation/comparisons to related works/baselines, and the robustness to hierachy depth (figure 4) is a good indicator of its scalability to general/deep networks - The parition algorithms (especially the score function/cost model in equation 1) is a bit ad-hoc, I can grasp the intuition behind it, e.g., it tries to identify a subgraph with least IO and penalize on number of nodes in it so that it can minimize the memory required to checkpoint its IO while keeping the scale of each subgraph relatively small. However, graph partition is a long-studied problem and usually such a heuristic/greedy based algo don't scale very well in the sense that they are typically tailored for specific known targets and would fail overtime when target envolves, that being said, I would suggest:\n  1. try the partition algos on a densenet to see if it produces good result\n  2. alternatively make this partition algo also modularized as the solvers, what's more valuable/solid in this work is the intuitionn of hierachy (devide and conquer) and the H-ILP solver IMO\n\n- the presentation can be improved:\n  1. the 3.1 H-partition part contains a lot implementation details without much explanation where they come from, e.g., as is briefly mentioned above regarding equation (1), and additionally why do you need alpha and why is it 0.5, why did you choose 4 candidte groups in \"Formation of candidate groups\" rather than other numbers.\n   2. On the other hand, the caption of the most important figure 1 doesn't have enough details, what's the time vs memory plot? (I think they refer to options), what's direct solver (I only got base solvers for bottom subgraph and H-ILP hierachical solver), etc.\n   3. How does H-ROCKMATE beat the baselines in Unet/Encoder-Deccoders more concretely? An explanation or preferrably an illustrative exmaple would help readers understand the quality of it more intuitively. In addition to the questions in Weakness, here are a couple more questions:\n\n1. what does \"the higher level algorithm adapts the sub schedules\" conrectely mean in Correction terms for memory usage?\n\n2. would \"model = HRockmate(model, sample, memory_budget)\" work with Tensor Parallel packages like Megatron? as my guess of the implementation relies on model/graph tracing and Megatron can pose difficulties in such tracing due to collective communications.",
         "549",
         "0",
         "2",
         "0.8388",
         "0.020962909000000002",
         "0.7621635199",
         "71",
         "49",
         "40.7196",
         "13.434",
         "16.3634",
         "15.041",
         "15.1895",
         "0.1463",
         "76",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "34",
         "zLwCT9srfo",
         "7961",
         "1695491975818",
         "['~Julia_Gusak1', '~Xunyi_Zhao1', '~Théotime_Le_Hellard1', '~Zhe_LI20', '~Lionel_Eyraud-Dubois1', '~Olivier_Beaumont1']",
         "H-Rockmate: Hierarchical Approach for Efficient Re-materialization of Large Neural Networks",
         "Training modern neural networks poses a significant memory challenge, as storing intermediate results during the forward and backward passes demands substantial memory resources. To address this issue while maintaining model accuracy, re-materialization techniques have been introduced to recompute selected intermediate results rather than storing them, thereby adhering to peak memory constraints. The main algorithmic problem is to compute a re-materialization schedule that minimizes the computational overhead within a given memory budget. Our H-Rockmate framework builds upon an existing Rockmate solution and overcomes its limitation to work with sequential block structures by proposing a hierarchical approach. The framework performs an automatic decomposition of the data-flow graph into a hierarchy of small-scale subgraphs, and finds a re-materialization schedule for the whole graph by recursively solving optimization problems for each subgraph. H-Rockmate allows users to transform their PyTorch models into nn.Modules that execute forward and backward passes efficiently within the specified memory budget. This framework can handle neural networks with diverse data-flow graph structures, including U-Nets and encoder-decoder Transformers. H-Rockmate outperforms existing re-materialization approaches in terms of average training iteration time and peak memory trade-offs, demonstrating superior memory efficiency in training modern neural networks.",
         "Reviewer_piuX",
         "1698748954661",
         "1699636978684",
         "6",
         "3",
         "3",
         "4",
         "3",
         "This paper introduces H-Rockmate, which is a hierarchical approach to find a re-materialization strategy for large neural networks. It decomposes a dataflow graph into multi-level and find efficient solutions of each blocks in bottom level. A related ILP formulation is proposed to recombine low-level solutions. H-Rockmate can find similar performance as ROCKMATE in less time, making it more practical. 1.\tH-Rockmate proposes a hierarchical decomposition method for the computation graph. Thus the size of the ILP problem is smaller. Experiments show that efficiency and performance haven’t been compromised.\n2.\tOther re-materialization strategies can be integrated into their frameworks to achieve better performance.\n3.\tTheoretical analysis of their algorithm and ILP formulation is provided in the Appendix. 1.\tSince they claim H-Rockmate works for large neural networks, the sizes of neural networks used in experiments are the same as other works.\n2.\tThere are some typos in the Appendix, such as “line ??”. 1.\tIf H-Rockmate is applied to a billion-level neural networks like LLaMA, how will the peak memory and iteration time be? I think experiments with larger neural networks than GPT2 is necessary.\n2.\tCan you introduce what constraints are considered in your main part of the paper and introduce detailed expressions in Appendix？\n3.\tWhat if modeling on-chip global memory to get a better scheduling? Can your method support this?",
         "222",
         "0",
         "8",
         "0.8209000000000001",
         "0.1093984962",
         "0.9032994509000001",
         "47",
         "10",
         "42.3728",
         "10.7806",
         "14.2128",
         "13.0239",
         "11.36",
         "0.2429",
         "81",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "4",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "35",
         "zLwCT9srfo",
         "7961",
         "1695491975818",
         "['~Julia_Gusak1', '~Xunyi_Zhao1', '~Théotime_Le_Hellard1', '~Zhe_LI20', '~Lionel_Eyraud-Dubois1', '~Olivier_Beaumont1']",
         "H-Rockmate: Hierarchical Approach for Efficient Re-materialization of Large Neural Networks",
         "Training modern neural networks poses a significant memory challenge, as storing intermediate results during the forward and backward passes demands substantial memory resources. To address this issue while maintaining model accuracy, re-materialization techniques have been introduced to recompute selected intermediate results rather than storing them, thereby adhering to peak memory constraints. The main algorithmic problem is to compute a re-materialization schedule that minimizes the computational overhead within a given memory budget. Our H-Rockmate framework builds upon an existing Rockmate solution and overcomes its limitation to work with sequential block structures by proposing a hierarchical approach. The framework performs an automatic decomposition of the data-flow graph into a hierarchy of small-scale subgraphs, and finds a re-materialization schedule for the whole graph by recursively solving optimization problems for each subgraph. H-Rockmate allows users to transform their PyTorch models into nn.Modules that execute forward and backward passes efficiently within the specified memory budget. This framework can handle neural networks with diverse data-flow graph structures, including U-Nets and encoder-decoder Transformers. H-Rockmate outperforms existing re-materialization approaches in terms of average training iteration time and peak memory trade-offs, demonstrating superior memory efficiency in training modern neural networks.",
         "Reviewer_J4PJ",
         "1699177659177",
         "1699636978582",
         "3",
         "4",
         "3",
         "2",
         "2",
         "This paper tries to solve the problem of efficient scheduling of re-materialization of the training computation. Concretely, the paper proposes H-rockmate, a hierarchical solution to decompose the data-flow graph into a hierarchy of small-scale subgraphs and compute a re-materialization schedule that minimizes the computational overhead within a given memory budget. Empirical studies are conducted to evaluate the performance of the proposed method in terms of solver efficiency and end-to-end performance. - The summarization of this research area is clear and accurate; the related work section is well-organized.\n\n- The intuition behind the scheduling algorithm design is clear and straightforward.   \n\n- Based on the reported experimental results, the reduction of the solver execution time is significant. - The writing of the paper can be significantly improved. First of all, there is a lack of a formal definition for the scheduling problem itself -- the current introduction of the problem is interweaved with the problem statement in Section 3.1. Additionally, section 3.2 is too casual; there is a lack of enough formalization about the mathematical representation of the problem -- I notice plenty of important information is left in the appendix. I do not think this is an appropriate trade-off; the technique content should be self-explained within the scope of the paper.   \n\n- I am a little confused by the presented results in Figure 3; I was expecting that when the budget is very low, every algorithm should be able to find the scheduling of re-computing every activation, while when the budget is very high, every algorithm should be able to find the scheduling of no-recomputation, but still there is some difference between each line. This was confusing. Additionally, the important hyper-parameters, such as batch size, are not enumerated in Section 4. \n\n- Another trivial detail is that the font style differs from other submissions I reviewed; please check the instructions to ensure you are using the requested font style. See my comments in the Weakness section.",
         "325",
         "0",
         "0",
         "0.7376",
         "0.0940166667",
         "0.8504388928000001",
         "47",
         "5",
         "31.936700000000002",
         "13.7268",
         "16.1269",
         "15.3315",
         "13.9392",
         "0.4828",
         "86",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "75.0",
         "75.0",
         "neutral",
         "polite"
        ],
        [
         "36",
         "zH6zBoktYO",
         "8000",
         "1695493297402",
         "['~Neel_Jain1', '~Khalid_Saifullah1', '~Yuxin_Wen2', '~John_Kirchenbauer1', '~Manli_Shu1', '~Aniruddha_Saha1', '~Micah_Goldblum1', '~Jonas_Geiping1', '~Tom_Goldstein1']",
         "Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models",
         "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set, which can lead to misleading evaluations. To alleviate the issues in traditional evaluation, we propose a complementary framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-sensitivity and human-supervised evaluations. The self-sensitivity paradigm complements current evaluation strategies that rely on labeled data.",
         "Reviewer_KAMN",
         "1698750843403",
         "1699636985472",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper presents a framework for self-supervised evaluation of Large Language Models (LLMs) by proposing a series of sensitivity (invariance) metrics that assess various aspects of language model behavior without the need for human-labeled datasets. These metrics evaluate the models based on their reaction to input transformations concerning knowledge via negations, toxicity, and word order. The authors claim that these self-supervised evaluation methods can complement traditional supervised benchmarks and provide efficient evaluation in real-world settings. - The proposed self-supervised evaluation framework addresses the significant challenge of evaluating LLMs without the extensive need for labeled datasets, which is a common bottleneck.\n\n- The authors provide empirical evidence that correlates the proposed self-supervised metrics with existing supervised benchmarks, lending credibility to their approach.\n\n- By analyzing how LLMs react to various textual transformations, the paper offers deeper insights into the behavior and limitations of these models, which can inform future research and model development. - The paper acknowledges model entropy as a factor that could influence sensitivity scores but does not explore it in detail. Understanding how the entropy of a model's output distribution affects evaluation metrics is crucial for interpreting results accurately.\n\n- The main methods proposed in this work—knowledge probing via negations, toxicity detection, and word order—seem to be presented as separate entities without a unifying theme or rationale that clearly ties them together. The paper could benefit from a more cohesive narrative that explains how these methods collectively advance the understanding and evaluation of LLMs.\n\n- The proposed methods, such as adding \"not\" after certain words for negation or appending trigger words for toxicity, may seem too basic or trivial. This simplicity could lead to questions about the depth and sophistication of the approach, as well as its ability to capture the nuances of language and behavior of LLMs. The straightforward nature of the methods may not generalize well to the complex and varied inputs that LLMs encounter in real-world applications. The paper might not demonstrate that the methods can handle different linguistic constructions, idiomatic expressions, or contextual nuances.\n\n- The motivation behind each method is not evidently articulated. While each method addresses a different aspect of language model behavior, the paper may not clearly explain why these particular aspects are chosen and how they complement each other in providing a comprehensive evaluation.\n\n- The methods may not be backed by a comprehensive set of experiments to validate their effectiveness across different models, domains, prompts, and languages. This could be seen as lacking in terms of the breadth and depth of experimental validation. - Could you explain the rationale behind the simplicity of the proposed methods? How do you ensure that such straightforward techniques can provide a robust evaluation of complex LLM behaviors?\n\n- To what extent did you consider more sophisticated prompt engineering in your evaluation framework? Could you elaborate on how different prompt designs might affect the outcomes of your proposed metrics? For example, how could changing the position of trigger words in toxicisy detection influence the outcome?\n\n- Can you discuss any additional experiments that might demonstrate the robustness of your evaluation methods across different languages, dialects, or domains?\n\n- How might the entropy of a model's output distribution or its propensity for memorization affect the outcomes of your self-supervised evaluation metrics?\n\n- What steps did you take to mitigate the impact of potential confounding factors, such as model overfitting or exposure to similar data during training, on your evaluation results?",
         "575",
         "0",
         "0",
         "0.8257",
         "0.0663548753",
         "0.9400341511",
         "47",
         "10",
         "20.8135",
         "15.7261",
         "18.6817",
         "16.7589",
         "16.8104",
         "0.3442",
         "95",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "37",
         "zH6zBoktYO",
         "8000",
         "1695493297402",
         "['~Neel_Jain1', '~Khalid_Saifullah1', '~Yuxin_Wen2', '~John_Kirchenbauer1', '~Manli_Shu1', '~Aniruddha_Saha1', '~Micah_Goldblum1', '~Jonas_Geiping1', '~Tom_Goldstein1']",
         "Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models",
         "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set, which can lead to misleading evaluations. To alleviate the issues in traditional evaluation, we propose a complementary framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-sensitivity and human-supervised evaluations. The self-sensitivity paradigm complements current evaluation strategies that rely on labeled data.",
         "Reviewer_tXds",
         "1698786794121",
         "1699636985358",
         "5",
         "3",
         "3",
         "3",
         "3",
         "The paper introduces a new self-supervised approach to the evaluation of LLMs, alleviating the need for small domain-specific datasets with human-curated labels as in traditional evaluations. The new evaluation method, on a higher level, is through analyzing invariances and sensitivities to transformations. The work provides detailed case studies on several self-supervised evaluation strategies for different aspects of LLMs, including those related to negations, toxicity detection, long-range dependency, and sensitivity to word order, etc. Strong correlations have been shown between the designed self-supervised evaluation metrics and human-supervised evaluations. - **Originality**: This paper offers a fresh approach to the evaluation of LLMs, moving away from dataset-bound evaluations to a sustainable assessment methodology.\n  \n- **Quality**: The transformations, like handling of negations, word order changes, and others, are impressive steps toward achieving a holistic evaluation of LLMs. \n  \n- **Clarity**: The paper is accessible to even readers that are unfamiliar with the domain. The delineation of their methods and results is commendable.\n  \n- **Significance**: The paper’s methodology, if thoroughly verified and broadly adopted, has the potential to revolutionize how LLM evaluations are conducted, making them more dynamic, comprehensive, and reflective of real-world applications. - **Terminological Ambiguity**: The usage of \"self-supervised\" is somewhat misleading. Given the context of this paper, an alternative term or a more precise explanation would be helpful.\n\n- **Metric Soundness**: While the paper puts forth several innovative metrics, further clarity and validation are needed. For example, the paper justifies its methods heavily by calculating the correlation between proposed scores and one specific existing task. Then I believe a natural question arises – if, for example, having high correlation with TriviaQA alone is enough to demonstrate the legitimacy of SSE, then why don’t we just use TriviaQA accuracy (and also HellaSwag) as the evaluation metric? I am therefore doubtful of the significance of the proposed metrics.\n \n \n- **Questionable Conclusion**: Following up on the comment on the correlation analysis, the paper tries to prove the usefulness of their metrics by showing correlation with existing task on some metrics (e.g. TriviaQA accuracy), but also tries to disprove other evaluation metrics by showing they correlate less nicely with their proposed metrics. For example, the paper concludes perplexity is not a robust evaluation metric because it does not have a very high correlation with SSE; the Cohere Command model is an outlier in their analysis which highlights a weakness of TriviaQA.\n\n- **Visualization**: The visualization in this paper is unfriendly to people with color vision deficiency if not anyone. I find it very hard to distinguish to the difference in the sizes and colors in the figures representing different models. - Can authors provide some examples of how they perform the transformations to evaluate long-range sensitivity.\n\n- How do you identify the neutral corpus?\n\n- “We further explore why correct normalization is important by cross-referencing the frequency with which perplexity goes down rather than up, see Figure 14 in Appendix A.5.” from the figure I see a nice negative correlation between “Percent PPL Drops” and TriviaQA accuracy. So how can this show correct normalization is import in SSE?\n\n- What data do the metric PPL use? Following this paper’s logic, I think the first step this paper should do is to evaluate the correlation between, for example, normalized PPL and TriviaQA accuracy (and other realistic tasks such as MMLU etc).\n\n- How well do toxicity scores by this paper correlate with those by Perspective API on instruction tuned models? From figure 6 left, it looks like there are no Xs. Same question for word order section and figure 4, 7. Without the results of instruction tuned models, it is hard to see if the scores correlate better on vanilla models than instruction tuned models. And therefore hard to assess the significance of the metrics.\n\n- It is still hard for me to understand how to use this paper in real-world applications. How adaptable are these proposed metrics? Would the methodology need alterations to assess LLMs in more dynamic, real-world scenarios?\n\n- Given the terminological ambiguity around \"self-supervised,\" can authors elaborate on this terminology or propose an alternative name to prevent misconceptions?",
         "684",
         "0",
         "0",
         "0.7944",
         "0.0862385928",
         "0.8980768919000001",
         "47",
         "9",
         "24.8802",
         "14.3988",
         "16.8833",
         "15.4333",
         "14.4001",
         "0.1651",
         "85",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "moderate",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "5",
         "90.0",
         "90.0",
         "neutral",
         "polite"
        ],
        [
         "38",
         "zH6zBoktYO",
         "8000",
         "1695493297402",
         "['~Neel_Jain1', '~Khalid_Saifullah1', '~Yuxin_Wen2', '~John_Kirchenbauer1', '~Manli_Shu1', '~Aniruddha_Saha1', '~Micah_Goldblum1', '~Jonas_Geiping1', '~Tom_Goldstein1']",
         "Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models",
         "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set, which can lead to misleading evaluations. To alleviate the issues in traditional evaluation, we propose a complementary framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-sensitivity and human-supervised evaluations. The self-sensitivity paradigm complements current evaluation strategies that rely on labeled data.",
         "Reviewer_cArL",
         "1698793273308",
         "1699636985240",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper presents a self-supervised method for evaluating LLMs without relying on domain-specific, human-annotated datasets. The authors detail a structured approach for self-supervised evaluation, focusing on LLM invariances and sensitivities. Preliminary tests indicate a correlation between their proposed metrics and established ones that depend on human annotations. - Originality: The paper unveils a fresh evaluation technique for Large Language Models that minimizes human intervention. This addresses the shortcomings of conventional methods and provides an alternative measure of a model's capabilities.\n- Their approach can be adapted to different data domains by simply varying the unlabeled text in evaluations. Such as the clinical setting, where they show their method has a good correlation with MMLU (clinical). - Weak evidence for the robustness of this method: In my opinion, using the correlation to TriviaQA's accuracies to prove their usefulness seems to be a bit of weak evidence, especially when only ~10+ models are considered in the experiments. The correlation results can be simply affected by noises/outliners. For example, you mentioned that \"The Pearson correlation between TriviaQA and Normalized sensitivity score is 0.76 for vanilla models and 0.73 for instruction models after removing the Cohere Command outlier\". It proves that the evaluation method is a little bit brittle. When I have a new model that wants to be tested, how can I know my model is not another outlier?\n- I would suggest the authors increase the number of models to 100+, so as to reduce the effects of noise when computing the correlations. If there are not enough LLMs to be tested, one of the strategies you can use is to do early exiting from the models \\[1\\] so that you can get different outputs from different layers of the model, representing different levels of understanding of the data, and thus increase the number of total data points to be compared.\n\n\\[1\\] Eliciting Latent Predictions from Transformers with the Tuned Lens\nNora Belrose, Zach Furman, Logan Smith, Danny Halawi, Igor Ostrovsky, Lev McKinney, Stella Biderman, Jacob Steinhardt https://arxiv.org/abs/2303.08112 - In figure 3, 4, 6, and 7, why the models used for comparison is changing all the time? In figure 3 there are 28 data points but in figure 7 there are only 11 data points. What's your standard of selecting these models to be evaluated? I think it's better to include all the models throughout the experiments to reduce the effects of noise/outliers. The experiment results presented make me feel that some of the results are hidden so the correlation may not be that good if we add them back to the figure.",
         "431",
         "3",
         "0",
         "0.7772",
         "0.0634541847",
         "0.9203519225000001",
         "47",
         "9",
         "39.0316",
         "12.6257",
         "15.0694",
         "14.2253",
         "13.0367",
         "0.2889",
         "87",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "low",
         "4.0",
         "4",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "39",
         "zH6zBoktYO",
         "8000",
         "1695493297402",
         "['~Neel_Jain1', '~Khalid_Saifullah1', '~Yuxin_Wen2', '~John_Kirchenbauer1', '~Manli_Shu1', '~Aniruddha_Saha1', '~Micah_Goldblum1', '~Jonas_Geiping1', '~Tom_Goldstein1']",
         "Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models",
         "With the rise of Large Language Models (LLMs) and their ubiquitous deployment in diverse domains, measuring language model behavior on realistic data is imperative. For example, a company deploying a client-facing chatbot must ensure that the model will not respond to client requests with profanity. Current evaluations approach this problem using small, domain-specific datasets with human-curated labels. These evaluation sets are often sampled from a narrow and simplified distribution, and data sources can unknowingly be leaked into the training set, which can lead to misleading evaluations. To alleviate the issues in traditional evaluation, we propose a complementary framework for self-supervised evaluation of LLMs by analyzing their sensitivity or invariance to transformations on the input text. Self-supervised evaluation can directly monitor LLM behavior on datasets collected in the wild or streamed during live model deployment. We demonstrate self-supervised evaluation strategies for measuring closed-book knowledge, toxicity, long-range context dependence, in addition to sensitivity to grammatical structure and tokenization errors. When comparisons to similar human-labeled benchmarks are available, we find strong correlations between self-sensitivity and human-supervised evaluations. The self-sensitivity paradigm complements current evaluation strategies that rely on labeled data.",
         "Reviewer_AbSH",
         "1699916249271",
         "1699916404107",
         "3",
         "4",
         "2",
         "3",
         "2",
         "The paper presents a self-supervised evaluation approach for toxicity classifiers. The paper cites that due to training data leakage, toxicity classifiers may have an inflated reported performance. Using the proposed approach where inputs are modified using negation and other techniques, the robustness of content classifiers is evaluated. The paper has the following strengths.\n\nFirst, it is well-written. The paper motivates the problem well, experiments are described clearly. Related work descriptions are reasonable (although the paper missed some key citations, e.g., Gröndahl et al.). \n\nSecond, the motivation for building a domain-specific toxicity classifier is well-received. The key weakness of the paper is:\n\n1. The modifications it is suggesting are too simplistic (e.g., F-bombing). There are many known modifications that have tripped content classifiers before (e.g., All You Need is \"Love\": Evading Hate Speech Detection by Gröndahl et al.) or examples of real-world examples tripping content classifiers (e.g., Are Chess Discussions Racist? An Adversarial Hate Speech Data Set by Sarkar and KhudaBukhsh). Instead of using obfuscation techniques well-grounded in literature, the paper adopts simplistic techniques to modify inputs.  \n\n2. The second weakness of the paper is it relies on Perspective API. Perspective API's toxic scores are not reliable. Recent research indicates that. Hence, an API that itself has calibration issues cannot be very useful for calibrating other systems. My questions are how would the authors respond to my two weaknesses listed above?",
         "230",
         "0",
         "2",
         "0.794",
         "-0.05675",
         "0.7675612569",
         "51",
         "0",
         "39.1619",
         "10.3942",
         "13.3992",
         "12.0793",
         "11.4429",
         "0.30110000000000003",
         "82",
         "0",
         "1",
         "0",
         "0",
         "3.0",
         "low",
         "4.0",
         "3",
         "3",
         "4",
         "3.0",
         "5.0",
         "4.0",
         "partially factual",
         "65.0",
         "65.0",
         "negative",
         "polite"
        ],
        [
         "40",
         "zEOnlJaRKp",
         "167",
         "1694772573802",
         "['~Jianan_Zhou1', '~Yaoxin_Wu2', '~Zhiguang_Cao1', '~Wen_Song1', '~Jie_Zhang9']",
         "Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems",
         "While enjoying desirable efficiency and less dependence on domain expertise, existing neural methods for vehicle routing problems (VRPs) are vulnerable to adversarial attacks -- their performance drops drastically on adversarial instances, i.e., clean instances with crafted perturbations. To enhance the robustness, we propose a Collaborative Neural Framework (CNF) w.r.t the adversarial defense of neural methods for VRPs, which is crucial yet underexplored in literature. Given a neural method, we adversarially train multiple models in a collaborative manner to synergistically promote the robustness against attacks, while maintaining (or even boosting) the standard generalization on clean instances. A neural router is designed to elegantly distribute instances to each model, which improves load balancing and collaborative performance. Extensive experiments verify the effectiveness and versatility of CNF to defend against various attacks for different neural methods. Notably, our trained models also achieve decent out-of-distribution generalization performance on real-world benchmark instances.",
         "Reviewer_4zRf",
         "1698726633349",
         "1700725165287",
         "6",
         "4",
         "3",
         "4",
         "2",
         "This paper presents a systematic study of the adversarial training of neural network solvers for TSP and CVRP. The methodology part extends the adversarial training pipeline by ensembling multiple models, leading to the so-called CNF approach in this paper. Experiments are conducted on TSP and CVRP, with adversarial samples mainly generated by (Zhang et al., 2022). * This paper is well-written and easy to follow. I could see the efforts of the authors in the organization and the figures.\n* Robustness in solving routing problems is an important measure and worth studying.\n* The experiment study seems extensive and in general seems sound. * The authors believe that model degeneration on clean data is an important issue, and propose the Collaborative Neural Framework to solve it. However, the motivation for developing such a collaborative framework is not clear. The authors only mentioned that collaboration will mitigate existing issues in adversarial training, but do not explain why. From my side, the reason for the improvements brought by \"collaboration\" is quite straightforward and trivial: \"collaboration\" in this paper means training multiple models in adversarial training and using all of them to predict on the same problem instance. Since we are studying an optimization problem where solution evaluation is very fast, we can easily generate multiple predictions using multiple models and pick the best one. Therefore, it is not surprising that \"collaborated\" models are way better than standalone AT models. \n* One step further on the previous point, it is not surprising to see that the performance of Collaborative Neural Framework is kept on clean instances after adversarial training. One can achieve similar results in Figure 1 by simply freezing one model on the clean data and doing adversarial training on the other models. The \"collaborated\" model will never degenerate on the clean data.\n* The improvements brought by the interesting neural router module seem only marginal. As read from Table 1, there are significant performance improvements when 1) from POMO to POMO_AT (add adversarial training), and 2) from POMO_AT (1) to POMO_AT (3) (use 3 models together, i.e., collaboration). Adversarial training seems not an original contribution in this paper; Collaboration, as discussed above, is not surprising to bring a significant improvement. While with the only technically sound module, the improvement from POMO_AT (3) to CNF (3) is not that significant.\n* The authors made the claim on Page 2 that \"simply increasing the model capacity\" will not help Adversarial Training to generalize better, but I do not find any experimental evidence to support that in the main paper.\n### Minor Points\n* In the title: in combinatorial optimization's convention, VRP is usually considered different from TSP. However, in this paper, the authors seem to call both TSP and CVRP \"subsets of VRP\". I believe it will cause confusion and would suggest changing the naming to \"routing problems\".\n* Please explain \"OOD\" in Section 4.3 to make it self-contained.\n* Not sure if it is proper to call all Reinforcement Learning methods as \"REINFORCE\" in Eq (1) because the RL algorithms deployed nowadays usually integrate many more tricks than the vanilla form in Eq (1). * The authors mentioned three papers on the adversarial robustness of CO, and based the major experiment study in the main paper on (Zhang et al. 2022). From my understanding, the other two papers (Geisler et al., 2022) and (Lu et al., 2023) considered the \"hardness\" of the CO problem itself (i.e., there are some guarantees on the optimal objective), while (Zhang et al., 2022) only considered the objective score solved by an existing solver. Can the author justify the reason of selecting (Zhang et al., 2022) as the main experiment protocol?\n* Do the neural network know the behavior of the attacker during training? I.e., are the adversarial data points generated by the attacker in the test dataset?",
         "641",
         "5",
         "1",
         "0.7954",
         "0.1382103825",
         "0.8802164197000001",
         "68",
         "23",
         "41.9616",
         "11.6231",
         "13.9229",
         "13.4172",
         "11.7013",
         "0.426",
         "87",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "low",
         "5.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "41",
         "zEOnlJaRKp",
         "167",
         "1694772573802",
         "['~Jianan_Zhou1', '~Yaoxin_Wu2', '~Zhiguang_Cao1', '~Wen_Song1', '~Jie_Zhang9']",
         "Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems",
         "While enjoying desirable efficiency and less dependence on domain expertise, existing neural methods for vehicle routing problems (VRPs) are vulnerable to adversarial attacks -- their performance drops drastically on adversarial instances, i.e., clean instances with crafted perturbations. To enhance the robustness, we propose a Collaborative Neural Framework (CNF) w.r.t the adversarial defense of neural methods for VRPs, which is crucial yet underexplored in literature. Given a neural method, we adversarially train multiple models in a collaborative manner to synergistically promote the robustness against attacks, while maintaining (or even boosting) the standard generalization on clean instances. A neural router is designed to elegantly distribute instances to each model, which improves load balancing and collaborative performance. Extensive experiments verify the effectiveness and versatility of CNF to defend against various attacks for different neural methods. Notably, our trained models also achieve decent out-of-distribution generalization performance on real-world benchmark instances.",
         "Reviewer_APh6",
         "1698806483129",
         "1699635942254",
         "5",
         "3",
         "2",
         "3",
         "2",
         "To solve vehicle routing problems’ (VRPs) vulnerability to adversarial examples and existing adversarial training methods do not strike a good balance between generalization (on clean instances) and robustness (on adversarial instances). The Collaborative Neural Framework (CNF) is proposed by the authors, but some descriptions in the paper are not very accurate and clear. The novelty is also limited. The following are some of my doubts and suggestions for the paper, hoping to improve the quality of the paper. The content of this paper is practical and valuable. The experiment of the paper is relatively sufficient. (1) This paper describes adversarial examples in the field of image processing, but does not give a formal definition of adversarial examples in the field of VRPS, and suggests adding a formal definition of adversarial examples in the field of VRPS.\n\n(2) When the number of trained models is listed in Figure 1, it is only increased to 5. Perhaps when the number of models increases, the traditional adversarial training method can exceed the method proposed in the paper. Therefore, it is suggested to increase the number of trained models to demonstrate the effectiveness of the method. \n\n(3) The basis for selecting an attacker is not elaborated, and it is suggested to prove the generality of the selected attacker.\n\n(4) At the end of the paper, experiments are conducted on the out of distribution data, but the relationship between OOD data’s performance and the adversarial robustness is not explained in detail, so it is suggested to elaborate. (1) During the Outer Minimization of CNF, there are three instance types, namely \"ori\", \"local attack\" and \"global attack\". How to prove that the instance of \"global attack\" improves the effectiveness of the method? It is suggested to add experiments in this part or give theoretical explanations.\n(2) In the Outer Minimization stage of CNF, a neural router is trained. Will training a neural router seriously increase the training time? It is suggested to clarify in the paper.",
         "330",
         "0",
         "0",
         "0.6622",
         "0.0738705739",
         "0.9385450482000001",
         "56",
         "9",
         "39.023",
         "12.3709",
         "14.9697",
         "13.985",
         "12.2858",
         "0.088",
         "89",
         "0",
         "2",
         "0",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "85.0",
         "85.0",
         "neutral",
         "polite"
        ],
        [
         "42",
         "zEOnlJaRKp",
         "167",
         "1694772573802",
         "['~Jianan_Zhou1', '~Yaoxin_Wu2', '~Zhiguang_Cao1', '~Wen_Song1', '~Jie_Zhang9']",
         "Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems",
         "While enjoying desirable efficiency and less dependence on domain expertise, existing neural methods for vehicle routing problems (VRPs) are vulnerable to adversarial attacks -- their performance drops drastically on adversarial instances, i.e., clean instances with crafted perturbations. To enhance the robustness, we propose a Collaborative Neural Framework (CNF) w.r.t the adversarial defense of neural methods for VRPs, which is crucial yet underexplored in literature. Given a neural method, we adversarially train multiple models in a collaborative manner to synergistically promote the robustness against attacks, while maintaining (or even boosting) the standard generalization on clean instances. A neural router is designed to elegantly distribute instances to each model, which improves load balancing and collaborative performance. Extensive experiments verify the effectiveness and versatility of CNF to defend against various attacks for different neural methods. Notably, our trained models also achieve decent out-of-distribution generalization performance on real-world benchmark instances.",
         "Reviewer_8oTe",
         "1699464036344",
         "1699635942134",
         "5",
         "3",
         "2",
         "3",
         "3",
         "In this paper, the authors focused on enchance the robustness and generalization of vehicle routing problems. The proposed Collaborative Neural Framework (CNF) enhances robustness by adversarially training multiple models to work together, thus improving defense against attacks and potentially increasing generalization on clean instances. This approach is supported by experimental evidence showing that CNF effectively defends against a range of attacks and also performs well on real-world benchmark instances. 1. The exploration of robustness within the context of vehicle routing problems represents a critical area of research that has received limited attention in prior studies. This paper makes a commendable contribution to the field by addressing this gap.\n\n2. The proposed method CNF stands out for its novelty. It builds upon the established principles of min-max optimization, fundamental to adversarial training, which ostensibly enhances the robustness of the model. The efficacy of CNF is further substantiated by the empirical results presented within the study. 1. It seems that the adversarial attack introduced in this model has no attack budget. While acknowledging the distinctions between Vehicle Routing Problems (VRPs) and image-based tasks, it is important to note that the intrinsic discreteness of VRPs does not preclude the assignment of an attack budget, as demonstrated in adversarial settings pertinent to GNNs. The reviewer posits that evaluating the model's performance across various attack budgets is crucial for addressing the balance between clean accuracy and robust accuracy.\n\n2. In the context of graph-based tasks, the absence of constraints on an adversary typically facilitates a significant degradation in performance, often to levels below random chance. Nevertheless, according to Table 1, the vanilla model's performance does not seem to be significantly compromised. Could the authors elucidate the factors that might be contributing to this unexpected resilience?\n\n3. A considerable volume of literature \\[1-5\\] suggests that adversarial data augmentation can bolster generalization capabilities, particularly when the adversarial perturbations involved are small. Should the CNF enhance generalization as well, would this imply that the adversarial attack delineated within this study is potentially suboptimal in terms of its strength?\n\n\\[1\\] Xie et al. Adversarial examples improve image recognition. CVPR 2020.\n\n\\[2\\] Herrmann et al. Pyramid adversarial training improves vit performance. CVPR 2022.\n\n\\[3\\] Wen et al. Adversarial cross-view disentangled graph contrastive learning. 2022\n\n\\[4\\] Kong et al. Robust optimization as data augmentation for large-scale graphs. CVPR 2022.\n\n\\[5\\] Cheng et al. Advaug: Robust adversarial augmentation for neural machine translation. 2020 See weaknesses",
         "403",
         "5",
         "17",
         "0.8363",
         "0.0853918651",
         "0.9295349717",
         "56",
         "1",
         "23.115",
         "13.7433",
         "16.3922",
         "14.5546",
         "14.3981",
         "0.1041",
         "94",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "80.0",
         "80.0",
         "positive",
         "polite"
        ],
        [
         "43",
         "zEOnlJaRKp",
         "167",
         "1694772573802",
         "['~Jianan_Zhou1', '~Yaoxin_Wu2', '~Zhiguang_Cao1', '~Wen_Song1', '~Jie_Zhang9']",
         "Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems",
         "While enjoying desirable efficiency and less dependence on domain expertise, existing neural methods for vehicle routing problems (VRPs) are vulnerable to adversarial attacks -- their performance drops drastically on adversarial instances, i.e., clean instances with crafted perturbations. To enhance the robustness, we propose a Collaborative Neural Framework (CNF) w.r.t the adversarial defense of neural methods for VRPs, which is crucial yet underexplored in literature. Given a neural method, we adversarially train multiple models in a collaborative manner to synergistically promote the robustness against attacks, while maintaining (or even boosting) the standard generalization on clean instances. A neural router is designed to elegantly distribute instances to each model, which improves load balancing and collaborative performance. Extensive experiments verify the effectiveness and versatility of CNF to defend against various attacks for different neural methods. Notably, our trained models also achieve decent out-of-distribution generalization performance on real-world benchmark instances.",
         "Reviewer_ko2G",
         "1699594966148",
         "1700712381908",
         "6",
         "4",
         "2",
         "3",
         "3",
         "This paper proposed a novel adversarial training based framework (CNF) on VRP tasks by generating global adversarial examples on a set of collaborative formed models, and distributing these samples through a well-designed attention-based neural router to perform effective joint adversarial training. The proposed method, CNF, is claimed to achieve better performance on both accuracy and robustness perspective. Experiments has been conducted by comparing CNF with various baselines on TSP and CVRP tasks. Results looks promising - CNF (3) achieves much better vanilla accuracy and robustness with large gap compared with existing baselines. Extensive ablation studies and analysis has been well presented to show the effectiveness of CNF. The whole paper contains enough experimental details and the overall writing is clear. - The overall novelty is okay but it is interesting to see when it is applied to VRP tasks.\n- Impressive experimental results - proposed CNF is better than other AT baslines by a quite large margin on TSP task.\n- Detailed experimental setup and solid experimental analysis. I really love reading the Section 4.3 OOD generalization part - most of the robust training algorithm do not consider such scenario.\n- The whole paper is well-written. Especially for Section 3, it is well-organized for reader to follow the exact CNF pipeline. - No training efficiency was discussed while compared with other baselines. According to Algorithm 1, the training cost is largely relied on n, k and for neural router, its inference time is also heavily relied on K. We should have a column showing the exact training time for CNF and other baselines to achieve the table numbers.\n- Notation is quite unclear: in Algorithm 1, n refers to the iterating variable from 1 to B and for later sections, n refers to the total number of generated samples. In Section 3.2, the captital N was introduced to refer the total number of instances. Also k refers to the attack steps while the capital K refers to the topK samples selected for neural router. However, in Section 4.2, the calligraphic K is also used to refer the topK parameter. This makes reader get confused while checking the experimental details. - (Included in Weakness part) Can you provide the total training time for both CNF and other baselines shown in Table 2? \n- You include the diversity-enhanced ensemble training methods (GAL) as one of baseline methods. However, it has been proved to be not that strong compared with other recent robust ensemble training methods, such as ADP, DVERGE, TRS. Especially for DVERGE, it also claimed to have well-balance between benign accuracy and robust accuracy by crafting adversarial examples on each submodels vulnerability region and reducing adversarial transferability between submodels. It would be interesting to see how DVERGE would perform on the VRP tasks.\n- I'm still quite confused about your inference setup. Given M models you have, it looks unfair to just report the best gap among all models on each instance as the actual robustness: attacker should have the prior information of each models' vulnerability to the attack instance so you should report the worst gap instead. From your side, you do not have the information about the ground-truth so you cannot always choose the best performed model against the unseen attack instances.\n\n\n=============================================================\n\nUpdates:\n\nI thank authors for conducting additional experiments and further clarifying paper notations. These new results and experimental details largely addressed my major concerns. However, I'm still quite confused about the inference reporting metric (Q.3): considering the white-box attack setting, attacker should have all information about your routing strategy and generate adv instances for the whole system instead of the best-performed model. Author should elaborate more on this. I will keep my score but raise my confidence to 4.",
         "623",
         "0",
         "0",
         "0.8047000000000001",
         "0.1379129204",
         "0.7871162891",
         "68",
         "12",
         "43.2301",
         "11.3253",
         "13.2175",
         "12.8439",
         "12.0945",
         "0.7458",
         "88",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "low",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "95.0",
         "95.0",
         "positive",
         "polite"
        ],
        [
         "44",
         "z7usV2BlEE",
         "7016",
         "1695451488958",
         "['~Peiyi_Wang1', '~Lei_Li14', '~Liang_Chen10', '~Feifan_Song1', '~Binghuai_Lin1', '~Yunbo_Cao3', '~Tianyu_Liu3', '~Zhifang_Sui1']",
         "Making Large Language Models Better Reasoners with Alignment",
         "Reasoning is a cognitive process of using evidence to reach a sound conclusion.\nThe reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent.\nRecent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. \nHowever, we find that the fine-tuned LLMs suffer from an \\textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities.\nIn this paper, we introduce an \\textit{Alignment Fine-Tuning (AFT)} paradigm with a novel \\textit{Constrained Alignment Loss} to alleviate the assessment misalignment problem.\nSpecifically, the proposed loss has two objectives:\na) Alignment, which guarantees the  scores of high-quality COTs surpass that of subpar ones;\nb) Constraint, which keeps the subpar scores confined to a reasonable range to prevent the model degradation.\nExtensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.\nAFT also performs well in multi-task and out-of-distribution situations.\nFurthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance.",
         "Reviewer_9VoV",
         "1697570161673",
         "1700585835418",
         "5",
         "4",
         "3",
         "3",
         "2",
         "The paper addresses reasoning problems using LLMs and Chain-of-Thought (CoT).\nThe paper proposes to sample multiple chains of thought of the same training question from a pretrained model, and finetune the model to prefer the solutions that lead to the correct final answer. This results in improvements on several reasoning benchmarks, compared to the baseline which was only finetuned on the training set without this augmentation. * The proposed approach is simple\n* The paper focuses on a class of important problems\n* The approach results in gains across multiple popular benchmarks 1. The proposed approach is very similar to \\[LARGE LANGUAGE MODELS CAN SELF-IMPROVE (Huang et al., 2022)\\](https://arxiv.org/pdf/2210.11610.pdf), which came out a year ago. Since the authors did not cite it, I assume that they were not aware of it, but in terms of novelty there is a significant overlap. \n\n2. Motivation - The motivation in Table 1 is unclear. T-Accuracy is ~40% but ~A-Accuracy is ~70% - Is it a surprising result?\nThe paper says that:\n>These results show that the assessment ability of VFT-LLMs is far from expected, as they cannot\naccurately discern the quality of various COTs of previously learned questions.\n\nI'm not sure I agree. What other results would the authors expect?\n\n3. Over-mathematical - I think that there are large complicated parts in the paper that are not necessarily needed, and the paper can be significantly simplified. Since \"Detached Constraint\" (Section 4.3.1) and \"Boundary Constraint\" (Section 4.3.2) perform almost the same, while none of them consistently outperforms the other, why do we need both of them? ### Questions\n1. The paper says that:\n>We discover that LLMs fine-tuned by the vanilla fine-tuning ... frequently assign lower scores to high-quality COTs compared to low-quality ones\n\nWhich is correct, but isn't it trivial? Isn't it the case with any machine learning model - sometimes the model assigns higher probability to the wrong output and low probability to the correct output? Isn't this the source of any kind of mistake in any machine learning model?\n\n### Comments\n1. While terms such as \"serve as the brain of the artificial general intelligence\" (appearing twice) are unfortunately popular in media, have no scientific basis, and I suggest avoiding them in a research paper.\n2. Figure 1 is confusing, or there is a mistake in the text that refers to it:  the second paragraph of the Introduction says: \n\n>As a result, they struggle to assess the quality of other answers and tend to assign lower perplexity (higher score) to\nincorrect Candidate Answer 1 compared to the correct Candidate Answers 2.\n\nHowever, Answer 1 **is the correct answer**, and Answer 2 is the incorrect.\n\n3. There are some claims that are inaccurate. For example:\n> Intuitively, the MLE objective seeks to exclusively allocate probability mass to the reference COT\n\nI wouldn't say that it *exclusively* allocates probability mass to the reference COT, since a lot of mass remains for other possible CoT. As evidence, their probability is not zero.\n\nAs another example:\n>As demonstrated by our pilot experiment, VFT-LLMs fail to give reasonable scores to COTs in GP and GN.\n\nWhat are \"reasonable scores\"? What scores did the authors expect?\n\n4. Figure 2 is visually nice, important, and extensive, but unfortunately impossible to read because the fonts are too tiny.\n5.  The experiments were performed across multiple benchmarks (which is great), using the 7B and 13B versions of LLama 1 and 2. However, I think that these models were only pretrained, without instruction tuning or RLHF. It would be great if the authors could also experiment with the \"Chat\" version of Llama 2 (of the same sizes).\n\n### Summary\nI appreciate the authors' efforts and extensive analysis, but I think that the main approach is too similar to a previous work that came out a year ago (and was not cited). This fact severely hurts the paper in terms of novelty. I thus vote for rejection at this time, unless convinced that there is a significant difference that I have missed.",
         "670",
         "2",
         "8",
         "0.7781",
         "0.08167044600000001",
         "0.8811685443",
         "59",
         "34",
         "49.0402",
         "10.9599",
         "13.2686",
         "13.0239",
         "11.6104",
         "0.8056000000000001",
         "100",
         "1",
         "0",
         "0",
         "0",
         "4.0",
         "low",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "partially factual",
         "75.0",
         "75.0",
         "negative",
         "polite"
        ],
        [
         "45",
         "z7usV2BlEE",
         "7016",
         "1695451488958",
         "['~Peiyi_Wang1', '~Lei_Li14', '~Liang_Chen10', '~Feifan_Song1', '~Binghuai_Lin1', '~Yunbo_Cao3', '~Tianyu_Liu3', '~Zhifang_Sui1']",
         "Making Large Language Models Better Reasoners with Alignment",
         "Reasoning is a cognitive process of using evidence to reach a sound conclusion.\nThe reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent.\nRecent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. \nHowever, we find that the fine-tuned LLMs suffer from an \\textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities.\nIn this paper, we introduce an \\textit{Alignment Fine-Tuning (AFT)} paradigm with a novel \\textit{Constrained Alignment Loss} to alleviate the assessment misalignment problem.\nSpecifically, the proposed loss has two objectives:\na) Alignment, which guarantees the  scores of high-quality COTs surpass that of subpar ones;\nb) Constraint, which keeps the subpar scores confined to a reasonable range to prevent the model degradation.\nExtensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.\nAFT also performs well in multi-task and out-of-distribution situations.\nFurthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance.",
         "Reviewer_MzKF",
         "1698829141476",
         "1700728897251",
         "6",
         "4",
         "3",
         "3",
         "3",
         "This work identified an Assessment Misalignment problem in pre-trained Large Language Models (LLMs), where these models cannot well distinguish subpar Chain of Thought (COT) reasoning processes from good COT reasoning processes. The paper then proposed an Alignment Fine-Tuning (AFT) paradigm to address this Assessment Misalignment problem. AFT addresses this by a three-step process: fine-tuning LLMs with COT data, generating multiple COT responses per question, and calibrating the scores using their proposed constraint alignment loss. The AFT method is validated through extensive experiments, showing improved performance in reasoning tasks across various benchmarks​.\n\n====After authors' discussion===\nI have read through the authors' response, and I think they have addressed my concerns. Therefore, I keep my score that this is a work marginally above the acceptance threshold. \\[+\\] The paper identified an important problem that may be overlooked in existing literature -- the misaligned assessment on different COT reasoning process\n\n\\[+\\] The proposed method achieved empirical improvement over vanilla finetuning and other baselines on several datasets \\[-\\] The improvements over existing methods seem a little bit incremental.\n\n\\[-\\] see questions - It would be great if the authors could provide some intuitions on their designed losses to address the corresponding constraint\n- It would be great if the authors could explain why the performance drop for other baseline methods when comparing to vanilla finetuning\n- I also wonder how the quality of LLM-generated COTs impact the performance of AFT. For example, how large is the variance using 3 generated examples?",
         "247",
         "0",
         "0",
         "0.8377",
         "0.1744419643",
         "0.9130199552",
         "61",
         "21",
         "27.3179",
         "16.0462",
         "19.9946",
         "17.6314",
         "19.059",
         "0.1262",
         "82",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "4.0",
         "factual",
         "80.0",
         "80.0",
         "positive",
         "polite"
        ],
        [
         "46",
         "z7usV2BlEE",
         "7016",
         "1695451488958",
         "['~Peiyi_Wang1', '~Lei_Li14', '~Liang_Chen10', '~Feifan_Song1', '~Binghuai_Lin1', '~Yunbo_Cao3', '~Tianyu_Liu3', '~Zhifang_Sui1']",
         "Making Large Language Models Better Reasoners with Alignment",
         "Reasoning is a cognitive process of using evidence to reach a sound conclusion.\nThe reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent.\nRecent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. \nHowever, we find that the fine-tuned LLMs suffer from an \\textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities.\nIn this paper, we introduce an \\textit{Alignment Fine-Tuning (AFT)} paradigm with a novel \\textit{Constrained Alignment Loss} to alleviate the assessment misalignment problem.\nSpecifically, the proposed loss has two objectives:\na) Alignment, which guarantees the  scores of high-quality COTs surpass that of subpar ones;\nb) Constraint, which keeps the subpar scores confined to a reasonable range to prevent the model degradation.\nExtensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.\nAFT also performs well in multi-task and out-of-distribution situations.\nFurthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance.",
         "Reviewer_rVEU",
         "1698832681688",
         "1699636822014",
         "5",
         "4",
         "2",
         "3",
         "2",
         "The paper proposes an improved fine-tuning procedure for LLMs to keep high chain of thought reasoning capabilities. The authors therefore propose a constrained alignment loss based on a constrastive loss function and constraints for the gradients of negative examples. The approach is evaluated on three reasoning datasets - GSM8K, AQUARAT, ECQA and a self-created extension of GSM8K. The chosen baselines are RFT, RRHF, PRO and vanilla fine-tuning. The results are on-par or superior to the baselines. The authors propose a sensible approach to do fine-tuning. The proposed fine-tuning loss including the constraints for negative examples is sufficiently introduced and defined. The method is also easily applicable to other problems, given that negative samples are identified. Also, the authors provide runnable code for the review, backing up the clarity and quality of their work.\n\nThe evaluation results are promising as well. The approach is mostly better than the chosen baselines, thereby showing improved reasoning capabilites. Here, the chosen baselines are quite sensible, as they include one approach tailored for mathematical reasoning (RFT) as well as general fine-tuning results (RRHF, PRO). Given the larger related work, it remains open what the current SoTA results are.\n\nIn a similar vein, it is quite clear from the paper where the loss design differences to the baselines of the evaluation lie, but originality wrt to some referenced works is more difficult to assess from the paper alone. The related work for preference alignment a tad vague: Although it includes the a variety of strongly related and relevant works, the focus of the discussion could/should be more on the diverse strategies of the LLMs tuned for mathematical reasoning tasks. Referenced works could thus be better introduced and compared to based on the respective losses/techniques. This would make clear how innovative/novel the proposed technique is.\n\nThere is no clear argumentation why other mathematical datasets are not used /or referenced in order to back up the design decision for the chosen datasets. It would be good/important to introduce a clear argumentation or reference why these datasets have been chosen, as there are other/more datasets in this field.\n\nThere is no evaluation against some of the direct competitors, such as the referenced Li et al., 2023. It would important to argument why these models have not been chosen for comparison - maybe it is not required. Otherwise it is difficult to understand for the reader if the proposed approach supersedes the current State-of-the-Art. As the approach of the paper can be applied to other/general fine-tuning problems, the added value could also be shown by comparing on more general datasets. Did you compare your methods to other approaches focussed on chain-of-though reasoning for mathematical tasks? \n\nWhy are the chosen evaluation datasets sufficient for your claims? Are these the main datasets of other related works in the field or other reasoning datasets \"easier\" than the chosen ones?\n\nAre the empirical results on-par with other referenced works in the field, such as Li et al., 2023?\n\nHow would standard RLHF perform here? It would be an interesting baseline, as no constrains on the ranking loss are put and it is simpler than PRO.\n\nHow difficult is it to set hyperparameter $B$ and what implications does it have on the results?",
         "538",
         "0",
         "0",
         "0.7659",
         "0.0453846154",
         "0.8569500446",
         "48",
         "9",
         "44.1227",
         "11.5437",
         "14.9079",
         "14.0682",
         "12.5766",
         "0.1163",
         "82",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "moderate",
         "4.0",
         "4",
         "4",
         "4",
         "4.0",
         "4.0",
         "5.0",
         "partially factual",
         "80.0",
         "80.0",
         "neutral",
         "polite"
        ],
        [
         "47",
         "z7usV2BlEE",
         "7016",
         "1695451488958",
         "['~Peiyi_Wang1', '~Lei_Li14', '~Liang_Chen10', '~Feifan_Song1', '~Binghuai_Lin1', '~Yunbo_Cao3', '~Tianyu_Liu3', '~Zhifang_Sui1']",
         "Making Large Language Models Better Reasoners with Alignment",
         "Reasoning is a cognitive process of using evidence to reach a sound conclusion.\nThe reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent.\nRecent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. \nHowever, we find that the fine-tuned LLMs suffer from an \\textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities.\nIn this paper, we introduce an \\textit{Alignment Fine-Tuning (AFT)} paradigm with a novel \\textit{Constrained Alignment Loss} to alleviate the assessment misalignment problem.\nSpecifically, the proposed loss has two objectives:\na) Alignment, which guarantees the  scores of high-quality COTs surpass that of subpar ones;\nb) Constraint, which keeps the subpar scores confined to a reasonable range to prevent the model degradation.\nExtensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.\nAFT also performs well in multi-task and out-of-distribution situations.\nFurthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance.",
         "Reviewer_voWS",
         "1698845846567",
         "1699636821917",
         "6",
         "4",
         "3",
         "3",
         "3",
         "The authors propose a method to improve the chain-of-thought reasoning training by adding a loss function that imposes additional constraints such that sampled generated outputs that reach the correct answer are consistently favored over those with incorrect answer.\nThe method is evaluated on several reasoning datasets and is shown to outperform existing methods. Overall the paper is easy to read and the presentation of the main ideas is clear.\n\nThe proposed method seems novel and is well-motivated. The empirical results are convincing. Although the intention is to improve the \"reasoning\" capability of the model, the additional loss function makes use of the slightly risky assumption that generated outputs with the correct final answer should be assigned higher score than those with the wrong final answer. One  could argue that the chain of thoughts itself is perhaps more important than the final answer and some negative examples should still be scored higher than positive examples with \"wrong\" reasoning steps. Obviously this cannot be done without additional annotation and the proposed approach seems to work fine despite the risk.\n\nAs in label smoothing, one wonders whether a simple entropy penalty can already help improve the \"overly high confidence\" problem in the first place. See above.",
         "203",
         "0",
         "1",
         "0.754",
         "0.1143434343",
         "0.8051519394000001",
         "48",
         "9",
         "37.6623",
         "13.6096",
         "15.918800000000001",
         "14.7122",
         "15.5092",
         "0.1041",
         "105",
         "1",
         "1",
         "0",
         "0",
         "4.0",
         "moderate",
         "5.0",
         "5",
         "2",
         "4",
         "5.0",
         "5.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "positive",
         "polite"
        ],
        [
         "48",
         "z6KS9D1dxt",
         "872",
         "1694939062755",
         "['~Simin_Li5', '~Jun_Guo6', '~Jingqiao_Xiu1', '~Ruixiao_Xu1', '~Xin_Yu7', '~Jiakai_Wang1', '~Aishan_Liu1', '~Yaodong_Yang1', '~Xianglong_Liu3']",
         "Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game",
         "In this study, we explore the robustness of cooperative multi-agent reinforcement learning (c-MARL) against Byzantine failures, where any agent can enact arbitrary, worst-case actions due to malfunction or adversarial attack. To address the uncertainty that any agent can be adversarial, we propose a Bayesian Adversarial Robust Dec-POMDP (BARDec-POMDP) framework, which views Byzantine adversaries as nature-dictated types, represented by a separate transition. This allows agents to learn policies grounded on their posterior beliefs about the type of other agents, fostering collaboration with identified allies and minimizing vulnerability to adversarial manipulation. We define the optimal solution to the BARDec-POMDP as an ex interim robust Markov perfect Bayesian equilibrium, which we proof to exist and the corresponding policy weakly dominates previous approaches as time goes to infinity. To realize this equilibrium, we put forward a two-timescale actor-critic algorithm with almost sure convergence under specific conditions. Experiments on matrix game, Level-based Foraging and StarCraft II indicate that, our method successfully acquires intricate micromanagement skills and adaptively aligns with allies under worst-case perturbations, showing resilience against non-oblivious adversaries, random allies, observation-based attacks, and transfer-based attacks.",
         "Reviewer_UzHb",
         "1698041520105",
         "1700544258549",
         "8",
         "4",
         "3",
         "2",
         "3",
         "The paper addresses Byzantine failures in multi-agent reinforcement learning (MARL), where agents can adopt malicious behavior due to malfunction caused by hardware/software faults. First, a new problem setting, called Bayesian Adversarial Robust Dec-POMDP (BARDec-POMDP), is proposed to model adversarial intervention as a transition, where originally cooperative joint actions are modified before being executed in the actual environment. The setting is inspired by Bayesian games, where agents have types that need to be inferred by other agents through their beliefs. The goal is to learn a more fine-grained solution than prior work, where policies are able to collaborate with functional agents, while being robust against adversaries therefore finding a better cooperation-robustness trade-off. Ex post mixed-strategy robust Bayesian Markov perfect equilibrium is proposed as a solution concept for BARDec-POMDPs, which is claimed to be weakly dominant over equilibria that were pursued in previous works.\n\nBased on this setting, a two-timescale actor-critic is proposed based on the robust Harsanyi-Bellman equation, defining the maximin value according to the ideal case (before any adversarial modification) and the adversarial case. The policy gradient uses the value of the adversarial case as critic. The approach is evaluated in a variety of games, including a matrix game, a gridworld game, and a map of SMAC. It is also evaluated against different attacker types. The paper addresses a very important problem, which is often neglected in the MARL community.\n\nThe proposed setting (BARDec-POMDP) can model realistic scenarios, where agents can behave adversarially due to malfunctioning.\n\nWhile most works on robust MARL focus on defenses against any kind of adversarial attack, which leads to conservative policies, the paper aims to find a trade-off between collaborating with actual functional agents and robustness against actual adversaries, which is a more desirable goal for real-world applications. Bayesian games provide a neat framework to discern between these types of agents, which is a convincing proposal.\n\nThe solution concept seems valid.\n\nI like the evaluation, which first starts with a small toy problem before scaling up to larger benchmarks like SMAC. I also appreciate the evaluation with different adversarial strategies. My main concern with the paper is the lack of self-containment: The paper excessively references the appendix, which hurts readability (it is not convenient to peek into the appendix for almost every paragraph of the main paper).\n\nThe paper needs a clear prioritization of what is really important and what can be safely left in the appendix. For example, important proofs can be sketched informally with little space, but delegating them to the appendix completely is not acceptable.\n\nBefore checking, if I can raise my score, I need a revised version of the paper that is more self-contained, e.g., where the number of appendix references is significantly reduced and proofs are at least sketched such that the reader is not forced to switch documents all the time.\n\n**Minor Comments**\n- In Dec-POMDPs (Section 2.1), policies select their actions by the history of past observations and actions. Conditioning only on observations is insufficient since they are not Markovian. The definition in Section 2.2 is correct, though.\n- Line 119: “was replaced” - “**is** replaced”\n- Line 277: “four type of threats” - “four type**s** of threats”\n- The text size in Figure 2 is too small for printed versions. 1. Why do adversaries condition on observations despite them not being Markovian (in contrast to the non-adversarial policies)? Is this intentional or a mistake?\n2. Do you have any intuition on why M3DDPG performs so poorly in the presence of an adversary compared to the standard MAPPO without any robustness mechanism in Figure 4?",
         "597",
         "0",
         "2",
         "0.7926000000000001",
         "0.1150439394",
         "0.8859655261",
         "64",
         "28",
         "34.8172",
         "13.2971",
         "15.5957",
         "14.6021",
         "14.3921",
         "0.7021000000000001",
         "80",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "moderate",
         "5.0",
         "5",
         "5",
         "5",
         "5.0",
         "5.0",
         "5.0",
         "partially factual",
         "95.0",
         "95.0",
         "positive",
         "5"
        ],
        [
         "49",
         "z6KS9D1dxt",
         "872",
         "1694939062755",
         "['~Simin_Li5', '~Jun_Guo6', '~Jingqiao_Xiu1', '~Ruixiao_Xu1', '~Xin_Yu7', '~Jiakai_Wang1', '~Aishan_Liu1', '~Yaodong_Yang1', '~Xianglong_Liu3']",
         "Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game",
         "In this study, we explore the robustness of cooperative multi-agent reinforcement learning (c-MARL) against Byzantine failures, where any agent can enact arbitrary, worst-case actions due to malfunction or adversarial attack. To address the uncertainty that any agent can be adversarial, we propose a Bayesian Adversarial Robust Dec-POMDP (BARDec-POMDP) framework, which views Byzantine adversaries as nature-dictated types, represented by a separate transition. This allows agents to learn policies grounded on their posterior beliefs about the type of other agents, fostering collaboration with identified allies and minimizing vulnerability to adversarial manipulation. We define the optimal solution to the BARDec-POMDP as an ex interim robust Markov perfect Bayesian equilibrium, which we proof to exist and the corresponding policy weakly dominates previous approaches as time goes to infinity. To realize this equilibrium, we put forward a two-timescale actor-critic algorithm with almost sure convergence under specific conditions. Experiments on matrix game, Level-based Foraging and StarCraft II indicate that, our method successfully acquires intricate micromanagement skills and adaptively aligns with allies under worst-case perturbations, showing resilience against non-oblivious adversaries, random allies, observation-based attacks, and transfer-based attacks.",
         "Reviewer_EssV",
         "1699329370678",
         "1700457812183",
         "5",
         "3",
         "3",
         "2",
         "3",
         "The paper addresses the robustness of multi-agent reinforcement learning against Byzantine failures. A Bayesian Adversarial Robust\nDec-POMDP (BARDec-POMDP) framework is proposed.  The theoretical formulation of the problem is one of the contributions of the\npaper and an actor-critic algorithm that produces convergence under some conditions.  Convergence is not ensured but experimentally\nthe approach shows great resilience against a spectrum of adversaries.\n\nThe paper makes some strong assumptions, like the fact that in each episode there is only one attacker. Other assumptions are consistency and sequential rationality, which are used to form an ex interim robust Markov perfect Bayesian equilibrium (RMPBE). With some additional assumptions, the existence of ex ante and ex interim RMPBE are guaranteed. For the ex interim equilibrium, the Q function can be written using the Bellman-type equation for the two Q functions, which the paper calls \"the robust Harsanyi-Bellman equation.\" With a few more assumptions, updating the value function via the Bayes rule guarantees convergence to the optimal value of Q.\n\nThe algorithm proposed is applied to different problems, a toy metrics game and some map problems. For the attacks, four types of threats are considered: non-oblivious adversaries, random agents, noisy observations, and transferred adversaries. The experimental results cover robustness over non-oblivious attacks and various types of attacks. The novelty of the paper is in the theoretical formulation of the problem and in the actor-critic algorithm that produces convergence\nunder some conditions.  Convergence is not ensured but experimentally the approach shows great resilience against a spectrum of adversaries. - The fact that convergence cannot be guaranteed despite the assumptions made is a weakness of the paper. The method proposed is complex, and the assumptions are strong, yet there is no guarantee of convergence\n- The proofs are all in the Appendix, which makes the paper quite long, too long for a conference paper, and that makes it appear incomplete.  Even the analysis of two of the environments used for the experiments is in the Appendix. Expecting the reviewers to read a paper of 36 pages is too much for a conference.  Without the Appendices the paper is incomplete.\n- The paper is hard to read, it assumes significant knowledge of the field and is full of acronyms and citations that break the flow of the text.\n\nAfter the discussion and the changes made to the paper, I reduced my criticism about convergence and increased the rating I gave for contribution. However, the presentation needs more work.  Many of the corrections made to the paper have grammar errors, like mismatches of singular/plural. I understand the rush of making the changes, but the writing is not where it should be.  I also still object to the length of the paper. If you were to write a paper that fits in the page limits, would you include some of the material from the Appendices and drop some of the material currently in the paper or leave the paper unchanged?  I am wondering what you think are the most important parts needed to present the work without exceeding the page limits.",
         "510",
         "0",
         "0",
         "0.7209",
         "0.16693548390000001",
         "0.9243630767000001",
         "63",
         "13",
         "43.1045",
         "11.912",
         "15.4007",
         "14.341",
         "12.8111",
         "0.5533",
         "86",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "low",
         "4.0",
         "4",
         "4",
         "4",
         "5.0",
         "4.0",
         "5.0",
         "factual",
         "85.0",
         "85.0",
         "neutral",
         "neutral"
        ]
       ],
       "shape": {
        "columns": 48,
        "rows": 3835
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_number</th>\n",
       "      <th>submission_creation_date</th>\n",
       "      <th>submission_authors</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_abstract</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>last_modification_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>llm_Actionability</th>\n",
       "      <th>llm_Constructiveness</th>\n",
       "      <th>llm_Relevance Alignment</th>\n",
       "      <th>llm_Clarity and Readability</th>\n",
       "      <th>llm_Usage of Technical Terms</th>\n",
       "      <th>llm_Factuality</th>\n",
       "      <th>llm_Overall Quality</th>\n",
       "      <th>llm_overall_score_100</th>\n",
       "      <th>llm_Sentiment Polarity</th>\n",
       "      <th>llm_Politeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>4303</td>\n",
       "      <td>1695343783421</td>\n",
       "      <td>[~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Reviewer_BcRN</td>\n",
       "      <td>1698598642014</td>\n",
       "      <td>1699636398632</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>factual</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>4303</td>\n",
       "      <td>1695343783421</td>\n",
       "      <td>[~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Reviewer_hJxN</td>\n",
       "      <td>1698648844616</td>\n",
       "      <td>1699636398538</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>4303</td>\n",
       "      <td>1695343783421</td>\n",
       "      <td>[~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Reviewer_8Cdu</td>\n",
       "      <td>1698863097320</td>\n",
       "      <td>1699636398427</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>4303</td>\n",
       "      <td>1695343783421</td>\n",
       "      <td>[~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Reviewer_Q843</td>\n",
       "      <td>1699416352034</td>\n",
       "      <td>1699636398331</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>factual</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zt8bb6vC4m</td>\n",
       "      <td>4003</td>\n",
       "      <td>1695329721281</td>\n",
       "      <td>[~Jianyu_Xu1, ~Yu-Xiang_Wang1]</td>\n",
       "      <td>Pricing with Contextual Elasticity and Heteros...</td>\n",
       "      <td>We study an online contextual dynamic pricing ...</td>\n",
       "      <td>Reviewer_6Reb</td>\n",
       "      <td>1698589805767</td>\n",
       "      <td>1699636362362</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>09iOdaeOzp</td>\n",
       "      <td>4531</td>\n",
       "      <td>1695351755791</td>\n",
       "      <td>[~Mengzhou_Xia1, ~Tianyu_Gao1, ~Zhiyuan_Zeng3,...</td>\n",
       "      <td>Sheared LLaMA: Accelerating Language Model Pre...</td>\n",
       "      <td>The popularity of LLaMA (Touvron et al., 2023a...</td>\n",
       "      <td>Reviewer_qt4Y</td>\n",
       "      <td>1698822664319</td>\n",
       "      <td>1699636430275</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>factual</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>09iOdaeOzp</td>\n",
       "      <td>4531</td>\n",
       "      <td>1695351755791</td>\n",
       "      <td>[~Mengzhou_Xia1, ~Tianyu_Gao1, ~Zhiyuan_Zeng3,...</td>\n",
       "      <td>Sheared LLaMA: Accelerating Language Model Pre...</td>\n",
       "      <td>The popularity of LLaMA (Touvron et al., 2023a...</td>\n",
       "      <td>Reviewer_wgpN</td>\n",
       "      <td>1698839708409</td>\n",
       "      <td>1699636430183</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>factual</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>030cjlZm4a</td>\n",
       "      <td>9267</td>\n",
       "      <td>1695548092232</td>\n",
       "      <td>[~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...</td>\n",
       "      <td>Learning Predictive Checklists with Probabilis...</td>\n",
       "      <td>Checklists have been widely recognized as effe...</td>\n",
       "      <td>Reviewer_SxKf</td>\n",
       "      <td>1698683826765</td>\n",
       "      <td>1700488544114</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>030cjlZm4a</td>\n",
       "      <td>9267</td>\n",
       "      <td>1695548092232</td>\n",
       "      <td>[~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...</td>\n",
       "      <td>Learning Predictive Checklists with Probabilis...</td>\n",
       "      <td>Checklists have been widely recognized as effe...</td>\n",
       "      <td>Reviewer_Ucnh</td>\n",
       "      <td>1698794126465</td>\n",
       "      <td>1699637167426</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>partially factual</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>030cjlZm4a</td>\n",
       "      <td>9267</td>\n",
       "      <td>1695548092232</td>\n",
       "      <td>[~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...</td>\n",
       "      <td>Learning Predictive Checklists with Probabilis...</td>\n",
       "      <td>Checklists have been widely recognized as effe...</td>\n",
       "      <td>Reviewer_eMqU</td>\n",
       "      <td>1698839690002</td>\n",
       "      <td>1700668054185</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3835 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     submission_id  submission_number  submission_creation_date  \\\n",
       "0       zxPDdw8koz               4303             1695343783421   \n",
       "1       zxPDdw8koz               4303             1695343783421   \n",
       "2       zxPDdw8koz               4303             1695343783421   \n",
       "3       zxPDdw8koz               4303             1695343783421   \n",
       "4       zt8bb6vC4m               4003             1695329721281   \n",
       "...            ...                ...                       ...   \n",
       "3830    09iOdaeOzp               4531             1695351755791   \n",
       "3831    09iOdaeOzp               4531             1695351755791   \n",
       "3832    030cjlZm4a               9267             1695548092232   \n",
       "3833    030cjlZm4a               9267             1695548092232   \n",
       "3834    030cjlZm4a               9267             1695548092232   \n",
       "\n",
       "                                     submission_authors  \\\n",
       "0     [~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...   \n",
       "1     [~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...   \n",
       "2     [~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...   \n",
       "3     [~Mohammadreza_Salehi3, ~Mehrdad_Farajtabar1, ...   \n",
       "4                        [~Jianyu_Xu1, ~Yu-Xiang_Wang1]   \n",
       "...                                                 ...   \n",
       "3830  [~Mengzhou_Xia1, ~Tianyu_Gao1, ~Zhiyuan_Zeng3,...   \n",
       "3831  [~Mengzhou_Xia1, ~Tianyu_Gao1, ~Zhiyuan_Zeng3,...   \n",
       "3832  [~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...   \n",
       "3833  [~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...   \n",
       "3834  [~Yukti_Makhija1, ~Edward_De_Brouwer1, ~Rahul_...   \n",
       "\n",
       "                                       submission_title  \\\n",
       "0     CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "1     CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "2     CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "3     CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "4     Pricing with Contextual Elasticity and Heteros...   \n",
       "...                                                 ...   \n",
       "3830  Sheared LLaMA: Accelerating Language Model Pre...   \n",
       "3831  Sheared LLaMA: Accelerating Language Model Pre...   \n",
       "3832  Learning Predictive Checklists with Probabilis...   \n",
       "3833  Learning Predictive Checklists with Probabilis...   \n",
       "3834  Learning Predictive Checklists with Probabilis...   \n",
       "\n",
       "                                    submission_abstract       reviewer  \\\n",
       "0     Contrastive language image pretraining (CLIP) ...  Reviewer_BcRN   \n",
       "1     Contrastive language image pretraining (CLIP) ...  Reviewer_hJxN   \n",
       "2     Contrastive language image pretraining (CLIP) ...  Reviewer_8Cdu   \n",
       "3     Contrastive language image pretraining (CLIP) ...  Reviewer_Q843   \n",
       "4     We study an online contextual dynamic pricing ...  Reviewer_6Reb   \n",
       "...                                                 ...            ...   \n",
       "3830  The popularity of LLaMA (Touvron et al., 2023a...  Reviewer_qt4Y   \n",
       "3831  The popularity of LLaMA (Touvron et al., 2023a...  Reviewer_wgpN   \n",
       "3832  Checklists have been widely recognized as effe...  Reviewer_SxKf   \n",
       "3833  Checklists have been widely recognized as effe...  Reviewer_Ucnh   \n",
       "3834  Checklists have been widely recognized as effe...  Reviewer_eMqU   \n",
       "\n",
       "      creation_date  last_modification_date  review_rating  ...  \\\n",
       "0     1698598642014           1699636398632              3  ...   \n",
       "1     1698648844616           1699636398538              3  ...   \n",
       "2     1698863097320           1699636398427              3  ...   \n",
       "3     1699416352034           1699636398331              8  ...   \n",
       "4     1698589805767           1699636362362              6  ...   \n",
       "...             ...                     ...            ...  ...   \n",
       "3830  1698822664319           1699636430275              8  ...   \n",
       "3831  1698839708409           1699636430183              5  ...   \n",
       "3832  1698683826765           1700488544114              8  ...   \n",
       "3833  1698794126465           1699637167426              3  ...   \n",
       "3834  1698839690002           1700668054185              6  ...   \n",
       "\n",
       "      llm_Actionability  llm_Constructiveness  llm_Relevance Alignment  \\\n",
       "0                     3                     4                      5.0   \n",
       "1                     4                     4                      5.0   \n",
       "2                     4                     4                      5.0   \n",
       "3                     4                     4                      5.0   \n",
       "4                     5                     5                      5.0   \n",
       "...                 ...                   ...                      ...   \n",
       "3830                  5                     5                      5.0   \n",
       "3831                  4                     4                      5.0   \n",
       "3832                  4                     4                      5.0   \n",
       "3833                  4                     4                      5.0   \n",
       "3834                  5                     5                      5.0   \n",
       "\n",
       "      llm_Clarity and Readability llm_Usage of Technical Terms  \\\n",
       "0                             4.0                          4.0   \n",
       "1                             4.0                          4.0   \n",
       "2                             5.0                          5.0   \n",
       "3                             4.0                          4.0   \n",
       "4                             4.0                          5.0   \n",
       "...                           ...                          ...   \n",
       "3830                          5.0                          5.0   \n",
       "3831                          4.0                          5.0   \n",
       "3832                          4.0                          5.0   \n",
       "3833                          4.0                          5.0   \n",
       "3834                          5.0                          5.0   \n",
       "\n",
       "         llm_Factuality  llm_Overall Quality  llm_overall_score_100  \\\n",
       "0               factual                 85.0                   85.0   \n",
       "1     partially factual                 65.0                   65.0   \n",
       "2     partially factual                 88.0                   88.0   \n",
       "3               factual                 85.0                   85.0   \n",
       "4     partially factual                 85.0                   85.0   \n",
       "...                 ...                  ...                    ...   \n",
       "3830            factual                 95.0                   95.0   \n",
       "3831            factual                 85.0                   85.0   \n",
       "3832  partially factual                 85.0                   85.0   \n",
       "3833  partially factual                 80.0                   80.0   \n",
       "3834                  5                100.0                  100.0   \n",
       "\n",
       "      llm_Sentiment Polarity  llm_Politeness  \n",
       "0                   positive          polite  \n",
       "1                    neutral         neutral  \n",
       "2                    neutral          polite  \n",
       "3                   positive          polite  \n",
       "4                    neutral          polite  \n",
       "...                      ...             ...  \n",
       "3830                positive          polite  \n",
       "3831                 neutral          polite  \n",
       "3832                 neutral          polite  \n",
       "3833                 neutral          polite  \n",
       "3834                positive          polite  \n",
       "\n",
       "[3835 rows x 48 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_json('final_data/iclr2024_1000_qwen.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['submission_id', 'submission_number', 'submission_creation_date',\n",
       "       'submission_authors', 'submission_title', 'submission_abstract',\n",
       "       'reviewer', 'creation_date', 'last_modification_date', 'review_rating',\n",
       "       'review_confidence', 'review_soundness', 'review_presentation',\n",
       "       'review_contribution', 'total_review', 'length_words', 'citation_count',\n",
       "       'question_count', 'mattr', 'sentiment_polarity', 'similarity_score',\n",
       "       'paper_submission_to_review_submission_days',\n",
       "       'review_creation_to_review_submission_days', 'flesch_reading_ease',\n",
       "       'flesch_kincaid_grade', 'gunning_fog', 'smog_index',\n",
       "       'automated_readability_index', 'politeness_score', 'hedge_C', 'hedge_D',\n",
       "       'hedge_E', 'hedge_I', 'hedge_N', 'llm_Comprehensiveness',\n",
       "       'llm_Vagueness', 'llm_Objectivity', 'llm_Fairness', 'llm_Actionability',\n",
       "       'llm_Constructiveness', 'llm_Relevance Alignment',\n",
       "       'llm_Clarity and Readability', 'llm_Usage of Technical Terms',\n",
       "       'llm_Factuality', 'llm_Overall Quality', 'llm_overall_score_100',\n",
       "       'llm_Sentiment Polarity', 'llm_Politeness'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot correlation map for columns starting with 'llm'\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Filter and clean the data\n",
    "llm_columns = [col for col in df.columns if col.startswith('llm_')]\n",
    "df_llm = df[llm_columns].dropna()\n",
    "df_llm = df_llm.drop(['llm_overall_score_100'], axis=1)\n",
    "\n",
    "# 2. Define validation rules and categorical mappings\n",
    "validation_rules = {\n",
    "    'Comprehensiveness': {'type': 'int', 'range': (0, 5)},\n",
    "    'Usage of Technical Terms': {'type': 'int', 'range': (0, 5)},\n",
    "    'Factuality': {'type': 'categorical', 'values': ['factual', 'partially factual', 'unfactual']},\n",
    "    'Sentiment Polarity': {'type': 'categorical', 'values': ['negative', 'neutral', 'positive']},\n",
    "    'Politeness': {'type': 'categorical', 'values': ['polite', 'neutral', 'impolite']},\n",
    "    'Vagueness': {'type': 'categorical', 'values': ['none', 'low', 'moderate', 'high', 'extreme']},\n",
    "    'Objectivity': {'type': 'int', 'range': (0, 5)},\n",
    "    'Fairness': {'type': 'int', 'range': (0, 5)},\n",
    "    'Actionability': {'type': 'int', 'range': (0, 5)},\n",
    "    'Constructiveness': {'type': 'int', 'range': (0, 5)},\n",
    "    'Relevance Alignment': {'type': 'int', 'range': (0, 5)},\n",
    "    'Clarity and Readability': {'type': 'int', 'range': (0, 5)},\n",
    "    'Overall Quality': {'type': 'int', 'range': (0, 100)}\n",
    "}\n",
    "\n",
    "categorical_mappings = {\n",
    "    'Factuality': {'unfactual': 0, 'partially factual': 1, 'factual': 2},\n",
    "    'Sentiment Polarity': {'negative': 0, 'neutral': 1, 'positive': 2},\n",
    "    'Politeness': {'impolite': 0, 'neutral': 1, 'polite': 2},\n",
    "    'Vagueness': {'none': 0, 'low': 1, 'moderate': 2, 'high': 3, 'extreme': 4}\n",
    "}\n",
    "\n",
    "# Modified step 3: Clean and validate data with type conversion\n",
    "for col in df_llm.columns:\n",
    "    base_name = col.replace('llm_', '')\n",
    "    rule = validation_rules[base_name]\n",
    "    \n",
    "    if rule['type'] == 'int':\n",
    "        # Convert to numeric first (handle strings like '3' -> 3)\n",
    "        df_llm[col] = pd.to_numeric(df_llm[col], errors='coerce')\n",
    "        min_val, max_val = rule['range']\n",
    "        valid_mask = df_llm[col].between(min_val, max_val)\n",
    "    else:\n",
    "        valid_mask = df_llm[col].isin(rule['values'])\n",
    "    \n",
    "    df_llm = df_llm[valid_mask]\n",
    "\n",
    "# 4. Encode categorical features\n",
    "for col, mapping in categorical_mappings.items():\n",
    "    full_col = f'llm_{col}'\n",
    "    df_llm[full_col] = df_llm[full_col].map(mapping)\n",
    "\n",
    "# 5. Prepare correlation matrix\n",
    "df_llm.columns = [col.replace('llm_', '') for col in df_llm.columns]\n",
    "corr_matrix = df_llm.corr()\n",
    "\n",
    "# 6. Plot correlation heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=False, \n",
    "            fmt=\".2f\", \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            linewidths=0.5,\n",
    "            annot_kws={'size': 8},\n",
    "            vmax=1,\n",
    "            vmin=-1,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "\n",
    "plt.title('Correlation Map - Qwen - ICLR', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
